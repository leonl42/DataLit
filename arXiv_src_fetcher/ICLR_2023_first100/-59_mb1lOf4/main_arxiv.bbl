\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Acar et~al.(2021)Acar, Zhao, Matas, Mattina, Whatmough, and
  Saligrama]{Acar2021federated}
Durmus Alp~Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough,
  and Venkatesh Saligrama.
\newblock Federated learning based on dynamic regularization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, May 2021.

\bibitem[Bonawitz et~al.(2019)Bonawitz, Eichner, Grieskamp, Huba, Ingerman,
  Ivanov, Kiddon, Kone{\v c}n{\'y}, Mazzocchi, McMahan, Van~Overveldt, Petrou,
  Ramage, and Roselander]{Bonawitz2019towards}
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
  Ingerman, Vladimir Ivanov, Chlo{\'e} Kiddon, Jakub Kone{\v c}n{\'y}, Stefano
  Mazzocchi, Brendan McMahan, Timon Van~Overveldt, David Petrou, Daniel Ramage,
  and Jason Roselander.
\newblock Towards federated learning at scale: System design.
\newblock In A~Talwalkar, V~Smith, and M~Zaharia (eds.), \emph{Proceedings of
  Machine Learning and Systems}, volume~1, pp.\  374--388, 2019.

\bibitem[Cohen et~al.(2017)Cohen, Afshar, Tapson, and
  Van~Schaik]{Cohen2017emnist}
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van~Schaik.
\newblock Emnist: Extending mnist to handwritten letters.
\newblock In \emph{International Joint Conference on Neural Networks (IJCNN)},
  pp.\  2921--2926, 2017.

\bibitem[Cover \& Thomas(2006)Cover and Thomas]{Cover2006elements}
Thomas~M. Cover and Joy~A. Thomas.
\newblock \emph{Elements of information theory}.
\newblock Wiley-Interscience, New York, 2006.

\bibitem[Durrett(2019)]{Durrett2019}
Rick Durrett.
\newblock \emph{Probability: Theory and Examples}.
\newblock Cambridge University Press, Cambridge, UK, fifth edition, 2019.
\newblock \doi{10.1017/9781108591034}.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{Han2016deep}
Song Han, Huizi Mao, and William~J. Dally.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, volume abs/1510.0, October 2016.

\bibitem[Hu et~al.(2018)Hu, Huang, and Qiu]{Hu2018group}
Jianhua Hu, Jian Huang, and Feng Qiu.
\newblock A group adaptive elastic-net approach for variable selection in
  high-dimensional linear regression.
\newblock \emph{Science China Mathematics}, 61\penalty0 (1):\penalty0 173--188,
  2018.

\bibitem[Jeong et~al.(2021)Jeong, Yoon, Yang, and Hwang]{Jeong2021federated}
Wonyong Jeong, Jaehong Yoon, Eunho Yang, and Sung~Ju Hwang.
\newblock {Federated semi-supervised learning with inter-client consistency \&
  disjoint learning}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Kairouz et~al.(2021)Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji,
  Bonawitz, Charles, Cormode, Cummings, et~al.]{Kairouz2021advances}
Peter Kairouz, H.~Brendan McMahan, Brendan Avent, Aur{\'e}lien Bellet, Mehdi
  Bennis, Arjun~Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
  Cormode, Rachel Cummings, et~al.
\newblock Advances and open problems in federated learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  14\penalty0 (1--2):\penalty0 1--210, 2021.

\bibitem[Karimireddy et~al.(2020)Karimireddy, Kale, Mohri, Reddi, Stich, and
  Suresh]{Karimireddy2020scaffold}
Sai~Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
  Stich, and Ananda~Theertha Suresh.
\newblock Scaffold: Stochastic controlled averaging for federated learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  5132--5143, 2020.

\bibitem[Kone{\v{c}}n{\`y} et~al.(2016{\natexlab{a}})Kone{\v{c}}n{\`y},
  McMahan, Ramage, and Richt{\'a}rik]{Konevcny2016federated}
Jakub Kone{\v{c}}n{\`y}, H.~Brendan McMahan, Daniel Ramage, and Peter
  Richt{\'a}rik.
\newblock Federated optimization: Distributed machine learning for on-device
  intelligence.
\newblock \emph{arXiv preprint arXiv:1610.02527}, 2016{\natexlab{a}}.

\bibitem[Kone{\v{c}}n{\`y} et~al.(2016{\natexlab{b}})Kone{\v{c}}n{\`y},
  McMahan, Yu, Richt{\'a}rik, Suresh, and Bacon]{Konevcny2016federatedlearning}
Jakub Kone{\v{c}}n{\`y}, H.~Brendan McMahan, Felix~X. Yu, Peter Richt{\'a}rik,
  Ananda~Theertha Suresh, and Dave Bacon.
\newblock Federated learning: Strategies for improving communication
  efficiency.
\newblock \emph{arXiv preprint arXiv:1610.05492}, 2016{\natexlab{b}}.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{Krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{Lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Sahu, Talwalkar, and
  Smith]{Li2020federatedlearning}
Tian Li, Anit~Kumar Sahu, Ameet Talwalkar, and Virginia Smith.
\newblock Federated learning: Challenges, methods, and future directions.
\newblock \emph{IEEE Signal Processing Magazine}, 37\penalty0 (3):\penalty0
  50--60, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Sahu, Zaheer, Sanjabi, Talwalkar, and
  Smith]{Li2020federated}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smith.
\newblock {Federated optimization in heterogeneous networks}.
\newblock In \emph{Proceedings of Machine Learning and Systems}, volume~2, pp.\
   429--450, 2020{\natexlab{b}}.

\bibitem[Malinovskiy et~al.(2020)Malinovskiy, Kovalev, Gasanov, Condat, and
  Richtarik]{Malinovskiy2020local}
Grigory Malinovskiy, Dmitry Kovalev, Elnur Gasanov, Laurent Condat, and Peter
  Richtarik.
\newblock From local sgd to local fixed-point methods for federated learning.
\newblock In \emph{International Conference on Machine Learnin (ICML)}, pp.\
  6692--6701, 2020.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{McMahan2017communication}
H.~Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise~Aguera
  y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, pp.\  1273--1282. PMLR, 2017.

\bibitem[Nesterov(2018)]{Nesterove2018}
Y.~Nesterov.
\newblock \emph{Lectures on convex optimization}, volume 137.
\newblock springer, 2018.
\newblock URL
  \url{https://link.springer.com/content/pdf/10.1007/978-3-319-91578-4.pdf}.

\bibitem[Reisizadeh et~al.(2020)Reisizadeh, Mokhtari, Hassani, Jadbabaie, and
  Pedarsani]{Reisizadeh2020fedpaq}
Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and
  Ramtin Pedarsani.
\newblock {FedPAQ: A communication-efficient federated learning method with
  periodic averaging and quantization}.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, volume 108, pp.\  2021--2031, August 2020.

\bibitem[Shakespeare(1914)]{Shakespeare1914complete}
William Shakespeare.
\newblock \emph{The complete works of William Shakespeare}.
\newblock Humphrey Milford, Oxford University Press, 1914.
\newblock URL \url{http://www.gutenberg.org/files/100/old/1994-01-100.zip}.

\bibitem[Tibshirani(1996)]{Tibshirani1996regression}
Robert Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 58\penalty0 (1):\penalty0 267--288, 1996.

\bibitem[Xu et~al.(2020)Xu, Du, Jin, He, and Cheng]{Xu2020ternary}
Jinjin Xu, Wenli Du, Yaochu Jin, Wangli He, and Ran Cheng.
\newblock Ternary compression for communication-efficient federated learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  2020.

\bibitem[Yoon et~al.(2021)Yoon, Jeong, Lee, Yang, and Hwang]{Yoon2021federated}
Jaehong Yoon, Wonyong Jeong, Giwoong Lee, Eunho Yang, and Sung~Ju Hwang.
\newblock Federated continual learning with weighted inter-client transfer.
\newblock In Marina Meila and Tong Zhang (eds.), \emph{International Conference
  on Machine Learning (ICML)}, volume 139 of \emph{Proceedings of Machine
  Learning Research}, pp.\  12073--12086, 2021.

\bibitem[Zhao et~al.(2018)Zhao, Li, Lai, Suda, Civin, and
  Chandra]{Zhao2018federated}
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.
\newblock Federated learning with non-iid data.
\newblock \emph{arXiv preprint arXiv:1806.00582}, 2018.

\bibitem[Zou \& Hastie(2005)Zou and Hastie]{Zou2005regularization}
Hui Zou and Trevor Hastie.
\newblock Regularization and variable selection via the elastic net.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 67\penalty0 (2):\penalty0 301--320, 2005.

\end{thebibliography}
