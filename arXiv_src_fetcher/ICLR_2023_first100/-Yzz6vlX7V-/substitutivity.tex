\subsection{Substitutivity}
\label{subsec:substitutivity}

Under a local interpretation of the principle of compositionality, synonym substitutions should be meaning-preserving: substituting a constituent in a complex expression with a synonym should not alter the complex expression's meaning, or, in the case of MT, its translation.
Here, we test to what extent models' translations abide by this principle, by performing the \textbf{substitutivity} test from \citet{hupkes2020compositionality}, that measures whether the outputs remain consistent after synonym substitution.

\subsubsection{Experiments}
To find synonyms -- source terms that translate into the same target terms -- we exploit the fact that OPUS contains texts both in British and American English.
Therefore, it contains synonymous terms that are spelt different -- e.g.\ \exa{doughnut} / \exa{donut} -- and synonymous terms with a very different form -- e.g.\ \exa{aubergine} / \exa{eggplant}.
We use 20 synonym pairs in total (see Figure~\ref{fig:per_synonym}).

\paragraph{Test design}
Per synonym pair, we select natural data from OPUS in which the terms appear and perform synonym substitutions.
Thus, each sample has two sentences, one with the British and one with the American English term.
We also insert the synonyms into the synthetic and semi-natural data using 500 samples per synonym pair per template, through subordinate clauses that modify a noun -- e.g. ``the king \textit{that eats the doughnut}''.
In Appendix~\ref{ap:substitutivity}, Table~\ref{tab:substitutivity_appendix}, we list all clauses used.

\paragraph{Evaluation}
Like systematicity, we evaluate substitutivity using the consistency score, expressing whether the model translations for a sample are identical.
We report both the full sentence consistency and the consistency of the synonyms' translations only, excluding the context.
Cases in which the model omits the synonym from both translations are labelled as consistent if the rest of the translation is the same for both input sequences.

\subsubsection{Results}
In Figure~\ref{fig:substitutivity}, we summarise all substitutivity consistency scores (tables are in Appendix~\ref{ap:substitutivity}).
We observe trends similar to the systematicity results: models trained on larger training sets perform better and synthetic data yields more consistent translations compared to (semi-)natural data.
We further observe large variations across synonyms, for which we further detail the performance aggregated across experimental setups in Figure~\ref{fig:per_synonym}.
The three lowest scoring synonyms -- \exa{flautist}, \exa{aubergine} and \exa{ladybug} -- are among the least frequent synonyms (see Appendix~\ref{ap:substitutivity}), which stresses the importance of frequency for the model to pick up on synonymy.

In Figure~\ref{fig:per_synonym}, we show both the regular consistency and the consistency of the synonym translations, illustrating that a substantial part of the inconsistencies are due to varying translations of the context rather than the synonym itself, stressing again the non-local processing of the models.