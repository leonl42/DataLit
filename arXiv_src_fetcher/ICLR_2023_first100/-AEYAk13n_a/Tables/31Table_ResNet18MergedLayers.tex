\begin{table} [htbp]
\caption{Performance comparison for the network with merged non-ReLU layers(with ReLU-layer) }
\label{tab:MergedLayerComp}
\centering 
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{c|cc|cc} 
 \toprule
\multirow{2}{*}{\bf Network } & \multirow{2}{*}{\bf \#Conv } & \multirow{2}{*}{\bf \#ReLU } & \multicolumn{2}{c}{\bf CIFAR-100 } \\
& & & {\bf w/o kD} & {\bf w/ KD} \\
 \toprule
ResNet18(FR) & 17 & 557.06K & 74.46 & \\
$Arch1 \rightarrow$ResNet18  & 17 & 311.3K & 73.72 & 74.81 \\
$Arch2 \rightarrow$ResNet18 & 9 & 311.3K & 73.33 & 75.96 \\
\bottomrule
\end{tabular}}

\end{table}
