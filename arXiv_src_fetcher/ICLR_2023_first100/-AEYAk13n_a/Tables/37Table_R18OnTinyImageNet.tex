\begin{table} [t] \centering
\caption{Optimizations steps (Culling, Thinning, and Reshaping) for ReLU-optimized ResNet18 networks on TinyImageNet. Stages with ``$^\star$'' have only one Block inside the ReLU-stages. Acc. is top-1 accuracy, and Lat. is inference time in seconds.}
\label{tab:R18OnTinyImageNet} 
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{cccccccc}\toprule
\multirow{2}{*}{ Culled } & \multirow{2}{*}{ Thinning } & \multicolumn{2}{c}{ ReLU Reshaping } & \multirow{2}{*}{ \#ReLUs } & \multirow{2}{*}{ Acc.(\%) } & \multirow{2}{*}{ Lat.(s) } & \multirow{2}{*}{ Acc./ReLU }  \\
\cmidrule(lr{0.5em}){3-4}
& & Ch. & Fmap & & & & \\ \toprule 
\multicolumn{8}{c} {ResNet18 baseline model: \#ReLUs = 2228.24K, top-1 accuracy (W/o KD) = 61.28\%} \\ \midrule
$S_1$ & NA & NA & NA & 917.52K & 64.66 & 17.16 & 0.070  \\
$S_1$ & $S_2$+$S_3$+$S_4$ & NA & NA & 458.76K & 62.26 & 8.87 & 0.136  \\
$S_1$+$S_2$ & NA & NA & NA & 393.24K & 61.65 & 7.77 & 0.157  \\
$S_1$ & $S_2$+$S_3$+$S_4$ & 0.5$\times$ & NA & 229.38K & 59.18 & 4.61 & 0.258  \\
$S_1$+$S_2$ & $S_3$+$S_4$ & NA & NA & 196.62K & 57.51 & 4.16 & 0.292  \\
$S_1$ & $S_2$+$S_3$+$S_4$ & NA & 0.5$\times$ & 114.69K & 56.18 & 2.47 & 0.490  \\
$S_1$+$S_2$ & $S_3$+$S_4$ & 0.5$\times$ & NA & 98.31K & 55.67 & 2.64 & 0.566  \\
$S_1$ & $S_2$+$S_3$+$S_4$ & 0.5$\times$ & 0.5$\times$ & 57.35K & 53.75 &  1.85 & 0.937 \\
$S_1$+$S_2$ & $S_3$+$S_4$ & NA & 0.5$\times$ & 49.16K & 49.00 & 1.325 & 0.997  \\
$S_1$ & $S_2^\star$+$S_3^\star$+$S_4^\star$ & 0.5$\times$ & 0.5$\times$ & 28.67K & 47.55 & 0.678 & 1.658  \\
$S_1$+$S_2$ & $S_3$+$S_4$ & 0.5$\times$ & 0.5$\times$ & 24.58K & 47.01 & 0.579 & 1.913  \\
$S_1$+$S_2$ & $S_3^\star$+$S_4^\star$ & 0.5$\times$ & 0.5$\times$ & 12.29K & 41.95 & 0.455 & 3.414  \\ 
\bottomrule
\end{tabular}}
\end{table}

