
\begin{figure}[t]
\includegraphics[scale=0.19]{Figures/LayerWiseOps_R18}
\vspace{-2em}
%\includegraphics[scale=0.2]{Figures/LayerWiseOps_Vgg16} \\
%\includegraphics[scale=0.2]{Figures/LayerWiseOps_R34} 
%\includegraphics[scale=0.2]{Figures/LayerWiseOps_MV1} \\
%\includegraphics[scale=0.32]{Figures/LayerWiseOps_MV2}
\caption{
Layer-wise distribution of parameters, FLOPs, and ReLUs in ResNet18.
FLOPs are evenly distributed, parameters (ReLUs) are increases (decreases) with network's depth.} 
\label{fig:LayerWiseReluInDNNs}
\vspace{-1em}
\end{figure}