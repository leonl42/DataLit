\begin{abstract}

% The widespread adoption of ``machine learning as a service" has raised the privacy and security concerns for protecting the user-sensitive and security-critical data and underscores the importance of privacy-preserving computation. Moreover, enabling privacy-preserving computation can increase the data utility {---} needed to develop better models in the data-hungry deep learning domains. This catapulted a growing research interest in deep learning with cryptographic techniques such as homomorphic encryption (HE). However, the inference latency with ciphertext is orders of magnitude higher than the plaintext, which hinders its practical usability for private inference (PI). Since operators costs are inverted in  PI and nonlinear (ReLUs) operations dominate the inference latency, new design paradigms are needed to minimize the ReLUs and maximize the accuracy. 
 
% In this paper,  we devise a novel technique, ``DeepReDuce'',  for ReLU-accuracy optimization based on the following key observations: (1) the criticality of ReLUs is heterogeneous with the layer's position, (2) the majority of the ReLUs lie in the initial stage of a network; however, they are less critical for both {---} training with and without knowledge distillation. Our ReLU optimization technique is scalable for a broad range of ReLU budgets, especially for a very low number of ReLUs. Compared to the SOTA automatic ReLU balancing techniques: (1) at lower ReLU budget, our model is 2.7\% more accurate with 1.7$\times$ reduction in the ReLU count, and (2) at higher ReLU budget, our model is 0.7\% more accurate with 1.5$\times$ reduction in ReLU count.  We demonstrate the efficacy of ``DeepReDuce'' on two datasets {---} CIFAR-100 and TinyImageNet.

The recent rise of privacy concerns has led researchers to devise
methods for private neural inference---where 
inferences are made directly on encrypted data, never seeing inputs.
The primary challenge facing private inference is that computing on encrypted data
levies an impractically-high latency penalty, stemming mostly from non-linear operators like ReLU.
Enabling practical and private inference requires new optimization methods that
minimize network ReLU counts while preserving accuracy. 
This paper proposes \textit{DeepReDuce}: a set of optimizations for
the judicious removal of ReLUs to reduce private inference latency.
The key insight is that not all ReLUs contribute equally to accuracy.
We leverage this insight to drop, or remove, ReLUs
from classic networks to significantly 
reduce inference latency and maintain high accuracy.
Given a network architecture,
DeepReDuce outputs a Pareto frontier of networks
that tradeoff the number of ReLUs and accuracy.
Compared to the state-of-the-art for private inference
DeepReDuce improves accuracy and reduces ReLU count by up to
3.5\% (iso-ReLU count) and 3.5$\times$ (iso-accuracy), respectively.

\end{abstract}