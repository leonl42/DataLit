\begin{thebibliography}{10}
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
\expandafter\ifx\csname href\endcsname\relax
  \def\href#1#2{#2} \def\path#1{#1}\fi

\bibitem{new1}
J.~Gui, T.~Chen, Q.~Cao, Z.~Sun, H.~Luo, D.~Tao, A survey of self-supervised
  learning from multiple perspectives: Algorithms, theory, applications and
  future trends, 2023.
\newblock \href {http://arxiv.org/abs/2301.05712} {\path{arXiv:2301.05712}}.

\bibitem{b25}
J.~Devlin, M.~Chang, K.~Lee, K.~Toutanova, {BERT:} pre-training of deep
  bidirectional transformers for language understanding, in: The North American
  Chapter of the Association for Computational Linguistics, 2019, pp.
  4171--4186.

\bibitem{b26}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, et~al., Learning transferable visual models
  from natural language supervision, in: International Conference on Machine
  Learning, 2021, pp. 8748--8763.

\bibitem{b1}
S.~Liu, A.~Mallol-Ragolta, E.~Parada-Cabaleiro, K.~Qian, X.~Jing, A.~Kathan,
  B.~Hu, B.~W. Schuller, Audio self-supervised learning: A survey, Patterns
  3~(12) (2022) 100616.

\bibitem{b2}
M.~C. Schiappa, Y.~S. Rawat, M.~Shah, Self-supervised learning for videos: A
  survey, ACM Computing Surveys 55~(12) (2022) 1 -- 37.

\bibitem{new2}
C.~Zeng, W.~Wang, A.~Nguyen, Y.~Yue, Self-supervised learning for point cloud
  data: A survey, Expert Systems with Applications (2023) 121354.

\bibitem{new3}
B.~VanBerlo, J.~Hoey, A.~Wong, A survey of the impact of self-supervised
  pretraining for diagnostic tasks with radiological images, 2023.
\newblock \href {http://arxiv.org/abs/2309.02555} {\path{arXiv:2309.02555}}.

\bibitem{b3}
T.~Chen, S.~Kornblith, M.~Norouzi, G.~Hinton, A simple framework for
  contrastive learning of visual representations, in: International Conference
  on Machine Learning, 2020, pp. 1597--1607.

\bibitem{b4}
K.~He, H.~Fan, Y.~Wu, S.~Xie, R.~Girshick, Momentum contrast for unsupervised
  visual representation learning, in: {IEEE/CVF} Conference on Computer Vision
  and Pattern Recognition, 2020, pp. 9729--9738.

\bibitem{b5}
X.~Chen, H.~Fan, R.~Girshick, K.~He, Improved baselines with momentum
  contrastive learning, 2020.
\newblock \href {http://arxiv.org/abs/2003.04297} {\path{arXiv:2003.04297}}.

\bibitem{b12}
D.~Dwibedi, Y.~Aytar, J.~Tompson, P.~Sermanet, A.~Zisserman, With a little help
  from my friends: Nearest-neighbor contrastive learning of visual
  representations, in: {IEEE/CVF} International Conference on Computer Vision,
  2021, pp. 9588--9597.

\bibitem{b13}
S.~A. Koohpayegani, A.~Tejankar, H.~Pirsiavash, Mean shift for self-supervised
  learning, in: {IEEE/CVF} International Conference on Computer Vision, 2021,
  pp. 10326--10335.

\bibitem{b6}
J.-B. Grill, F.~Strub, F.~Altch{\'e}, C.~Tallec, P.~Richemond, E.~Buchatskaya,
  C.~Doersch, B.~Avila~Pires, Z.~Guo, M.~Gheshlaghi~Azar, et~al., Bootstrap
  your own latent-a new approach to self-supervised learning, in: Advances in
  Neural Information Processing Systems, 2020, pp. 21271--21284.

\bibitem{b14}
M.~Azabou, M.~G. Azar, R.~Liu, C.-H. Lin, E.~C. Johnson, K.~Bhaskaran-Nair,
  M.~Dabagia, B.~Avila-Pires, L.~Kitchell, K.~B. Hengen, et~al., Mine your own
  view: Self-supervised learning through across-sample prediction, 2021.
\newblock \href {http://arxiv.org/abs/2102.10106} {\path{arXiv:2102.10106}}.

\bibitem{b15}
G.~Chongjian, J.~Wang, Z.~Tong, S.~Chen, Y.~Song, P.~Luo, Soft neighbors are
  positive supporters in contrastive visual representation learning, in:
  International Conference on Learning Representations, 2023.

\bibitem{b16}
T.-S. Chen, W.-C. Hung, H.-Y. Tseng, S.-Y. Chien, M.-H. Yang, Incremental false
  negative detection for contrastive learning, in: International Conference on
  Learning Representations, 2022.

\bibitem{b17}
T.~Huynh, S.~Kornblith, M.~R. Walter, M.~Maire, M.~Khademi, Boosting
  contrastive self-supervised learning with false negative cancellation, in:
  IEEE/CVF Winter Conference on Applications of Computer Vision, 2022, pp.
  2785--2795.

\bibitem{b19}
C.-Y. Chuang, J.~Robinson, Y.-C. Lin, A.~Torralba, S.~Jegelka, Debiased
  contrastive learning, in: Advances in Neural Information Processing Systems,
  2020, pp. 8765--8775.

\bibitem{b18}
Y.~Kalantidis, M.~B. Sariyildiz, N.~Pion, P.~Weinzaepfel, D.~Larlus, Hard
  negative mixing for contrastive learning, in: Advances in Neural Information
  Processing Systems, 2020, pp. 21798--21809.

\bibitem{b20}
J.~Robinson, C.-Y. Chuang, S.~Sra, S.~Jegelka, Contrastive learning with hard
  negative samples, in: International Conference on Learning Representations,
  2021, pp. 1--29.

\bibitem{b21}
B.~Liu, B.~Wang, Bayesian self-supervised contrastive learning, 2023.
\newblock \href {http://arxiv.org/abs/2301.11673} {\path{arXiv:2301.11673}}.

\bibitem{b7}
X.~Chen, K.~He, Exploring simple siamese representation learning, in:
  {IEEE/CVF} Conference on Computer Vision and Pattern Recognition, 2021, pp.
  15750--15758.

\bibitem{b8}
J.~Zbontar, L.~Jing, I.~Misra, Y.~LeCun, S.~Deny, Barlow twins: Self-supervised
  learning via redundancy reduction, in: International Conference on Machine
  Learning, 2021, pp. 12310--12320.

\bibitem{b9}
A.~Bardes, J.~Ponce, Y.~LeCun, {VICR}eg: Variance-invariance-covariance
  regularization for self-supervised learning, in: International Conference on
  Learning Representations, 2022.

\bibitem{b10}
C.~Zhang, K.~Zhang, T.~X. Pham, A.~Niu, Z.~Qiao, C.~D. Yoo, I.~S. Kweon, Dual
  temperature helps contrastive learning without many negative samples: Towards
  understanding and simplifying moco, in: IEEE/CVF Conference on Computer
  Vision and Pattern Recognition, 2022, pp. 14441--14450.

\bibitem{b11}
C.-H. Yeh, C.-Y. Hong, Y.-C. Hsu, T.-L. Liu, Y.~Chen, Y.~LeCun, Decoupled
  contrastive learning, in: European Conference on Computer Vision, Springer,
  2022, pp. 668--684.

\bibitem{b22}
M.~Caron, I.~Misra, J.~Mairal, P.~Goyal, P.~Bojanowski, A.~Joulin, Unsupervised
  learning of visual features by contrasting cluster assignments, in: Advances
  in Neural Information Processing Systems, 2020, pp. 9912--9924.

\bibitem{b23}
S.~Kim, G.~Lee, S.~Bae, S.-Y. Yun, Mixco: Mix-up contrastive learning for
  visual representation, 2020.
\newblock \href {http://arxiv.org/abs/2010.06300} {\path{arXiv:2010.06300}}.

\bibitem{b31}
X.~Peng, K.~Wang, Z.~Zhu, M.~Wang, Y.~You, Crafting better contrastive views
  for siamese representation learning, in: IEEE/CVF Conference on Computer
  Vision and Pattern Recognition, 2022, pp. 16031--16040.

\bibitem{b32}
T.~Zhang, C.~Qiu, W.~Ke, S.~S{\"u}sstrunk, M.~Salzmann, Leverage your local and
  global representations: A new self-supervised learning strategy, in:
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition, 2022, pp. 16580--16589.

\bibitem{b24}
R.~Zhu, B.~Zhao, J.~Liu, Z.~Sun, C.~W. Chen, Improving contrastive learning by
  visualizing feature transformation, in: IEEE/CVF International Conference on
  Computer Vision, 2021, pp. 10306--10315.

\bibitem{b27}
A.~Krizhevsky, G.~Hinton, et~al., Learning multiple layers of features from
  tiny images, 2009, pp. 1--60.

\bibitem{b28}
Y.~Le, X.~Yang, Tiny imagenet visual recognition challenge, CS 231N 7~(7)
  (2015) 3.

\bibitem{b29}
K.~He, X.~Zhang, S.~Ren, J.~Sun, Deep residual learning for image recognition,
  in: {IEEE/CVF} Conference on Computer Vision and Pattern Recognition, 2016,
  pp. 770--778.

\bibitem{b30}
S.~Ioffe, C.~Szegedy, Batch normalization: Accelerating deep network training
  by reducing internal covariate shift, in: International Conference on Machine
  Learning, 2015, pp. 448--456.

\end{thebibliography}
