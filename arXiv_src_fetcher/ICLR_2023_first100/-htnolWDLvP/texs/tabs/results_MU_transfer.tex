\begin{wraptable}{r}{63mm}
\centering
\vspace*{-3.3mm}
\caption{
Transfer learning accuracy (Acc) and computation time (mins) of the unlearned   ImageNet model with $n \in \{ 100,200,300\}$ classes removed, where SUN397 and OxfordPets are downstream target datasets on linear probing transfer learning setting. When $n = 0$, transfer learning is performed using the pretrained model on the full ImageNet, serving as a baseline, together with the method in \cite{jain2022data}  for comparison. %\JC{[updated]}
% \JC{need to align SUN397 performance}
}
% \JC{Performance comparison of transfer learning on various datasets using the proposed unlearning method with different numbers of classes removal from the source dataset. {\acc} represents the post-fine-tuning model's generalization performance on the test set of downstream tasks, while {\TIME} signifies the time cost in minutes required to obtain a pre-trained model on the scrubbed ImageNet dataset via retraining or unlearning. Removing no class indicates that pre-training is performed on the full ImageNet dataset, which serves as the baseline for transfer learning.}
% \JC{Keep or change to Tab.\,\ref{tab: transfer_results_new}}
%\JC{Remove RTE, change RTE to Time, TA to ACC}
%Performance of transfer learning on various datasets via proposed unlearning vs. different numbers of classes in the source dataset be removed. \JC{{\acc} indicates the generalization performance on the testing set after fine-tuning on downstream tasks, {\TIME} indicates the time cost of getting a pre-trained on scrubbed ImageNet dataset by retraining or unlearning. Furthermore, removing zero class means pre-training is conducted on the full ImageNet dataset, which is the baseline of transfer learning.}
\label{tab: transfer_results}
\resizebox{63mm}{!}{
\begin{tabular}{c|c|cc|cc|cc}
\toprule[1pt]
\midrule
\multirow{2}{*}{Forgetting class \#}
  & 0 & \multicolumn{2}{c|}{100} & \multicolumn{2}{c|}{200} & \multicolumn{2}{c}{300}  \\ 
 % \midrule
  %Methods
  & \multicolumn{1}{c|}{{\acc}}  & 

\multicolumn{1}{c|}{{\acc}}  & \multicolumn{1}{c|}{{\TIME}} &  
\multicolumn{1}{c|}{{\acc}}  & \multicolumn{1}{c|}{{\TIME}} & 
\multicolumn{1}{c|}{{\acc}}  & \multicolumn{1}{c}{{\TIME}} 
  \\
% \cline{3-10}

\midrule
\rowcolor{Gray}
\multicolumn{8}{c}{OxfordPets} \\
\midrule
% {\retrain}
Method \cite{jain2022data} 
 & \multirow{2}{*}{85.70}  & 85.79	& 71.84 &86.10 & 61.53  &86.32 & 54.53
 \\
 \MUSparse & & 85.83&35.47&	86.12&30.19& 86.26& 26.49
 \\
\midrule
\rowcolor{Gray}
\multicolumn{8}{c}{SUN397} \\
\midrule
 Method \cite{jain2022data}   & \multirow{2}{*}{46.55} & 46.97	& 73.26 &47.14& 61.43 &47.31 & 55.24
 % Re-pretrain \cite{jain2022data}   & \multirow{2}{*}{46.55} & 46.62	& 73.26 &46.85& 61.43 &47.06 & 55.24
 				
 \\
 \MUSparse & & 47.20& 36.69 &	47.25& 30.96 &	47.37& 27.12	
 \\
\midrule
\bottomrule[1pt]
\end{tabular}
}
\vspace*{-8mm}
\end{wraptable}%