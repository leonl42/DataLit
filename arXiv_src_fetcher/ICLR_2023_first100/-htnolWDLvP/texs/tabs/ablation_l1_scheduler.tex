\iffalse
\begin{wraptable}{R}{80mm}
\centering
\vspace*{-4.25mm}
\caption{\footnotesize{{\MU} performance  comparison of using {\MUSparse} with different   sparsity schedulers of $\gamma$  in \eqref{eq: MUSparse} and using {\retrain}.  
The unlearning scenario is given by random data forgetting (10\% data points across all classes) on (ResNet-18, CIFAR-10).
%considering various unlearning scenarios on CIFAR10 dataset. The content format follows Tab.\,\ref{tab: overall_perfoamnce}.
%Bold numbers indicate the closest performance to {\retrain}, and
A performance gap  against \textcolor{blue}{{\retrain}} is provided 
%. The relative drop or improvement represented 
in (\textcolor{blue}{$\bullet$}).
}}
\label{tab: ablation_l1_scheduler}
% \vspace*{0.1in} % Requirements, do not delete.
\resizebox{0.57\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c}
\toprule[1pt]
\midrule
  {\MU}& {\UA} & {{\MIAF}}& {{\RA}} & {{\TA}} & {{RTE} (min)} \\ 

% \cline{3-10}

% \midrule
% \rowcolor{Gray}
% \multicolumn{6}{c}{Class-wise forgetting} \\
% \midrule
% {\retrain} & \textcolor{blue}{100.00} & \textcolor{blue}{100.00} & \textcolor{blue}{100.00} & \textcolor{blue}{94.83} & 43.23
% \\
% {\MUSparse} + constant $\gamma$ & 100.00 (\textcolor{blue}{0.00}) & 100.00 (\textcolor{blue}{0.00}) & 91.69 (\textcolor{blue}{8.31})	& 87.3 (\textcolor{blue}{7.53}) & 2.61
% \\
% {\MUSparse} +   growing $\gamma$  & 100.00 (\textcolor{blue}{0.00}) & 100.00 (\textcolor{blue}{0.00}) & 94.43 (\textcolor{blue}{5.57})	& 88.43 (\textcolor{blue}{6.40}) & 2.61
% \\
% {\MUSparse} +   decaying $\gamma$ & 100.00 (\textcolor{blue}{0.00}) & 100.00 (\textcolor{blue}{0.00}) & \textbf{98.99} (\textcolor{blue}{\textbf{1.01}})	& \textbf{93.40} (\textcolor{blue}{\textbf{1.43}}) & 2.61
% \\
% \midrule
% \rowcolor{Gray}
% \multicolumn{6}{c}{Random data forgetting (all classes)} \\
\midrule
{\retrain} & \textcolor{blue}{5.41} & \textcolor{blue}{13.12} & \textcolor{blue}{100.00} & \textcolor{blue}{94.42} & 42.15
\\
%  \FT & $6.83$ (\textcolor{blue}{$1.42$}) & $14.97$ (\textcolor{blue}{$1.85$})& $96.61$ (\textcolor{blue}{$3.39$})& $90.13$ (\textcolor{blue}{$4.29$})  & 2.33 
% \\		
% \IU & $2.03$ (\textcolor{blue}{$3.38$})&  $5.07$ (\textcolor{blue}{$8.05$})& $98.26$ (\textcolor{blue}{$1.74$})& $\textbf{91.33}$ (\textcolor{blue}{$\textbf{3.09}$}) & 3.22
% \\
{\MUSparse} + constant $\gamma$ & 6.60 (\textcolor{blue}{1.19}) & 14.64 (\textcolor{blue}{1.52}) & 96.51 (\textcolor{blue}{3.49})	& 87.30 (\textcolor{blue}{7.53}) & 2.53
\\

{\MUSparse} + linear growing $\gamma$  & 3.80 (\textcolor{blue}{1.61}) & 8.75 (\textcolor{blue}{4.37}) & 97.13 (\textcolor{blue}{2.87})	& 90.63 (\textcolor{blue}{3.79}) & 2.53
\\
{\MUSparse} + linear decaying $\gamma$ & \textbf{5.35} (\textcolor{blue}{\textbf{0.06}}) & \textbf{12.71} (\textcolor{blue}{\textbf{0.41}}) & \textbf{97.39} (\textcolor{blue}{\textbf{2.61}})	& {\textbf{91.26}} (\textcolor{blue}{\textbf{3.16}}) & 2.53
\\
\midrule
\bottomrule[1pt]
\end{tabular}
}
\vspace*{-4mm}
\end{wraptable}
\fi
\vspace{-5mm}
\begin{table}[htb!]
\centering
\caption{\footnotesize{{\MU} performance  comparison of using {\MUSparse} with different   sparsity schedulers of $\gamma$  in \eqref{eq: MUSparse} and using {\retrain}.  
The unlearning scenario is given by random data forgetting (10\% data points across all classes) on (ResNet-18, CIFAR-10).
%considering various unlearning scenarios on CIFAR10 dataset. The content format follows Tab.\,\ref{tab: overall_perfoamnce}.
%Bold numbers indicate the closest performance to {\retrain}, and
A performance gap  against \textcolor{blue}{{\retrain}} is provided 
%. The relative drop or improvement represented 
in (\textcolor{blue}{$\bullet$}).
}}
\label{tab: ablation_l1_scheduler}
\vspace*{1mm}
% \vspace*{0.1in} % Requirements, do not delete.
\resizebox{0.85\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c}
\toprule[1pt]
\midrule
  {\MU}& {\UA} & {{\MIAF}}& {{\RA}} & {{\TA}} & {{RTE} (min)} \\ 

% \cline{3-10}

% \midrule
% \rowcolor{Gray}
% \multicolumn{6}{c}{Class-wise forgetting} \\
% \midrule
% {\retrain} & \textcolor{blue}{100.00} & \textcolor{blue}{100.00} & \textcolor{blue}{100.00} & \textcolor{blue}{94.83} & 43.23
% \\
% {\MUSparse} + constant $\gamma$ & 100.00 (\textcolor{blue}{0.00}) & 100.00 (\textcolor{blue}{0.00}) & 91.69 (\textcolor{blue}{8.31})	& 87.3 (\textcolor{blue}{7.53}) & 2.61
% \\
% {\MUSparse} +   growing $\gamma$  & 100.00 (\textcolor{blue}{0.00}) & 100.00 (\textcolor{blue}{0.00}) & 94.43 (\textcolor{blue}{5.57})	& 88.43 (\textcolor{blue}{6.40}) & 2.61
% \\
% {\MUSparse} +   decaying $\gamma$ & 100.00 (\textcolor{blue}{0.00}) & 100.00 (\textcolor{blue}{0.00}) & \textbf{98.99} (\textcolor{blue}{\textbf{1.01}})	& \textbf{93.40} (\textcolor{blue}{\textbf{1.43}}) & 2.61
% \\
% \midrule
% \rowcolor{Gray}
% \multicolumn{6}{c}{Random data forgetting (all classes)} \\
\midrule
{\retrain} & \textcolor{blue}{5.41} & \textcolor{blue}{13.12} & \textcolor{blue}{100.00} & \textcolor{blue}{94.42} & 42.15
\\
%  \FT & $6.83$ (\textcolor{blue}{$1.42$}) & $14.97$ (\textcolor{blue}{$1.85$})& $96.61$ (\textcolor{blue}{$3.39$})& $90.13$ (\textcolor{blue}{$4.29$})  & 2.33 
% \\		
% \IU & $2.03$ (\textcolor{blue}{$3.38$})&  $5.07$ (\textcolor{blue}{$8.05$})& $98.26$ (\textcolor{blue}{$1.74$})& $\textbf{91.33}$ (\textcolor{blue}{$\textbf{3.09}$}) & 3.22
% \\
{\MUSparse} + constant $\gamma$ & 6.60 (\textcolor{blue}{1.19}) & 14.64 (\textcolor{blue}{1.52}) & 96.51 (\textcolor{blue}{3.49})	& 87.30 (\textcolor{blue}{7.12}) & 2.53
\\

{\MUSparse} + linear growing $\gamma$  & 3.80 (\textcolor{blue}{1.61}) & 8.75 (\textcolor{blue}{4.37}) & 97.13 (\textcolor{blue}{2.87})	& 90.63 (\textcolor{blue}{3.79}) & 2.53
\\
{\MUSparse} + linear decaying $\gamma$ & \textbf{5.35} (\textcolor{blue}{\textbf{0.06}}) & \textbf{12.71} (\textcolor{blue}{\textbf{0.41}}) & \textbf{97.39} (\textcolor{blue}{\textbf{2.61}})	& {\textbf{91.26}} (\textcolor{blue}{\textbf{3.16}}) & 2.53
\\
\midrule
\bottomrule[1pt]
\end{tabular}
}
\end{table}