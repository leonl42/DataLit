\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi
\providecommand{\eprint}[2][]{\url{#2}}

\bibitem[{Abati et~al.(2020)Abati, Tomczak, Blankevoort, Calderara, Cucchiara,
  and Bejnordi}]{abati2020conditional}
Abati D, Tomczak J, Blankevoort T, Calderara S, Cucchiara R, Bejnordi BE (2020)
  Conditional channel gated networks for task-aware continual learning. In:
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition, pp 3931--3940

\bibitem[{Aljundi et~al.(2018)Aljundi, Babiloni, Elhoseiny, Rohrbach, and
  Tuytelaars}]{aljundi2018memory}
Aljundi R, Babiloni F, Elhoseiny M, Rohrbach M, Tuytelaars T (2018) Memory
  aware synapses: Learning what (not) to forget. In: Proceedings of the
  European Conference on Computer Vision (ECCV), pp 139--154

\bibitem[{Aljundi et~al.(2019)Aljundi, Lin, Goujaud, and
  Bengio}]{aljundi2019gradient}
Aljundi R, Lin M, Goujaud B, Bengio Y (2019) Gradient based sample selection
  for online continual learning. Advances in neural information processing
  systems 32

\bibitem[{Bang et~al.(2021)Bang, Kim, Yoo, Ha, and Choi}]{bang2021rainbow}
Bang J, Kim H, Yoo Y, Ha JW, Choi J (2021) Rainbow memory: Continual learning
  with a memory of diverse samples. In: Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition, pp 8218--8227

\bibitem[{Benjamin et~al.(2018)Benjamin, Rolnick, and
  Kording}]{benjamin2018measuring}
Benjamin AS, Rolnick D, Kording K (2018) Measuring and regularizing networks in
  function space. arXiv preprint arXiv:180508289

\bibitem[{Buzzega et~al.(2020)Buzzega, Boschini, Porrello, Abati, and
  Calderara}]{buzzega2020dark}
Buzzega P, Boschini M, Porrello A, Abati D, Calderara S (2020) Dark experience
  for general continual learning: a strong, simple baseline. Advances in neural
  information processing systems 33:15920--15930

\bibitem[{Buzzega et~al.(2021)Buzzega, Boschini, Porrello, and
  Calderara}]{buzzega2021rethinking}
Buzzega P, Boschini M, Porrello A, Calderara S (2021) Rethinking experience
  replay: a bag of tricks for continual learning. In: 2020 25th International
  Conference on Pattern Recognition (ICPR), IEEE, pp 2180--2187

\bibitem[{Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal,
  Bojanowski, and Joulin}]{caron2021emerging}
Caron M, Touvron H, Misra I, J{\'e}gou H, Mairal J, Bojanowski P, Joulin A
  (2021) Emerging properties in self-supervised vision transformers. In:
  Proceedings of the IEEE/CVF International Conference on Computer Vision, pp
  9650--9660

\bibitem[{Castro et~al.(2018)Castro, Mar{\'\i}n-Jim{\'e}nez, Guil, Schmid, and
  Alahari}]{castro2018end}
Castro FM, Mar{\'\i}n-Jim{\'e}nez MJ, Guil N, Schmid C, Alahari K (2018)
  End-to-end incremental learning. In: Proceedings of the European conference
  on computer vision (ECCV), pp 233--248

\bibitem[{Chaudhry et~al.(2018)Chaudhry, Dokania, Ajanthan, and
  Torr}]{chaudhry2018riemannian}
Chaudhry A, Dokania PK, Ajanthan T, Torr PH (2018) Riemannian walk for
  incremental learning: Understanding forgetting and intransigence. In:
  Proceedings of the European Conference on Computer Vision (ECCV), pp 532--547

\bibitem[{Chaudhry et~al.(2019)Chaudhry, Ranzato, Rohrbach, and
  Elhoseiny}]{chaudhry2018efficient}
Chaudhry A, Ranzato M, Rohrbach M, Elhoseiny M (2019) Efficient lifelong
  learning with a-gem. In: International Conference on Learning Representations

\bibitem[{Chaudhry et~al.(2021)Chaudhry, Gordo, Dokania, Torr, and
  Lopez-Paz}]{chaudhry2021using}
Chaudhry A, Gordo A, Dokania P, Torr P, Lopez-Paz D (2021) Using hindsight to
  anchor past knowledge in continual learning. In: Proceedings of the AAAI
  Conference on Artificial Intelligence, vol~35, pp 6993--7001

\bibitem[{Del~Chiaro et~al.(2020)Del~Chiaro, Twardowski, Bagdanov, and Van
  De~Weijer}]{del2020ratt}
Del~Chiaro R, Twardowski B, Bagdanov A, Van De~Weijer J (2020) Ratt: Recurrent
  attention to transient tasks for continual image captioning. Advances in
  Neural Information Processing Systems 33:16736--16748

\bibitem[{Delange et~al.(2021)Delange, Aljundi, Masana, Parisot, Jia,
  Leonardis, Slabaugh, and Tuytelaars}]{delange2021continual}
Delange M, Aljundi R, Masana M, Parisot S, Jia X, Leonardis A, Slabaugh G,
  Tuytelaars T (2021) A continual learning survey: Defying forgetting in
  classification tasks. IEEE Transactions on Pattern Analysis and Machine
  Intelligence

\bibitem[{Dhar et~al.(2019)Dhar, Singh, Peng, Wu, and
  Chellappa}]{dhar2019learning}
Dhar P, Singh RV, Peng KC, Wu Z, Chellappa R (2019) Learning without
  memorizing. In: Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition, pp 5138--5146

\bibitem[{Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly
  et~al.}]{dosovitskiy2020image}
Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T,
  Dehghani M, Minderer M, Heigold G, Gelly S, et~al. (2020) An image is worth
  16x16 words: Transformers for image recognition at scale. arXiv preprint
  arXiv:201011929

\bibitem[{Douillard et~al.(2020)Douillard, Cord, Ollion, Robert, and
  Valle}]{douillard2020podnet}
Douillard A, Cord M, Ollion C, Robert T, Valle E (2020) Podnet: Pooled outputs
  distillation for small-tasks incremental learning. In: Computer Vision--ECCV
  2020: 16th European Conference, Glasgow, UK, August 23--28, 2020,
  Proceedings, Part XX 16, Springer, pp 86--102

\bibitem[{Douillard et~al.(2022)Douillard, Ram{\'e}, Couairon, and
  Cord}]{douillard2022dytox}
Douillard A, Ram{\'e} A, Couairon G, Cord M (2022) Dytox: Transformers for
  continual learning with dynamic token expansion. In: Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 9285--9295

\bibitem[{Fini et~al.(2022)Fini, da~Costa, Alameda-Pineda, Ricci, Alahari, and
  Mairal}]{fini2022self}
Fini E, da~Costa VGT, Alameda-Pineda X, Ricci E, Alahari K, Mairal J (2022)
  Self-supervised models are continual learners. In: Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 9621--9630

\bibitem[{Gehring et~al.(2017)Gehring, Auli, Grangier, Yarats, and
  Dauphin}]{gehring2017convolutional}
Gehring J, Auli M, Grangier D, Yarats D, Dauphin YN (2017) Convolutional
  sequence to sequence learning. In: International conference on machine
  learning, PMLR, pp 1243--1252

\bibitem[{Gomez-Villa et~al.(2022)Gomez-Villa, Twardowski, Yu, Bagdanov, and
  van~de Weijer}]{gomez2022continually}
Gomez-Villa A, Twardowski B, Yu L, Bagdanov AD, van~de Weijer J (2022)
  Continually learning self-supervised representations with projected
  functional regularization. In: Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition, pp 3867--3877

\bibitem[{Goodfellow et~al.(2014)Goodfellow, Mirza, Da, Courville, and
  Bengio}]{goodfellow2014empirical}
Goodfellow IJ, Mirza M, Da X, Courville AC, Bengio Y (2014) An empirical
  investigation of catastrophic forgeting in gradient-based neural networks.
  In: Bengio Y, LeCun Y (eds) 2nd International Conference on Learning
  Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014,
  Conference Track Proceedings, \urlprefix\url{http://arxiv.org/abs/1312.6211}

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{he2016deep}
He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image
  recognition. In: Proceedings of the IEEE conference on computer vision and
  pattern recognition, pp 770--778

\bibitem[{Hinton et~al.(2015)Hinton, Vinyals, Dean
  et~al.}]{hinton2015distilling}
Hinton G, Vinyals O, Dean J, et~al. (2015) Distilling the knowledge in a neural
  network. arXiv preprint arXiv:150302531 2(7)

\bibitem[{Hou et~al.(2019)Hou, Pan, Loy, Wang, and Lin}]{hou2019learning}
Hou S, Pan X, Loy CC, Wang Z, Lin D (2019) Learning a unified classifier
  incrementally via rebalancing. In: Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition, pp 831--839

\bibitem[{Jung et~al.(2016)Jung, Ju, Jung, and Kim}]{jung2016less}
Jung H, Ju J, Jung M, Kim J (2016) Less-forgetting learning in deep neural
  networks. arXiv preprint arXiv:160700122

\bibitem[{Kirkpatrick et~al.(2017)Kirkpatrick, Pascanu, Rabinowitz, Veness,
  Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska
  et~al.}]{kirkpatrick2017overcoming}
Kirkpatrick J, Pascanu R, Rabinowitz N, Veness J, Desjardins G, Rusu AA, Milan
  K, Quan J, Ramalho T, Grabska-Barwinska A, et~al. (2017) Overcoming
  catastrophic forgetting in neural networks. Proceedings of the national
  academy of sciences 114(13):3521--3526

\bibitem[{Krizhevsky et~al.(2009)Krizhevsky, Hinton
  et~al.}]{krizhevsky2009learning}
Krizhevsky A, Hinton G, et~al. (2009) Learning multiple layers of features from
  tiny images. Tech Report

\bibitem[{Le and Yang(2015)}]{le2015tiny}
Le Y, Yang X (2015) Tiny imagenet visual recognition challenge. CS 231N 7(7):3

\bibitem[{Lee et~al.(2020)Lee, Hong, Joo, and Kim}]{lee2020continual}
Lee J, Hong HG, Joo D, Kim J (2020) Continual learning with extended
  kronecker-factored approximate curvature. In: Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition, pp 9001--9010

\bibitem[{Li and Hoiem(2017)}]{li2017learning}
Li Z, Hoiem D (2017) Learning without forgetting. IEEE transactions on pattern
  analysis and machine intelligence 40(12):2935--2947

\bibitem[{Liu et~al.(2018)Liu, Masana, Herranz, Van~de Weijer, Lopez, and
  Bagdanov}]{liu2018rotate}
Liu X, Masana M, Herranz L, Van~de Weijer J, Lopez AM, Bagdanov AD (2018)
  Rotate your networks: Better weight consolidation and less catastrophic
  forgetting. In: 2018 24th International Conference on Pattern Recognition
  (ICPR), IEEE, pp 2262--2268

\bibitem[{Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo}]{liu2021swin}
Liu Z, Lin Y, Cao Y, Hu H, Wei Y, Zhang Z, Lin S, Guo B (2021) Swin
  transformer: Hierarchical vision transformer using shifted windows. In:
  Proceedings of the IEEE/CVF International Conference on Computer Vision, pp
  10012--10022

\bibitem[{Lopez-Paz and Ranzato(2017)}]{lopez2017gradient}
Lopez-Paz D, Ranzato M (2017) Gradient episodic memory for continual learning.
  Advances in neural information processing systems 30

\bibitem[{Van~der Maaten and Hinton(2008)}]{van2008visualizing}
Van~der Maaten L, Hinton G (2008) Visualizing data using t-sne. Journal of
  machine learning research 9(11)

\bibitem[{Mallya and Lazebnik(2018)}]{mallya2018packnet}
Mallya A, Lazebnik S (2018) Packnet: Adding multiple tasks to a single network
  by iterative pruning. In: Proceedings of the IEEE conference on Computer
  Vision and Pattern Recognition, pp 7765--7773

\bibitem[{Mallya et~al.(2018)Mallya, Davis, and Lazebnik}]{mallya2018piggyback}
Mallya A, Davis D, Lazebnik S (2018) Piggyback: Adapting a single network to
  multiple tasks by learning to mask weights. In: Proceedings of the European
  Conference on Computer Vision (ECCV), pp 67--82

\bibitem[{Masana et~al.(2020)Masana, Liu, Twardowski, Menta, Bagdanov, and
  van~de Weijer}]{masana2020class}
Masana M, Liu X, Twardowski B, Menta M, Bagdanov AD, van~de Weijer J (2020)
  Class-incremental learning: survey and performance evaluation on image
  classification. arXiv preprint arXiv:201015277

\bibitem[{Masana et~al.(2021)Masana, Tuytelaars, and Van~de
  Weijer}]{masana2021ternary}
Masana M, Tuytelaars T, Van~de Weijer J (2021) Ternary feature masks:
  zero-forgetting for task-incremental learning. In: Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 3570--3579

\bibitem[{Mermillod et~al.(2013)Mermillod, Bugaiska, and
  Bonin}]{mermillod2013stability}
Mermillod M, Bugaiska A, Bonin P (2013) The stability-plasticity dilemma:
  Investigating the continuum from catastrophic forgetting to age-limited
  learning effects

\bibitem[{Mundt et~al.(2021)Mundt, Lang, Delfosse, and
  Kersting}]{mundt2021cleva}
Mundt M, Lang S, Delfosse Q, Kersting K (2021) Cleva-compass: A continual
  learning evaluation assessment compass to promote research transparency and
  comparability. arXiv preprint arXiv:211003331

\bibitem[{Pelosin et~al.(2022)Pelosin, Jha, Torsello, Raducanu, and van~de
  Weijer}]{pelosin2022towards}
Pelosin F, Jha S, Torsello A, Raducanu B, van~de Weijer J (2022) Towards
  exemplar-free continual learning in vision transformers: an account of
  attention, functional and weight regularization. In: Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 3820--3829

\bibitem[{Rajasegaran et~al.(2019)Rajasegaran, Hayat, Khan, Khan, and
  Shao}]{rajasegaran2019random}
Rajasegaran J, Hayat M, Khan SH, Khan FS, Shao L (2019) Random path selection
  for continual learning. Advances in Neural Information Processing Systems 32

\bibitem[{Rebuffi et~al.(2017)Rebuffi, Kolesnikov, Sperl, and
  Lampert}]{rebuffi2017icarl}
Rebuffi SA, Kolesnikov A, Sperl G, Lampert CH (2017) icarl: Incremental
  classifier and representation learning. In: Proceedings of the IEEE
  conference on Computer Vision and Pattern Recognition, pp 2001--2010

\bibitem[{Riemer et~al.(2018)Riemer, Cases, Ajemian, Liu, Rish, Tu, and
  Tesauro}]{riemer2018learning}
Riemer M, Cases I, Ajemian R, Liu M, Rish I, Tu Y, Tesauro G (2018) Learning to
  learn without forgetting by maximizing transfer and minimizing interference.
  arXiv preprint arXiv:181011910

\bibitem[{Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein et~al.}]{russakovsky2015imagenet}
Russakovsky O, Deng J, Su H, Krause J, Satheesh S, Ma S, Huang Z, Karpathy A,
  Khosla A, Bernstein M, et~al. (2015) Imagenet large scale visual recognition
  challenge. International journal of computer vision 115(3):211--252

\bibitem[{Rusu et~al.(2016)Rusu, Rabinowitz, Desjardins, Soyer, Kirkpatrick,
  Kavukcuoglu, Pascanu, and Hadsell}]{rusu2016progressive}
Rusu AA, Rabinowitz NC, Desjardins G, Soyer H, Kirkpatrick J, Kavukcuoglu K,
  Pascanu R, Hadsell R (2016) Progressive neural networks. arXiv

\bibitem[{Serra et~al.(2018)Serra, Suris, Miron, and
  Karatzoglou}]{serra2018overcoming}
Serra J, Suris D, Miron M, Karatzoglou A (2018) Overcoming catastrophic
  forgetting with hard attention to the task. In: International Conference on
  Machine Learning, PMLR, pp 4548--4557

\bibitem[{Strudel et~al.(2021)Strudel, Garcia, Laptev, and
  Schmid}]{strudel2021segmenter}
Strudel R, Garcia R, Laptev I, Schmid C (2021) Segmenter: Transformer for
  semantic segmentation. In: Proceedings of the IEEE/CVF International
  Conference on Computer Vision, pp 7262--7272

\bibitem[{Toldo and Ozay(2022)}]{toldo2022bring}
Toldo M, Ozay M (2022) Bring evanescent representations to life in lifelong
  class incremental learning. In: Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition, pp 16732--16741

\bibitem[{Touvron et~al.(2021)Touvron, Cord, Sablayrolles, Synnaeve, and
  J{\'e}gou}]{touvron2021going}
Touvron H, Cord M, Sablayrolles A, Synnaeve G, J{\'e}gou H (2021) Going deeper
  with image transformers. In: Proceedings of the IEEE/CVF International
  Conference on Computer Vision, pp 32--42

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{vaswani2017attention}
Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser {\L},
  Polosukhin I (2017) Attention is all you need. Advances in neural information
  processing systems 30

\bibitem[{Wang et~al.(2021)Wang, Yang, Li, Hong, Li, and Zhu}]{wang2021ordisco}
Wang L, Yang K, Li C, Hong L, Li Z, Zhu J (2021) Ordisco: Effective and
  efficient usage of incremental unlabeled data for semi-supervised continual
  learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition, pp 5383--5392

\bibitem[{Wang et~al.(2022{\natexlab{a}})Wang, Liu, Duan, Kong, and
  Tao}]{wang2022continual}
Wang Z, Liu L, Duan Y, Kong Y, Tao D (2022{\natexlab{a}}) Continual learning
  with lifelong vision transformer. In: Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition, pp 171--181

\bibitem[{Wang et~al.(2022{\natexlab{b}})Wang, Zhang, Lee, Zhang, Sun, Ren, Su,
  Perot, Dy, and Pfister}]{wang2022learning}
Wang Z, Zhang Z, Lee CY, Zhang H, Sun R, Ren X, Su G, Perot V, Dy J, Pfister T
  (2022{\natexlab{b}}) Learning to prompt for continual learning. In:
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition, pp 139--149

\bibitem[{Wu et~al.(2019)Wu, Chen, Wang, Ye, Liu, Guo, and Fu}]{wu2019large}
Wu Y, Chen Y, Wang L, Ye Y, Liu Z, Guo Y, Fu Y (2019) Large scale incremental
  learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition, pp 374--382

\bibitem[{Yan et~al.(2021)Yan, Xie, and He}]{yan2021dynamically}
Yan S, Xie J, He X (2021) Der: Dynamically expandable representation for class
  incremental learning. In: Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition, pp 3014--3023

\bibitem[{Yu et~al.(2020)Yu, Twardowski, Liu, Herranz, Wang, Cheng, Jui, and
  Weijer}]{yu2020semantic}
Yu L, Twardowski B, Liu X, Herranz L, Wang K, Cheng Y, Jui S, Weijer Jvd (2020)
  Semantic drift compensation for class-incremental learning. In: Proceedings
  of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp
  6982--6991

\bibitem[{Zenke et~al.(2017)Zenke, Poole, and Ganguli}]{zenke2017continual}
Zenke F, Poole B, Ganguli S (2017) Continual learning through synaptic
  intelligence. In: International Conference on Machine Learning, PMLR, pp
  3987--3995

\bibitem[{Zhai et~al.(2021)Zhai, Chen, and Mori}]{zhai2021hyper}
Zhai M, Chen L, Mori G (2021) Hyper-lifelonggan: scalable lifelong learning for
  image conditioned generation. In: Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition, pp 2246--2255

\bibitem[{Zhang et~al.(2020)Zhang, Zhang, Ghosh, Li, Tasci, Heck, Zhang, and
  Kuo}]{zhang2020class}
Zhang J, Zhang J, Ghosh S, Li D, Tasci S, Heck L, Zhang H, Kuo CCJ (2020)
  Class-incremental learning via deep model consolidation. In: Proceedings of
  the IEEE/CVF Winter Conference on Applications of Computer Vision, pp
  1131--1140

\bibitem[{Zheng et~al.(2021)Zheng, Lu, Zhao, Zhu, Luo, Wang, Fu, Feng, Xiang,
  Torr et~al.}]{zheng2021rethinking}
Zheng S, Lu J, Zhao H, Zhu X, Luo Z, Wang Y, Fu Y, Feng J, Xiang T, Torr PH,
  et~al. (2021) Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers. In: Proceedings of the IEEE/CVF conference on
  computer vision and pattern recognition, pp 6881--6890

\bibitem[{Zhou et~al.(2022)Zhou, Wang, Ye, and Zhan}]{zhou2022model}
Zhou DW, Wang QW, Ye HJ, Zhan DC (2022) A model or 603 exemplars: Towards
  memory-efficient class-incremental learning. arXiv preprint arXiv:220513218

\bibitem[{Zhu et~al.(2021)Zhu, Zhang, Wang, Yin, and Liu}]{zhu2021prototype}
Zhu F, Zhang XY, Wang C, Yin F, Liu CL (2021) Prototype augmentation and
  self-supervision for incremental learning. In: Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition, pp 5871--5880

\end{thebibliography}
