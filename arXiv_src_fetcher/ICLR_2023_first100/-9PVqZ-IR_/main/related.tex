%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Works}
\label{main:sec:related}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\gls{cnp}~\citep{garnelo2018conditional} is the first \gls{npf} model which consists of simple \gls{mlp} layers as its encoder and decoder. \gls{np}~\citep{garnelo2018neural} also uses \gls{mlp} layers as its encoder and decoder but introduces a global latent variable to model a functional uncertainty.
\gls{canp}~\citep{kim2018attentive} and \gls{anp}~\citep{kim2018attentive} are the models which apply attention modules as their encoder block in order to well summarize context information relevant to target points. 
\citet{louizos2019functional} proposed \glspl{np} model which employs local latent variables instead of a global latent variable by applying a graph neural network.
By applying convolution layers as their encoder, \citet{gordon2020convolutional} and \citet{foong2020meta} introduced a translation equivariant \glspl{cnp} and \glspl{np} model, respectively. 
In addition to these works, \gls{bnp}~\citep{lee2020bootstrapping} suggests modeling functional uncertainty with the bootstrap~\citep{efron1992bootstrap} method instead of using a single global latent variable. 
% \gls{neubnp}~\citep{lee2022neural} also used a recent bootstrap method called Neural Bootstrapper~\citep{shin2021neural} to model functional uncertainty.
