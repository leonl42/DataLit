@misc{https://doi.org/10.48550/arxiv.2206.11795,
  doi = {10.48550/ARXIV.2206.11795},
  
  author = {Baker, Bowen and Akkaya, Ilge and Zhokhov, Peter and Huizinga, Joost and Tang, Jie and Ecoffet, Adrien and Houghton, Brandon and Sampedro, Raul and Clune, Jeff},
  

  title = {Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos},
  

  year = {2022},
  
}

@misc{https://doi.org/10.48550/arxiv.1912.02875,
  doi = {10.48550/ARXIV.1912.02875},
  

  author = {Schmidhuber, Juergen},
  
  title = {Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map Them to Actions},
  

  year = {2019},
  
}

@inproceedings{airl,
title={Learning Robust Rewards with Adverserial Inverse Reinforcement Learning},
author={Justin Fu and Katie Luo and Sergey Levine},
booktitle={{Proceedings of the Sixth International Conference on Learning Representations}},
year={2018}}

@article{gcl,
  author  = {Chelsea Finn and Paul Christiano and Pieter Abbeel and Sergey Levine}, 
  title   = {A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models},
  journal = {in Proceedings of the {Thirtieth International Conference on Neural Information Processing Systems Workshop on Adversarial Training}},
  year    = 2016
}

@misc{yang2021representation,
      title={Representation Matters: Offline Pretraining for Sequential Decision Making}, 
      author={Mengjiao Yang and Ofir Nachum},
      year={2021},
      eprint={2102.05815},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{venuto2020oirl,
    title={{oIRL}: Robust Adversarial Inverse Reinforcement Learning with Temporally Extended Actions},
    author={David Venuto and Jhelum Chakravorty and Leonard Boussioux and Junhao Wang and Gavin McCracken and Doina Precup},
    year={2020},
    journal={arXiv},
    volume={2002.09043}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}


@inproceedings{10.5555/3045390.3045531,
author = {Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
title = {Benchmarking Deep Reinforcement Learning for Continuous Control},
year = {2016},
booktitle = {Proceedings of the {Thirty-Third International Conference on International Conference on Machine Learning}},
}


@article{10.5555/1577069.1755839,
author = {Taylor, Matthew E. and Stone, Peter},
title = {Transfer Learning for Reinforcement Learning Domains: A Survey},
year = {2009},
journal = {Journal of Machine Learning Research},
}

@inproceedings{45903,
title	= {Deep Variational Information Bottleneck},
author	= {Alex Alemi and Ian Fischer and Josh Dillon and Kevin Murphy},
year	= {2017},
URL	= {https://arxiv.org/abs/1612.00410},
booktitle	= {ICLR}
}

@inproceedings{NEURIPS2018_f02208a0,
 author = {Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion},
 year = {2018}
}


@inproceedings{10.5555/3009657.3009806,
author = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
year = {1999},
booktitle = {Proceedings of the 12th International Conference on Neural Information Processing Systems},
}





@InProceedings{pmlr-v80-haarnoja18b,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
}


@ARTICLE{10.3389/fnins.2012.00050,
  
AUTHOR={Smaldino, Paul and Richerson, Peter},   
	 
TITLE={The Origins of Options},      
	
JOURNAL={Frontiers in Neuroscience},      
	
YEAR={2012},     
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Proceedings of the {27th International Conference on Neural Information Processing Systems}},
year=2014,
}

@inproceedings{Schulmanetal_ICLR2016,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
booktitle = {{Proceedings of the Fourth International Conference of Learning Representations}},
year  = 2016
}

@article{Drusvyatskiy2016ErrorBQ,
  title={Error Bounds, Quadratic Growth, and Linear Convergence of Proximal Methods},
  author={Dmitriy Drusvyatskiy and Adrian S. Lewis},
  journal={Mathematics of Operations Research},
  year={2016},
}



@inproceedings{Wang:2017:RID:3295222.3295284,
author = {Wang, Ziyu and Merel, Josh and Reed, Scott and Wayne, Greg and de Freitas, Nando and Heess, Nicolas},
title = {Robust Imitation of Diverse Behaviors},
year = {2017},
booktitle = {Proceedings of the {Thirty First International Conference on Neural Information Processing Systems}},
}


@inproceedings{NIPS2017_6723,
author = {Hausman, Karol and Chebotar, Yevgen and Schaal, Stefan and Sukhatme, Gaurav and Lim, Joseph J.},
title = {Multi-Modal Imitation Learning from Unstructured Demonstrations Using Generative Adversarial Nets},
year = {2017},
booktitle = {Proceedings of the {31st International Conference on Neural Information Processing Systems}},
}


@article{Krishnan2016HIRLHI,
  title={{HIRL:} Hierarchical Inverse Reinforcement Learning for Long-Horizon Tasks with Delayed Rewards},
  author={Sanjay Krishnan and Animesh Garg and Richard Liaw and Lauren Miller and Florian T. Pokorny and Kenneth Y. Goldberg},
  journal={ArXiv},
  year={2016},
  volume={1604.06508}
}


@inproceedings{ho_generative_2016,
author = {Ho, Jonathan and Ermon, Stefano},
title = {Generative Adversarial Imitation Learning},
year = {2016},
booktitle = {Proceedings of the {Thirtieth International Conference on Neural Information Processing Systems}},
}


@inproceedings{Finn:2016:GCL:3045390.3045397,
author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
year = {2016},
booktitle = {Proceedings of the {Thirty-Third International Conference on International Conference on Machine Learning}},
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{
sharma2018directedinfo,
title={Directed-Info {GAIL}: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information},
author={Mohit Sharma and Arjun Sharma and Nicholas Rhinehart and Kris M. Kitani},
journal={{Proceedings of the Seventh International Conference on Learning Representations}},
year={2019},
}

@article{DBLP:conf/iclr/2017,
  title     = {in ICLR},
  year      = {2017},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
}



@inproceedings{pmlr-v97-turner19a,
  title = 	 {Metropolis-Hastings Generative Adversarial Networks},
  author = 	 {Turner, Ryan and Hung, Jane and Frank, Eric and Saatchi, Yunus and Yosinski, Jason},
  booktitle = 	 {Proceedings of the {Thirty Sixth International Conference on Machine Learning}},
  year = 	 {2019}
}

@incollection{transfer_git,
title = {Transfer Environments for {MuJoCo}},
author = {Elizabeth Chu and Sebastien Arnold},
year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  URL = {https://github.com/seba-1511/shapechanger}
}

@inproceedings{10.5555/3020751.3020832,
author = {Talvitie, Erik},
title = {Model Regularization for Stable Sample Rollouts},
year = {2014},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
}


@InProceedings{pmlr-v80-asadi18a,
  title = 	 {{L}ipschitz Continuity in Model-based Reinforcement Learning},
  author =       {Asadi, Kavosh and Misra, Dipendra and Littman, Michael},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
}


@inproceedings{10.5555/3104482.3104541,
author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward},
title = {PILCO: A Model-Based and Data-Efficient Approach to Policy Search},
year = {2011},
booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
}

@article{10.1145/122344.122377,
author = {Sutton, Richard S.},
title = {Dyna, an Integrated Architecture for Learning, Planning, and Reacting},
year = {1991},
journal = {SIGART Bull.},
}

@misc{
  zhang2018decoupling,
  title={Decoupling Dynamics and Reward for Transfer Learning},
  author={Amy Zhang and Harsh Satija and Joelle Pineau},
  year={2018},
}


@InProceedings{pmlr-v162-seo22a,
  title = 	 {Reinforcement Learning with Action-Free Pre-Training from Videos},
  author =       {Seo, Younggyo and Lee, Kimin and James, Stephen L and Abbeel, Pieter},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
}




@article{Sutton:1999,
author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
title = {Between {MDPs} and {Semi-MDPs}: A Framework for Temporal Abstraction in Reinforcement Learning},
year = {1999},
journal = {Artificial Intelligence},
}


@inproceedings{Ng00algorithmsfo,
author = {Ng, Andrew Y. and Russell, Stuart J.},
title = {Algorithms for Inverse Reinforcement Learning},
year = {2000},
booktitle = {Proceedings of the {Seventeenth International Conference on Machine Learning}},
}

@article{Kroemer2019ARO,
  title={A Review of Robot Learning for Manipulation: Challenges, Representations, and Algorithms},
  author={Oliver Kroemer and Scott Niekum and George Konidaris},
  journal={ArXiv},
  year={2019},
  volume={1907.03146}
}

@INPROCEEDINGS{Konidaris07buildingportable,
    author = {George Konidaris and Andrew Barto},
    title = {Building portable options: Skill transfer in reinforcement learning},
    booktitle = {{Proceedings of the Twentieth International Joint Conference on Artificial Intelligence}},
    year = {2007},
}

@book{10.5555/1642718,
author = {Pearl, Judea},
title = {Causality: Models, Reasoning and Inference},
year = {2009},
}


@misc{bengio2019consciousness,
      title={The Consciousness Prior}, 
      author={Yoshua Bengio},
      year={2019},
      eprint={1709.08568},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{10.5555/3042573.3042635,
author = {Sch\"{o}lkopf, Bernhard and Janzing, Dominik and Peters, Jonas and Sgouritsa, Eleni and Zhang, Kun and Mooij, Joris},
title = {On Causal and Anticausal Learning},
year = {2012},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
}

@article{45512,
title	= {Concrete Problems in AI Safety},
author	= {Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Mané},
year	= {2016},
journal	= {arXiv},
  volume={1606.06565}

}

@misc{vanhasselt2018deep,
      title={Deep Reinforcement Learning and the Deadly Triad}, 
      author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
      year={2018},
      eprint={1812.02648},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{10.5555/2998981.2999132,
author = {Tsitsiklis, John N. and Van Roy, Benjamin},
title = {Analysis of Temporal-Difference Learning with Function Approximation},
year = {1996},
booktitle = {Proceedings of the 9th International Conference on Neural Information Processing Systems},
}

@InProceedings{pmlr-v119-abbas20a, title = {Selective Dyna-Style Planning Under Limited Model Capacity}, author = {Abbas, Zaheer and Sokota, Samuel and Talvitie, Erin and White, Martha}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, abstract = {In model-based reinforcement learning, planning with an imperfect model of the environment has the potential to harm learning progress. But even when a model is imperfect, it may still contain information that is useful for planning. In this paper, we investigate the idea of using an imperfect model selectively. The agent should plan in parts of the state space where the model would be helpful but refrain from using the model where it would be harmful. An effective selective planning mechanism requires estimating predictive uncertainty, which arises out of aleatoric uncertainty, parameter uncertainty, and model inadequacy, among other sources. Prior work has focused on parameter uncertainty for selective planning. In this work, we emphasize the importance of model inadequacy. We show that heteroscedastic regression can signal predictive uncertainty arising from model inadequacy that is complementary to that which is detected by methods designed for parameter uncertainty, indicating that considering both parameter uncertainty and model inadequacy may be a more promising direction for effective selective planning than either in isolation.} }

@inproceedings{DBLP:conf/icml/TannerS05,
  author={Brian Tanner and Richard S. Sutton},
  title={TD(lambda) networks: temporal-difference networks with eligibility traces},
  year={2005},
  cdate={1104537600000},
  booktitle={ICML},
}



@Inbook{Lange2012,
author="Lange, Sascha
and Gabel, Thomas
and Riedmiller, Martin",
title="Batch Reinforcement Learning",
bookTitle="Reinforcement Learning: State-of-the-Art",
year="2012",
abstract="Batch reinforcement learning is a subfield of dynamic programming-based reinforcement learning. Originally defined as the task of learning the best possible policy from a fixed set of a priori-known transition samples, the (batch) algorithms developed in this field can be easily adapted to the classical online case, where the agent interacts with the environment while learning. Due to the efficient use of collected data and the stability of the learning process, this research area has attracted a lot of attention recently. In this chapter, we introduce the basic principles and the theory behind batch reinforcement learning, describe the most important algorithms, exemplarily discuss ongoing research within this field, and briefly survey real-world applications of batch reinforcement learning.",
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{10.5555/2998687.2998730,
author = {Jaakkola, Tommi and Singh, Satinder P. and Jordan, Michael I.},
title = {Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems},
year = {1994},
booktitle = {Proceedings of the 7th International Conference on Neural Information Processing Systems},
}

@InProceedings{pmlr-v48-mniha16, title = {Asynchronous Methods for Deep Reinforcement Learning}, author = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray}, booktitle = {Proceedings of The 33rd International Conference on Machine Learning}, abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.} }



@inproceedings{10.5555/2074022.2074088,
author = {Weaver, Lex and Tao, Nigel},
title = {The Optimal Reward Baseline for Gradient-Based Reinforcement Learning},
year = {2001},
booktitle = {Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence},
}




@InProceedings{pmlr-v97-fujimoto19a, title = {Off-Policy Deep Reinforcement Learning without Exploration}, author = {Fujimoto, Scott and Meger, David and Precup, Doina}, booktitle = {Proceedings of the 36th International Conference on Machine Learning},year = {2019} }

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author =       {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
}

@book{10.5555/3312046,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

@misc{nachum2019algaedice,
      title={AlgaeDICE: Policy Gradient from Arbitrary Experience}, 
      author={Ofir Nachum and Bo Dai and Ilya Kostrikov and Yinlam Chow and Lihong Li and Dale Schuurmans},
      year={2019},
      eprint={1912.02074},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{Tishby99theinformation,
    author = {Naftali Tishby and Fernando C. Pereira and William Bialek},
    title = {The Information Bottleneck Method},
    booktitle = {},
    year = {1999},
}

@inproceedings{
michael2018on,
title={On the Information Bottleneck Theory of Deep Learning},
author={Andrew Michael Saxe and Yamini Bansal and Joel Dapello and Madhu Advani and Artemy Kolchinsky and Brendan Daniel Tracey and David Daniel Cox},
booktitle={International Conference on Learning Representations},
year={2018},
}

@inproceedings{NIPS2009_a2557a7b,
 author = {Bush, Keith and Pineau, Joelle},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability},
 year = {2009}
}



@inproceedings{NIPS1998_6d3a1e06,
 author = {Suematsu, Nobuo and Hayashi, Akira},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {A Reinforcement Learning Algorithm in Partially Observable Environments Using Short-Term Memory},
 year = {1999}
}



@inproceedings{
Kaiser2020Model,
title={Model Based Reinforcement Learning for Atari},
author={Łukasz Kaiser and Mohammad Babaeizadeh and Piotr Miłos and Błażej Osiński and Roy H Campbell and Konrad Czechowski and Dumitru Erhan and Chelsea Finn and Piotr Kozakowski and Sergey Levine and Afroz Mohiuddin and Ryan Sepassi and George Tucker and Henryk Michalewski},
booktitle={International Conference on Learning Representations},
year={2020},
}

@article{10.1109/TNN.2004.828762,
author = {Honkela, A. and Valpola, H.},
title = {Variational Learning and Bits-Back Coding: An Information-Theoretic View to Bayesian Learning},
year = {2004},
journal = {Trans. Neur. Netw.},
}


@misc{
wang2020benchmarking,
title={Benchmarking Model-Based Reinforcement Learning},
author={Tingwu Wang and Xuchan Bao and Ignasi Clavera and Jerrick Hoang and Yeming Wen and Eric Langlois and Shunshi Zhang and Guodong Zhang and Pieter Abbeel and Jimmy Ba},
year={2020},
}


@misc{pascanu2017learning,
      title={Learning model-based planning from scratch}, 
      author={Razvan Pascanu and Yujia Li and Oriol Vinyals and Nicolas Heess and Lars Buesing and Sebastien Racanière and David Reichert and Théophane Weber and Daan Wierstra and Peter Battaglia},
      year={2017},
      eprint={1707.06170},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{chiappa2017recurrent,
      title={Recurrent Environment Simulators}, 
      author={Silvia Chiappa and Sébastien Racaniere and Daan Wierstra and Shakir Mohamed},
      year={2017},
      eprint={1704.02254},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{10.5555/3305890.3305962,
author = {Ostrovski, Georg and Bellemare, Marc G. and van den Oord, A\"{a}ron and Munos, R\'{e}mi},
title = {Count-Based Exploration with Neural Density Models},
year = {2017},
booktitle = {Proceedings of the 34th International Conference on Machine Learning },
}

@inproceedings{10.5555/3305890.3305968,
author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
title = {Curiosity-Driven Exploration by Self-Supervised Prediction},
year = {2017},
booktitle = {Proceedings of the 34th International Conference on Machine Learning}
}


@inproceedings{NIPS2017_9e82757e,
 author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
 year = {2017}
}



@misc{
zhang2021brac,
title={{\{}BRAC{\}}+: Going Deeper with Behavior Regularized Offline Reinforcement Learning},
author={Chi Zhang and Sanmukh Rao Kuppannagari and Viktor Prasanna},
year={2021},
url={https://openreview.net/forum?id=bMCfFepJXM}
}

@inproceedings{NEURIPS2019_c2073ffa,
 author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
 year = {2019}
}



@misc{
wu2020behavior,
title={Behavior Regularized Offline Reinforcement Learning},
author={Yifan Wu and George Tucker and Ofir Nachum},
year={2020},
url={https://openreview.net/forum?id=BJg9hTNKPH}
}

@article{Francois-Lavet_Bengio_Precup_Pineau_2019, title={Combined Reinforcement Learning via Abstract Representations},
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
year={2019} }

@inproceedings{peng-etal-2018-deeppeng-etal-2018-deep,
    title = "{D}eep {D}yna-{Q}: Integrating Planning for Task-Completion Dialogue Policy Learning",
    author = "Peng, Baolin  and
      Li, Xiujun  and
      Gao, Jianfeng  and
      Liu, Jingjing  and
      Wong, Kam-Fai",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics)",
    year = "2018",
}

@article {Johnson-Laird18243,
	author = {Johnson-Laird, Philip N.},
	title = {Mental models and human reasoning},
	year = {2010},

	journal = {Proceedings of the National Academy of Sciences}
}

@article{TACL1296,
	author = {Kelvin Guu and Tatsunori Hashimoto and Yonatan Oren and Percy Liang},
	title = {Generating Sentences by Editing Prototypes},
	journal = {Transactions of the Association for Computational Linguistics},
	year = {2018}
}

@misc{gulrajani2016pixelvae,
      title={PixelVAE: A Latent Variable Model for Natural Images}, 
      author={Ishaan Gulrajani and Kundan Kumar and Faruk Ahmed and Adrien Ali Taiga and Francesco Visin and David Vazquez and Aaron Courville},
      year={2016},
      eprint={1611.05013},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{krishnan2015deep,
      title={Deep Kalman Filters}, 
      author={Rahul G. Krishnan and Uri Shalit and David Sontag},
      year={2015},
      eprint={1511.05121},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{chen2017variational,
      title={Variational Lossy Autoencoder}, 
      author={Xi Chen and Diederik P. Kingma and Tim Salimans and Yan Duan and Prafulla Dhariwal and John Schulman and Ilya Sutskever and Pieter Abbeel},
      year={2017},
      eprint={1611.02731},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{Sutton1988,
author = {Sutton, Richard S.},
title = {Learning to Predict by the Methods of Temporal Differences},
year = {1988},
journal = {Machine Learning},

}

@inproceedings{10.5555/3042573.3042600,
author = {Degris, Thomas and White, Martha and Sutton, Richard S.},
title = {Off-Policy Actor-Critic},
year = {2012},
booktitle = {Proceedings of the {Twenty-Ninth International Coference on International Conference on Machine Learning}},
}

@article{10.1007/BF00992696, author = {Williams, Ronald J.}, title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning}, year = {1992}, journal = {Machine Learning}}




@Article{Watkins1992,
author="Watkins, Christopher J.C.H.
and Dayan, Peter",
title="Technical Note: Q-Learning",
journal="Machine Learning",
year="1992",
}



@article{Bellman767,
	author = {Bellman, Richard},
	title = {DYNAMIC PROGRAMMING AND LAGRANGE MULTIPLIERS},
	year = {1956},
	journal = {Proceedings of the National Academy of Sciences},
	publisher = {National Academy of Sciences},

}

@article{ziebart2008maximum,
   author = {Brian D. Ziebart and Andrew Maas 
            and J. Andrew Bagnell and Anind K. Dey},
   title = {Maximum Entropy Inverse Reinforcement Learning},
   year = {2008},
   journal = {in AAAI}}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {{OpenAI Gym}},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@article{DBLP:journals/corr/abs-1712-00004,
  author    = {Martin Klissarov and
               Pierre{-}Luc Bacon and
               Jean Harb and
               Doina Precup},
  title     = {Learnings Options End-to-End for Continuous Action Tasks},
  journal   = {arXiv},
  volume    = {1712.00004},
  year      = {2017}
}

@article{Tennenholtz_Shalit_Mannor_2020, title={Off-Policy Evaluation in Partially Observable Environments}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Tennenholtz, Guy and Shalit, Uri and Mannor, Shie}, year={2020}, }

@inproceedings{NIPS2017_ffbd6cbb,
 author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Value Prediction Network},
 year = {2017}
}



@article{10.5555/1622262.1622264,
author = {Hauskrecht, Milos},
title = {Value-Function Approximations for Partially Observable Markov Decision Processes},
year = {2000},

journal = {J. Artif. Int. Res.},
}

@inproceedings{10.5555/645529.658134,
author = {Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
title = {Eligibility Traces for Off-Policy Policy Evaluation},
year = {2000},
booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
}



@article{pmlr-v78-florensa17a,
  title = 	 {Reverse Curriculum Generation for Reinforcement Learning},
  author = 	 {Carlos Florensa and David Held and Markus Wulfmeier and Michael Zhang and Pieter Abbeel},
  year = 	 {2017},
  journal =  {Proceedings of Machine Learning Research}
}

@article{kullback1951,
author = "Kullback, S. and Leibler, R. A.",
fjournal = "Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
title = "On Information and Sufficiency",
year = "1951"
}



@inproceedings{NIPS2019_9348,
title = {Meta-Inverse Reinforcement Learning with Probabilistic Context Variables},
author = {Yu, Lantao and Yu, Tianhe and Finn, Chelsea and Ermon, Stefano},
booktitle = {Proceedings of the {Thirty Second Conference on Neural Information Processing Systems}},
year = {2019}
}


@book{duerr2020probabilistic,
  title={Probabilistic Deep Learning: With Python, Keras and TensorFlow Probability},
  author={Oliver Duerr and Beate Sick and Elvis Murina},
  year={2020},
  publisher={Manning Publications}
}

@inproceedings{osband2020bsuite,
    title={Behaviour Suite for Reinforcement Learning},
    author={Osband, Ian and
            Doron, Yotam and
            Hessel, Matteo and
            Aslanides, John and
            Sezener, Eren and
            Saraiva, Andre and
            McKinney, Katrina and
            Lattimore, Tor and
            {Sz}epesv{\'a}ri, Csaba and
            Singh, Satinder and
            Van Roy, Benjamin and
            Sutton, Richard and
            Silver, David and
            van Hasselt, Hado},
    booktitle={International Conference on Learning Representations},
    year={2020},
}

@inproceedings{10.5555/2969442.2969527,
author = {Kingma, Diederik P. and Salimans, Tim and Welling, Max},
title = {Variational Dropout and the Local Reparameterization Trick},
year = {2015},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems },
}


@misc{gym_minigrid,
  author = {Chevalier-Boisvert, Maxime and Willems, Lucas and Pal, Suman},
  title = {Minimalistic Gridworld Environment for {OpenAI Gym}},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/maximecb/gym-minigrid}},
}

@inproceedings{10.5555/3305381.3305521,
author = {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017},
booktitle = {Proceedings of the 34th International Conference on Machine Learning },
}

@article{NIPS2019_8421,
title = {Hierarchical Reinforcement Learning with Advantage-Based Auxiliary Rewards},
author = {Li, Siyuan and Wang, Rui and Tang, Minxue and Zhang, Chongjie},
journal = {in NeurIPS},
year = {2019}
}


@inproceedings{10.5555/268319.273078,
author = {Tikhonov, A. N. and Leonov, A. S. and Yagola, A. G.},
title = {Nonlinear Ill-Posed Problems},
year = {1996},
booktitle = {Proceedings of the {First World Congress on World Congress of Nonlinear Analysts}},
}


@article{10.1007/BF00332914, author = {Vogl, T. P. and Mangis, J. K. and Rigler, A. K. and Zink, W. T. and Alkon, D. L.}, title = {Accelerating the Convergence of the Back-Propagation Method}, year = {1988}, journal = {Biological Cybernetics}}

@inproceedings{10.5555/646469.691875, author = {LeCun, Yann and Haffner, Patrick and Bottou, L\'{e}on and Bengio, Yoshua}, title = {Object Recognition with Gradient-Based Learning}, year = {1999}, booktitle = {Shape, Contour and Grouping in Computer Vision}, }


@article{10.5555/2627435.2670313,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
year = {2014},
journal = {Journal of Machine Learning Research},
}

@misc{rusu2016progressive,
      title={Progressive Neural Networks}, 
      author={Andrei A. Rusu and Neil C. Rabinowitz and Guillaume Desjardins and Hubert Soyer and James Kirkpatrick and Koray Kavukcuoglu and Razvan Pascanu and Raia Hadsell},
      year={2016},
      eprint={1606.04671},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{DBLP:journals/corr/GulrajaniKATVVC16,
  author    = {Ishaan Gulrajani and
               Kundan Kumar and
               Faruk Ahmed and
               Adrien Ali Ta{\"{\i}}ga and
               Francesco Visin and
               David V{\'{a}}zquez and
               Aaron C. Courville},
  title     = {PixelVAE: {A} Latent Variable Model for Natural Images},
  journal   = {CoRR},
  volume    = {abs/1611.05013},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.05013},
  archivePrefix = {arXiv},
  eprint    = {1611.05013},
}


@InProceedings{pmlr-v139-mesnard21a,
  title = 	 {Counterfactual Credit Assignment in Model-Free Reinforcement Learning},
  author =       {Mesnard, Thomas and Weber, Theophane and Viola, Fabio and Thakoor, Shantanu and Saade, Alaa and Harutyunyan, Anna and Dabney, Will and Stepleton, Thomas S and Heess, Nicolas and Guez, Arthur and Moulines, Eric and Hutter, Marcus and Buesing, Lars and Munos, Remi},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  year = 	 {2021},
}

@article{DBLP:journals/corr/abs-1910-07207,
  author    = {Petros Christodoulou},
  title     = {Soft Actor-Critic for Discrete Action Settings},
  journal   = {CoRR},
  volume    = {abs/1910.07207},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.07207},
  eprinttype = {arXiv},
  eprint    = {1910.07207},
  timestamp = {Tue, 22 Oct 2019 18:17:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-07207.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/GuezVWBKPSH20,
  author    = {Arthur Guez and
               Fabio Viola and
               Theophane Weber and
               Lars Buesing and
               Steven Kapturowski and
               Doina Precup and
               David Silver and
               Nicolas Heess},
  title     = {Value-driven Hindsight Modelling},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference},
  year      = {2020}
}
@misc{schmidhuber2020reinforcement,
      title={Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map Them to Actions}, 
      author={Juergen Schmidhuber},
      year={2020},
      eprint={1912.02875},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@InProceedings{pmlr-v139-nota21a,
  title = 	 {Posterior Value Functions: Hindsight Baselines for Policy Gradient Methods},
  author =       {Nota, Chris and Thomas, Philip and Silva, Bruno C. Da},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  year = 	 {2021},
}
@misc{wulfmeier2021dataefficient,
      title={Data-efficient Hindsight Off-policy Option Learning}, 
      author={Markus Wulfmeier and Dushyant Rao and Roland Hafner and Thomas Lampe and Abbas Abdolmaleki and Tim Hertweck and Michael Neunert and Dhruva Tirumala and Noah Siegel and Nicolas Heess and Martin Riedmiller},
      year={2021},
      eprint={2007.15588},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@article{guu-etal-2018-generating,
    title = "Generating Sentences by Editing Prototypes",
    author = "Guu, Kelvin  and
      Hashimoto, Tatsunori B.  and
      Oren, Yonatan  and
      Liang, Percy",
    journal = "Transactions of the Association for Computational Linguistics",
    year = "2018",
}



@inproceedings{10.5555/2969239.2969370,
author = {Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
title = {Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks},
year = {2015},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems },
}

@inproceedings{NIPS2016_16026d60,
 author = {Lamb, Alex M and Anirudh Goyal and Zhang, Ying and Zhang, Saizheng and Courville, Aaron C and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Professor Forcing: A New Algorithm for Training Recurrent Networks},
 year = {2016}
}





@inproceedings{10.5555/3298483.3298491,
author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
title = {The Option-Critic Architecture},
year = {2017},
booktitle = {Proceedings of the {Thirty-First AAAI Conference on Artificial Intelligence}},
}

@inproceedings{10.5555/647636.733043,
author = {Bain, Michael and Sammut, Claude},
title = {A Framework for Behavioural Cloning},
year = {1999},
booktitle = {Machine Intelligence 15, Intelligent Agents},
}


@inproceedings{10.5555/645528.657613,
author = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart J.},
title = {Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
year = {1999},
booktitle = {Proceedings of the {Sixteenth International Conference on Machine Learning}},
}



@inproceedings{abbeel2004apprenticeship,
author = {Abbeel, Pieter and Ng, Andrew Y.},
title = {Apprenticeship Learning via Inverse Reinforcement Learning},
year = {2004},
booktitle = {Proceedings of {the Twenty-First International Conference on Machine Learning}},
}

@article{10.5555/645529.657801, author = {Ng, Andrew Y. and Russell, Stuart J.}, title = {Algorithms for Inverse Reinforcement Learning}, year = {2000}, journal = {in ICML}}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv},
  volume={1707.06347},
  year={2017}
}

@inproceedings{45929,
title	= {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
author	= {Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
year	= {2017},
booktitle = {Proceedings of the Fifth International Conference of Learning Representations}}
}



@article{DBLP:journals/corr/DuanSCBSA16,
  author    = {Yan Duan and
               John Schulman and
               Xi Chen and
               Peter L. Bartlett and
               Ilya Sutskever and
               Pieter Abbeel},
  title     = {RL{\textdollar}{\^{}}2{\textdollar}: Fast Reinforcement Learning via
               Slow Reinforcement Learning},
  journal   = {arXiv},
  volume    = {1611.02779},
  year      = {2016}
}
@INPROCEEDINGS{pmlr-v80-smith18a,
  title = 	 {An Inference-Based Policy Gradient Method for Learning Options},
  author =       {Smith, Matthew and van Hoof, Herke and Pineau, Joelle},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
}

@article{Arulkumaran_2017,
   title={Deep Reinforcement Learning: A Brief Survey},
   journal={IEEE Signal Processing Magazine},
   author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
   year={2017},
}


@misc{bayer2015learning,
      title={Learning Stochastic Recurrent Networks}, 
      author={Justin Bayer and Christian Osendorfer},
      year={2015},
      eprint={1411.7610},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{Karl2017DeepVB,
  title={Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data},
  author={M. Karl and Maximilian S{\"o}lch and J. Bayer and P. V. D. Smagt},
  journal={ArXiv},
  year={2017},
  volume={abs/1605.06432}
}

@ARTICLE{6392457,
  author={Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel A. D. and Babuska, Robert},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
  title={A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients}, 
  year={2012},}



@inproceedings{hca,
 author = {Harutyunyan, Anna and Dabney, Will and Mesnard, Thomas and Gheshlaghi Azar, Mohammad and Piot, Bilal and Heess, Nicolas and van Hasselt, Hado P and Wayne, Gregory and Singh, Satinder and Precup, Doina and Munos, Remi},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Hindsight Credit Assignment},
 year = {2019}
}




@article{janner2020sequence,
  title={Reinforcement Learning as One Big Sequence Modeling Problem},
  author={Michael Janner and Qiyang Li and Sergey Levine},
  journal={arXiv preprint arXiv:2106.02039},
  year={2021},
}

@inproceedings{10.5555/3295222.3295416,
author = {Goyal, Anirudh and Sordoni, Alessandro and C\^{o}t\'{e}, Marc-Alexandre and Ke, Nan Rosemary and Bengio, Yoshua},
title = {Z-Forcing: Training Stochastic Recurrent Networks},
year = {2017},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
}

@inproceedings{
goyal2020recurrent,
title={Recurrent Independent Mechanisms},
author={Anirudh Goyal and Alex Lamb and Jordan Hoffmann and Shagun Sodhani and Sergey Levine and Yoshua Bengio and Bernhard Sch{\"o}lkopf},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{10.5555/3042573.3042813,
author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
title = {Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription},
year = {2012},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
}

@inproceedings{
madan2021meta,
title={Meta Attention Networks: Meta-Learning Attention to Modulate Information Between Recurrent Independent Mechanisms},
author={Kanika Madan and Nan Rosemary Ke and Anirudh Goyal and Bernhard Sch{\"o}lkopf and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
ke2018modeling,
title={Modeling the Long Term Future in Model-Based Reinforcement Learning},
author={Nan Rosemary Ke and Amanpreet Singh and Ahmed Touati and Anirudh Goyal and Yoshua Bengio and Devi Parikh and Dhruv Batra},
booktitle={International Conference on Learning Representations},
year={2019},
}

@misc{zhu2020transfer,
      title={Transfer Learning in Deep Reinforcement Learning: A Survey}, 
      author={Zhuangdi Zhu and Kaixiang Lin and Jiayu Zhou},
      year={2020},
      eprint={2009.07888},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kingma2014autoencoding,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2014},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{Bellemare_2013,
   title={The Arcade Learning Environment: An Evaluation Platform for General Agents},
   journal={Journal of Artificial Intelligence Research},
   author={Bellemare, M. G. and Naddaf, Y. and Veness, J. and Bowling, M.},
   year={2013},
  }

@inproceedings{
Osband2020Behaviour,
title={Behaviour Suite for Reinforcement Learning},
author={Ian Osband and Yotam Doron and Matteo Hessel and John Aslanides and Eren Sezener and Andre Saraiva and Katrina McKinney and Tor Lattimore and Csaba Szepesvari and Satinder Singh and Benjamin Van Roy and Richard Sutton and David Silver and Hado Van Hasselt},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{bowman-etal-2016-generating,
    title = "Generating Sentences from a Continuous Space",
    author = "Bowman, Samuel R.  and
      Vilnis, Luke  and
      Vinyals, Oriol  and
      Dai, Andrew  and
      Jozefowicz, Rafal  and
      Bengio, Samy",
    booktitle = "Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning",
    year = "2016",
}

@INPROCEEDINGS{Singh94learningwithout,
    author = {Satinder P. Singh},
    title = {Learning without state-estimation in partially observable markovian decision processes},
    booktitle = {In Proceedings of the Eleventh International Conference on Machine Learning},
    year = {1994},
}

@inproceedings{NIPS2009_e58cc5ca,
 author = {Cai, Chenghui and Liao, Xuejun and Carin, Lawrence},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Learning to Explore and Exploit in POMDPs},
 year = {2009}
}

@misc{pytorchrl,
  author = {Kostrikov, Ilya},
  title = {PyTorch Implementations of Reinforcement Learning Algorithms},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail}},
}

@misc{levine2018reinforcement,
      title={Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review}, 
      author={Sergey Levine},
      year={2018},
      eprint={1805.00909},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{10.5555/3524938.3524949,
author = {Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
title = {An Optimistic Perspective on Offline Reinforcement Learning},
year = {2020},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
series = {ICML'20}
}

@inproceedings{fujimoto2019off,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019}
}

@INPROCEEDINGS{henderson2017optiongan,
	author = {Peter Henderson and Wei-Di Chang and Pierre-Luc Bacon and David Meger and Joelle Pineau and Doina Precup},
	title = {OptionGAN: Learning Joint Reward-Policy Options Using Generative Adversarial Inverse Reinforcement Learning},
	booktitle = {In Proceedings of the {Thirty-Second AAAI Conference on Artificial Intelligence}},
	year = {2018},
}

@INPROCEEDINGS{6386109, 
author={E. {Todorov} and T. {Erez} and Y. {Tassa}}, 
booktitle={2012 {IEEE/RSJ} International Conference on Intelligent Robots and Systems}, 
title={{MuJoCo}: A physics engine for model-based control},
year={2012}
}

@article{Krishnan2015,
       author = {{Krishnan}, Rahul G. and {Shalit}, Uri and {Sontag}, David},
        title = "{Deep Kalman Filters}",
      journal = {ArXiv},
         year = 2015,
       volume = {1511.05121},
}


@inproceedings{agarwal2020optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

BibTeX
@inproceedings{10.1145/3462244.3479913,
author = {Akula, Jayaprakash and Abhishek and Dabral, Rishabh and Jyothi, Preethi and Ramakrishnan, Ganesh},
title = {Cross Lingual Video and Text Retrieval: A New Benchmark Dataset and Algorithm},
year = {2021},
address = {New York, NY, USA},
booktitle = {Proceedings of the 2021 International Conference on Multimodal Interaction},
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 year = {2017}
}


@misc{https://doi.org/10.48550/arxiv.2103.05247,
  doi = {10.48550/ARXIV.2103.05247},
  
  author = {Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  
  title = {Pretrained Transformers as Universal Computation Engines},
  

  year = {2021},
  
}


@inproceedings{10.5555/3327144.3327175,
author = {Bastani, Osbert and Pu, Yewen and Solar-Lezama, Armando},
title = {Verifiable Reinforcement Learning via Policy Extraction},
year = {2018},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
}

@article{JMLR:v21:20-074,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
}

@inproceedings{ijcai2020p651,
  title     = {Playing Atari with Six Neurons (Extended Abstract)},
  author    = {Cuccu, Giuseppe and Togelius, Julian and Cudré-Mauroux, Philippe},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  year      = {2020},
}


@misc{https://doi.org/10.48550/arxiv.2205.06175,
  doi = {10.48550/ARXIV.2205.06175},
  

  author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and Eccles, Tom and Bruce, Jake and Razavi, Ali and Edwards, Ashley and Heess, Nicolas and Chen, Yutian and Hadsell, Raia and Vinyals, Oriol and Bordbar, Mahyar and de Freitas, Nando},
  
  title = {A Generalist Agent},
  

  year = {2022},
  
}
@article{JMLR:v10:taylor09a,
  author  = {Matthew E. Taylor and Peter Stone},
  title   = {Transfer Learning for Reinforcement Learning Domains: A Survey},
  journal = {Journal of Machine Learning Research},
  year    = {2009},
}

@Inbook{Tzeng2020,
author="Tzeng, Eric
and Devin, Coline
and Hoffman, Judy
and Finn, Chelsea
and Abbeel, Pieter
and Levine, Sergey
and Saenko, Kate
and Darrell, Trevor,
and Abbeel, Pieter
and Bekris, Kostas
and Miller, Lauren",
title="Adapting Deep Visuomotor Representations with Weak Pairwise Constraints",
bookTitle="Algorithmic Foundations of Robotics XII: Proceedings of the Twelfth Workshop on the Algorithmic Foundations of Robotics",
year="2020",
}

@inproceedings{10.5555/3495724.3495824,
author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
title = {Conservative Q-Learning for Offline Reinforcement Learning},
year = {2020},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
series = {NIPS'20}
}

@inproceedings{ParisottoBS15,
  author={Emilio Parisotto and Lei Jimmy Ba and Ruslan Salakhutdinov},
  title={Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning},
  year={2016},
  cdate={1451606400000},
  booktitle={ICLR (Poster)},
}



@inproceedings{policydist,
  author={Andrei A. Rusu and Sergio Gomez Colmenarejo and Çaglar Gülçehre and Guillaume Desjardins and James Kirkpatrick and Razvan Pascanu and Volodymyr Mnih and Koray Kavukcuoglu and Raia Hadsell},
  title={Policy Distillation},
  year={2016},
  cdate={1451606400000},
  booktitle={ICLR (Poster)},
}

@INPROCEEDINGS{7487140,
  author={Mordatch, Igor and Mishra, Nikhil and Eppner, Clemens and Abbeel, Pieter},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Combining model-based policy search with online model learning for control of physical humanoids}, 
  year={2016},
}
@inproceedings{10.5555/3045390.3045684,
author = {Oh, Junhyuk and Chockalingam, Valliappa and Singh, Satinder and Lee, Honglak},
title = {Control of Memory, Active Perception, and Action in Minecraft},
year = {2016},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning},
}

@TECHREPORT{Zhu02learningfrom,
    author = {Xiaojin Zhu and Zoubin Ghahramani},
    title = {Learning from Labeled and Unlabeled Data with Label Propagation},
    institution = {},
    year = {2002}
}

@misc{https://doi.org/10.48550/arxiv.2011.13885,
  doi = {10.48550/ARXIV.2011.13885},
  
  author = {Zolna, Konrad and Novikov, Alexander and Konyushkova, Ksenia and Gulcehre, Caglar and Wang, Ziyu and Aytar, Yusuf and Denil, Misha and de Freitas, Nando and Reed, Scott},
 
  
  title = {Offline Learning from Demonstrations and Unlabeled Experience},
  
  publisher = {arXiv},
  
  year = {2020},
  
}

@incollection{mnih-atari-2013,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  booktitle = {NIPS Deep Learning Workshop},
  year = {2013}
}
@article{sciencepub,
author = {Max Jaderberg  and Wojciech M. Czarnecki  and Iain Dunning  and Luke Marris  and Guy Lever  and Antonio Garcia Castañeda  and Charles Beattie  and Neil C. Rabinowitz  and Ari S. Morcos  and Avraham Ruderman  and Nicolas Sonnerat  and Tim Green  and Louise Deason  and Joel Z. Leibo  and David Silver  and Demis Hassabis  and Koray Kavukcuoglu  and Thore Graepel },
title = {Human-level performance in 3D multiplayer games with population-based reinforcement learning},
journal = {Science},
year = {2019}}


@inproceedings{
ye2021mastering,
title={Mastering Atari Games with Limited Data},
author={Weirui Ye and Shaohuai Liu and Thanard Kurutach and Pieter Abbeel and Yang Gao},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
}

@misc{https://doi.org/10.48550/arxiv.1912.06680,
  doi = {10.48550/ARXIV.1912.06680},
  

  author = {Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dębiak, Przemysław and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Pinto, Henrique P. d. O. and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Dota 2 with Large Scale Deep Reinforcement Learning},
  

  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{
Baker2020Emergent,
title={Emergent Tool Use From Multi-Agent Autocurricula},
author={Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
booktitle={International Conference on Learning Representations},
year={2020},
}



@TECHREPORT{metarl,
    author = {Jürgen Schmidhuber},
    title = {Evolutionary principles in self-referential learning. (On learning how to learn: The meta-meta-... hook.},
    institution = {PhD Thesis},
    year = {1987}
}

@InProceedings{pmlr-v97-rakelly19a,
  title = 	 {Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables},
  author =       {Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
  series = 	 {Proceedings of Machine Learning Research},
}

@inproceedings{10.5555/3305381.3305498,
author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
title = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
year = {2017},
booktitle = {Proceedings of the 34th International Conference on Machine Learning},
}
@inproceedings{
clavera2018learning,
title={Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning},
author={Ignasi Clavera and Anusha Nagabandi and Simin Liu and Ronald S. Fearing and Pieter Abbeel and Sergey Levine and Chelsea Finn},
booktitle={International Conference on Learning Representations},
year={2019},
}

@InProceedings{pmlr-v162-pong22a,
  title = 	 {Offline Meta-Reinforcement Learning with Online Self-Supervision},
  author =       {Pong, Vitchyr H and Nair, Ashvin V and Smith, Laura M and Huang, Catherine and Levine, Sergey},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},  year = 	 {2022},
  series = 	 {Proceedings of Machine Learning Research},

}

@misc{
duan2017rl,
title={{RL}{\textasciicircum}2: Fast Reinforcement Learning via Slow Reinforcement Learning},
author={Yan Duan and John Schulman and Xi Chen and Peter L. Bartlett and Ilya Sutskever and Pieter Abbeel},
year={2017},
}

@INPROCEEDINGS{155621,
  author={Bengio, Y. and Bengio, S. and Cloutier, J.},
  booktitle={IJCNN-91-Seattle International Joint Conference on Neural Networks}, 
  title={Learning a synaptic learning rule}, 
  year={1991},
  number={},
}

@InProceedings{pmlr-v139-sodhani21a,
  title = 	 {Multi-Task Reinforcement Learning with Context-based Representations},
  author =       {Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  year = 	 {2021},
  series = 	 {Proceedings of Machine Learning Research},
}


@inproceedings{
zhang2021learning,
title={Learning Robust State Abstractions for Hidden-Parameter Block {\{}MDP{\}}s},
author={Amy Zhang and Shagun Sodhani and Khimya Khetarpal and Joelle Pineau},
booktitle={International Conference on Learning Representations},
year={2021},
}

@InProceedings{10.1007/978-3-030-46133-1_9,
author="Br{\"a}m, Timo
and Brunner, Gino
and Richter, Oliver
and Wattenhofer, Roger",
title="Attentive Multi-task Deep Reinforcement Learning",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2020",
}


@inproceedings{
DEramo2020Sharing,
title={Sharing Knowledge in Multi-Task Deep Reinforcement Learning},
author={Carlo D'Eramo and Davide Tateo and Andrea Bonarini and Marcello Restelli and Jan Peters},
booktitle={International Conference on Learning Representations},
year={2020},
}

@misc{https://doi.org/10.48550/arxiv.1603.02041,
  doi = {10.48550/ARXIV.1603.02041},
  
  author = {Borsa, Diana and Graepel, Thore and Shawe-Taylor, John},
  
  keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning Shared Representations in Multi-task Reinforcement Learning},
  

  year = {2016},
  
}

@misc{https://doi.org/10.48550/arxiv.1706.05098,


  author = {Ruder, Sebastian},
  

  title = {An Overview of Multi-Task Learning in Deep Neural Networks},
  
  publisher = {arXiv},
  
  year = {2017},
  
}


@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}

@article{10.1023/A:1007379606734,
author = {Caruana, Rich},
title = {Multitask Learning},
year = {1997},
issue_date = {July 1997}
}

@InProceedings{10.1007/978-3-319-10599-4_7,
author="Zhang, Zhanpeng
and Luo, Ping
and Loy, Chen Change
and Tang, Xiaoou",
title="Facial Landmark Detection by Deep Multi-task Learning",
booktitle="Computer Vision -- ECCV 2014",
year="2014",

}

@inproceedings{NIPS2014_94c7bb58,
 author = {Calandriello, Daniele and Lazaric, Alessandro and Restelli, Marcello},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Sparse Multi-Task Reinforcement Learning},
 year = {2014}
}


@article{zhang2018study,
  title={A study on overfitting in deep reinforcement learning},
  author={Zhang, Chiyuan and Vinyals, Oriol and Munos, Remi and Bengio, Samy},
  journal={arXiv preprint arXiv:1804.06893},
  year={2018}
}

@inproceedings{10.5555/2969442.2969635,
author = {Rasmus, Antti and Valpola, Harri and Honkala, Mikko and Berglund, Mathias and Raiko, Tapani},
title = {Semi-Supervised Learning with Ladder Networks},
year = {2015},
abstract = {We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on top of the Ladder network proposed by Valpola [1] which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification in addition to permutation-invariant MNIST classification with all labels.},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems},
}


@inproceedings{10.5555/2969033.2969226,
author = {Kingma, Diederik P. and Rezende, Danilo J. and Mohamed, Shakir and Welling, Max},
title = {Semi-Supervised Learning with Deep Generative Models},
year = {2014},
booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems},
}

@inproceedings{NIPS2001_a82d922b,
 author = {Szummer, Martin and Jaakkola, Tommi},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Partially labeled classification with Markov random walks},
 year = {2001}
}



@book{10.5555/1717872,
author = {Zhu, Xiaojin and Goldberg, Andrew B. and Brachman, Ronald and Dietterich, Thomas},
title = {Introduction to Semi-Supervised Learning},
year = {2009},
}

@misc{https://doi.org/10.48550/arxiv.1904.00962,
  author = {You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Large Batch Optimization for Deep Learning: Training BERT in 76 minutes},
  
  publisher = {arXiv},
  
  year = {2019},
  }
  
 @article{yang2022chain,
  title={Chain of Thought Imitation with Procedure Cloning},
  author={Yang, Mengjiao and Schuurmans, Dale and Abbeel, Pieter and Nachum, Ofir},
  journal={arXiv preprint arXiv:2205.10816},
  year={2022}
}

@software{deepmind2020jax,
  title = {The {D}eep{M}ind {JAX} {E}cosystem},
  author = {Babuschkin, Igor and Baumli, Kate and Bell, Alison and Bhupatiraju, Surya and Bruce, Jake and Buchlovsky, Peter and Budden, David and Cai, Trevor and Clark, Aidan and Danihelka, Ivo and Fantacci, Claudio and Godwin, Jonathan and Jones, Chris and Hemsley, Ross and Hennigan, Tom and Hessel, Matteo and Hou, Shaobo and Kapturowski, Steven and Keck, Thomas and Kemaev, Iurii and King, Michael and Kunesch, Markus and Martens, Lena and Merzic, Hamza and Mikulik, Vladimir and Norman, Tamara and Quan, John and Papamakarios, George and Ring, Roman and Ruiz, Francisco and Sanchez, Alvaro and Schneider, Rosalia and Sezener, Eren and Spencer, Stephen and Srinivasan, Srivatsan and Wang, Luyu and Stokowiec, Wojciech and Viola, Fabio},
  year = {2020},
}

@INPROCEEDINGS{6386109,
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={MuJoCo: A physics engine for model-based control}, 
  year={2012},
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@InProceedings{pmlr-v119-cobbe20a,
  title = 	 {Leveraging Procedural Generation to Benchmark Reinforcement Learning},
  author =       {Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  year = 	 {2020},

  series = 	 {Proceedings of Machine Learning Research},
}


@Article{young19minatar,
author = {{Young}, Kenny and {Tian}, Tian},
title = {MinAtar: An Atari-Inspired Testbed for Thorough and Reproducible Reinforcement Learning Experiments},
journal = {arXiv preprint arXiv:1903.03176},
year = "2019"
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@article{10.2307/171139,
 ISSN = {0030364X, 15265463},
 author = {Ross D. Shachter},
 journal = {Operations Research},
 title = {Probabilistic Inference and Influence Diagrams},
 year = {1988}
}



@inproceedings{NIPS2006_d806ca13,
 author = {Todorov, Emanuel},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Linearly-solvable Markov decision problems},
 year = {2006}
}




@misc{https://doi.org/10.48550/arxiv.2205.15241,
  author = {Lee, Kuang-Huei and Nachum, Ofir and Yang, Mengjiao and Lee, Lisa and Freeman, Daniel and Xu, Winnie and Guadarrama, Sergio and Fischer, Ian and Jang, Eric and Michalewski, Henryk and Mordatch, Igor},
  
  title = {Multi-Game Decision Transformers},
  
  publisher = {arXiv},
  
  year = {2022},
  
}

@misc{https://doi.org/10.48550/arxiv.2106.01345,
  doi = {10.48550/ARXIV.2106.01345},
  

  author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  
  title = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
  
  publisher = {arXiv},
  
  year = {2021},
  
}

@article{10.5555/2566972.2566979,
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
year = {2013},
journal = {J. Artif. Int. Res.},
}

@inproceedings{NEURIPS2021_7f489f64,
 author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
 year = {2021}
}

@inproceedings{
Baker2020Emergent,
title={Emergent Tool Use From Multi-Agent Autocurricula},
author={Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{4936,
  title = {Learning Inverse Dynamics: A Comparison},
  author = {Nguyen-Tuong, D. and Peters, J. and Seeger, M. and Sch{\"o}lkopf, B.},
  journal = {Advances in Computational Intelligence and Learning: Proceedings of the European Symposium on Artificial Neural Networks (ESANN 2008)},
  booktitle = {Advances in Computational Intelligence and Learning: Proceedings of the European Symposium on Artificial Neural Networks},
  year = {2008},
}

@misc{https://doi.org/10.48550/arxiv.1912.06680,
  doi = {10.48550/ARXIV.1912.06680},
  

  author = {Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dębiak, Przemysław and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Pinto, Henrique P. d. O. and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
  

  title = {Dota 2 with Large Scale Deep Reinforcement Learning},
  

  year = {2019},
  
}

@misc{https://doi.org/10.48550/arxiv.2106.04560,
  doi = {10.48550/ARXIV.2106.04560},
  

  author = {Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  

  title = {Scaling Vision Transformers},
  

  year = {2021},
  
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    year = "2019",
    publisher = "Association for Computational Linguistics",
}

@phdthesis{kalousis2002algorithm,
  title={Algorithm selection via meta-learning},
  author={Kalousis, Alexandros},
  year={2002},
  school={University of Geneva}
}

@INPROCEEDINGS{9533842,
  author={Lacombe, Thomas and Koh, Yun Sing and Dobbie, Gillian and Wu, Ocean},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={A Meta-Learning Approach for Automated Hyperparameter Tuning in Evolving Data Streams}, 
  year={2021},
  number={},
}
@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Language Models are Few-Shot Learners},
 year = {2020}
}

@inproceedings{DBLP:conf/eccv/MahajanGRHPLBM18,
  author    = {Dhruv Mahajan and
               Ross B. Girshick and
               Vignesh Ramanathan and
               Kaiming He and
               Manohar Paluri and
               Yixuan Li and
               Ashwin Bharambe and
               Laurens van der Maaten},
  title     = {Exploring the Limits of Weakly Supervised Pretraining},
  booktitle = {Computer Vision - {ECCV} 2018 - 15th European Conference, Proceedings, Part {II}},
  year      = {2018},
}

@inproceedings{10.5555/3327144.3327216,
author = {Aytar, Yusuf and Pfaff, Tobias and Budden, David and Paine, Tom Le and Wang, Ziyu and Freitas, Nando de},
title = {Playing Hard Exploration Games by Watching YouTube},
year = {2018},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}



@misc{https://doi.org/10.48550/arxiv.2108.07258,


  author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
  

  title = {On the Opportunities and Risks of Foundation Models},
  
  publisher = {arXiv},
  
  year = {2021},
  
}

@article{gulcehre2020rl,
  title={Rl unplugged: A suite of benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Thomas and G{\'o}mez, Sergio and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh S and Mankowitz, Daniel J and Paduraru, Cosmin and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7248--7259},
  year={2020}
}