\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2020{\natexlab{a}})Agarwal, Schuurmans, and
  Norouzi]{10.5555/3524938.3524949}
Rishabh Agarwal, Dale Schuurmans, and Mohammad Norouzi.
\newblock An optimistic perspective on offline reinforcement learning.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, ICML'20, 2020{\natexlab{a}}.

\bibitem[Agarwal et~al.(2020{\natexlab{b}})Agarwal, Schuurmans, and
  Norouzi]{agarwal2020optimistic}
Rishabh Agarwal, Dale Schuurmans, and Mohammad Norouzi.
\newblock An optimistic perspective on offline reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  104--114. PMLR, 2020{\natexlab{b}}.

\bibitem[Aytar et~al.(2018)Aytar, Pfaff, Budden, Paine, Wang, and
  Freitas]{10.5555/3327144.3327216}
Yusuf Aytar, Tobias Pfaff, David Budden, Tom~Le Paine, Ziyu Wang, and Nando~de
  Freitas.
\newblock Playing hard exploration games by watching youtube.
\newblock NIPS'18, 2018.

\bibitem[Baker et~al.(2022)Baker, Akkaya, Zhokhov, Huizinga, Tang, Ecoffet,
  Houghton, Sampedro, and Clune]{https://doi.org/10.48550/arxiv.2206.11795}
Bowen Baker, Ilge Akkaya, Peter Zhokhov, Joost Huizinga, Jie Tang, Adrien
  Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune.
\newblock Video pretraining (vpt): Learning to act by watching unlabeled online
  videos, 2022.

\bibitem[Bengio et~al.(1991)Bengio, Bengio, and Cloutier]{155621}
Y.~Bengio, S.~Bengio, and J.~Cloutier.
\newblock Learning a synaptic learning rule.
\newblock In \emph{IJCNN-91-Seattle International Joint Conference on Neural
  Networks}, 1991.

\bibitem[Borsa et~al.(2016)Borsa, Graepel, and
  Shawe-Taylor]{https://doi.org/10.48550/arxiv.1603.02041}
Diana Borsa, Thore Graepel, and John Shawe-Taylor.
\newblock Learning shared representations in multi-task reinforcement learning,
  2016.

\bibitem[Br{\"a}m et~al.(2020)Br{\"a}m, Brunner, Richter, and
  Wattenhofer]{10.1007/978-3-030-46133-1_9}
Timo Br{\"a}m, Gino Brunner, Oliver Richter, and Roger Wattenhofer.
\newblock Attentive multi-task deep reinforcement learning.
\newblock In \emph{Machine Learning and Knowledge Discovery in Databases},
  2020.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{NEURIPS2020_1457c0d6}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Calandriello et~al.(2014)Calandriello, Lazaric, and
  Restelli]{NIPS2014_94c7bb58}
Daniele Calandriello, Alessandro Lazaric, and Marcello Restelli.
\newblock Sparse multi-task reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Caruana(1997)]{10.1023/A:1007379606734}
Rich Caruana.
\newblock Multitask learning.
\newblock 1997.

\bibitem[Chen et~al.(2021{\natexlab{a}})Chen, Lu, Rajeswaran, Lee, Grover,
  Laskin, Abbeel, Srinivas, and
  Mordatch]{https://doi.org/10.48550/arxiv.2106.01345}
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael
  Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling,
  2021{\natexlab{a}}.

\bibitem[Chen et~al.(2021{\natexlab{b}})Chen, Lu, Rajeswaran, Lee, Grover,
  Laskin, Abbeel, Srinivas, and Mordatch]{NEURIPS2021_7f489f64}
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha
  Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2021{\natexlab{b}}.

\bibitem[Clavera et~al.(2019)Clavera, Nagabandi, Liu, Fearing, Abbeel, Levine,
  and Finn]{clavera2018learning}
Ignasi Clavera, Anusha Nagabandi, Simin Liu, Ronald~S. Fearing, Pieter Abbeel,
  Sergey Levine, and Chelsea Finn.
\newblock Learning to adapt in dynamic, real-world environments through
  meta-reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[D'Eramo et~al.(2020)D'Eramo, Tateo, Bonarini, Restelli, and
  Peters]{DEramo2020Sharing}
Carlo D'Eramo, Davide Tateo, Andrea Bonarini, Marcello Restelli, and Jan
  Peters.
\newblock Sharing knowledge in multi-task deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock Association for Computational Linguistics, 2019.

\bibitem[Duan et~al.(2017)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{duan2017rl}
Yan Duan, John Schulman, Xi~Chen, Peter~L. Bartlett, Ilya Sutskever, and Pieter
  Abbeel.
\newblock {RL}{\textasciicircum}2: Fast reinforcement learning via slow
  reinforcement learning, 2017.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{10.5555/3305381.3305498}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, 2017.

\bibitem[Fujimoto et~al.(2019)Fujimoto, Meger, and Precup]{fujimoto2019off}
Scott Fujimoto, David Meger, and Doina Precup.
\newblock Off-policy deep reinforcement learning without exploration.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2052--2062, 2019.

\bibitem[Gulcehre et~al.(2020)Gulcehre, Wang, Novikov, Paine, G{\'o}mez, Zolna,
  Agarwal, Merel, Mankowitz, Paduraru, et~al.]{gulcehre2020rl}
Caglar Gulcehre, Ziyu Wang, Alexander Novikov, Thomas Paine, Sergio G{\'o}mez,
  Konrad Zolna, Rishabh Agarwal, Josh~S Merel, Daniel~J Mankowitz, Cosmin
  Paduraru, et~al.
\newblock Rl unplugged: A suite of benchmarks for offline reinforcement
  learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 7248--7259, 2020.

\bibitem[Kalousis(2002)]{kalousis2002algorithm}
Alexandros Kalousis.
\newblock \emph{Algorithm selection via meta-learning}.
\newblock PhD thesis, University of Geneva, 2002.

\bibitem[Kingma et~al.(2014)Kingma, Rezende, Mohamed, and
  Welling]{10.5555/2969033.2969226}
Diederik~P. Kingma, Danilo~J. Rezende, Shakir Mohamed, and Max Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In \emph{Proceedings of the 27th International Conference on Neural
  Information Processing Systems}, 2014.

\bibitem[Kumar et~al.(2019)Kumar, Fu, Soh, Tucker, and
  Levine]{NEURIPS2019_c2073ffa}
Aviral Kumar, Justin Fu, Matthew Soh, George Tucker, and Sergey Levine.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and
  Levine]{10.5555/3495724.3495824}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock In \emph{Proceedings of the 34th International Conference on Neural
  Information Processing Systems}, NIPS'20, 2020.

\bibitem[Lacombe et~al.(2021)Lacombe, Koh, Dobbie, and Wu]{9533842}
Thomas Lacombe, Yun~Sing Koh, Gillian Dobbie, and Ocean Wu.
\newblock A meta-learning approach for automated hyperparameter tuning in
  evolving data streams.
\newblock In \emph{2021 International Joint Conference on Neural Networks
  (IJCNN)}, 2021.

\bibitem[Lee et~al.(2022)Lee, Nachum, Yang, Lee, Freeman, Xu, Guadarrama,
  Fischer, Jang, Michalewski, and
  Mordatch]{https://doi.org/10.48550/arxiv.2205.15241}
Kuang-Huei Lee, Ofir Nachum, Mengjiao Yang, Lisa Lee, Daniel Freeman, Winnie
  Xu, Sergio Guadarrama, Ian Fischer, Eric Jang, Henryk Michalewski, and Igor
  Mordatch.
\newblock Multi-game decision transformers, 2022.

\bibitem[Mahajan et~al.(2018)Mahajan, Girshick, Ramanathan, He, Paluri, Li,
  Bharambe, and van~der Maaten]{DBLP:conf/eccv/MahajanGRHPLBM18}
Dhruv Mahajan, Ross~B. Girshick, Vignesh Ramanathan, Kaiming He, Manohar
  Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van~der Maaten.
\newblock Exploring the limits of weakly supervised pretraining.
\newblock In \emph{Computer Vision - {ECCV} 2018 - 15th European Conference,
  Proceedings, Part {II}}, 2018.

\bibitem[Mordatch et~al.(2016)Mordatch, Mishra, Eppner, and Abbeel]{7487140}
Igor Mordatch, Nikhil Mishra, Clemens Eppner, and Pieter Abbeel.
\newblock Combining model-based policy search with online model learning for
  control of physical humanoids.
\newblock In \emph{2016 IEEE International Conference on Robotics and
  Automation (ICRA)}, 2016.

\bibitem[Nachum et~al.(2019)Nachum, Dai, Kostrikov, Chow, Li, and
  Schuurmans]{nachum2019algaedice}
Ofir Nachum, Bo~Dai, Ilya Kostrikov, Yinlam Chow, Lihong Li, and Dale
  Schuurmans.
\newblock Algaedice: Policy gradient from arbitrary experience, 2019.

\bibitem[Nguyen-Tuong et~al.(2008)Nguyen-Tuong, Peters, Seeger, and
  Sch{\"o}lkopf]{4936}
D.~Nguyen-Tuong, J.~Peters, M.~Seeger, and B.~Sch{\"o}lkopf.
\newblock Learning inverse dynamics: A comparison.
\newblock In \emph{Advances in Computational Intelligence and Learning:
  Proceedings of the European Symposium on Artificial Neural Networks}, 2008.

\bibitem[Oh et~al.(2016)Oh, Chockalingam, Singh, and
  Lee]{10.5555/3045390.3045684}
Junhyuk Oh, Valliappa Chockalingam, Satinder Singh, and Honglak Lee.
\newblock Control of memory, active perception, and action in minecraft.
\newblock In \emph{Proceedings of the 33rd International Conference on
  International Conference on Machine Learning}, 2016.

\bibitem[Parisotto et~al.(2016)Parisotto, Ba, and Salakhutdinov]{ParisottoBS15}
Emilio Parisotto, Lei~Jimmy Ba, and Ruslan Salakhutdinov.
\newblock Actor-mimic: Deep multitask and transfer reinforcement learning.
\newblock In \emph{ICLR (Poster)}, 2016.

\bibitem[Pong et~al.(2022)Pong, Nair, Smith, Huang, and
  Levine]{pmlr-v162-pong22a}
Vitchyr~H Pong, Ashvin~V Nair, Laura~M Smith, Catherine Huang, and Sergey
  Levine.
\newblock Offline meta-reinforcement learning with online self-supervision.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research, 2022.

\bibitem[Radford et~al.(2019{\natexlab{a}})Radford, Wu, Child, Luan, Amodei,
  and Sutskever]{Radford2019LanguageMA}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019{\natexlab{a}}.

\bibitem[Radford et~al.(2019{\natexlab{b}})Radford, Wu, Child, Luan, Amodei,
  and Sutskever]{radford2019language}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019{\natexlab{b}}.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Finn, Levine, and
  Quillen]{pmlr-v97-rakelly19a}
Kate Rakelly, Aurick Zhou, Chelsea Finn, Sergey Levine, and Deirdre Quillen.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research, 2019.

\bibitem[Rasmus et~al.(2015)Rasmus, Valpola, Honkala, Berglund, and
  Raiko]{10.5555/2969442.2969635}
Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, and Tapani Raiko.
\newblock Semi-supervised learning with ladder networks.
\newblock In \emph{Proceedings of the 28th International Conference on Neural
  Information Processing Systems}, 2015.

\bibitem[Reed et~al.(2022)Reed, Zolna, Parisotto, Colmenarejo, Novikov,
  Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, Eccles, Bruce, Razavi,
  Edwards, Heess, Chen, Hadsell, Vinyals, Bordbar, and
  de~Freitas]{https://doi.org/10.48550/arxiv.2205.06175}
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio~Gomez Colmenarejo, Alexander
  Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
  Jost~Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards,
  Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar, and
  Nando de~Freitas.
\newblock A generalist agent, 2022.

\bibitem[Ruder(2017)]{https://doi.org/10.48550/arxiv.1706.05098}
Sebastian Ruder.
\newblock An overview of multi-task learning in deep neural networks, 2017.

\bibitem[Rusu et~al.(2016)Rusu, Colmenarejo, Çaglar Gülçehre, Desjardins,
  Kirkpatrick, Pascanu, Mnih, Kavukcuoglu, and Hadsell]{policydist}
Andrei~A. Rusu, Sergio~Gomez Colmenarejo, Çaglar Gülçehre, Guillaume
  Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray
  Kavukcuoglu, and Raia Hadsell.
\newblock Policy distillation.
\newblock In \emph{ICLR (Poster)}, 2016.

\bibitem[Schmidhuber(1987)]{metarl}
Jürgen Schmidhuber.
\newblock Evolutionary principles in self-referential learning. (on learning
  how to learn: The meta-meta-... hook.
\newblock Technical report, PhD Thesis, 1987.

\bibitem[Seo et~al.(2022)Seo, Lee, James, and Abbeel]{pmlr-v162-seo22a}
Younggyo Seo, Kimin Lee, Stephen~L James, and Pieter Abbeel.
\newblock Reinforcement learning with action-free pre-training from videos.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le~Song, Csaba Szepesvari,
  Gang Niu, and Sivan Sabato (eds.), \emph{Proceedings of the 39th
  International Conference on Machine Learning}, 2022.

\bibitem[Sodhani et~al.(2021)Sodhani, Zhang, and Pineau]{pmlr-v139-sodhani21a}
Shagun Sodhani, Amy Zhang, and Joelle Pineau.
\newblock Multi-task reinforcement learning with context-based representations.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research, 2021.

\bibitem[Szummer \& Jaakkola(2001)Szummer and Jaakkola]{NIPS2001_a82d922b}
Martin Szummer and Tommi Jaakkola.
\newblock Partially labeled classification with markov random walks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2001.

\bibitem[Taylor \& Stone(2009)Taylor and Stone]{JMLR:v10:taylor09a}
Matthew~E. Taylor and Peter Stone.
\newblock Transfer learning for reinforcement learning domains: A survey.
\newblock \emph{Journal of Machine Learning Research}, 2009.

\bibitem[Tzeng et~al.(2020)Tzeng, Devin, Hoffman, Finn, Abbeel, Levine, Saenko,
  Darrell, Abbeel, Bekris, and Miller]{Tzeng2020}
Eric Tzeng, Coline Devin, Judy Hoffman, Chelsea Finn, Pieter Abbeel, Sergey
  Levine, Kate Saenko, Trevor Darrell, Pieter Abbeel, Kostas Bekris, and Lauren
  Miller.
\newblock \emph{Adapting Deep Visuomotor Representations with Weak Pairwise
  Constraints}.
\newblock 2020.

\bibitem[Wu et~al.(2020)Wu, Tucker, and Nachum]{wu2020behavior}
Yifan Wu, George Tucker, and Ofir Nachum.
\newblock Behavior regularized offline reinforcement learning, 2020.
\newblock URL \url{https://openreview.net/forum?id=BJg9hTNKPH}.

\bibitem[Yang et~al.(2022)Yang, Schuurmans, Abbeel, and Nachum]{yang2022chain}
Mengjiao Yang, Dale Schuurmans, Pieter Abbeel, and Ofir Nachum.
\newblock Chain of thought imitation with procedure cloning.
\newblock \emph{arXiv preprint arXiv:2205.10816}, 2022.

\bibitem[Ye et~al.(2021)Ye, Liu, Kurutach, Abbeel, and Gao]{ye2021mastering}
Weirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, and Yang Gao.
\newblock Mastering atari games with limited data.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Zhai et~al.(2021)Zhai, Kolesnikov, Houlsby, and
  Beyer]{https://doi.org/10.48550/arxiv.2106.04560}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers, 2021.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Sodhani, Khetarpal, and
  Pineau]{zhang2021learning}
Amy Zhang, Shagun Sodhani, Khimya Khetarpal, and Joelle Pineau.
\newblock Learning robust state abstractions for hidden-parameter block
  {\{}mdp{\}}s.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Kuppannagari, and
  Prasanna]{zhang2021brac}
Chi Zhang, Sanmukh~Rao Kuppannagari, and Viktor Prasanna.
\newblock {\{}BRAC{\}}+: Going deeper with behavior regularized offline
  reinforcement learning, 2021{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=bMCfFepJXM}.

\bibitem[Zhang et~al.(2018)Zhang, Vinyals, Munos, and Bengio]{zhang2018study}
Chiyuan Zhang, Oriol Vinyals, Remi Munos, and Samy Bengio.
\newblock A study on overfitting in deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1804.06893}, 2018.

\bibitem[Zhang et~al.(2014)Zhang, Luo, Loy, and
  Tang]{10.1007/978-3-319-10599-4_7}
Zhanpeng Zhang, Ping Luo, Chen~Change Loy, and Xiaoou Tang.
\newblock Facial landmark detection by deep multi-task learning.
\newblock In \emph{Computer Vision -- ECCV 2014}, 2014.

\bibitem[Zhu \& Ghahramani(2002)Zhu and Ghahramani]{Zhu02learningfrom}
Xiaojin Zhu and Zoubin Ghahramani.
\newblock Learning from labeled and unlabeled data with label propagation.
\newblock Technical report, 2002.

\bibitem[Zhu et~al.(2009)Zhu, Goldberg, Brachman, and
  Dietterich]{10.5555/1717872}
Xiaojin Zhu, Andrew~B. Goldberg, Ronald Brachman, and Thomas Dietterich.
\newblock \emph{Introduction to Semi-Supervised Learning}.
\newblock 2009.

\bibitem[Zolna et~al.(2020)Zolna, Novikov, Konyushkova, Gulcehre, Wang, Aytar,
  Denil, de~Freitas, and Reed]{https://doi.org/10.48550/arxiv.2011.13885}
Konrad Zolna, Alexander Novikov, Ksenia Konyushkova, Caglar Gulcehre, Ziyu
  Wang, Yusuf Aytar, Misha Denil, Nando de~Freitas, and Scott Reed.
\newblock Offline learning from demonstrations and unlabeled experience, 2020.

\end{thebibliography}
