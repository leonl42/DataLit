<?xml version="1.0" encoding="UTF-8"?>
<?latexml searchpaths="/home/miri/Documents/DataLit/arXiv_src_fetcher/ICLR_2023_first100/-kAWfaLkPT3"?>
<?latexml class="article"?>
<?latexml package="iclr2023_conference,times"?>
<?latexml package="tikz"?>
<!--  %%%%% NEW MATH DEFINITIONS %%%%% --><?latexml package="amsmath,amsfonts,bm"?>
<!--  %Laplace distribution --><!--  %See usage in notation.tex. Chosen to match Daphne’s book. --><?latexml package="graphicx"?>
<?latexml package="wrapfig"?>
<?latexml package="subcaption"?>
<?latexml package="hyperref"?>
<?latexml package="url"?>
<?latexml package="float"?>
<?latexml package="algorithm"?>
<?latexml package="amssymb"?>
<?latexml package="comment"?>
<?latexml package="algpseudocode" options="noend"?>
<!--  %diverse offline pretraining improves transfer to action limited datasets --><!--  %diverse pretraining improves transfer to action limited offline RL datasets --><!--  %multi-environment pretraining improves generalization in action limited offline datasets --><!--  %multi-environment pretraining leads to generalizeable modelling in action limited offline datasets --><!--  %Authors must not appear in the submitted version. They should be hidden --><!--  %as long as the “iclrfinalcopy macro remains commented out below. --><!--  %Non-anonymous submissions will be rejected without review. --><!--  %The “author macro works with any number of authors. There are two commands --><!--  %used to separate the names and addresses of multiple authors: “And and “AND. --><!--  %Using “And between authors leaves it to “LaTeX–˝ to determine where to break --><!--  %the lines. Using “AND forces a linebreak at that point. So, if “LaTeX–˝ --><!--  %puts 3 of 4 authors names on the first line, and the last on the second --><!--  %line, try using “AND instead of “And before the third author name. --><?latexml RelaxNGSchema="LaTeXML"?>
<document xmlns="http://dlmf.nist.gov/LaTeXML" class="ltx_authors_1line">
  <resource src="LaTeXML.css" type="text/css"/>
  <resource src="ltx-article.css" type="text/css"/>
  <para xml:id="p1">
    <ERROR class="undefined">\iclrfinalcopy</ERROR>
<!--  %Uncomment for camera-ready version, but NOT for submission. -->  </para>
  <title>Multi-Environment Pretraining Enables Transfer to Action Limited Datasets</title>
  <creator role="author">
    <personname>David Venuto <sup><Math mode="inline" tex="1,2" text="list@(1, 2)" xml:id="m1">
          <XMath>
            <XMDual>
              <XMApp>
                <XMTok meaning="list"/>
                <XMRef idref="m1.1"/>
                <XMRef idref="m1.2"/>
              </XMApp>
              <XMWrap>
                <XMTok meaning="1" role="NUMBER" xml:id="m1.1">1</XMTok>
                <XMTok role="PUNCT">,</XMTok>
                <XMTok meaning="2" role="NUMBER" xml:id="m1.2">2</XMTok>
              </XMWrap>
            </XMDual>
          </XMath>
        </Math></sup>, Mengjiao Yang<sup><Math mode="inline" tex="3,4" text="list@(3, 4)" xml:id="m2">
          <XMath>
            <XMDual>
              <XMApp>
                <XMTok meaning="list"/>
                <XMRef idref="m2.1"/>
                <XMRef idref="m2.2"/>
              </XMApp>
              <XMWrap>
                <XMTok meaning="3" role="NUMBER" xml:id="m2.1">3</XMTok>
                <XMTok role="PUNCT">,</XMTok>
                <XMTok meaning="4" role="NUMBER" xml:id="m2.2">4</XMTok>
              </XMWrap>
            </XMDual>
          </XMath>
        </Math></sup>, Pieter Abbeel<sup><Math mode="inline" tex="4" text="4" xml:id="m3">
          <XMath>
            <XMTok meaning="4" role="NUMBER">4</XMTok>
          </XMath>
        </Math></sup>, <break/><text font="bold">Doina Precup<sup><Math mode="inline" tex="1,2,5" text="list@(1, 2, 5)" xml:id="m4">
            <XMath>
              <XMDual>
                <XMApp>
                  <XMTok meaning="list"/>
                  <XMRef idref="m4.1"/>
                  <XMRef idref="m4.2"/>
                  <XMRef idref="m4.3"/>
                </XMApp>
                <XMWrap>
                  <XMTok font="medium" meaning="1" role="NUMBER" xml:id="m4.1">1</XMTok>
                  <XMTok font="medium" role="PUNCT">,</XMTok>
                  <XMTok font="medium" meaning="2" role="NUMBER" xml:id="m4.2">2</XMTok>
                  <XMTok font="medium" role="PUNCT">,</XMTok>
                  <XMTok font="medium" meaning="5" role="NUMBER" xml:id="m4.3">5</XMTok>
                </XMWrap>
              </XMDual>
            </XMath>
          </Math></sup>, Igor Mordatch<sup><Math mode="inline" tex="3" text="3" xml:id="m5">
            <XMath>
              <XMTok font="medium" meaning="3" role="NUMBER">3</XMTok>
            </XMath>
          </Math></sup>, Ofir Nachum<sup><Math mode="inline" tex="3" text="3" xml:id="m6">
            <XMath>
              <XMTok font="medium" meaning="3" role="NUMBER">3</XMTok>
            </XMath>
          </Math></sup></text> <break/><sup><Math mode="inline" tex="1" text="1" xml:id="m7">
          <XMath>
            <XMTok meaning="1" role="NUMBER">1</XMTok>
          </XMath>
        </Math></sup>McGill University, <sup><Math mode="inline" tex="2" text="2" xml:id="m8">
          <XMath>
            <XMTok meaning="2" role="NUMBER">2</XMTok>
          </XMath>
        </Math></sup>Mila, <sup><Math mode="inline" tex="3" text="3" xml:id="m9">
          <XMath>
            <XMTok meaning="3" role="NUMBER">3</XMTok>
          </XMath>
        </Math></sup>Google Brain, <sup><Math mode="inline" tex="4" text="4" xml:id="m10">
          <XMath>
            <XMTok meaning="4" role="NUMBER">4</XMTok>
          </XMath>
        </Math></sup>University of California, Berkeley, <sup><Math mode="inline" tex="5" text="5" xml:id="m11">
          <XMath>
            <XMTok meaning="5" role="NUMBER">5</XMTok>
          </XMath>
        </Math></sup>DeepMind<break/><text font="typewriter">david.venuto@mail.mcgill.ca</text></personname>
    <contact role="thanks">Work done as a Student Researcher at Google Brain</contact>
<!--  %Affiliation ““ 
     %Address ““ 
     %“texttt–email˝ ““ 
     %“AND 
     %Coauthor ““ 
     %Affiliation ““ 
     %Address ““ 
     %“texttt–email˝ ““ 
     %“And 
     %Coauthor ““ 
     %**** iclr2023˙conference.tex Line 50 **** 
     %Affiliation ““ 
     %Address ““ 
     %“texttt–email˝ ““ 
     %“And 
     %Coauthor ““ 
     %Affiliation ““ 
     %Address ““ 
     %“texttt–email˝ ““ -->  </creator>
  <abstract name="Abstract">
    <p>Using massive datasets to train large-scale models has emerged as a dominant approach for broad generalization in natural language and vision applications. In reinforcement learning, however, a key challenge is that available data of sequential decision making is often not annotated with actions - for example, videos of game-play are much more available than sequences of frames paired with their logged game controls. We propose to circumvent this challenge by combining large but sparsely-annotated datasets from a <emph font="italic">target</emph> environment of interest with fully-annotated datasets from various other <emph font="italic">source</emph> environments. Our method, Action Limited PreTraining (ALPT), leverages the generalization capabilities of inverse dynamics modelling (IDM) to label missing action data in the target environment. We show that utilizing even one additional environment dataset of labelled data during IDM pretraining gives rise to substantial improvements in generating action labels for unannotated sequences. We evaluate our method on benchmark game-playing environments and show that we can significantly improve game performance and generalization capability compared to other approaches, using annotated datasets equivalent to only <Math mode="inline" tex="12" text="12" xml:id="m12">
        <XMath>
          <XMTok meaning="12" role="NUMBER">12</XMTok>
        </XMath>
      </Math> minutes of gameplay.
Highlighting the power of IDM, we show that these benefits remain even when target and source environments share no common actions.</p>
  </abstract>
<!--  %**** iclr2023˙conference.tex Line 75 **** -->  <section inlist="toc" xml:id="S1">
    <tags>
      <tag>1</tag>
      <tag role="autoref">section 1</tag>
      <tag role="refnum">1</tag>
      <tag role="typerefnum">§1</tag>
    </tags>
    <title><tag close=" ">1</tag>Introduction</title>
    <para xml:id="S1.p1">
      <p>The training of large-scale models on large and diverse data has become a standard approach in natural language and computer vision applications <cite class="ltx_citemacro_citep">(<bibref bibrefs="devlin-etal-2019-bert,NEURIPS2020_1457c0d6,DBLP:conf/eccv/MahajanGRHPLBM18,https://doi.org/10.48550/arxiv.2106.04560" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>.
Recently, a number of works have shown that a similar approach can be applied to tasks more often tackled by reinforcement learning (RL), such as robotics and game-playing.
For example, <cite class="ltx_citemacro_citet"><bibref bibrefs="https://doi.org/10.48550/arxiv.2205.06175" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
            <bibrefphrase>(</bibrefphrase>
            <bibrefphrase>)</bibrefphrase>
          </bibref></cite> suggest combining large datasets of expert behavior from a variety of RL domains in order to train a single generalist agent, while <cite class="ltx_citemacro_citet"><bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
            <bibrefphrase>(</bibrefphrase>
            <bibrefphrase>)</bibrefphrase>
          </bibref></cite> demonstrate a similar result but using non-expert (offline RL) data from a suite of Atari game-playing environments and using a decision transformer (DT) sequence modeling objective <cite class="ltx_citemacro_citep">(<bibref bibrefs="NEURIPS2021_7f489f64" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>.</p>
    </para>
    <para xml:id="S1.p2">
      <p>Applying large-scale training necessarily relies on the ability to gather sufficiently large and diverse datasets. For RL domains, this can be a challenge, as
the most easily available data – for example, videos of a human playing a video game or a human completing a predefined task – often does not contain <emph font="italic">labelled</emph> actions, i.e., game controls or robot joint controls.
We call such datasets <emph font="italic">action limited</emph>, because little or none of the dataset is annotated with action information.
Transferring the success of approaches like DT to such tasks is therefore bottlenecked by the ability to acquire action labels, which can be expensive and time-consuming <cite class="ltx_citemacro_citep">(<bibref bibrefs="https://doi.org/10.48550/arxiv.2011.13885" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>.</p>
    </para>
<!--  %Whereas much of internet-sized natural language and computer vision data is generally well annotated, large datasets of interest in the reinforcement learning (RL) paradigm require knowledge of the agent action as well as state at each frame.  Easily available datasets such as videos of a human playing a video game or a robot completing a predefined task do not generally contain “emph–labelled˝ actions, making it difficult to learn a behavior policy.  The lack of “emph–massive˝ labelled datasets for training RL policies, generally requires sample inefficient strategies such as DQN “citep–mnih-atari-2013˝.  This problem is exacerbated when exploration is a challenging component of solving the environment successfully “citep–Baker2020Emergent, https://doi.org/10.48550/arxiv.1912.06680, sciencepub, Baker2020Emergent˝. “ofir–This seems a bit vague. What are these sample-inefficient strategies?˝ 
     %As opposed to relatively smaller models used in RL “citep–10.5555/3045390.3045684˝, training large models “citep–NIPS2017˙3f5ee243˝ using massive task agnostic datasets has lead to improved “emph–generalist˝ task adaptation in a variety of challenging domains “citep–JMLR:v21:20-074, 10.1145/3462244.3479913˝.  These models have shown the capability of learning from unrelated data and modality extension “citep–https://doi.org/10.48550/arxiv.2103.05247˝. Most RL methods have only examined comparatively small models “citep–ijcai2020p651, 10.5555/3327144.3327175˝ which solve only related tasks in highly similar environments and do not take advantage of highly scale-able model architectures.  Training across a large suite of environments with radically different dynamics, but similar state spaces has shown promise using the Arcade learning environment (ALE) “citep–10.5555/2566972.2566979˝ using a decision transformer (DT) based sequence modelling architecture “citep–NEURIPS2021˙7f489f64, https://doi.org/10.48550/arxiv.2205.15241, https://doi.org/10.48550/arxiv.2205.06175˝.  These methods still require a large amount of labelled data from each task, which can be difficult to generate in domains outside of synthetic highly contained tasks. -->    <para xml:id="S1.p3">
      <p>Some recent works have explored approaches to mitigate the issue of action limited datasets. For example, Video PreTraining (VPT) <cite class="ltx_citemacro_citep">(<bibref bibrefs="https://doi.org/10.48550/arxiv.2206.11795" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite> proposes gathering a small amount (<Math mode="inline" tex="2" text="2" xml:id="S1.p3.m1">
          <XMath>
            <XMTok meaning="2" role="NUMBER">2</XMTok>
          </XMath>
        </Math>k hours of video) of labeled data manually which is used to train an inverse dynamics model (IDM) <cite class="ltx_citemacro_citep">(<bibref bibrefs="4936" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>; the IDM is then used to provide action labels on a much larger video-only dataset (<Math mode="inline" tex="70" text="70" xml:id="S1.p3.m2">
          <XMath>
            <XMTok meaning="70" role="NUMBER">70</XMTok>
          </XMath>
        </Math><!--  %Inverse dynamics being a well positioned choice as opposed to behavior cloning, since it is non-causal, allowing it to see past and future information. -->k hours). This method is shown to achieve human level performance in Minecraft. It has also been demonstrated that some agents can learn directly from videos without any action labels <cite class="ltx_citemacro_citep">(<bibref bibrefs="pmlr-v162-seo22a" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>.</p>
    </para>
    <para xml:id="S1.p4">
      <p>While VPT shows promising results, it still requires over <Math mode="inline" tex="2" text="2" xml:id="S1.p4.m1">
          <XMath>
            <XMTok meaning="2" role="NUMBER">2</XMTok>
          </XMath>
        </Math><!--  %**** iclr2023˙conference.tex Line 100 **** -->k hours of manually-labelled data; thus, a similar amount of expensive labelling is potentially necessary to extend VPT to other environments.
In this paper, we propose an orthogonal but related approach to VPT: leveraging a large set of labeled data from various <emph font="italic">source</emph> domains to learn an agent policy on a limited action dataset of a <emph font="italic">target</emph><!--  %Can the availability of such multi-environment datasets help reduce the amount of action labels needed to solve the target environment? --> evaluation environment. To tackle this setting, we propose Action Limited Pretraining (ALPT), which relies on the hypothesis that shared structures between environments can be exploited by non-causal (i.e., bidirectional) transformer IDMs. This allows us to look at both past and future frames to infer actions. In many experimental settings, the dynamics are far simpler than multi-faceted human behavior in the same setting. It has been suggested that IDMs are therefore more data efficient and this has been empirically shown <!--  %we first examine the performance of these method given a “emph–much˝ smaller amount of labeled data, approximately only $12$ minutes. We then propose an orthogonal problem to VPT: can we leverage a larger set of labeled data from similar tasks to better learn an agent policy from limited labeled action data in our evaluation environment? We investigate if IDM based architectures exploit shared structure between environments and generalize under limited labeled data? --><cite class="ltx_citemacro_citep">(<bibref bibrefs="https://doi.org/10.48550/arxiv.2206.11795" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite><!--  %causal transformer -->. ALPT thus uses the multi-environment source datasets as pretraining for an IDM, which is then finetuned on the action-limited data of the target environment in order to provide labels for the unlabelled target data, which is then used for training a
DT agent.</p>
    </para>
<!--  %We propose training on a diverse set of environments as a practical method to accelerating labeling observation data.  A summary of our method, which we name Action Limited Pretraining (ALPT), is detailed in Figure “ref–fig:idm˝.  The key hypothesis of this work is that shared structures between environments can be exploited by these architectures and be made practical for dynamics modeling.  We aim to provide a bootstrap-able method for labeling of frames in large scale RL datasets, as more labelled datasets become available. -->    <para xml:id="S1.p5">
      <p><!--  %To highlight the difficulty of learning under limited labelled data, we first show that sequence modeling fails to learn under limited action data.  We then show that performance cannot be recovered using dynamics modeling under the same quantities of limited actions.  We then present an alternative approach, training under a highly diverse set of labeled data.  Using numerous ablations of ALPT we show that this can result in substantial performance improvements in modelling and improved downstream offline RL performance follows. -->Through various experiments and ablations, we demonstrate that leveraging the generalization capabilities of IDMs is critical to the success of ALPT, as opposed to, for example, pretraining the DT model alone on the multi-environment datasets or training the IDM only on the target environment.
On a benchmark game-playing environment, we show that ALPT yields as much as <Math mode="inline" tex="5" text="5" xml:id="S1.p5.m1">
          <XMath>
            <XMTok meaning="5" role="NUMBER">5</XMTok>
          </XMath>
        </Math>x improvement in performance, with as little as <Math mode="inline" tex="10k" text="10 * k" xml:id="S1.p5.m2">
          <XMath>
            <XMApp>
              <XMTok meaning="times" role="MULOP">⁢</XMTok>
              <XMTok meaning="10" role="NUMBER">10</XMTok>
              <XMTok font="italic" role="UNKNOWN">k</XMTok>
            </XMApp>
          </XMath>
        </Math> labelled samples required (i.e., <Math mode="inline" tex="0.01\%" text="0.01percent" xml:id="S1.p5.m3">
          <XMath>
            <XMApp>
              <XMTok meaning="percent" role="POSTFIX">%</XMTok>
              <XMTok meaning="0.01" role="NUMBER">0.01</XMTok>
            </XMApp>
          </XMath>
        </Math> of the original labels), derived from only <Math mode="inline" tex="12" text="12" xml:id="S1.p5.m4">
          <XMath>
            <XMTok meaning="12" role="NUMBER">12</XMTok>
          </XMath>
        </Math> minutes of labelled game play <cite class="ltx_citemacro_citep">(<bibref bibrefs="ye2021mastering" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>.
We show that these benefits even hold when the source and target environments use distinct action spaces; i.e., the environments share similar states but <emph font="italic">no</emph> common actions, further demonstrating the power of IDM pretraining.</p>
    </para>
    <para xml:id="S1.p6">
      <p>While ALPT is, algorithmically, a straightforward application of existing offline RL approaches, our results provide a new perspective on large-scale training for RL. Namely, our results suggest that the most efficient path to large-scale RL methods may be via generalist inverse dynamics modelling paired with specialized agent finetuning, instead of generalist agent training alone.</p>
    </para>
<!--  %In these results, we show successful pretraining given a diverse dataset and limited data from our evaluation environment, can be used for alignment.  We further show that a pretraining the dynamics model under diverse environments is required for improved downstream performance and that pretraining only a sequence model with this diverse dataset does not result in better performance across action spaces. -->    <figure inlist="lof" labels="LABEL:fig:idm" xml:id="S1.F1">
      <tags>
        <tag><text fontsize="90%">Figure 1</text></tag>
        <tag role="autoref">Figure 1</tag>
        <tag role="refnum">1</tag>
        <tag role="typerefnum">Figure 1</tag>
      </tags>
      <graphics candidates="idm_model.png" class="ltx_centering" graphic="idm_model.png" options="width=312.9803pt,keepaspectratio=true" xml:id="S1.F1.g1"/>
      <toccaption class="ltx_centering"><tag close=" ">1</tag>The dynamics model pretraining procedure of ALPT using the source set of environments along with the limited action target environment dataset.</toccaption>
      <caption class="ltx_centering"><tag close=": "><text fontsize="90%">Figure 1</text></tag><text fontsize="90%">The dynamics model pretraining procedure of ALPT using the source set of environments along with the limited action target environment dataset.</text></caption>
    </figure>
  </section>
  <section inlist="toc" xml:id="S2">
    <tags>
      <tag>2</tag>
      <tag role="autoref">section 2</tag>
      <tag role="refnum">2</tag>
      <tag role="typerefnum">§2</tag>
    </tags>
    <title><tag close=" ">2</tag>Related Work</title>
    <para xml:id="S2.p1">
      <p>In this section, we briefly review relevant works in multi-task RL, meta-learning for RL, semi-supervised learning, and transfer learning.</p>
    </para>
    <para xml:id="S2.p2">
      <p><text font="bold">Multi-Task RL.</text> It is commonly assumed that similar tasks share similar structure and properties <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.1023/A:1007379606734,https://doi.org/10.48550/arxiv.1706.05098,10.1007/978-3-319-10599-4_7,Radford2019LanguageMA" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. Many multi-task RL works leverage this assumption by learning a shared low-dimensional representation across all tasks <cite class="ltx_citemacro_citep">(<bibref bibrefs="NIPS2014_94c7bb58,https://doi.org/10.48550/arxiv.1603.02041,DEramo2020Sharing" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. These methods have also been extended to tasks where the action space does not align completely <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.1007/978-3-030-46133-1_9" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. Other methods assume a universal dynamics model when the reward structure is shared but dynamics are not <cite class="ltx_citemacro_citep">(<bibref bibrefs="zhang2021learning" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. Multi-task RL has generally relied on a task identifier (ID) to provide contextual information, but recent methods have explored using additional side information available in the task meta-data to establish a richer context <cite class="ltx_citemacro_citep">(<bibref bibrefs="pmlr-v139-sodhani21a" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. ALPT can be seen as multi-task RL, given that we train both the sequence model and IDM using multiple different environments, but we do not explicitly model context information or have access to task IDs.</p>
    </para>
    <para xml:id="S2.p3">
      <p><text font="bold">Meta RL.</text> Meta-learning is a set of approaches for <emph font="italic">learning to learn</emph> which leverages a set of meta-training tasks <cite class="ltx_citemacro_citep">(<bibref bibrefs="metarl,155621" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>, from which an agent can learn either parts of the learning algorithms (eg how to tune the learning rate) or the entire algorithm <cite class="ltx_citemacro_citep">(<bibref bibrefs="9533842,kalousis2002algorithm" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite><!--  %Meta RL makes use of these principles to learn structure from experience.  %The introduce using these selected meta-training tasks and then aiming to learn new behaviors quickly at evaluation. -->. In this setting, meta-learning can be used to learn policies <cite class="ltx_citemacro_citep">(<bibref bibrefs="duan2017rl,10.5555/3305381.3305498" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite> or dynamics models <cite class="ltx_citemacro_citep">(<bibref bibrefs="clavera2018learning" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. A distribution of tasks is assumed to be available for sampling, in order to provide additional contextual information to the policy. One such method models contextual information as probabilistic context variables which condition the policy <cite class="ltx_citemacro_citep">(<bibref bibrefs="pmlr-v97-rakelly19a" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. This method has been shown to learn from only a handful of trajectories. Meta-training can be used to learn policies offline, while using online interaction to correct for distribution shift, without requiring any rewards in the online data <cite class="ltx_citemacro_citep">(<bibref bibrefs="pmlr-v162-pong22a" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite><!--  %and an explicitly defined set of meta-training tasks. -->. These methods are commonly used to train on a source set of tasks, like ALPT, but usually require task labels. Meta-training tasks need to be hand-selected, and the results are highly dependent on the quality of that process.</p>
    </para>
    <para xml:id="S2.p4">
      <p><text font="bold">Semi-supervised learning.</text> <emph font="italic">Semi-supervised</emph> learning uses both labelled and unlabelled data to improve supervised learning performance <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.5555/1717872" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. It is especially useful when a limited amount of labelles data is given and additional labels are difficult to acquire, unlabelled data is plentiful. Early methods of this type infer unknown labels using a classifier trained on the labeled data <cite class="ltx_citemacro_citep">(<bibref bibrefs="Zhu02learningfrom" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. Other methods rely on additional structural side information to regularize supervised objectives <cite class="ltx_citemacro_citep">(<bibref bibrefs="NIPS2001_a82d922b" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>, such as the time scale of a Markov random walk over a representation of the data. Many methods, especially those using deep learning, combine supervised and unsupervised learning objectives <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.5555/2969442.2969635" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. More recent methods use generative models and approximate Bayesian inference to fill in missing labels <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.5555/2969033.2969226" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite><!--  %Despite their relevance to practice, semi-supervised methods have not commonly been applied to actions and control. -->. The problem of semi-supervised learning is especially relevant in RL, where large datasets of experience containing action descriptions or rewards may hard to acquire, eg. through manual annotation of videos or running robotic experiments.
By using an inverse dynamics model, ALPT applies semi-supervised learning to label actions in a large dataset of experience frames, given only limited labeled action data.</p>
    </para>
    <para xml:id="S2.p5">
      <p><text font="bold">Transfer Learning and Zero-shot RL.</text> Policies learned by RL in one domain can have limited capability to generalize to new settings <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.5555/3045390.3045684" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. The most difficult problem is zero-shot RL, where the agent must generalize at evaluation time to a new environment that was not seen in training, without acquiring any new data. Transfer learning <cite class="ltx_citemacro_citep">(<bibref bibrefs="JMLR:v10:taylor09a" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite> tackles a subset of generalization problems where the agent can access interactions from a related environment or task during training. This prior experience in other environments is leveraged to improve learning in novel environments. Transfer learning has been applied across both environments <cite class="ltx_citemacro_citep">(<bibref bibrefs="7487140,Tzeng2020" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite> and tasks <cite class="ltx_citemacro_citep">(<bibref bibrefs="policydist,ParisottoBS15" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. It has also been examined in hard exploration games, using imitation learning from human-generated video data <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.5555/3327144.3327216" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. ALPT can be seen as tackling the transfer learning problem, with limited action data from the target environment and providing pseudo-labels for actions. Notably, we consider the under-explored scenario where the action space is not completely shared between the training and test environments.</p>
    </para>
    <para xml:id="S2.p6">
      <p><text font="bold">Offline RL.</text> Offline RL describes a setting that during learning, the agent has access to only a fixed dataset of experience. When function approximation becomes necessary in environments with large, complex state spaces, online RL algorithms are extremely sensitive to the dataset distribution. It has been shown that even when the logged data is collected with a single behavior policy, standard online algorithms fail <cite class="ltx_citemacro_citep">(<bibref bibrefs="fujimoto2019off" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. This has been hypothesized to be due erroneous generalization of the state action function. One such class of methods applies random ensembles of Q-value function targets <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.5555/3524938.3524949" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. Other works suggest regularizing the agent policy to the behavior policy <cite class="ltx_citemacro_citep">(<bibref bibrefs="zhang2021brac" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. In offline RL, errors arise when needed to bootstrap the value function and algorithms must apply strong regularizations on both learned policy and value function to achieve stable performance <cite class="ltx_citemacro_citep">(<bibref bibrefs="wu2020behavior,NEURIPS2019_c2073ffa,zhang2021brac,nachum2019algaedice" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>. We use decision transformers (DT) <cite class="ltx_citemacro_citep">(<bibref bibrefs="NEURIPS2021_7f489f64" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite> as the backbone for ALPT, and these have been shown to be successful in learning generalizable agents from logged data in a diverse set of environments <cite class="ltx_citemacro_citep">(<bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite>.</p>
    </para>
  </section>
  <section inlist="toc" xml:id="S3">
    <tags>
      <tag>3</tag>
      <tag role="autoref">section 3</tag>
      <tag role="refnum">3</tag>
      <tag role="typerefnum">§3</tag>
    </tags>
    <title><tag close=" ">3</tag>Background</title>
    <para xml:id="S3.p1">
      <p>In this section, we review the standard offline RL setting and the use of decision transformers (DT) as a sequence modelling objective for offline RL. We then define the setting of multi-environment offline RL with action-limited data, which is our focus.</p>
    </para>
    <subsection inlist="toc" labels="LABEL:offline-rl" xml:id="S3.SS1">
      <tags>
        <tag>3.1</tag>
        <tag role="autoref">subsection 3.1</tag>
        <tag role="refnum">3.1</tag>
        <tag role="typerefnum">§3.1</tag>
      </tags>
      <title><tag close=" ">3.1</tag>Offline Reinforcement Learning</title>
      <para xml:id="S3.SS1.p1">
        <p>We consider an agent acting within a Markov decision process (MDP) defined by <Math mode="inline" tex="\langle\mathcal{S},\mathcal{A},\mathcal{P},\mathcal{R}\rangle" text="list@(S, A, P, R)" xml:id="S3.SS1.p1.m1">
            <XMath>
              <XMDual>
                <XMApp>
                  <XMTok meaning="list"/>
                  <XMRef idref="S3.SS1.p1.m1.1"/>
                  <XMRef idref="S3.SS1.p1.m1.2"/>
                  <XMRef idref="S3.SS1.p1.m1.3"/>
                  <XMRef idref="S3.SS1.p1.m1.4"/>
                </XMApp>
                <XMWrap>
                  <XMTok name="langle" role="OPEN" stretchy="false">⟨</XMTok>
                  <XMTok font="caligraphic" role="UNKNOWN" xml:id="S3.SS1.p1.m1.1">S</XMTok>
                  <XMTok role="PUNCT">,</XMTok>
                  <XMTok font="caligraphic" role="UNKNOWN" xml:id="S3.SS1.p1.m1.2">A</XMTok>
                  <XMTok role="PUNCT">,</XMTok>
                  <XMTok font="caligraphic" role="UNKNOWN" xml:id="S3.SS1.p1.m1.3">P</XMTok>
                  <XMTok role="PUNCT">,</XMTok>
                  <XMTok font="caligraphic" role="UNKNOWN" xml:id="S3.SS1.p1.m1.4">R</XMTok>
                  <XMTok name="rangle" role="CLOSE" stretchy="false">⟩</XMTok>
                </XMWrap>
              </XMDual>
            </XMath>
          </Math>, where <Math mode="inline" tex="\mathcal{S}" text="S" xml:id="S3.SS1.p1.m2">
            <XMath>
              <XMTok font="caligraphic" role="UNKNOWN">S</XMTok>
            </XMath>
          </Math> is the set of states, <Math mode="inline" tex="\mathcal{A}" text="A" xml:id="S3.SS1.p1.m3">
            <XMath>
              <XMTok font="caligraphic" role="UNKNOWN">A</XMTok>
            </XMath>
          </Math> is the set of actions, <Math mode="inline" tex="\mathcal{P}:\mathcal{S}\times\mathcal{A}\rightarrow\mathrm{Dist}(\mathcal{S})" text="P colon S * A rightarrow Dist * S" xml:id="S3.SS1.p1.m4">
            <XMath>
              <XMApp>
                <XMTok name="colon" role="METARELOP">:</XMTok>
                <XMTok font="caligraphic" role="UNKNOWN">P</XMTok>
                <XMApp>
                  <XMTok name="rightarrow" role="ARROW">→</XMTok>
                  <XMApp>
                    <XMTok meaning="times" role="MULOP">×</XMTok>
                    <XMTok font="caligraphic" role="UNKNOWN">S</XMTok>
                    <XMTok font="caligraphic" role="UNKNOWN">A</XMTok>
                  </XMApp>
                  <XMApp>
                    <XMTok meaning="times" role="MULOP">⁢</XMTok>
                    <XMTok role="UNKNOWN">Dist</XMTok>
                    <XMDual>
                      <XMRef idref="S3.SS1.p1.m4.1"/>
                      <XMWrap>
                        <XMTok role="OPEN" stretchy="false">(</XMTok>
                        <XMTok font="caligraphic" role="UNKNOWN" xml:id="S3.SS1.p1.m4.1">S</XMTok>
                        <XMTok role="CLOSE" stretchy="false">)</XMTok>
                      </XMWrap>
                    </XMDual>
                  </XMApp>
                </XMApp>
              </XMApp>
            </XMath>
          </Math> is the transition probability kernel and <Math mode="inline" tex="\mathcal{R}:\mathcal{S}\times\mathcal{A}\rightarrow[0,1]" text="R colon S * A rightarrow closed-interval@(0, 1)" xml:id="S3.SS1.p1.m5">
            <XMath>
              <XMApp>
                <XMTok name="colon" role="METARELOP">:</XMTok>
                <XMTok font="caligraphic" role="UNKNOWN">R</XMTok>
                <XMApp>
                  <XMTok name="rightarrow" role="ARROW">→</XMTok>
                  <XMApp>
                    <XMTok meaning="times" role="MULOP">×</XMTok>
                    <XMTok font="caligraphic" role="UNKNOWN">S</XMTok>
                    <XMTok font="caligraphic" role="UNKNOWN">A</XMTok>
                  </XMApp>
                  <XMDual>
                    <XMApp>
                      <XMTok meaning="closed-interval"/>
                      <XMRef idref="S3.SS1.p1.m5.1"/>
                      <XMRef idref="S3.SS1.p1.m5.2"/>
                    </XMApp>
                    <XMWrap>
                      <XMTok role="OPEN" stretchy="false">[</XMTok>
                      <XMTok meaning="0" role="NUMBER" xml:id="S3.SS1.p1.m5.1">0</XMTok>
                      <XMTok role="PUNCT">,</XMTok>
                      <XMTok meaning="1" role="NUMBER" xml:id="S3.SS1.p1.m5.2">1</XMTok>
                      <XMTok role="CLOSE" stretchy="false">]</XMTok>
                    </XMWrap>
                  </XMDual>
                </XMApp>
              </XMApp>
            </XMath>
          </Math> is the scalar reward function.</p>
      </para>
      <para xml:id="S3.SS1.p2">
        <p>In offline RL, the agent is given a dataset of episodes, i.e., sequences of states, actions, and rewards collected by unknown policies interacting with the environment:</p>
        <equation xml:id="S3.E1">
<!--  %**** iclr2023˙conference.tex Line 150 **** -->          <tags>
            <tag>(1)</tag>
            <tag role="autoref">Equation 1</tag>
            <tag role="refnum">1</tag>
          </tags>
          <Math mode="display" tex="\langle\dots,\mathbf{s_{t}},a_{t},r_{t},\dots\rangle." text="list@(dots, s _ t, a _ t, r _ t, dots)" xml:id="S3.E1.m1">
            <XMath>
              <XMDual>
                <XMRef idref="S3.E1.m1.3"/>
                <XMWrap>
                  <XMDual xml:id="S3.E1.m1.3">
                    <XMApp>
                      <XMTok meaning="list"/>
                      <XMRef idref="S3.E1.m1.1"/>
                      <XMRef idref="S3.E1.m1.3.1"/>
                      <XMRef idref="S3.E1.m1.3.2"/>
                      <XMRef idref="S3.E1.m1.3.3"/>
                      <XMRef idref="S3.E1.m1.2"/>
                    </XMApp>
                    <XMWrap>
                      <XMTok name="langle" role="OPEN" stretchy="false">⟨</XMTok>
                      <XMTok name="dots" role="ID" xml:id="S3.E1.m1.1">…</XMTok>
                      <XMTok role="PUNCT">,</XMTok>
                      <XMApp xml:id="S3.E1.m1.3.1">
                        <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                        <XMTok font="bold" role="UNKNOWN">s</XMTok>
                        <XMTok font="bold" fontsize="70%" role="UNKNOWN">t</XMTok>
                      </XMApp>
                      <XMTok role="PUNCT">,</XMTok>
                      <XMApp xml:id="S3.E1.m1.3.2">
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="italic" role="UNKNOWN">a</XMTok>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                      </XMApp>
                      <XMTok role="PUNCT">,</XMTok>
                      <XMApp xml:id="S3.E1.m1.3.3">
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="italic" role="UNKNOWN">r</XMTok>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                      </XMApp>
                      <XMTok role="PUNCT">,</XMTok>
                      <XMTok name="dots" role="ID" xml:id="S3.E1.m1.2">…</XMTok>
                      <XMTok name="rangle" role="CLOSE" stretchy="false">⟩</XMTok>
                    </XMWrap>
                  </XMDual>
                  <XMTok role="PERIOD">.</XMTok>
                </XMWrap>
              </XMDual>
            </XMath>
          </Math>
        </equation>
        <p>The objective is typically to use this dataset in order to learn a conditional action distribution, <Math mode="inline" tex="P_{\theta}(a_{t}|\mathbf{s}_{\leq t},a_{&lt;t},r_{&lt;t})" text="P _ theta * conditional@(a _ t, list@(s _ (absent &lt;= t), a _ (absent &lt; t), r _ (absent &lt; t)))" xml:id="S3.SS1.p2.m1">
            <XMath>
              <XMApp>
                <XMTok meaning="times" role="MULOP">⁢</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="italic" role="UNKNOWN">P</XMTok>
                  <XMTok font="italic" fontsize="70%" name="theta" role="UNKNOWN">θ</XMTok>
                </XMApp>
                <XMDual>
                  <XMRef idref="S3.SS1.p2.m1.1"/>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="false">(</XMTok>
                    <XMApp xml:id="S3.SS1.p2.m1.1">
                      <XMTok meaning="conditional" role="MODIFIEROP" stretchy="false">|</XMTok>
                      <XMApp>
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="italic" role="UNKNOWN">a</XMTok>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                      </XMApp>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="list"/>
                          <XMRef idref="S3.SS1.p2.m1.1.1"/>
                          <XMRef idref="S3.SS1.p2.m1.1.2"/>
                          <XMRef idref="S3.SS1.p2.m1.1.3"/>
                        </XMApp>
                        <XMWrap>
                          <XMApp xml:id="S3.SS1.p2.m1.1.1">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="bold" role="UNKNOWN">s</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than-or-equals" name="leq" role="RELOP">≤</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS1.p2.m1.1.2">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="italic" role="UNKNOWN">a</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS1.p2.m1.1.3">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="italic" role="UNKNOWN">r</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="false">)</XMTok>
                  </XMWrap>
                </XMDual>
              </XMApp>
            </XMath>
          </Math>, that maximizes the expectation of the total return, <Math mode="inline" tex="G_{t}=\sum_{k\geq 0}r_{t+k}" text="G _ t = (sum _ (k &gt;= 0))@(r _ (t + k))" xml:id="S3.SS1.p2.m2">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="italic" role="UNKNOWN">G</XMTok>
                  <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                </XMApp>
                <XMApp>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMTok mathstyle="text" meaning="sum" role="SUMOP" scriptpos="post">∑</XMTok>
                    <XMApp>
                      <XMTok fontsize="70%" meaning="greater-than-or-equals" name="geq" role="RELOP">≥</XMTok>
                      <XMTok font="italic" fontsize="70%" role="UNKNOWN">k</XMTok>
                      <XMTok fontsize="70%" meaning="0" role="NUMBER">0</XMTok>
                    </XMApp>
                  </XMApp>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="italic" role="UNKNOWN">r</XMTok>
                    <XMApp>
                      <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                      <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                      <XMTok font="italic" fontsize="70%" role="UNKNOWN">k</XMTok>
                    </XMApp>
                  </XMApp>
                </XMApp>
              </XMApp>
            </XMath>
          </Math> when used to interact with the environment from which the training episodes were generated.</p>
      </para>
    </subsection>
    <subsection inlist="toc" labels="LABEL:seqmodel" xml:id="S3.SS2">
      <tags>
        <tag>3.2</tag>
        <tag role="autoref">subsection 3.2</tag>
        <tag role="refnum">3.2</tag>
        <tag role="typerefnum">§3.2</tag>
      </tags>
      <title><tag close=" ">3.2</tag>Offline RL as Sequence Modeling</title>
      <para xml:id="S3.SS2.p1">
        <p>Decision transformer (DT) <cite class="ltx_citemacro_citep">(<bibref bibrefs="https://doi.org/10.48550/arxiv.2106.01345" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
              <bibrefphrase>, </bibrefphrase>
            </bibref>)</cite> is an approach to offline RL which formulates this problem as sequence modeling, and then uses transformer-based architectures to solve it. For this purpose, the episodes in the offline dataset are augmented with the returns associated with each step:</p>
        <equation xml:id="S3.E2">
          <tags>
            <tag>(2)</tag>
            <tag role="autoref">Equation 2</tag>
            <tag role="refnum">2</tag>
          </tags>
          <Math mode="display" tex="\tau=\langle\dots,\mathbf{s_{t}},a_{t},r_{t},G_{t},\dots\rangle." text="tau = list@(dots, s _ t, a _ t, r _ t, G _ t, dots)" xml:id="S3.E2.m1">
            <XMath>
              <XMDual>
                <XMRef idref="S3.E2.m1.3"/>
                <XMWrap>
                  <XMApp xml:id="S3.E2.m1.3">
                    <XMTok meaning="equals" role="RELOP">=</XMTok>
                    <XMTok font="italic" name="tau" role="UNKNOWN">τ</XMTok>
                    <XMDual>
                      <XMApp>
                        <XMTok meaning="list"/>
                        <XMRef idref="S3.E2.m1.1"/>
                        <XMRef idref="S3.E2.m1.3.1"/>
                        <XMRef idref="S3.E2.m1.3.2"/>
                        <XMRef idref="S3.E2.m1.3.3"/>
                        <XMRef idref="S3.E2.m1.3.4"/>
                        <XMRef idref="S3.E2.m1.2"/>
                      </XMApp>
                      <XMWrap>
                        <XMTok name="langle" role="OPEN" stretchy="false">⟨</XMTok>
                        <XMTok name="dots" role="ID" xml:id="S3.E2.m1.1">…</XMTok>
                        <XMTok role="PUNCT">,</XMTok>
                        <XMApp xml:id="S3.E2.m1.3.1">
                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                          <XMTok font="bold" role="UNKNOWN">s</XMTok>
                          <XMTok font="bold" fontsize="70%" role="UNKNOWN">t</XMTok>
                        </XMApp>
                        <XMTok role="PUNCT">,</XMTok>
                        <XMApp xml:id="S3.E2.m1.3.2">
                          <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                          <XMTok font="italic" role="UNKNOWN">a</XMTok>
                          <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                        </XMApp>
                        <XMTok role="PUNCT">,</XMTok>
                        <XMApp xml:id="S3.E2.m1.3.3">
                          <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                          <XMTok font="italic" role="UNKNOWN">r</XMTok>
                          <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                        </XMApp>
                        <XMTok role="PUNCT">,</XMTok>
                        <XMApp xml:id="S3.E2.m1.3.4">
                          <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                          <XMTok font="italic" role="UNKNOWN">G</XMTok>
                          <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                        </XMApp>
                        <XMTok role="PUNCT">,</XMTok>
                        <XMTok name="dots" role="ID" xml:id="S3.E2.m1.2">…</XMTok>
                        <XMTok name="rangle" role="CLOSE" stretchy="false">⟩</XMTok>
                      </XMWrap>
                    </XMDual>
                  </XMApp>
                  <XMTok role="PERIOD">.</XMTok>
                </XMWrap>
              </XMDual>
            </XMath>
          </Math>
        </equation>
        <p>This sequence is tokenized and passed to a causal transformer <Math mode="inline" tex="P_{\theta}" text="P _ theta" xml:id="S3.SS2.p1.m1">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="italic" role="UNKNOWN">P</XMTok>
                <XMTok font="italic" fontsize="70%" name="theta" role="UNKNOWN">θ</XMTok>
              </XMApp>
            </XMath>
          </Math><!--  %In practice, we divide the state $“mathbf–s˝˙t$ into $M$ image patches, $“mathbf–s˝^1˙t , “dots, “mathbf–s˝^M˙t$. The state patches are combined additive with a trainable position encoding. The returns are quantized into a discrete range uniformly, and actions are discrete in the ALE. The model is trained to predict the next return and action in a sequence using a cross-entropy loss, defined for a single trajectory $“tau$ as, -->, which predicts both returns and actions using a cross-entropy loss.
Thus, the learning objective for <Math mode="inline" tex="\theta" text="theta" xml:id="S3.SS2.p1.m2">
            <XMath>
              <XMTok font="italic" name="theta" role="UNKNOWN">θ</XMTok>
            </XMath>
          </Math> is:</p>
        <equation labels="LABEL:dtloss" xml:id="S3.E3">
          <tags>
            <tag>(3)</tag>
            <tag role="autoref">Equation 3</tag>
            <tag role="refnum">3</tag>
          </tags>
          <Math mode="display" tex="J(\theta)=\mathbb{E}_{\tau}\left[\sum_{t}-\log P_{\theta}(G_{t}|\mathbf{s}_{%&#10;\leq t},a_{&lt;t},r_{&lt;t})-\log P_{\theta}(a_{t}|\mathbf{s}_{\leq t},a_{&lt;t},r_{&lt;t}%&#10;,G_{t})\right]." text="J * theta = E _ tau * delimited-[]@(sum _ t - logarithm@(P _ theta) * conditional@(G _ t, list@(s _ (absent &lt;= t), a _ (absent &lt; t), r _ (absent &lt; t))) - logarithm@(P _ theta) * conditional@(a _ t, list@(s _ (absent &lt;= t), a _ (absent &lt; t), r _ (absent &lt; t), G _ t)))" xml:id="S3.E3.m1">
            <XMath>
              <XMDual>
                <XMRef idref="S3.E3.m1.2"/>
                <XMWrap>
                  <XMApp xml:id="S3.E3.m1.2">
                    <XMTok meaning="equals" role="RELOP">=</XMTok>
                    <XMApp>
                      <XMTok meaning="times" role="MULOP">⁢</XMTok>
                      <XMTok font="italic" role="UNKNOWN">J</XMTok>
                      <XMDual>
                        <XMRef idref="S3.E3.m1.1"/>
                        <XMWrap>
                          <XMTok role="OPEN" stretchy="false">(</XMTok>
                          <XMTok font="italic" name="theta" role="UNKNOWN" xml:id="S3.E3.m1.1">θ</XMTok>
                          <XMTok role="CLOSE" stretchy="false">)</XMTok>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMApp>
                      <XMTok meaning="times" role="MULOP">⁢</XMTok>
                      <XMApp>
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="blackboard" role="UNKNOWN">E</XMTok>
                        <XMTok font="italic" fontsize="70%" name="tau" role="UNKNOWN">τ</XMTok>
                      </XMApp>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="delimited-[]"/>
                          <XMRef idref="S3.E3.m1.2.1"/>
                        </XMApp>
                        <XMWrap>
                          <XMTok role="OPEN" stretchy="true">[</XMTok>
                          <XMApp xml:id="S3.E3.m1.2.1">
                            <XMTok meaning="minus" role="ADDOP">-</XMTok>
                            <XMApp>
                              <XMTok role="SUBSCRIPTOP" scriptpos="mid2"/>
                              <XMTok mathstyle="display" meaning="sum" role="SUMOP" scriptpos="mid">∑</XMTok>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                            <XMApp>
                              <XMTok meaning="times" role="MULOP">⁢</XMTok>
                              <XMApp>
                                <XMTok meaning="logarithm" role="OPFUNCTION">log</XMTok>
                                <XMApp>
                                  <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                  <XMTok font="italic" role="UNKNOWN">P</XMTok>
                                  <XMTok font="italic" fontsize="70%" name="theta" role="UNKNOWN">θ</XMTok>
                                </XMApp>
                              </XMApp>
                              <XMDual>
                                <XMRef idref="S3.E3.m1.2.1.1"/>
                                <XMWrap>
                                  <XMTok role="OPEN" stretchy="false">(</XMTok>
                                  <XMApp xml:id="S3.E3.m1.2.1.1">
                                    <XMTok meaning="conditional" role="MODIFIEROP" stretchy="false">|</XMTok>
                                    <XMApp>
                                      <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                      <XMTok font="italic" role="UNKNOWN">G</XMTok>
                                      <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                    </XMApp>
                                    <XMDual>
                                      <XMApp>
                                        <XMTok meaning="list"/>
                                        <XMRef idref="S3.E3.m1.2.1.1.1"/>
                                        <XMRef idref="S3.E3.m1.2.1.1.2"/>
                                        <XMRef idref="S3.E3.m1.2.1.1.3"/>
                                      </XMApp>
                                      <XMWrap>
                                        <XMApp xml:id="S3.E3.m1.2.1.1.1">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="bold" role="UNKNOWN">s</XMTok>
                                          <XMApp>
                                            <XMTok fontsize="70%" meaning="less-than-or-equals" name="leq" role="RELOP">≤</XMTok>
                                            <XMTok meaning="absent"/>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                          </XMApp>
                                        </XMApp>
                                        <XMTok role="PUNCT">,</XMTok>
                                        <XMApp xml:id="S3.E3.m1.2.1.1.2">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="italic" role="UNKNOWN">a</XMTok>
                                          <XMApp>
                                            <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                                            <XMTok meaning="absent"/>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                          </XMApp>
                                        </XMApp>
                                        <XMTok role="PUNCT">,</XMTok>
                                        <XMApp xml:id="S3.E3.m1.2.1.1.3">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="italic" role="UNKNOWN">r</XMTok>
                                          <XMApp>
                                            <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                                            <XMTok meaning="absent"/>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                          </XMApp>
                                        </XMApp>
                                      </XMWrap>
                                    </XMDual>
                                  </XMApp>
                                  <XMTok role="CLOSE" stretchy="false">)</XMTok>
                                </XMWrap>
                              </XMDual>
                            </XMApp>
                            <XMApp>
                              <XMTok meaning="times" role="MULOP">⁢</XMTok>
                              <XMApp>
                                <XMTok meaning="logarithm" role="OPFUNCTION">log</XMTok>
                                <XMApp>
                                  <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                  <XMTok font="italic" role="UNKNOWN">P</XMTok>
                                  <XMTok font="italic" fontsize="70%" name="theta" role="UNKNOWN">θ</XMTok>
                                </XMApp>
                              </XMApp>
                              <XMDual>
                                <XMRef idref="S3.E3.m1.2.1.2"/>
                                <XMWrap>
                                  <XMTok role="OPEN" stretchy="false">(</XMTok>
                                  <XMApp xml:id="S3.E3.m1.2.1.2">
                                    <XMTok meaning="conditional" role="MODIFIEROP" stretchy="false">|</XMTok>
                                    <XMApp>
                                      <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                      <XMTok font="italic" role="UNKNOWN">a</XMTok>
                                      <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                    </XMApp>
                                    <XMDual>
                                      <XMApp>
                                        <XMTok meaning="list"/>
                                        <XMRef idref="S3.E3.m1.2.1.2.1"/>
                                        <XMRef idref="S3.E3.m1.2.1.2.2"/>
                                        <XMRef idref="S3.E3.m1.2.1.2.3"/>
                                        <XMRef idref="S3.E3.m1.2.1.2.4"/>
                                      </XMApp>
                                      <XMWrap>
                                        <XMApp xml:id="S3.E3.m1.2.1.2.1">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="bold" role="UNKNOWN">s</XMTok>
                                          <XMApp>
                                            <XMTok fontsize="70%" meaning="less-than-or-equals" name="leq" role="RELOP">≤</XMTok>
                                            <XMTok meaning="absent"/>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                          </XMApp>
                                        </XMApp>
                                        <XMTok role="PUNCT">,</XMTok>
                                        <XMApp xml:id="S3.E3.m1.2.1.2.2">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="italic" role="UNKNOWN">a</XMTok>
                                          <XMApp>
                                            <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                                            <XMTok meaning="absent"/>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                          </XMApp>
                                        </XMApp>
                                        <XMTok role="PUNCT">,</XMTok>
                                        <XMApp xml:id="S3.E3.m1.2.1.2.3">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="italic" role="UNKNOWN">r</XMTok>
                                          <XMApp>
                                            <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                                            <XMTok meaning="absent"/>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                          </XMApp>
                                        </XMApp>
                                        <XMTok role="PUNCT">,</XMTok>
                                        <XMApp xml:id="S3.E3.m1.2.1.2.4">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="italic" role="UNKNOWN">G</XMTok>
                                          <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                        </XMApp>
                                      </XMWrap>
                                    </XMDual>
                                  </XMApp>
                                  <XMTok role="CLOSE" stretchy="false">)</XMTok>
                                </XMWrap>
                              </XMDual>
                            </XMApp>
                          </XMApp>
                          <XMTok role="CLOSE" stretchy="true">]</XMTok>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                  </XMApp>
                  <XMTok role="PERIOD">.</XMTok>
                </XMWrap>
              </XMDual>
            </XMath>
          </Math>
        </equation>
        <p>During inference, at each timestep <Math mode="inline" tex="t" text="t" xml:id="S3.SS2.p1.m3">
            <XMath>
              <XMTok font="italic" role="UNKNOWN">t</XMTok>
            </XMath>
          </Math>, after observing <Math mode="inline" tex="\mathbf{s}_{t}" text="s _ t" xml:id="S3.SS2.p1.m4">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="bold" role="UNKNOWN">s</XMTok>
                <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
              </XMApp>
            </XMath>
          </Math>, DT uses the predicted return distribution <Math mode="inline" tex="P_{\theta}(G_{t}|\mathbf{s}_{\leq t},a_{&lt;t},r_{&lt;t})" text="P _ theta * conditional@(G _ t, list@(s _ (absent &lt;= t), a _ (absent &lt; t), r _ (absent &lt; t)))" xml:id="S3.SS2.p1.m5">
            <XMath>
              <XMApp>
                <XMTok meaning="times" role="MULOP">⁢</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="italic" role="UNKNOWN">P</XMTok>
                  <XMTok font="italic" fontsize="70%" name="theta" role="UNKNOWN">θ</XMTok>
                </XMApp>
                <XMDual>
                  <XMRef idref="S3.SS2.p1.m5.1"/>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="false">(</XMTok>
                    <XMApp xml:id="S3.SS2.p1.m5.1">
                      <XMTok meaning="conditional" role="MODIFIEROP" stretchy="false">|</XMTok>
                      <XMApp>
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="italic" role="UNKNOWN">G</XMTok>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                      </XMApp>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="list"/>
                          <XMRef idref="S3.SS2.p1.m5.1.1"/>
                          <XMRef idref="S3.SS2.p1.m5.1.2"/>
                          <XMRef idref="S3.SS2.p1.m5.1.3"/>
                        </XMApp>
                        <XMWrap>
                          <XMApp xml:id="S3.SS2.p1.m5.1.1">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="bold" role="UNKNOWN">s</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than-or-equals" name="leq" role="RELOP">≤</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS2.p1.m5.1.2">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="italic" role="UNKNOWN">a</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS2.p1.m5.1.3">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="italic" role="UNKNOWN">r</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="false">)</XMTok>
                  </XMWrap>
                </XMDual>
              </XMApp>
            </XMath>
          </Math> to choose an optimistic estimate <Math mode="inline" tex="\hat{G}_{t}" text="(hat@(G)) _ t" xml:id="S3.SS2.p1.m6">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMApp>
                  <XMTok name="hat" role="OVERACCENT" stretchy="false">^</XMTok>
                  <XMTok font="italic" role="UNKNOWN">G</XMTok>
                </XMApp>
                <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
              </XMApp>
            </XMath>
          </Math> of return, before using <Math mode="inline" tex="P_{\theta}(a_{t}|\mathbf{s}_{\leq t},a_{&lt;t},r_{&lt;t},\hat{G}_{t})" text="P _ theta * conditional@(a _ t, list@(s _ (absent &lt;= t), a _ (absent &lt; t), r _ (absent &lt; t), (hat@(G)) _ t))" xml:id="S3.SS2.p1.m7">
            <XMath>
              <XMApp>
                <XMTok meaning="times" role="MULOP">⁢</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="italic" role="UNKNOWN">P</XMTok>
                  <XMTok font="italic" fontsize="70%" name="theta" role="UNKNOWN">θ</XMTok>
                </XMApp>
                <XMDual>
                  <XMRef idref="S3.SS2.p1.m7.1"/>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="false">(</XMTok>
                    <XMApp xml:id="S3.SS2.p1.m7.1">
                      <XMTok meaning="conditional" role="MODIFIEROP" stretchy="false">|</XMTok>
                      <XMApp>
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="italic" role="UNKNOWN">a</XMTok>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                      </XMApp>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="list"/>
                          <XMRef idref="S3.SS2.p1.m7.1.1"/>
                          <XMRef idref="S3.SS2.p1.m7.1.2"/>
                          <XMRef idref="S3.SS2.p1.m7.1.3"/>
                          <XMRef idref="S3.SS2.p1.m7.1.4"/>
                        </XMApp>
                        <XMWrap>
                          <XMApp xml:id="S3.SS2.p1.m7.1.1">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="bold" role="UNKNOWN">s</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than-or-equals" name="leq" role="RELOP">≤</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS2.p1.m7.1.2">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="italic" role="UNKNOWN">a</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS2.p1.m7.1.3">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMTok font="italic" role="UNKNOWN">r</XMTok>
                            <XMApp>
                              <XMTok fontsize="70%" meaning="less-than" role="RELOP">&lt;</XMTok>
                              <XMTok meaning="absent"/>
                              <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                            </XMApp>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS2.p1.m7.1.4">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                            <XMApp>
                              <XMTok name="hat" role="OVERACCENT" stretchy="false">^</XMTok>
                              <XMTok font="italic" role="UNKNOWN">G</XMTok>
                            </XMApp>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="false">)</XMTok>
                  </XMWrap>
                </XMDual>
              </XMApp>
            </XMath>
          </Math> to select an action <Math mode="inline" tex="\hat{a}_{t}" text="(hat@(a)) _ t" xml:id="S3.SS2.p1.m8">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMApp>
                  <XMTok name="hat" role="OVERACCENT" stretchy="false">^</XMTok>
                  <XMTok font="italic" role="UNKNOWN">a</XMTok>
                </XMApp>
                <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
              </XMApp>
            </XMath>
          </Math> (see <cite class="ltx_citemacro_citet"><bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
              <bibrefphrase>(</bibrefphrase>
              <bibrefphrase>)</bibrefphrase>
            </bibref></cite> for details).</p>
      </para>
<!--  %, we implement an inference time method to predict expert actions.  This method utilizes a binary classifier to predict if an action is optimal $P(a˙t “sim “mathrm–expert˝ — “hat–R˝˙t)$.  The binary classifier is defined as $“mathrm–exp˝(“kappa “hat–R˙t˝)$ as demonstrated in “citep–NIPS2006˙d806ca13,10.2307/171139˝.  During evaluation time, returns are sampled with $P(“hat–R˙t˝ — “dots) + “kappa “hat–R˙t˝$ and then actions are sampled according to $P(a˙t — “hat–R˝˙t)$. -->    </subsection>
    <subsection inlist="toc" labels="LABEL:mtl" xml:id="S3.SS3">
      <tags>
        <tag>3.3</tag>
        <tag role="autoref">subsection 3.3</tag>
        <tag role="refnum">3.3</tag>
        <tag role="typerefnum">§3.3</tag>
      </tags>
      <title><tag close=" ">3.3</tag>Multi-Environment and Action Limited Datasets</title>
      <para xml:id="S3.SS3.p1">
        <p>Our goal is to use pretraining on a set of environments where labelled data is plentiful, in order to do well on a target environment where only limited action-labelled data is available. Therefore, the offline RL setting we consider includes multiple environments and action-limited datasets, as we detail below.</p>
      </para>
      <para xml:id="S3.SS3.p2">
        <p><!--  %We introduce notation describing both a “emph–diverse˝ and “emph–target˝ environment training procedure that ALPT will rely on. -->We consider a set of <Math mode="inline" tex="n" text="n" xml:id="S3.SS3.p2.m1">
            <XMath>
              <XMTok font="italic" role="UNKNOWN">n</XMTok>
            </XMath>
          </Math> <emph font="italic">source</emph> environments, defined by a set of MDPs: <Math mode="inline" tex="E=\{\mathcal{M}_{1},\dots,\mathcal{M}_{n}\}" text="E = set@(M _ 1, dots, M _ n)" xml:id="S3.SS3.p2.m2">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMTok font="italic" role="UNKNOWN">E</XMTok>
                <XMDual>
                  <XMApp>
                    <XMTok meaning="set"/>
                    <XMRef idref="S3.SS3.p2.m2.2"/>
                    <XMRef idref="S3.SS3.p2.m2.1"/>
                    <XMRef idref="S3.SS3.p2.m2.3"/>
                  </XMApp>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="false">{</XMTok>
                    <XMApp xml:id="S3.SS3.p2.m2.2">
                      <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                      <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                      <XMTok fontsize="70%" meaning="1" role="NUMBER">1</XMTok>
                    </XMApp>
                    <XMTok role="PUNCT">,</XMTok>
                    <XMTok name="dots" role="ID" xml:id="S3.SS3.p2.m2.1">…</XMTok>
                    <XMTok role="PUNCT">,</XMTok>
                    <XMApp xml:id="S3.SS3.p2.m2.3">
                      <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                      <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                      <XMTok font="italic" fontsize="70%" role="UNKNOWN">n</XMTok>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="false">}</XMTok>
                  </XMWrap>
                </XMDual>
              </XMApp>
            </XMath>
          </Math>, and a single <emph font="italic">target</emph> environment <Math mode="inline" tex="\mathcal{M}_{\star}" text="M _ star" xml:id="S3.SS3.p2.m3">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
              </XMApp>
            </XMath>
          </Math><!--  %**** iclr2023˙conference.tex Line 175 **** -->.
For each source environment <Math mode="inline" tex="\mathcal{M}_{d}" text="M _ d" xml:id="S3.SS3.p2.m4">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
              </XMApp>
            </XMath>
          </Math>, we have an offline dataset of episodes generated from <Math mode="inline" tex="\mathcal{M}_{d}" text="M _ d" xml:id="S3.SS3.p2.m5">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
              </XMApp>
            </XMath>
          </Math>, denoted by <Math mode="inline" tex="\mathcal{D}_{d}=\left\{\tau:=\langle\dots,\mathbf{s}_{t},a_{t},r_{t},\dots%&#10;\rangle\right\}" text="D _ d = set@(tau assign list@(dots, s _ t, a _ t, r _ t, dots))" xml:id="S3.SS3.p2.m6">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                  <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                </XMApp>
                <XMDual>
                  <XMApp>
                    <XMTok meaning="set"/>
                    <XMRef idref="S3.SS3.p2.m6.3"/>
                  </XMApp>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="true">{</XMTok>
                    <XMApp xml:id="S3.SS3.p2.m6.3">
                      <XMTok meaning="assign" role="RELOP">:=</XMTok>
                      <XMTok font="italic" name="tau" role="UNKNOWN">τ</XMTok>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="list"/>
                          <XMRef idref="S3.SS3.p2.m6.1"/>
                          <XMRef idref="S3.SS3.p2.m6.3.1"/>
                          <XMRef idref="S3.SS3.p2.m6.3.2"/>
                          <XMRef idref="S3.SS3.p2.m6.3.3"/>
                          <XMRef idref="S3.SS3.p2.m6.2"/>
                        </XMApp>
                        <XMWrap>
                          <XMTok name="langle" role="OPEN" stretchy="false">⟨</XMTok>
                          <XMTok name="dots" role="ID" xml:id="S3.SS3.p2.m6.1">…</XMTok>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m6.3.1">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="bold" role="UNKNOWN">s</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m6.3.2">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="italic" role="UNKNOWN">a</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m6.3.3">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="italic" role="UNKNOWN">r</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMTok name="dots" role="ID" xml:id="S3.SS3.p2.m6.2">…</XMTok>
                          <XMTok name="rangle" role="CLOSE" stretchy="false">⟩</XMTok>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="true">}</XMTok>
                  </XMWrap>
                </XMDual>
              </XMApp>
            </XMath>
          </Math><!--  %The agent is trained using the offline dataset of episodes $“bigcup˙–d=1˝^n “mathcal–D˝˙d“right$. -->, fully labelled with actions. For the target environment, the agent has access to a small labelled dataset from <Math mode="inline" tex="\mathcal{M}_{\star}" text="M _ star" xml:id="S3.SS3.p2.m7">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
              </XMApp>
            </XMath>
          </Math>, denoted as <Math mode="inline" tex="\mathcal{D}^{+}_{\star}=\left\{\tau:=\langle\dots,\mathbf{s}_{t},a_{t},r_{t},%&#10;\dots\rangle\right\}" text="(D ^ +) _ star = set@(tau assign list@(dots, s _ t, a _ t, r _ t, dots))" xml:id="S3.SS3.p2.m8">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                    <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                  </XMApp>
                  <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                </XMApp>
                <XMDual>
                  <XMApp>
                    <XMTok meaning="set"/>
                    <XMRef idref="S3.SS3.p2.m8.3"/>
                  </XMApp>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="true">{</XMTok>
                    <XMApp xml:id="S3.SS3.p2.m8.3">
                      <XMTok meaning="assign" role="RELOP">:=</XMTok>
                      <XMTok font="italic" name="tau" role="UNKNOWN">τ</XMTok>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="list"/>
                          <XMRef idref="S3.SS3.p2.m8.1"/>
                          <XMRef idref="S3.SS3.p2.m8.3.1"/>
                          <XMRef idref="S3.SS3.p2.m8.3.2"/>
                          <XMRef idref="S3.SS3.p2.m8.3.3"/>
                          <XMRef idref="S3.SS3.p2.m8.2"/>
                        </XMApp>
                        <XMWrap>
                          <XMTok name="langle" role="OPEN" stretchy="false">⟨</XMTok>
                          <XMTok name="dots" role="ID" xml:id="S3.SS3.p2.m8.1">…</XMTok>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m8.3.1">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="bold" role="UNKNOWN">s</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m8.3.2">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="italic" role="UNKNOWN">a</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m8.3.3">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="italic" role="UNKNOWN">r</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMTok name="dots" role="ID" xml:id="S3.SS3.p2.m8.2">…</XMTok>
                          <XMTok name="rangle" role="CLOSE" stretchy="false">⟩</XMTok>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="true">}</XMTok>
                  </XMWrap>
                </XMDual>
              </XMApp>
            </XMath>
          </Math>, and a large dataset without action labels, <Math mode="inline" tex="\mathcal{D}^{-}_{\star}=\left\{\tau:=\langle\dots,\mathbf{s}_{t},r_{t},\dots%&#10;\rangle\right\}" text="(D ^ -) _ star = set@(tau assign list@(dots, s _ t, r _ t, dots))" xml:id="S3.SS3.p2.m9">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                    <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                  </XMApp>
                  <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                </XMApp>
                <XMDual>
                  <XMApp>
                    <XMTok meaning="set"/>
                    <XMRef idref="S3.SS3.p2.m9.3"/>
                  </XMApp>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="true">{</XMTok>
                    <XMApp xml:id="S3.SS3.p2.m9.3">
                      <XMTok meaning="assign" role="RELOP">:=</XMTok>
                      <XMTok font="italic" name="tau" role="UNKNOWN">τ</XMTok>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="list"/>
                          <XMRef idref="S3.SS3.p2.m9.1"/>
                          <XMRef idref="S3.SS3.p2.m9.3.1"/>
                          <XMRef idref="S3.SS3.p2.m9.3.2"/>
                          <XMRef idref="S3.SS3.p2.m9.2"/>
                        </XMApp>
                        <XMWrap>
                          <XMTok name="langle" role="OPEN" stretchy="false">⟨</XMTok>
                          <XMTok name="dots" role="ID" xml:id="S3.SS3.p2.m9.1">…</XMTok>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m9.3.1">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="bold" role="UNKNOWN">s</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMApp xml:id="S3.SS3.p2.m9.3.2">
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="italic" role="UNKNOWN">r</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                          </XMApp>
                          <XMTok role="PUNCT">,</XMTok>
                          <XMTok name="dots" role="ID" xml:id="S3.SS3.p2.m9.2">…</XMTok>
                          <XMTok name="rangle" role="CLOSE" stretchy="false">⟩</XMTok>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="true">}</XMTok>
                  </XMWrap>
                </XMDual>
              </XMApp>
            </XMath>
          </Math>.</p>
      </para>
<!--  %We denote the combined action limited dataset of the target environment as $“mathcal–D˝˙“star = “mathcal–D˝^-˙“star “cup “mathcal–D˝^+˙“star $. 
     %One approach to the offline RL problem using these datasets is to first label the target environment, making use of the diverse environment during training of a dynamics model for labelling.  We now introduce preliminary information on a method for dynamics modelling that can be used to label missing actions in our target environment, given the observation frames. 
     %“subsection–Inverse Dynamics Modeling˝ 
     %“label–idm˝ 
     %“ofir–I would move this to methods˝ 
     %Inverse dynamics models (IDM) aim to minimize the negative log-likelihood of an action $a˙t$ at timestep $t$, trained with a trajectory of $T$ frames $“tau = “–“mathbf–s˝˙0,“dots, “mathbf–s˝˙T“˝$. As opposed to imitation learning, inverse dynamics modeling is not causally constrained and allows conditioning on past and future frames.  It has been shown that an IDMs are much easier to learn and can be trained accurately under limited data in complex environments “citep–https://doi.org/10.48550/arxiv.2206.11795˝. -->    </subsection>
  </section>
  <section inlist="toc" xml:id="S4">
    <tags>
      <tag>4</tag>
      <tag role="autoref">section 4</tag>
      <tag role="refnum">4</tag>
      <tag role="typerefnum">§4</tag>
    </tags>
    <title><tag close=" ">4</tag>Action Limited Pretraining (ALPT)</title>
<!--  %“ofir–TODO: determine if we also label returns, or just actions˝  Just actions 
     %“ofir–TODO: determine if we need pretraining for DT˝ Done with pretraining -->    <para xml:id="S4.p1">
      <p><!--  %, trained with limited labeled data.  This dynamics model is used to label either actions or returns in trajectories only containing frames. -->We now describe our proposed approach to offline RL in multi-environment and action limited settings. ALPT relies upon an inverse dynamics model (IDM) which uses the combined labelled data in order to learn a representation that generalizes well to the limited action data from the target environment. The predicted labels of the IDM on the unlabelled portion of the target environment dataset are then used for training a sequence model parameterized as a decision transformer (DT). We elaborate on this procedure below and summarize the full algorithm in Table <ref labelref="LABEL:tab:data"/>.</p>
    </para>
<!--  %We detail our dynamics models and training procedure in the following: Algorithm “ref–pretrain˝, Table “ref–tab:data˝, Subsection “ref–idm˝ and “ref–multigametrain˝. -->    <subsection inlist="toc" labels="LABEL:idm" xml:id="S4.SS1">
      <tags>
        <tag>4.1</tag>
        <tag role="autoref">subsection 4.1</tag>
        <tag role="refnum">4.1</tag>
        <tag role="typerefnum">§4.1</tag>
      </tags>
      <title><tag close=" ">4.1</tag>Inverse Dynamics Modeling</title>
      <para xml:id="S4.SS1.p1">
        <p>Our inverse dynamics model (IDM) is a bidirectional transformer trained to predict actions from an action-unlabelled sub-trajectory of an episode. The training objective for learning an IDM <Math mode="inline" tex="P_{\beta}" text="P _ beta" xml:id="S4.SS1.p1.m1">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="italic" role="UNKNOWN">P</XMTok>
                <XMTok font="italic" fontsize="70%" name="beta" role="UNKNOWN">β</XMTok>
              </XMApp>
            </XMath>
          </Math> is</p>
        <equation labels="LABEL:eq:idm" xml:id="S4.E4">
<!--  %**** iclr2023˙conference.tex Line 200 **** -->          <tags>
            <tag>(4)</tag>
            <tag role="autoref">Equation 4</tag>
            <tag role="refnum">4</tag>
          </tags>
          <Math mode="display" tex="J(\beta)=\mathbb{E}_{\tau}\left[\sum_{t}\sum_{i=0}^{k-1}-\log P_{\beta}(a_{t+i%&#10;}|\mathbf{s}_{t},\dots,\mathbf{s}_{t+k})\right]," text="J * beta = E _ tau * delimited-[]@((sum _ t)@((sum _ (i = 0)) ^ (k - 1)) - logarithm@(P _ beta) * conditional@(a _ (t + i), list@(s _ t, dots, s _ (t + k))))" xml:id="S4.E4.m1">
            <XMath>
              <XMDual>
                <XMRef idref="S4.E4.m1.3"/>
                <XMWrap>
                  <XMApp xml:id="S4.E4.m1.3">
                    <XMTok meaning="equals" role="RELOP">=</XMTok>
                    <XMApp>
                      <XMTok meaning="times" role="MULOP">⁢</XMTok>
                      <XMTok font="italic" role="UNKNOWN">J</XMTok>
                      <XMDual>
                        <XMRef idref="S4.E4.m1.1"/>
                        <XMWrap>
                          <XMTok role="OPEN" stretchy="false">(</XMTok>
                          <XMTok font="italic" name="beta" role="UNKNOWN" xml:id="S4.E4.m1.1">β</XMTok>
                          <XMTok role="CLOSE" stretchy="false">)</XMTok>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                    <XMApp>
                      <XMTok meaning="times" role="MULOP">⁢</XMTok>
                      <XMApp>
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="blackboard" role="UNKNOWN">E</XMTok>
                        <XMTok font="italic" fontsize="70%" name="tau" role="UNKNOWN">τ</XMTok>
                      </XMApp>
                      <XMDual>
                        <XMApp>
                          <XMTok meaning="delimited-[]"/>
                          <XMRef idref="S4.E4.m1.3.1"/>
                        </XMApp>
                        <XMWrap>
                          <XMTok role="OPEN" stretchy="true">[</XMTok>
                          <XMApp xml:id="S4.E4.m1.3.1">
                            <XMTok meaning="minus" role="ADDOP">-</XMTok>
                            <XMApp>
                              <XMApp>
                                <XMTok role="SUBSCRIPTOP" scriptpos="mid2"/>
                                <XMTok mathstyle="display" meaning="sum" role="SUMOP" scriptpos="mid">∑</XMTok>
                                <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                              </XMApp>
                              <XMApp>
                                <XMTok role="SUPERSCRIPTOP" scriptpos="mid2"/>
                                <XMApp>
                                  <XMTok role="SUBSCRIPTOP" scriptpos="mid2"/>
                                  <XMTok mathstyle="display" meaning="sum" role="SUMOP" scriptpos="mid">∑</XMTok>
                                  <XMApp>
                                    <XMTok fontsize="70%" meaning="equals" role="RELOP">=</XMTok>
                                    <XMTok font="italic" fontsize="70%" role="UNKNOWN">i</XMTok>
                                    <XMTok fontsize="70%" meaning="0" role="NUMBER">0</XMTok>
                                  </XMApp>
                                </XMApp>
                                <XMApp>
                                  <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                                  <XMTok font="italic" fontsize="70%" role="UNKNOWN">k</XMTok>
                                  <XMTok fontsize="70%" meaning="1" role="NUMBER">1</XMTok>
                                </XMApp>
                              </XMApp>
                            </XMApp>
                            <XMApp>
                              <XMTok meaning="times" role="MULOP">⁢</XMTok>
                              <XMApp>
                                <XMTok meaning="logarithm" role="OPFUNCTION">log</XMTok>
                                <XMApp>
                                  <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                  <XMTok font="italic" role="UNKNOWN">P</XMTok>
                                  <XMTok font="italic" fontsize="70%" name="beta" role="UNKNOWN">β</XMTok>
                                </XMApp>
                              </XMApp>
                              <XMDual>
                                <XMRef idref="S4.E4.m1.3.1.1"/>
                                <XMWrap>
                                  <XMTok role="OPEN" stretchy="false">(</XMTok>
                                  <XMApp xml:id="S4.E4.m1.3.1.1">
                                    <XMTok meaning="conditional" role="MODIFIEROP" stretchy="false">|</XMTok>
                                    <XMApp>
                                      <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                      <XMTok font="italic" role="UNKNOWN">a</XMTok>
                                      <XMApp>
                                        <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">i</XMTok>
                                      </XMApp>
                                    </XMApp>
                                    <XMDual>
                                      <XMApp>
                                        <XMTok meaning="list"/>
                                        <XMRef idref="S4.E4.m1.3.1.1.1"/>
                                        <XMRef idref="S4.E4.m1.2"/>
                                        <XMRef idref="S4.E4.m1.3.1.1.2"/>
                                      </XMApp>
                                      <XMWrap>
                                        <XMApp xml:id="S4.E4.m1.3.1.1.1">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="bold" role="UNKNOWN">s</XMTok>
                                          <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                        </XMApp>
                                        <XMTok role="PUNCT">,</XMTok>
                                        <XMTok name="dots" role="ID" xml:id="S4.E4.m1.2">…</XMTok>
                                        <XMTok role="PUNCT">,</XMTok>
                                        <XMApp xml:id="S4.E4.m1.3.1.1.2">
                                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                                          <XMTok font="bold" role="UNKNOWN">s</XMTok>
                                          <XMApp>
                                            <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">t</XMTok>
                                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">k</XMTok>
                                          </XMApp>
                                        </XMApp>
                                      </XMWrap>
                                    </XMDual>
                                  </XMApp>
                                  <XMTok role="CLOSE" stretchy="false">)</XMTok>
                                </XMWrap>
                              </XMDual>
                            </XMApp>
                          </XMApp>
                          <XMTok role="CLOSE" stretchy="true">]</XMTok>
                        </XMWrap>
                      </XMDual>
                    </XMApp>
                  </XMApp>
                  <XMTok role="PUNCT">,</XMTok>
                </XMWrap>
              </XMDual>
            </XMath>
          </Math>
        </equation>
        <p>where <Math mode="inline" tex="k" text="k" xml:id="S4.SS1.p1.m2">
            <XMath>
              <XMTok font="italic" role="UNKNOWN">k</XMTok>
            </XMath>
          </Math> is the length of training sub-trajectories.
In our experiments, we use <Math mode="inline" tex="k=5" text="k = 5" xml:id="S4.SS1.p1.m3">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMTok font="italic" role="UNKNOWN">k</XMTok>
                <XMTok meaning="5" role="NUMBER">5</XMTok>
              </XMApp>
            </XMath>
          </Math> and parameterize <Math mode="inline" tex="P_{\beta}" text="P _ beta" xml:id="S4.SS1.p1.m4">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="italic" role="UNKNOWN">P</XMTok>
                <XMTok font="italic" fontsize="70%" name="beta" role="UNKNOWN">β</XMTok>
              </XMApp>
            </XMath>
          </Math> using the GPT-2 transformer architecture <cite class="ltx_citemacro_citep">(<bibref bibrefs="radford2019language" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
              <bibrefphrase>, </bibrefphrase>
            </bibref>)</cite>, modified to be bidirectional by changing the attention mask.</p>
      </para>
<!--  %We obtained $k$ through experimental tuning. -->    </subsection>
    <subsection inlist="toc" labels="LABEL:multigametrain" xml:id="S4.SS2">
      <tags>
        <tag>4.2</tag>
        <tag role="autoref">subsection 4.2</tag>
        <tag role="refnum">4.2</tag>
        <tag role="typerefnum">§4.2</tag>
      </tags>
      <title><tag close=" ">4.2</tag>Multi-Environment Pretraining and Finetuning</title>
      <para xml:id="S4.SS2.p1">
        <p>ALPT is composed of a two-stage <text font="bold">pretraining</text> and <text font="bold">finetuning</text> process.</p>
      </para>
<!--  %In this section, we utilize notation described in Subsection “ref–mtl˝. -->      <para xml:id="S4.SS2.p2">
        <p>During <text font="bold">pretraining</text>, we use the combined labelled datasets for all source environments combined with the labelled portion of the target environment dataset: <Math mode="inline" tex="\left(\bigcup_{d=1}^{n}\mathcal{D}_{d}\right)\cup\mathcal{D}^{+}_{\star}" text="((union _ (d = 1)) ^ n)@(D _ d) union (D ^ +) _ star" xml:id="S4.SS2.p2.m1">
            <XMath>
              <XMApp>
                <XMTok meaning="union" name="cup" role="ADDOP">∪</XMTok>
                <XMDual>
                  <XMRef idref="S4.SS2.p2.m1.1"/>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="true">(</XMTok>
                    <XMApp xml:id="S4.SS2.p2.m1.1">
                      <XMApp>
                        <XMTok role="SUPERSCRIPTOP" scriptpos="post2"/>
                        <XMApp>
                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                          <XMTok mathstyle="text" meaning="union" name="bigcup" role="SUMOP" scriptpos="post">⋃</XMTok>
                          <XMApp>
                            <XMTok fontsize="70%" meaning="equals" role="RELOP">=</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                            <XMTok fontsize="70%" meaning="1" role="NUMBER">1</XMTok>
                          </XMApp>
                        </XMApp>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">n</XMTok>
                      </XMApp>
                      <XMApp>
                        <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                        <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                      </XMApp>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="true">)</XMTok>
                  </XMWrap>
                </XMDual>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                    <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                  </XMApp>
                  <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                </XMApp>
              </XMApp>
            </XMath>
          </Math>, to train the IDM <Math mode="inline" tex="P_{\beta}" text="P _ beta" xml:id="S4.SS2.p2.m2">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="italic" role="UNKNOWN">P</XMTok>
                <XMTok font="italic" fontsize="70%" name="beta" role="UNKNOWN">β</XMTok>
              </XMApp>
            </XMath>
          </Math>. Concurrently, we also train the DT <Math mode="inline" tex="P_{\theta}" text="P _ theta" xml:id="S4.SS2.p2.m3">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="italic" role="UNKNOWN">P</XMTok>
                <XMTok font="italic" fontsize="70%" name="theta" role="UNKNOWN">θ</XMTok>
              </XMApp>
            </XMath>
          </Math> on the combined labelled and unlabelled datasets for all source environments combined with the target environment datasets, by using the IDM to provide action labels on the unlabelled portion <Math mode="inline" tex="\mathcal{D}^{-}_{\star}" text="(D ^ -) _ star" xml:id="S4.SS2.p2.m4">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMApp>
                  <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                  <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                </XMApp>
                <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
              </XMApp>
            </XMath>
          </Math>. The DT training dataset is therefore: <Math mode="inline" tex="\left(\bigcup_{d=1}^{n}\mathcal{D}_{d}\right)\cup\mathcal{D}^{+}_{\star}\cup%&#10;\mathcal{D}^{-}_{\star}" text="((union _ (d = 1)) ^ n)@(D _ d) union (D ^ +) _ star union (D ^ -) _ star" xml:id="S4.SS2.p2.m5">
            <XMath>
              <XMApp>
                <XMTok meaning="union" name="cup" role="ADDOP">∪</XMTok>
                <XMDual>
                  <XMRef idref="S4.SS2.p2.m5.1"/>
                  <XMWrap>
                    <XMTok role="OPEN" stretchy="true">(</XMTok>
                    <XMApp xml:id="S4.SS2.p2.m5.1">
                      <XMApp>
                        <XMTok role="SUPERSCRIPTOP" scriptpos="post2"/>
                        <XMApp>
                          <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                          <XMTok mathstyle="text" meaning="union" name="bigcup" role="SUMOP" scriptpos="post">⋃</XMTok>
                          <XMApp>
                            <XMTok fontsize="70%" meaning="equals" role="RELOP">=</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                            <XMTok fontsize="70%" meaning="1" role="NUMBER">1</XMTok>
                          </XMApp>
                        </XMApp>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">n</XMTok>
                      </XMApp>
                      <XMApp>
                        <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                        <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                        <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                      </XMApp>
                    </XMApp>
                    <XMTok role="CLOSE" stretchy="true">)</XMTok>
                  </XMWrap>
                </XMDual>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                    <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                  </XMApp>
                  <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                </XMApp>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                    <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                  </XMApp>
                  <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                </XMApp>
              </XMApp>
            </XMath>
          </Math>.</p>
      </para>
<!--  %We therefore train our sequence model on the labeled and unlabelled data from our target environment. The IDM (objective from Equation “ref–eq:idm˝) is trained using both labeled data from the diverse set of environments and a small portion of labeled data from the target evaluation environment, using dataset: $“–“mathcal–D˝˙d “cup “mathcal–D˝˙t^+“˝$. -->      <para xml:id="S4.SS2.p3">
        <p>During <text font="bold">finetuning</text>, we simultaneously train both the IDM and DT exclusively on the target environment dataset. We train the IDM on the labelled portion <Math mode="inline" tex="\mathcal{D}^{+}_{\star}" text="(D ^ +) _ star" xml:id="S4.SS2.p3.m1">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMApp>
                  <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                  <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                </XMApp>
                <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
              </XMApp>
            </XMath>
          </Math>. We train DT on the full action limited dataset <Math mode="inline" tex="\mathcal{D}^{+}_{\star}\cup\mathcal{D}^{-}_{\star}" text="(D ^ +) _ star union (D ^ -) _ star" xml:id="S4.SS2.p3.m2">
            <XMath>
              <XMApp>
                <XMTok meaning="union" name="cup" role="ADDOP">∪</XMTok>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                    <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                  </XMApp>
                  <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                </XMApp>
                <XMApp>
                  <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                    <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                  </XMApp>
                  <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                </XMApp>
              </XMApp>
            </XMath>
          </Math> by using the IDM to provide action labels on the unlabelled portion <Math mode="inline" tex="\mathcal{D}^{-}_{\star}" text="(D ^ -) _ star" xml:id="S4.SS2.p3.m3">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMApp>
                  <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                  <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                  <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                </XMApp>
                <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
              </XMApp>
            </XMath>
          </Math>.</p>
      </para>
      <para xml:id="S4.SS2.p4">
        <p>Finally, during evaluation we use the trained DT agent to select actions in the target environment <Math mode="inline" tex="\mathcal{M}_{\star}" text="M _ star" xml:id="S4.SS2.p4.m1">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
              </XMApp>
            </XMath>
          </Math>, following the same protocol described in Section <ref labelref="LABEL:seqmodel"/>.</p>
      </para>
<!--  %“begin–algorithm˝ 
     %“caption–Pretraining˝“label–pretrain˝ 
     %“begin–algorithmic˝[1] 
     %“Require–$“mathcal–D˝˙t^-, “mathcal–D˝˙t^+, “mathcal–D˝˙d, “mathcal–M˝˙t, E˙D, “text– Init IDM parameters: ˝ “beta, “text– Init DT parameters: ˝ “theta, “alpha˙1, “alpha˙2$ ˝ 
     %“While–“text–not done˝˝ 
     %“State $“tau˙–“mathrm–IDM˝˝ “sim  “––“mathcal–D˝˝˙d “cup “mathcal–D˝˙t^+“˝$ “text– Sample from diverse and limited action target dataset to train IDM. ˝ 
     %“State $J˙–“mathrm–IDM˝˝ = “sum˙–t=0˝^T - “log “pi˙–“theta˝ (a˙t — “mathbf–s˝˙0, “dots, “mathbf–s˝˙t), a˙t “sim p˙–“beta˝(a˙t — “mathbf–s˝˙1, “dots “mathbf–s˝˙T) “forall “–“mathbf–s˝˙t, a˙t“˝ “in “tau˙–“mathrm–IDM˝˝$ 
     %“State $“beta “leftarrow “beta - “alpha˙1 “nabla˙–“beta˝  J˙–“mathrm–IDM˝˝$ Compute IDM loss and update IDM parameters. 
     %“State $“forall “mathbf–s˝˙t “in “mathcal–D˝˙t^-, “hat–“mathcal–D˝˙t˝ = “–“mathbf–s˝˙0, “hat–a˝˙0 “dots “mathbf–s˝˙t, “hat–a˝˙t “˝, “text– where ˝  “hat–a˝˙t “sim p˙–“beta˝(“hat–a˝˙t — “mathbf–s˝˙0, “dots “mathbf–s˝˙T)$ Label missing data. 
     %**** iclr2023˙conference.tex Line 225 **** 
     %“State $“tau˙–“mathrm–DT˝˝ “sim  “–“mathcal–D˝˙d “cup “mathcal–D˝˙t^+ “cup “hat–“mathcal–D˝˙t˝“˝$ Sample from diverse dataset, and labeled actions to train DT. 
     %“State $“mathbf–“hat–a˝˝ = f˙–“mathrm–DT˝, “theta˝(“tau˙–“mathrm–DT˝˝)$ Obtain predicted actions from DT. 
     %“State Obtain loss $J˙–“mathrm–DT˝˝$ using Equation “ref–dtloss˝. 
     %“State $“theta “leftarrow “theta - “alpha˙2 “nabla˙–“theta˝  J˙–“mathrm–DT˝˝$ Update DT parameters. 
     %“EndWhile 
     %“end–algorithmic˝ 
     %“end–algorithm˝ -->    </subsection>
  </section>
  <section inlist="toc" xml:id="S5">
    <tags>
      <tag>5</tag>
      <tag role="autoref">section 5</tag>
      <tag role="refnum">5</tag>
      <tag role="typerefnum">§5</tag>
    </tags>
    <title><tag close=" ">5</tag>Experiments</title>
    <table inlist="lot" labels="LABEL:tab:data" placement="t" xml:id="S5.T1">
      <tags>
        <tag><text fontsize="90%">Table 1</text></tag>
        <tag role="autoref">Table 1</tag>
        <tag role="refnum">1</tag>
        <tag role="typerefnum">Table 1</tag>
      </tags>
      <toccaption><tag close=" ">1</tag>A summary of ALPT.</toccaption>
      <caption><tag close=": "><text fontsize="90%">Table 1</text></tag><text fontsize="90%">A summary of ALPT.</text></caption>
      <tabular class="ltx_centering ltx_guessed_headers" vattach="middle">
        <thead>
          <tr>
            <td align="center" thead="column row"><text font="bold">Step</text></td>
            <td align="center" thead="column"><text font="bold">Procedure</text></td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left" border="t" thead="row"><text font="bold">Pretraining</text></td>
            <td align="left" border="t">Train IDM on all labelled data: <Math mode="inline" tex="\left(\bigcup_{d=1}^{n}\mathcal{D}_{d}\right)\cup\mathcal{D}^{+}_{\star}" text="((union _ (d = 1)) ^ n)@(D _ d) union (D ^ +) _ star" xml:id="S5.T1.m1">
                <XMath>
                  <XMApp>
                    <XMTok meaning="union" name="cup" role="ADDOP">∪</XMTok>
                    <XMDual>
                      <XMRef idref="S5.T1.m1.1"/>
                      <XMWrap>
                        <XMTok role="OPEN" stretchy="true">(</XMTok>
                        <XMApp xml:id="S5.T1.m1.1">
                          <XMApp>
                            <XMTok role="SUPERSCRIPTOP" scriptpos="post2"/>
                            <XMApp>
                              <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                              <XMTok mathstyle="text" meaning="union" name="bigcup" role="SUMOP" scriptpos="post">⋃</XMTok>
                              <XMApp>
                                <XMTok fontsize="70%" meaning="equals" role="RELOP">=</XMTok>
                                <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                                <XMTok fontsize="70%" meaning="1" role="NUMBER">1</XMTok>
                              </XMApp>
                            </XMApp>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">n</XMTok>
                          </XMApp>
                          <XMApp>
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                          </XMApp>
                        </XMApp>
                        <XMTok role="CLOSE" stretchy="true">)</XMTok>
                      </XMWrap>
                    </XMDual>
                    <XMApp>
                      <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                      <XMApp>
                        <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                        <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                      </XMApp>
                      <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                    </XMApp>
                  </XMApp>
                </XMath>
              </Math>.</td>
          </tr>
          <tr>
            <td thead="row"/>
            <td align="left">Train DT on all data: <Math mode="inline" tex="\left(\bigcup_{d=1}^{n}\mathcal{D}_{d}\right)\cup\mathcal{D}^{+}_{\star}\cup%&#10;\mathcal{D}^{-}_{\star}" text="((union _ (d = 1)) ^ n)@(D _ d) union (D ^ +) _ star union (D ^ -) _ star" xml:id="S5.T1.m2">
                <XMath>
                  <XMApp>
                    <XMTok meaning="union" name="cup" role="ADDOP">∪</XMTok>
                    <XMDual>
                      <XMRef idref="S5.T1.m2.1"/>
                      <XMWrap>
                        <XMTok role="OPEN" stretchy="true">(</XMTok>
                        <XMApp xml:id="S5.T1.m2.1">
                          <XMApp>
                            <XMTok role="SUPERSCRIPTOP" scriptpos="post2"/>
                            <XMApp>
                              <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                              <XMTok mathstyle="text" meaning="union" name="bigcup" role="SUMOP" scriptpos="post">⋃</XMTok>
                              <XMApp>
                                <XMTok fontsize="70%" meaning="equals" role="RELOP">=</XMTok>
                                <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                                <XMTok fontsize="70%" meaning="1" role="NUMBER">1</XMTok>
                              </XMApp>
                            </XMApp>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">n</XMTok>
                          </XMApp>
                          <XMApp>
                            <XMTok role="SUBSCRIPTOP" scriptpos="post2"/>
                            <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                            <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                          </XMApp>
                        </XMApp>
                        <XMTok role="CLOSE" stretchy="true">)</XMTok>
                      </XMWrap>
                    </XMDual>
                    <XMApp>
                      <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                      <XMApp>
                        <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                        <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                      </XMApp>
                      <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                    </XMApp>
                    <XMApp>
                      <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                      <XMApp>
                        <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                        <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                      </XMApp>
                      <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                    </XMApp>
                  </XMApp>
                </XMath>
              </Math>, with IDM</td>
          </tr>
          <tr>
            <td thead="row"/>
            <td align="left">providing action labels on <Math mode="inline" tex="\mathcal{D}^{-}_{\star}" text="(D ^ -) _ star" xml:id="S5.T1.m3">
                <XMath>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMApp>
                      <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                      <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                      <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                    </XMApp>
                    <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                  </XMApp>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" border="t" thead="row"><text font="bold">Finetuning</text></td>
            <td align="left" border="t">Train IDM on labelled data in target environment dataset: <Math mode="inline" tex="\mathcal{D}^{+}_{\star}" text="(D ^ +) _ star" xml:id="S5.T1.m4">
                <XMath>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMApp>
                      <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                      <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                      <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                    </XMApp>
                    <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                  </XMApp>
                </XMath>
              </Math>.</td>
          </tr>
          <tr>
            <td thead="row"/>
            <td align="left">Train DT on all data in target environment dataset: <Math mode="inline" tex="\mathcal{D}^{+}_{\star}\cup\mathcal{D}^{-}_{\star}" text="(D ^ +) _ star union (D ^ -) _ star" xml:id="S5.T1.m5">
                <XMath>
                  <XMApp>
                    <XMTok meaning="union" name="cup" role="ADDOP">∪</XMTok>
                    <XMApp>
                      <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                      <XMApp>
                        <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                        <XMTok fontsize="70%" meaning="plus" role="ADDOP">+</XMTok>
                      </XMApp>
                      <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                    </XMApp>
                    <XMApp>
                      <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                      <XMApp>
                        <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                        <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                      </XMApp>
                      <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                    </XMApp>
                  </XMApp>
                </XMath>
              </Math>,</td>
          </tr>
          <tr>
            <td thead="row"/>
            <td align="left">with IDM providing action labels on <Math mode="inline" tex="\mathcal{D}^{-}_{\star}" text="(D ^ -) _ star" xml:id="S5.T1.m6">
                <XMath>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMApp>
                      <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                      <XMTok font="caligraphic" role="UNKNOWN">D</XMTok>
                      <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                    </XMApp>
                    <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                  </XMApp>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" border="t" thead="row"><text font="bold">Evaluation</text></td>
            <td align="left" border="t">Use trained DT agent to interact with target environment <Math mode="inline" tex="\mathcal{M}_{\star}" text="M _ star" xml:id="S5.T1.m7">
                <XMath>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">M</XMTok>
                    <XMTok fontsize="70%" name="star" role="MULOP">⋆</XMTok>
                  </XMApp>
                </XMath>
              </Math>.</td>
          </tr>
        </tbody>
      </tabular>
<!--  %“begin–tabular˝–lll˝ 
     %“multicolumn–1˝–c˝–˝ &amp; 
     %“multicolumn–1˝–c˝–“bf Pretraining˝  &amp;“multicolumn–1˝–c˝–“bf Finetuning˝ 
     %““ “hline ““ 
     %“textbf–IDM Training Dataset˝ &amp; “–Diverse, Act. Lim. Target“˝ &amp; Act. Lim. Target ““  &amp;$“––“mathcal–D˝˝˙d “cup “mathcal–D˝˙t^+“˝$          &amp; $“mathcal–D˝˙t^+$ ““ ““ “hline %““ 
     %“textbf–DT Training Dataset˝             &amp; 
     %“–Diverse, Act. Lim. Target, IDM Labelled Target“˝ &amp; Act. Lim. Target““ &amp;$“–“mathcal–D˝˙d “cup “mathcal–D˝˙t^+ “cup “hat–“mathcal–D˝˙t˝“˝, “text– where ˝ “mathcal–D˝˙t^- “rightarrow^–“mathrm–IDM˝˝ “hat–“mathcal–D˝˙t˝$       &amp; $“mathcal–D˝˙t^+$ ““ 
     %“end–tabular˝ -->    </table>
    <para xml:id="S5.p1">
      <p>We evaluate ALPT on a multi-game Atari setup similar to <cite class="ltx_citemacro_citet"><bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
            <bibrefphrase>(</bibrefphrase>
            <bibrefphrase>)</bibrefphrase>
          </bibref></cite>. Our findings are three-fold: (1) ALPT, when pretrained on multiple source games, demonstrates significant benefits on the target game with limited action labels; (2) ALPT maintains its significant benefits even when pretrained on just a single source game with a disjoint action space, (3) we demonstrate similar benefits on maze navigation tasks.</p>
    </para>
<!--  %We formulate our experiments to evaluate the following aspects of ALPT: 
     %“begin–itemize˝ 
     %“item How does the DT sequence modelling architecture perform under limited action data, but a large dataset of observations? 
     %“item How well do IDM methods recover performance with action limited training data? 
     %“item Is dynamics modelling improved under more or less source datasets? 
     %“item Can we apply ALPT to pretraining on environments where the action space is disjoint with the target environment? 
     %“item Can training an IDM under a source data regime generalize in a practical navigation task given action limited data? 
     %**** iclr2023˙conference.tex Line 275 **** 
     %“end–itemize˝ -->    <subsection inlist="toc" xml:id="S5.SS1">
      <tags>
        <tag>5.1</tag>
        <tag role="autoref">subsection 5.1</tag>
        <tag role="refnum">5.1</tag>
        <tag role="typerefnum">§5.1</tag>
      </tags>
      <title><tag close=" ">5.1</tag>Experimental Procedure</title>
      <paragraph inlist="toc" xml:id="S5.SS1.SSS0.Px1">
        <title>Architecture and Training.</title>
        <para xml:id="S5.SS1.SSS0.Px1.p1">
          <p>Our architecture and training protocol follow the multi-game Atari setting outlined in <cite class="ltx_citemacro_citet"><bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
                <bibrefphrase>(</bibrefphrase>
                <bibrefphrase>)</bibrefphrase>
              </bibref></cite>. Specifically, we use a transformer with 6 layers of 8 heads each and hidden size 512. The rest of the architecture and training hyperparameters remain unchanged for experiments on Atari. For the Maze navigation experiments, we modify the original hyperparameters to use a batch size of <Math mode="inline" tex="256" text="256" xml:id="S5.SS1.SSS0.Px1.p1.m1">
              <XMath>
                <XMTok meaning="256" role="NUMBER">256</XMTok>
              </XMath>
            </Math> and a weight decay of <Math mode="inline" tex="5\times 10^{-5}" text="5 * 10 ^ (- 5)" xml:id="S5.SS1.SSS0.Px1.p1.m2">
              <XMath>
                <XMApp>
                  <XMTok meaning="times" role="MULOP">×</XMTok>
                  <XMTok meaning="5" role="NUMBER">5</XMTok>
                  <XMApp>
                    <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                    <XMTok meaning="10" role="NUMBER">10</XMTok>
                    <XMApp>
                      <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                      <XMTok fontsize="70%" meaning="5" role="NUMBER">5</XMTok>
                    </XMApp>
                  </XMApp>
                </XMApp>
              </XMath>
            </Math>. During pre-training, we train the DT and IDM for <Math mode="inline" tex="1M" text="1 * M" xml:id="S5.SS1.SSS0.Px1.p1.m3">
              <XMath>
                <XMApp>
                  <XMTok meaning="times" role="MULOP">⁢</XMTok>
                  <XMTok meaning="1" role="NUMBER">1</XMTok>
                  <XMTok font="italic" role="UNKNOWN">M</XMTok>
                </XMApp>
              </XMath>
            </Math> frames.</p>
        </para>
<!--  %We choose a smaller batch size given the complexity of the environment and adjust the weight decay accordingly. 
     %“ofir–Can we just cite the MGDT paper? Are there any differences?˝ 
     %A few differences in batch size and weight decay. 
     %“textbf–DT Architecture.˝ Our DT architecture is derived from GPT-2.  All results are utilizing an architecture with 200M parameters. The sequence length contains 4 transitions. 
     %“textbf–Training Procedure.˝ We train our DT architecture using the JaxLine “citep–deepmind2020jax˝ framework.  We use a LAMB optimizer “citep–https://doi.org/10.48550/arxiv.1904.00962˝ with a learning rate of $3 “times 10^–-4˝$, $4000$ warm up steps, a gradient clipping of $0.25$, weight decay $5 “times 10^–-5˝$ and a batch size of $1024$. -->      </paragraph>
      <paragraph inlist="toc" xml:id="S5.SS1.SSS0.Px2">
        <title>Datasets</title>
        <para xml:id="S5.SS1.SSS0.Px2.p1">
          <p>As in <cite class="ltx_citemacro_citet"><bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
                <bibrefphrase>(</bibrefphrase>
                <bibrefphrase>)</bibrefphrase>
              </bibref></cite>, we use the standard offline RL Atari datasets from RL Unplugged <cite class="ltx_citemacro_citep">(<bibref bibrefs="gulcehre2020rl" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
                <bibrefphrase>, </bibrefphrase>
              </bibref>)</cite>. Each game’s dataset consists of 100M environment steps of training a DQN agent <cite class="ltx_citemacro_citep">(<bibref bibrefs="agarwal2020optimistic" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
                <bibrefphrase>, </bibrefphrase>
              </bibref>)</cite>.
For the source games, we use this dataset in its entirety. For the target game, we derive an action-limited dataset by keeping the action labels for randomly sampled sequences consisting of a total 10k transitions (0.01% of the original dataset, equivalent to 12 minutes of gameplay) and removing action labels in the remainder of the dataset. For the maze navigation experiments, we generate the data ourselves. The offline datasets for each maze configuration contain <Math mode="inline" tex="500" text="500" xml:id="S5.SS1.SSS0.Px2.p1.m1">
              <XMath>
                <XMTok meaning="500" role="NUMBER">500</XMTok>
              </XMath>
            </Math> trajectories with a length of <Math mode="inline" tex="500" text="500" xml:id="S5.SS1.SSS0.Px2.p1.m2">
              <XMath>
                <XMTok meaning="500" role="NUMBER">500</XMTok>
              </XMath>
            </Math> steps or until the goal state is reached. They are generated using an optimal policy for each maze, with an <Math mode="inline" tex="\epsilon" text="epsilon" xml:id="S5.SS1.SSS0.Px2.p1.m3">
              <XMath>
                <XMTok font="italic" name="epsilon" role="UNKNOWN">ϵ</XMTok>
              </XMath>
            </Math>-greedy exploration rate of <Math mode="inline" tex="0.5" text="0.5" xml:id="S5.SS1.SSS0.Px2.p1.m4">
              <XMath>
                <XMTok meaning="0.5" role="NUMBER">0.5</XMTok>
              </XMath>
            </Math> to increase data diversity.</p>
        </para>
<!--  %For multi-game pretraining, we consider 
     %“ofir–Can we cite the MGDT paper and the RLUnplugged paper instead of this paragraph?˝ 
     %Let see how much space we have in the end? 
     %For each Atari environment we generate 2 training runs, with every run having $1$ million environment steps.  Since we include the entire training run, the dataset contains expert and non-expert trajectories.  We do this since suboptimal trajectories are both highly diverse and can improve representation learning of environmental effects of poor agent behavior. 
     %For the action limited dataset associated with the target environment, we take a small subset of the data ($10K$ transitions, equivalent to $12$ minutes of gameplay), and leave it unchanged while replacing the action labels in the remainder of the dataset with a null token. % This is a token that does not correspond to any true action in the game, which in practice is $-1$. 
     %“textbf–Arcade Learning Environments.˝ 
     %“textbf–Minatar Environments.˝ Next, we evaluate our method on MinAtar “citep–young19minatar˝, a simplified and miniaturized set of Arcade learning environment tasks where the ALE games are compressed into a $10 “times 10$ state representation. 
     %“textbf–Procgen. ˝In addition, we evaluate our proposed approach on the offline version of the Procgen set of environments “citep–pmlr-v119-cobbe20a˝.  This set of environments is commonly used to evaluate zero-shot generalization given a wide set of visual perturbation. The Procgen benchmark samples procedurally generated “emph–levels˝ or perturbed configurations for various different games.  The approach for our method is similar to ALE with each selected game of our diverse set from Procgen being labeled and one game having limited labeled frames. -->      </paragraph>
    </subsection>
    <subsection inlist="toc" xml:id="S5.SS2">
      <tags>
        <tag>5.2</tag>
        <tag role="autoref">subsection 5.2</tag>
        <tag role="refnum">5.2</tag>
        <tag role="typerefnum">§5.2</tag>
      </tags>
      <title><tag close=" ">5.2</tag>Baseline Methods</title>
      <para xml:id="S5.SS2.p1">
        <p>We detail the methods that we compare ALPT to below.</p>
      </para>
      <para xml:id="S5.SS2.p2">
        <p><text font="bold">Single-game variants.</text> To evaluate the benefit of multi- versus single-environment training, we assess the performance of training either DT alone or DT and IDM simultaneously on the target game. When training DT alone (<text font="bold">DT1</text>), we train it only on the <Math mode="inline" tex="10" text="10" xml:id="S5.SS2.p2.m1">
            <XMath>
              <XMTok meaning="10" role="NUMBER">10</XMTok>
            </XMath>
          </Math>k subset of data that is labelled, while when training DT and IDM simultaneously (<text font="bold">DT1-IDM</text>) we use the IDM to provide action labels on the unlabelled portion of the data.</p>
      </para>
<!--  %The IDM is trained to label the missing actions on only the single game given a dataset of limited actions ($10K$ true actions).  We pretrain a DT “textbf–with IDM labeling˝ and “textbf–without IDM labeling˝ (containing the null token labels), denoted as “textbf–DT$1$-IDM˝ and “textbf–DT$1$˝ respectively.  For the DT$1$ game, we exclude null action data from the dataset. -->      <para xml:id="S5.SS2.p3">
        <p><text font="bold">Multi-game DT variants.</text> To assess the need for IDM versus training on DT alone, we evaluate a multi-game baseline (<text font="bold">DT5</text>) composed of DT alone. For this baseline, we pretrain DT on all labelled datasets combined from both the source and target environments before finetuning the DT model on the <Math mode="inline" tex="10" text="10" xml:id="S5.SS2.p3.m1">
            <XMath>
              <XMTok meaning="10" role="NUMBER">10</XMTok>
            </XMath>
          </Math>k labelled portion of the target game.</p>
      </para>
<!--  %We pretrain a DT on all games from the limited set of Atari games and evaluate it on a single selected game.  The IDM is used to label the missing actions on the target game.  This training dataset contains all true action labels from the source set of non-evaluation games and only a limited amount of labeled actions ($10K$) on the evaluation game.  We pretrain a DT “textbf–with˝ and “textbf–without˝ IDM labelling, denoted as “textbf–ALPT˝ (our method) and “textbf–DT5˝ respectively. -->      <para xml:id="S5.SS2.p4">
        <p><text font="bold">Return prediction DT variants.</text> As an alternative way for DT to leverage the unlabelled portion of the target environment dataset, we evaluate a baseline (<text font="bold">DT5-RET</text>) that uses the unlabelled portion for training its return prediction.
The model still undergoes a pretraining and finetuning stage, first pretraining on all available data and then finetuning only on data from the target game.</p>
      </para>
<!--  %The agent is trained to predict tokenized returns using a cross entropy loss.  The DT is not trained using a cross-entropy loss to predict actions. This method is titled “textbf–DT$5$-RET˝. -->      <para xml:id="S5.SS2.p5">
        <p>We give a summary of the baseline methods as well as ALPT in Table <ref labelref="LABEL:tab:baselines"/>.
We also present results of an additional variant of ALPT in which only the IDM is pretrained (rather than both the IDM and DT) in Appendix <ref labelref="LABEL:app:alpt-no-dt"/>.</p>
      </para>
      <table inlist="lot" labels="LABEL:tab:baselines" placement="t" xml:id="S5.T2">
        <tags>
          <tag><text fontsize="90%">Table 2</text></tag>
          <tag role="autoref">Table 2</tag>
          <tag role="refnum">2</tag>
          <tag role="typerefnum">Table 2</tag>
        </tags>
        <toccaption><tag close=" ">2</tag>A summary of the baseline methods.</toccaption>
        <caption><tag close=": "><text fontsize="90%">Table 2</text></tag><text fontsize="90%">A summary of the baseline methods.</text></caption>
        <tabular class="ltx_centering ltx_guessed_headers" vattach="middle">
          <thead>
            <tr>
              <td align="center" thead="column row"><text font="bold">Method</text></td>
              <td align="center" thead="column"><text font="bold">Training Games</text></td>
              <td align="center" thead="column"><text font="bold">IDM</text></td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" border="t" thead="row">DT-1</td>
              <td align="center" border="t"><Math mode="inline" tex="1" text="1" xml:id="S5.T2.m1">
                  <XMath>
                    <XMTok meaning="1" role="NUMBER">1</XMTok>
                  </XMath>
                </Math></td>
              <td align="center" border="t"><Math mode="inline" tex="\times" text="*" xml:id="S5.T2.m2">
                  <XMath>
                    <XMTok meaning="times" role="MULOP">×</XMTok>
                  </XMath>
                </Math></td>
            </tr>
            <tr>
              <td align="left" border="t" thead="row">DT-5</td>
              <td align="center" border="t"><Math mode="inline" tex="5" text="5" xml:id="S5.T2.m3">
                  <XMath>
                    <XMTok meaning="5" role="NUMBER">5</XMTok>
                  </XMath>
                </Math></td>
              <td align="center" border="t"><Math mode="inline" tex="\times" text="*" xml:id="S5.T2.m4">
                  <XMath>
                    <XMTok meaning="times" role="MULOP">×</XMTok>
                  </XMath>
                </Math></td>
            </tr>
            <tr>
              <td align="left" border="t" thead="row">DT-1-IDM</td>
              <td align="center" border="t"><Math mode="inline" tex="1" text="1" xml:id="S5.T2.m5">
                  <XMath>
                    <XMTok meaning="1" role="NUMBER">1</XMTok>
                  </XMath>
                </Math></td>
              <td align="center" border="t">✓</td>
            </tr>
            <tr>
              <td align="left" border="t" thead="row">DT-5-RET</td>
              <td align="center" border="t"><Math mode="inline" tex="1" text="1" xml:id="S5.T2.m6">
                  <XMath>
                    <XMTok meaning="1" role="NUMBER">1</XMTok>
                  </XMath>
                </Math></td>
              <td align="center" border="t"><Math mode="inline" tex="\times" text="*" xml:id="S5.T2.m7">
                  <XMath>
                    <XMTok meaning="times" role="MULOP">×</XMTok>
                  </XMath>
                </Math></td>
            </tr>
            <tr>
              <td align="left" border="t" thead="row"><text font="bold">ALPT-<Math mode="inline" tex="X" text="X" xml:id="S5.T2.m8">
                    <XMath>
                      <XMTok font="medium italic" role="UNKNOWN">X</XMTok>
                    </XMath>
                  </Math></text></td>
              <td align="center" border="t"><Math mode="inline" tex="X" text="X" xml:id="S5.T2.m9">
                  <XMath>
                    <XMTok font="italic" role="UNKNOWN">X</XMTok>
                  </XMath>
                </Math> if specified, otherwise <Math mode="inline" tex="5" text="5" xml:id="S5.T2.m10">
                  <XMath>
                    <XMTok meaning="5" role="NUMBER">5</XMTok>
                  </XMath>
                </Math></td>
              <td align="center" border="t">✓</td>
            </tr>
          </tbody>
        </tabular>
<!--  %“begin–tabular˝–lll˝ 
     %“multicolumn–1˝–c˝–˝ &amp; 
     %“multicolumn–1˝–c˝–“bf Pretraining˝  &amp;“multicolumn–1˝–c˝–“bf Finetuning˝ 
     %““ “hline ““ 
     %“textbf–IDM Training Dataset˝ &amp; “–Diverse, Act. Lim. Target“˝ &amp; Act. Lim. Target ““  &amp;$“––“mathcal–D˝˝˙d “cup “mathcal–D˝˙t^+“˝$          &amp; $“mathcal–D˝˙t^+$ ““ ““ “hline %““ 
     %“textbf–DT Training Dataset˝             &amp; 
     %“–Diverse, Act. Lim. Target, IDM Labelled Target“˝ &amp; Act. Lim. Target““ &amp;$“–“mathcal–D˝˙d “cup “mathcal–D˝˙t^+ “cup “hat–“mathcal–D˝˙t˝“˝, “text– where ˝ “mathcal–D˝˙t^- “rightarrow^–“mathrm–IDM˝˝ “hat–“mathcal–D˝˙t˝$       &amp; $“mathcal–D˝˙t^+$ ““ 
     %“end–tabular˝ -->      </table>
    </subsection>
    <subsection inlist="toc" xml:id="S5.SS3">
      <tags>
        <tag>5.3</tag>
        <tag role="autoref">subsection 5.3</tag>
        <tag role="refnum">5.3</tag>
        <tag role="typerefnum">§5.3</tag>
      </tags>
      <title><tag close=" ">5.3</tag>How does ALPT perform compared to the baselines?</title>
<!--  %**** iclr2023˙conference.tex Line 350 **** 
     %the DT sequence modelling architecture perform under limited action data, but a large dataset of observations?˝ 
     %In these experiments, we investigate the ability of the DT architecture to solve ALE tasks given a action limited target environment dataset. We pretrain our model using the Multi-game DT variants and Single-game DT variants, where the target environment dataset is action limited. We finetune all models on the action limited target environment dataset only ($“mathcal–D˝˙*^-$). 
     %We first examine this experimental result with the ALE in Figure “ref–aleres˝.  In this figure, we show the evaluation game performance during finetuning with the action limited target environment. We first show that the performance of the DT under both the Single-game (DT$1$) and Multi-game (DT$5$) regimes is poor, achieving minimal game performance during finetuning evaluation.   We note that performance is especially poor when actions are removed as opposed to when we train our DT with only returns (DT$5$-RET). Overall, there is a failure to achieve even marginal game performance using a standard DT.  %Additionally, pretraining an IDM (DT$1$-IDM) with the limited dataset from our target game does not recover performance well.  This indicates that $10k$ actions is not sufficient to train our IDM to label actions correctly.  Pretraining the DT and IDM (ALPT) with a diverse dataset of environments recovers performance up to $~“approx500“%$ higher than pretraining only using the action limited target dataset.  The performance difference is particularly stark while finetuning on “emph–Seaquest˝. 
     %“subsection–How well do IDM methods recover performance with action limited training data?˝ -->      <para xml:id="S5.SS3.p1">
        <p>We focus our first set of multi-game pretraining experiments on 5 Atari games: <Math mode="inline" tex="\{" text="{" xml:id="S5.SS3.p1.m1">
            <XMath>
              <XMTok role="OPEN" stretchy="false">{</XMTok>
            </XMath>
          </Math><emph font="italic">Asterix, Breakout, SpaceInvaders, Freeway, Seaquest</emph><Math mode="inline" tex="\}" text="}" xml:id="S5.SS3.p1.m2">
            <XMath>
              <XMTok role="CLOSE" stretchy="false">}</XMTok>
            </XMath>
          </Math>.
This subset of games is selected due to having a similar shared game structure and access to high-quality and diverse pretraining data.
We evaluate each choice of target game in this setting, i.e., for each game we evaluate using it as the target game while the remaining <Math mode="inline" tex="4" text="4" xml:id="S5.SS3.p1.m3">
            <XMath>
              <XMTok meaning="4" role="NUMBER">4</XMTok>
            </XMath>
          </Math> games comprise the source environments.</p>
      </para>
<!--  %In subsequent results, involving generalization to disjoint action spaces, we expand the set of Atari games to include additional games that have action spaces disjoint with “emph–Freeway˝. -->      <para xml:id="S5.SS3.p2">
        <p><!--  %We evaluate the performance of the DT architecture while using a pretrained IDM to label the missing actions. -->We compare our pretraining regime (ALPT) with the single-game variant and standard DT baselines in Figure <ref labelref="LABEL:aleres"/>. We see that pretraining ALPT on the source games results in substantial downstream performance improvements. We show that there are relatively minimal performance improvements when pretraining on datasets that do not include any non-target environments (DT<Math mode="inline" tex="1" text="1" xml:id="S5.SS3.p2.m1">
            <XMath>
              <XMTok meaning="1" role="NUMBER">1</XMTok>
            </XMath>
          </Math>-IDM). Utilizing ALPT results in improvements up to <Math mode="inline" tex="\approx 500\%" text="absent approximately-equals 500percent" xml:id="S5.SS3.p2.m2">
            <XMath>
              <XMApp>
                <XMTok meaning="approximately-equals" name="approx" role="RELOP">≈</XMTok>
                <XMTok meaning="absent"/>
                <XMApp>
                  <XMTok meaning="percent" role="POSTFIX">%</XMTok>
                  <XMTok meaning="500" role="NUMBER">500</XMTok>
                </XMApp>
              </XMApp>
            </XMath>
          </Math> higher than the single-game training regime. The performance difference is especially stark in <emph font="italic">Breakout</emph> and <emph font="italic">Seaquest</emph>. Additionally, we show that performance is not recovered under pretraining only the sequence model (DT<Math mode="inline" tex="5" text="5" xml:id="S5.SS3.p2.m3">
            <XMath>
              <XMTok meaning="5" role="NUMBER">5</XMTok>
            </XMath>
          </Math>) on the action rich environments, indicating that most generalization benefits are occurring due to the IDM pretraining. We also show that performance using DT1 and DT5-RET is poor, highlighting the need for explicit re-labelling to achieve good performance during sequence model finetuning.</p>
      </para>
      <para xml:id="S5.SS3.p3">
        <p>We also encourage the reader to look to Appendix <ref labelref="LABEL:app:alpt-no-dt"/> for a comparison to a variant of ALPT for which only the IDM is pretrained, while the DT is initialized from scratch during finetuning. We find that this variant maintains strong performance compared to DT1-IDM, suggesting that the main benefit of pretraining is the IDM.</p>
      </para>
      <figure inlist="lof" labels="LABEL:aleres" xml:id="S5.F2">
        <tags>
          <tag><text fontsize="90%">Figure 2</text></tag>
          <tag role="autoref">Figure 2</tag>
          <tag role="refnum">2</tag>
          <tag role="typerefnum">Figure 2</tag>
        </tags>
        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F2.sf1">
          <tags>
            <tag><text fontsize="90%">(a)</text></tag>
            <tag role="autoref">2(a)</tag>
            <tag role="refnum">2(a)</tag>
          </tags>
          <graphics candidates="asterix.png" graphic="asterix.png" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F2.sf1.g1"/>
          <toccaption><tag close=" ">(a)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(a)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F2.sf2">
          <tags>
            <tag><text fontsize="90%">(b)</text></tag>
            <tag role="autoref">2(b)</tag>
            <tag role="refnum">2(b)</tag>
          </tags>
          <graphics candidates="breakout.png" graphic="breakout.png" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F2.sf2.g1"/>
          <toccaption><tag close=" ">(b)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(b)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F2.sf3">
          <tags>
            <tag><text fontsize="90%">(c)</text></tag>
            <tag role="autoref">2(c)</tag>
            <tag role="refnum">2(c)</tag>
          </tags>
          <graphics candidates="freeway.png" graphic="freeway.png" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F2.sf3.g1"/>
          <toccaption><tag close=" ">(c)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(c)</text></tag></caption>
        </figure>
        <break/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F2.sf4">
          <tags>
            <tag><text fontsize="90%">(d)</text></tag>
            <tag role="autoref">2(d)</tag>
            <tag role="refnum">2(d)</tag>
          </tags>
          <graphics candidates="seaquest.png" graphic="seaquest.png" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F2.sf4.g1"/>
          <toccaption><tag close=" ">(d)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(d)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F2.sf5">
          <tags>
            <tag><text fontsize="90%">(e)</text></tag>
            <tag role="autoref">2(e)</tag>
            <tag role="refnum">2(e)</tag>
          </tags>
          <graphics candidates="spaceinvaders.png" graphic="spaceinvaders.png" options="width=126.47249pt,keepaspectratio=true" xml:id="S5.F2.sf5.g1"/>
          <toccaption><tag close=" ">(e)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(e)</text></tag></caption>
        </figure>
        <toccaption class="ltx_centering"><tag close=" ">2</tag>Game performance across the ALE environments for the baseline and ALPT. The figure shows the evaluation game performance (Episodic Return) of our DT policies during finetuning on the limited action target dataset. Higher score is better. The shaded area represents the standard deviation over <Math mode="inline" tex="3" text="3" xml:id="S5.F2.m1">
            <XMath>
              <XMTok meaning="3" role="NUMBER">3</XMTok>
            </XMath>
          </Math> random seeds. The <Math mode="inline" tex="x" text="x" xml:id="S5.F2.m2">
            <XMath>
              <XMTok font="italic" role="UNKNOWN">x</XMTok>
            </XMath>
          </Math>-axis shows the number of finetuning steps. We evaluate ALPT on 16 episodes of length 2500 each following <cite class="ltx_citemacro_citep">(<bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
              <bibrefphrase>, </bibrefphrase>
            </bibref>)</cite>.</toccaption>
        <caption class="ltx_centering"><tag close=": "><text fontsize="90%">Figure 2</text></tag><text fontsize="90%">Game performance across the ALE environments for the baseline and ALPT. The figure shows the evaluation game performance (Episodic Return) of our DT policies during finetuning on the limited action target dataset. Higher score is better. The shaded area represents the standard deviation over <Math mode="inline" tex="3" text="3" xml:id="S5.F2.m3">
              <XMath>
                <XMTok meaning="3" role="NUMBER">3</XMTok>
              </XMath>
            </Math> random seeds. The <Math mode="inline" tex="x" text="x" xml:id="S5.F2.m4">
              <XMath>
                <XMTok font="italic" role="UNKNOWN">x</XMTok>
              </XMath>
            </Math>-axis shows the number of finetuning steps. We evaluate ALPT on 16 episodes of length 2500 each following <cite class="ltx_citemacro_citep">(<bibref bibrefs="https://doi.org/10.48550/arxiv.2205.15241" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
                <bibrefphrase>, </bibrefphrase>
              </bibref>)</cite>.</text></caption>
      </figure>
    </subsection>
    <subsection inlist="toc" xml:id="S5.SS4">
      <tags>
        <tag>5.4</tag>
        <tag role="autoref">subsection 5.4</tag>
        <tag role="refnum">5.4</tag>
        <tag role="typerefnum">§5.4</tag>
      </tags>
      <title><tag close=" ">5.4</tag>Is dynamics modelling improved under more or less source datasets?</title>
      <para xml:id="S5.SS4.p1">
        <p>In this set of experiments, we expand the set of source and target games. As in the previous experiments, each source game provides a fully-labelled dataset of size 100M, while each target game has a dataset of size 100M with only 10k action labels. We evaluate performance using 5 target games ({<text font="italic">‘Pong’, ‘SpaceInvaders’, ‘StarGunner’, ‘MsPacman’, ‘Alien’</text>}) and using either 36 source games (ALPT-36, trained on all 41 game datasets available in <cite class="ltx_citemacro_citet"><bibref bibrefs="agarwal2020optimistic" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
              <bibrefphrase>(</bibrefphrase>
              <bibrefphrase>)</bibrefphrase>
            </bibref></cite> minus the 5 target games) and using 9 source games (ALPT-9, trained on {<text font="italic">‘Asterix’, ‘Breakout’, ‘Freeway’, ‘Seaquest’, ‘Atlantis’, ‘DemonAttack’, ‘Frostbite’, ‘Gopher’, ‘TimePilot’</text>}).
Note that for each of these ALPT variants, we perform a <emph font="italic">single</emph> pretraining phase and then <emph font="italic">multiple</emph> finetuning phases (one for each target game), thus showing that a single pretrained model can be transferred to various target games.</p>
      </para>
      <para xml:id="S5.SS4.p2">
        <p>We compare pretraining with ALPT to training DT1-IDM on each target game alone. Results are presented in Figure <ref labelref="LABEL:alptall"/>, and show that target game performance improves with more source games.</p>
      </para>
      <figure inlist="lof" labels="LABEL:alptall" xml:id="S5.F3">
        <tags>
          <tag><text fontsize="90%">Figure 3</text></tag>
          <tag role="autoref">Figure 3</tag>
          <tag role="refnum">3</tag>
          <tag role="typerefnum">Figure 3</tag>
        </tags>
<!--  %We selected $5$ as a practical baseline in our initial experiments, but as more data becomes available, it is possible to achieve better performance. -->        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F3.sf1">
          <tags>
            <tag><text fontsize="90%">(a)</text></tag>
            <tag role="autoref">3(a)</tag>
            <tag role="refnum">3(a)</tag>
          </tags>
          <graphics candidates="Pong.pdf" graphic="Pong.pdf" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F3.sf1.g1"/>
          <toccaption><tag close=" ">(a)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(a)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F3.sf2">
          <tags>
            <tag><text fontsize="90%">(b)</text></tag>
            <tag role="autoref">3(b)</tag>
            <tag role="refnum">3(b)</tag>
          </tags>
          <graphics candidates="SpaceInvaders.pdf" graphic="SpaceInvaders.pdf" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F3.sf2.g1"/>
          <toccaption><tag close=" ">(b)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(b)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F3.sf3">
          <tags>
            <tag><text fontsize="90%">(c)</text></tag>
            <tag role="autoref">3(c)</tag>
            <tag role="refnum">3(c)</tag>
          </tags>
          <graphics candidates="StarGunner.pdf" graphic="StarGunner.pdf" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F3.sf3.g1"/>
          <toccaption><tag close=" ">(c)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(c)</text></tag></caption>
        </figure>
        <break/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F3.sf4">
          <tags>
            <tag><text fontsize="90%">(d)</text></tag>
            <tag role="autoref">3(d)</tag>
            <tag role="refnum">3(d)</tag>
          </tags>
          <graphics candidates="MsPacman.pdf" graphic="MsPacman.pdf" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F3.sf4.g1"/>
          <toccaption><tag close=" ">(d)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(d)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F3.sf5">
          <tags>
            <tag><text fontsize="90%">(e)</text></tag>
            <tag role="autoref">3(e)</tag>
            <tag role="refnum">3(e)</tag>
          </tags>
          <graphics candidates="Alien.pdf" graphic="Alien.pdf" options="width=115.63243pt,keepaspectratio=true" xml:id="S5.F3.sf5.g1"/>
          <toccaption><tag close=" ">(e)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(e)</text></tag></caption>
        </figure>
        <toccaption class="ltx_centering"><tag close=" ">3</tag>We evaluate performance of ALPT with a higher number of source games. We show performance of ALPT trained on 36 Atari source games (ALPT-36) and ALPT trained on 9 Atari source games (ALPT-9). We find that performance generally improves with more source games.</toccaption>
        <caption class="ltx_centering"><tag close=": "><text fontsize="90%">Figure 3</text></tag><text fontsize="90%">We evaluate performance of ALPT with a higher number of source games. We show performance of ALPT trained on 36 Atari source games (ALPT-36) and ALPT trained on 9 Atari source games (ALPT-9). We find that performance generally improves with more source games.</text></caption>
      </figure>
    </subsection>
    <subsection inlist="toc" xml:id="S5.SS5">
      <tags>
        <tag>5.5</tag>
        <tag role="autoref">subsection 5.5</tag>
        <tag role="refnum">5.5</tag>
        <tag role="typerefnum">§5.5</tag>
      </tags>
      <title><tag close=" ">5.5</tag>Can ALPT help when source and target have disjoint action spaces?</title>
      <para xml:id="S5.SS5.p1">
        <p><!--  %**** iclr2023˙conference.tex Line 400 **** -->The previous experiments have included at least one source game during pretraining whose the action space overlaps with that of the target environment. The next set of experiments aims to explore pretraining on source environments where the action space (<Math mode="inline" tex="\mathcal{A}_{d}" text="A _ d" xml:id="S5.SS5.p1.m1">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="caligraphic" role="UNKNOWN">A</XMTok>
                <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
              </XMApp>
            </XMath>
          </Math>) is disjoint with the target environment action space (<Math mode="inline" tex="\mathcal{A}_{*}" text="A _ *" xml:id="S5.SS5.p1.m2">
            <XMath>
              <XMApp>
                <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                <XMTok font="caligraphic" role="UNKNOWN">A</XMTok>
                <XMTok fontsize="70%" meaning="times" role="MULOP">∗</XMTok>
              </XMApp>
            </XMath>
          </Math>), that is, <Math mode="inline" tex="\mathcal{A}_{d}\cap\mathcal{A}_{*}=\emptyset" text="A _ d intersection A _ * = empty-set" xml:id="S5.SS5.p1.m3">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMApp>
                  <XMTok meaning="intersection" name="cap" role="ADDOP">∩</XMTok>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">A</XMTok>
                    <XMTok font="italic" fontsize="70%" role="UNKNOWN">d</XMTok>
                  </XMApp>
                  <XMApp>
                    <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                    <XMTok font="caligraphic" role="UNKNOWN">A</XMTok>
                    <XMTok fontsize="70%" meaning="times" role="MULOP">∗</XMTok>
                  </XMApp>
                </XMApp>
                <XMTok meaning="empty-set" name="emptyset" role="ID">∅</XMTok>
              </XMApp>
            </XMath>
          </Math>. To do so, we use <emph font="italic">Freeway</emph> as our single source environment dataset. In <emph font="italic">Freeway</emph>, the action space consists of {Up, Down}. In contrast, a game such as <emph font="italic">Breakout</emph> has an action space consisting of {Left, Right}.
Surprisingly, using <emph font="italic">Freeway</emph> as a source environment and <emph font="italic">Breakout</emph> as a target environment still yields significant benefits for ALPT.
We present this result in Figure <ref labelref="LABEL:disres"/>, as well as a variety of other choices for the target environment, none of which share any actions with the source environment <emph font="italic">Freeway</emph>.</p>
      </para>
      <para xml:id="S5.SS5.p2">
        <p>We hypothesize that performance improvements are not unexpected due to the already known broad generalization capabilities of transformer architectures. It may also be the case that, despite the action spaces being disjoint, they still exhibit similar structure. For example, a top-down action space and a left-right action space are structurally opposite to each other in terms of movement, differing only in orientation. This similar structure is potentially learned and leveraged during finetuning.</p>
      </para>
<!--  %during finetuning, generalizing with similar state spaces but disjoint actions. Again, we fine performance improvements by using a multi-environment dataset to pretrain our method (ALPT) when compared to training on only the action limited target dataset. 
     %We evaluate this phenomenon by training on multiple different games with disjoint actions to our target environment, with the results being consistent across these disjoint pretraining environments. -->      <figure inlist="lof" labels="LABEL:disres" xml:id="S5.F4">
        <tags>
          <tag><text fontsize="90%">Figure 4</text></tag>
          <tag role="autoref">Figure 4</tag>
          <tag role="refnum">4</tag>
          <tag role="typerefnum">Figure 4</tag>
        </tags>
<!--  %todo: add breakout 
     %todo: standardize legend -->        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf1">
          <tags>
            <tag><text fontsize="90%">(a)</text></tag>
            <tag role="autoref">4(a)</tag>
            <tag role="refnum">4(a)</tag>
          </tags>
          <graphics candidates="atlantis_disjoint.png" graphic="atlantis_disjoint.png" options="width=93.95122pt,keepaspectratio=true" xml:id="S5.F4.sf1.g1"/>
          <toccaption><tag close=" ">(a)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(a)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf2">
          <tags>
            <tag><text fontsize="90%">(b)</text></tag>
            <tag role="autoref">4(b)</tag>
            <tag role="refnum">4(b)</tag>
          </tags>
          <graphics candidates="Breakout.pdf" graphic="Breakout.pdf" options="width=90.3375pt,keepaspectratio=true" xml:id="S5.F4.sf2.g1"/>
          <toccaption><tag close=" ">(b)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(b)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf3">
          <tags>
            <tag><text fontsize="90%">(c)</text></tag>
            <tag role="autoref">4(c)</tag>
            <tag role="refnum">4(c)</tag>
          </tags>
          <graphics candidates="demon_attack_disjoint.png" graphic="demon_attack_disjoint.png" options="width=90.3375pt,keepaspectratio=true" xml:id="S5.F4.sf3.g1"/>
          <toccaption><tag close=" ">(c)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(c)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf4">
          <tags>
            <tag><text fontsize="90%">(d)</text></tag>
            <tag role="autoref">4(d)</tag>
            <tag role="refnum">4(d)</tag>
          </tags>
          <graphics candidates="pong_disjoint.png" graphic="pong_disjoint.png" options="width=90.3375pt,keepaspectratio=true" xml:id="S5.F4.sf4.g1"/>
          <toccaption><tag close=" ">(d)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(d)</text></tag></caption>
        </figure>
        <break class="ltx_centering"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf5">
          <tags>
            <tag><text fontsize="90%">(e)</text></tag>
            <tag role="autoref">4(e)</tag>
            <tag role="refnum">4(e)</tag>
          </tags>
          <graphics candidates="phoenix_disjoint.png" graphic="phoenix_disjoint.png" options="width=93.95122pt,keepaspectratio=true" xml:id="S5.F4.sf5.g1"/>
          <toccaption><tag close=" ">(e)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(e)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf6">
          <tags>
            <tag><text fontsize="90%">(f)</text></tag>
            <tag role="autoref">4(f)</tag>
            <tag role="refnum">4(f)</tag>
          </tags>
          <graphics candidates="name_this_game_disjoint.png" graphic="name_this_game_disjoint.png" options="width=93.95122pt,keepaspectratio=true" xml:id="S5.F4.sf6.g1"/>
          <toccaption><tag close=" ">(f)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(f)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf7">
          <tags>
            <tag><text fontsize="90%">(g)</text></tag>
            <tag role="autoref">4(g)</tag>
            <tag role="refnum">4(g)</tag>
          </tags>
          <graphics candidates="enduro_disjoint.png" graphic="enduro_disjoint.png" options="width=90.3375pt,keepaspectratio=true" xml:id="S5.F4.sf7.g1"/>
          <toccaption><tag close=" ">(g)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(g)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F4.sf8">
          <tags>
            <tag><text fontsize="90%">(h)</text></tag>
            <tag role="autoref">4(h)</tag>
            <tag role="refnum">4(h)</tag>
          </tags>
          <graphics candidates="space_invaders_disjoint.png" graphic="space_invaders_disjoint.png" options="width=90.3375pt,keepaspectratio=true" xml:id="S5.F4.sf8.g1"/>
          <toccaption><tag close=" ">(h)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(h)</text></tag></caption>
        </figure>
<!--  %**** iclr2023˙conference.tex Line 425 **** -->        <toccaption class="ltx_centering"><tag close=" ">4</tag>We evaluate performance of ALPT when source and target games have disjoint action spaces. In each of these plots we pretrain using a single source game Freeway. Despite the disjoint action space, we still see benefits of pretraining.</toccaption>
        <caption class="ltx_centering"><tag close=": "><text fontsize="90%">Figure 4</text></tag><text fontsize="90%">We evaluate performance of ALPT when source and target games have disjoint action spaces. In each of these plots we pretrain using a single source game Freeway. Despite the disjoint action space, we still see benefits of pretraining.</text></caption>
      </figure>
    </subsection>
    <subsection inlist="toc" xml:id="S5.SS6">
      <tags>
        <tag>5.6</tag>
        <tag role="autoref">subsection 5.6</tag>
        <tag role="refnum">5.6</tag>
        <tag role="typerefnum">§5.6</tag>
      </tags>
      <title><tag close=" ">5.6</tag>Do ALPT’s benefits persist in other domains ?</title>
      <para xml:id="S5.SS6.p1">
        <p>We now demonstrate ALPT’s benefits on an action-limited navigation task. This corresponds to a scenario where we have densely annotated navigation maps for a set of source regions but only a sparsely annotated navigation map for a target region. We would like to evaluate whether ALPT, pretrained on source regions with abundant action labels, can generalize to navigating in a target region (of a different layout) with limited action labels.</p>
      </para>
      <para xml:id="S5.SS6.p2">
        <p><text font="bold">Maze Navigation Environments.</text><!--  %To showcase the practicality of ALPT, we evaluate it on a discrete action maze navigation task. --> To answer the above question, we consider a gridworld navigation task where an agent seeks to navigate to a goal location in a <Math mode="inline" tex="20\times 20" text="20 * 20" xml:id="S5.SS6.p2.m1">
            <XMath>
              <XMApp>
                <XMTok meaning="times" role="MULOP">×</XMTok>
                <XMTok meaning="20" role="NUMBER">20</XMTok>
                <XMTok meaning="20" role="NUMBER">20</XMTok>
              </XMApp>
            </XMath>
          </Math> 2D maze from a random starting location to a random goal location using 4 discrete actions: {Up, Down, Left, Right}. The agent receives a reward of <Math mode="inline" tex="1" text="1" xml:id="S5.SS6.p2.m2">
            <XMath>
              <XMTok meaning="1" role="NUMBER">1</XMTok>
            </XMath>
          </Math> at the goal state and <Math mode="inline" tex="r=0" text="r = 0" xml:id="S5.SS6.p2.m3">
            <XMath>
              <XMApp>
                <XMTok meaning="equals" role="RELOP">=</XMTok>
                <XMTok font="italic" role="UNKNOWN">r</XMTok>
                <XMTok meaning="0" role="NUMBER">0</XMTok>
              </XMApp>
            </XMath>
          </Math> otherwise. To collect the offline training datasets, we follow <cite class="ltx_citemacro_citet"><bibref bibrefs="yang2022chain,zhang2018study" separator=";" show="Authors Phrase1YearPhrase2" yyseparator=",">
              <bibrefphrase>(</bibrefphrase>
              <bibrefphrase>)</bibrefphrase>
            </bibref></cite> to algorithmically generate maze layouts with random internal walls that form blocked or tunneled obstacles as shown in Figure <ref labelref="LABEL:fig:maze"/>. We start with blocked obstacles, and generate one <emph font="italic">source</emph> maze from which we collect <Math mode="inline" tex="500" text="500" xml:id="S5.SS6.p2.m4">
            <XMath>
              <XMTok meaning="500" role="NUMBER">500</XMTok>
            </XMath>
          </Math> trajectories with full action labels. We then use a different random seed to generate the <emph font="italic">target</emph> maze, from which we collect <Math mode="inline" tex="500" text="500" xml:id="S5.SS6.p2.m5">
            <XMath>
              <XMTok meaning="500" role="NUMBER">500</XMTok>
            </XMath>
          </Math> trajectories with only <Math mode="inline" tex="250" text="250" xml:id="S5.SS6.p2.m6">
            <XMath>
              <XMTok meaning="250" role="NUMBER">250</XMTok>
            </XMath>
          </Math> action labels (<Math mode="inline" tex="0.5\%" text="0.5percent" xml:id="S5.SS6.p2.m7">
            <XMath>
              <XMApp>
                <XMTok meaning="percent" role="POSTFIX">%</XMTok>
                <XMTok meaning="0.5" role="NUMBER">0.5</XMTok>
              </XMApp>
            </XMath>
          </Math> of the full action labels). We then train the IDM of ALPT-Blocked on both the source and target datasets, labeling the missing actions from the target game, and train DT all at the same time (no separate finetuning stage). ALPT-Blocked and other baselines are evaluated in the target maze only.</p>
      </para>
<!--  %Specifically, we consider $2$ configurations of the Maze, where $10$ different blocks are randomly placed in each configuration as shown in Figure~“ref–fig:maze˝ (a). One of these configurations is used to generate an action rich source environment ($500$ trajectories) dataset.  The other is used to generate an action limited “emph–target˝ environment dataset (with $250$ labelled actions).  Training on these environments is referred to as the ALPT-Blocked method. -->      <para xml:id="S5.SS6.p3">
        <p><text font="bold">Results.</text> Performance in the target maze environment with limited action labels is presented in Figure <ref labelref="LABEL:fig:maze"/> (b). ALPT-Blocked trained on both source and target mazes allows us to solve the target task twice as fast compared to only training on the target maze without access to another source maze. To further illustrate the benefit of multi-environment training on more diverse data, we introduce the tunnelled maze, and train ALPT-Blocked+Tunnelled on <Math mode="inline" tex="500" text="500" xml:id="S5.SS6.p3.m1">
            <XMath>
              <XMTok meaning="500" role="NUMBER">500</XMTok>
            </XMath>
          </Math> trajectories with full actions from a source blocked maze and a source tunneled maze, respectively, as well as <Math mode="inline" tex="250" text="250" xml:id="S5.SS6.p3.m2">
            <XMath>
              <XMTok meaning="250" role="NUMBER">250</XMTok>
            </XMath>
          </Math><!--  %Training ALPT, with source environments consisting of both Tunneled and Blocked datasets is referred to as ALPT-Tunneled. We also consider an additional maze where the walls are tunnels as part of our action rich source environment dataset, which we refer to as Tunneled. --> action samples of the target blocked maze. Training on both tunnelled and blocked mazes enables greater dataset diversity, which further improves generalization, leading to even faster convergence on the target task. These preliminary results on navigation suggest that multi-environment pretraining can benefit a broad set of tasks.</p>
      </para>
<!--  %We present this result to complement our dramatic performance improvements in the ALE, showing that our method is capable outside of that domain. 
     %We note that this maze configuration is rather simple, with the single-game DT1-IDM baseline being able to solve the task in slightly less than $5000$ steps.  We show that using ALPT to train with multiple source configurations allows us to solve the task approximately twice as fast. -->      <figure inlist="lof" labels="LABEL:fig:maze" xml:id="S5.F5">
        <tags>
          <tag><text fontsize="90%">Figure 5</text></tag>
          <tag role="autoref">Figure 5</tag>
          <tag role="refnum">5</tag>
          <tag role="typerefnum">Figure 5</tag>
        </tags>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F5.sf1">
          <tags>
            <tag><text fontsize="90%">(a)</text></tag>
            <tag role="autoref">5(a)</tag>
            <tag role="refnum">5(a)</tag>
          </tags>
          <graphics candidates="maze_fig.png" graphic="maze_fig.png" options="width=65.04256pt,keepaspectratio=true" xml:id="S5.F5.sf1.g1"/>
          <toccaption><tag close=" ">(a)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(a)</text></tag></caption>
        </figure>
        <break class="ltx_break"/>
        <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="S5.F5.sf2">
          <tags>
            <tag><text fontsize="90%">(b)</text></tag>
            <tag role="autoref">5(b)</tag>
            <tag role="refnum">5(b)</tag>
          </tags>
          <graphics candidates="20x20maze.png" graphic="20x20maze.png" options="width=137.31255pt,keepaspectratio=true" xml:id="S5.F5.sf2.g1"/>
          <toccaption><tag close=" ">(b)</tag></toccaption>
          <caption><tag close=" "><text fontsize="90%">(b)</text></tag></caption>
        </figure>
        <toccaption class="ltx_centering"><tag close=" ">5</tag>(a) An example diagram of the Blocked (above) and Tunneled (below) mazes. The green cell is the goal state. (b) Evaluation performance while training on the 20x20 Maze dataset. Higher score is better. The shaded area represents the standard deviation over <Math mode="inline" tex="3" text="3" xml:id="S5.F5.m1">
            <XMath>
              <XMTok meaning="3" role="NUMBER">3</XMTok>
            </XMath>
          </Math> random seeds. The action limited target dataset contains <Math mode="inline" tex="250" text="250" xml:id="S5.F5.m2">
            <XMath>
              <XMTok meaning="250" role="NUMBER">250</XMTok>
            </XMath>
          </Math> labelled actions in these experiments.</toccaption>
        <caption class="ltx_centering"><tag close=": "><text fontsize="90%">Figure 5</text></tag><text fontsize="90%">(a) An example diagram of the Blocked (above) and Tunneled (below) mazes. The green cell is the goal state. (b) Evaluation performance while training on the 20x20 Maze dataset. Higher score is better. The shaded area represents the standard deviation over <Math mode="inline" tex="3" text="3" xml:id="S5.F5.m3">
              <XMath>
                <XMTok meaning="3" role="NUMBER">3</XMTok>
              </XMath>
            </Math> random seeds. The action limited target dataset contains <Math mode="inline" tex="250" text="250" xml:id="S5.F5.m4">
              <XMath>
                <XMTok meaning="250" role="NUMBER">250</XMTok>
              </XMath>
            </Math> labelled actions in these experiments.</text></caption>
<!--  %**** iclr2023˙conference.tex Line 450 **** -->      </figure>
    </subsection>
  </section>
  <section inlist="toc" xml:id="S6">
    <tags>
      <tag>6</tag>
      <tag role="autoref">section 6</tag>
      <tag role="refnum">6</tag>
      <tag role="typerefnum">§6</tag>
    </tags>
    <title><tag close=" ">6</tag>Conclusion</title>
    <para xml:id="S6.p1">
      <p>We explored the problem of learning agent policies from action limited datasets.
Inspired by the paradigm of large-scale, multi-environment training, we proposed ALPT, which pretrains an inverse dynamics model (IDM) on multiple environments to provide accurate action labels for a decision transformer (DT) agent on an action limited target environment dataset.
Our experiments and ablations highlight the importance of pretraining the IDM, as opposed to pretraining the DT agent alone. Our results support the importance of generalist inverse dynamics models as an efficient way to implement large-scale RL.
As more labelled data becomes available for training offline RL agents, ALPT provides an efficient way of bootstrapping performance on new tasks with action limited data.</p>
    </para>
<!--  %This is arguably distinct from more common paradigms for large-scale training of RL agents, and 
     %We hypothesize that the inverse dynamics model may be a better mechanism to exploit shared structure between tasks. 
     %We hope that our results encourage researchers to continue investigating these and other alternative approaches for large-scale RL agent training. 
     %As more labelled decision making data becomes available for training offline RL policies, we present a fast way of bootstrapping for learning effectively with the vast amount of unannotated sequential decision making data already available. 
     %problem of utilizing vast quantities of unlabelled data, even from environments where the action space is not shared for training sequence models.  Given an action limited target environment dataset, we highlight improvements by pretraining with labelled data from environments that differ from our target evaluation task. We propose a novel dynamics model training regime, applicable in scenarios where we have access to a large amount of labelled data from similar problems but limited labelled data in a target environment.  Our results indicate the difficulty of traditional sequence models to learn under limited data, and provide an effective solution which does not require additional labels in the target environment.  We hypothesize that this dynamics model better exploits shared structure between tasks for downstream generalization.  ALPT is both scale-able and is highly applicable for bootstrapping.  As more labelled decision making data becomes available for training offline RL policies, we present a fast way of bootstrapping for learning effectively with the vast amount of unannotated sequential decision making data already available. -->    <subsection inlist="toc" xml:id="S6.SS1">
      <tags>
        <tag>6.1</tag>
        <tag role="autoref">subsection 6.1</tag>
        <tag role="refnum">6.1</tag>
        <tag role="typerefnum">§6.1</tag>
      </tags>
      <title><tag close=" ">6.1</tag>Limitations</title>
      <para xml:id="S6.SS1.p1">
        <p><!--  %Our method may not generalize as widely as comparable large language or computer vision models do using internet-sized datasets during pretraining. -->The largest limitation of ALPT is the assumption that we would have plentiful labelled data from related environments. One interesting fact we uncover is that this data does not have to be based on the same action space as the desired target environment, indicating the versatility of ALPT and its ability to ingest diverse source environment training data. We also caution that we have only evaluated ALPT so far on limited, self-contained video game tasks and simple navigation environments. We hope that as more labelled data becomes available in RL domains, ALPT will have wider applicability, allowing RL agents to scale and bootstrap to new environments. It would also be useful to investigate further how much labelled data from a limited set of source environments is required to be able to handle a much larger set of unlabelled datasets.</p>
      </para>
      <pagination role="newpage"/>
    </subsection>
  </section>
  <bibliography citestyle="authoryear" files="iclr2023_conference" xml:id="bib">
    <title>References</title>
  </bibliography>
  <pagination role="newpage"/>
  <appendix inlist="toc" labels="LABEL:app:alpt-no-dt" xml:id="A1">
    <tags>
      <tag>Appendix A</tag>
      <tag role="autoref">Appendix A</tag>
      <tag role="refnum">A</tag>
      <tag role="typerefnum">Appendix A</tag>
    </tags>
    <title><tag close=" ">Appendix A</tag>Experiments with no DT pretraining</title>
    <toctitle><tag close=" ">A</tag>Experiments with no DT pretraining</toctitle>
    <para xml:id="A1.p1">
      <p><!--  %**** iclr2023˙conference.tex Line 475 **** -->In the following set of experiments, we pretrain only the IDM component of ALPT and not the DT. We show the finetuning performance results for the Narrow set of Atari games in Figure <ref labelref="LABEL:fig:nodt"/>. Note that the axis here is up to <Math mode="inline" tex="100" text="100" xml:id="A1.p1.m1">
          <XMath>
            <XMTok meaning="100" role="NUMBER">100</XMTok>
          </XMath>
        </Math>k steps as opposed to 1M for the figures in the main text.</p>
    </para>
    <figure inlist="lof" labels="LABEL:fig:nodt" placement="H" xml:id="A1.F6">
      <tags>
        <tag><text fontsize="90%">Figure 6</text></tag>
        <tag role="autoref">Figure 6</tag>
        <tag role="refnum">6</tag>
        <tag role="typerefnum">Figure 6</tag>
      </tags>
      <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="A1.F6.sf1">
        <tags>
          <tag><text fontsize="90%">(a)</text></tag>
          <tag role="autoref">6(a)</tag>
          <tag role="refnum">6(a)</tag>
        </tags>
        <graphics candidates="asterix_nodt.png" graphic="asterix_nodt.png" options="width=126.47249pt,keepaspectratio=true" xml:id="A1.F6.sf1.g1"/>
        <toccaption><tag close=" ">(a)</tag></toccaption>
        <caption><tag close=" "><text fontsize="90%">(a)</text></tag></caption>
      </figure>
      <break class="ltx_break"/>
      <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="A1.F6.sf2">
        <tags>
          <tag><text fontsize="90%">(b)</text></tag>
          <tag role="autoref">6(b)</tag>
          <tag role="refnum">6(b)</tag>
        </tags>
        <graphics candidates="breakout_nodt.png" graphic="breakout_nodt.png" options="width=119.24506pt,keepaspectratio=true" xml:id="A1.F6.sf2.g1"/>
        <toccaption><tag close=" ">(b)</tag></toccaption>
        <caption><tag close=" "><text fontsize="90%">(b)</text></tag></caption>
      </figure>
      <break class="ltx_centering"/>
      <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="A1.F6.sf3">
        <tags>
          <tag><text fontsize="90%">(c)</text></tag>
          <tag role="autoref">6(c)</tag>
          <tag role="refnum">6(c)</tag>
        </tags>
        <graphics candidates="freeway_nodt.png" graphic="freeway_nodt.png" options="width=119.24506pt,keepaspectratio=true" xml:id="A1.F6.sf3.g1"/>
        <toccaption><tag close=" ">(c)</tag></toccaption>
        <caption><tag close=" "><text fontsize="90%">(c)</text></tag></caption>
      </figure>
      <break class="ltx_break"/>
      <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="A1.F6.sf4">
        <tags>
          <tag><text fontsize="90%">(d)</text></tag>
          <tag role="autoref">6(d)</tag>
          <tag role="refnum">6(d)</tag>
        </tags>
        <graphics candidates="seaquest_nodt.png" graphic="seaquest_nodt.png" options="width=126.47249pt,keepaspectratio=true" xml:id="A1.F6.sf4.g1"/>
        <toccaption><tag close=" ">(d)</tag></toccaption>
        <caption><tag close=" "><text fontsize="90%">(d)</text></tag></caption>
      </figure>
      <break class="ltx_break"/>
      <figure align="center" class="ltx_figure_panel" inlist="lof" xml:id="A1.F6.sf5">
        <tags>
          <tag><text fontsize="90%">(e)</text></tag>
          <tag role="autoref">6(e)</tag>
          <tag role="refnum">6(e)</tag>
        </tags>
        <graphics candidates="space_invaders_nodt.png" graphic="space_invaders_nodt.png" options="width=126.47249pt,keepaspectratio=true" xml:id="A1.F6.sf5.g1"/>
        <toccaption><tag close=" ">(e)</tag></toccaption>
        <caption><tag close=" "><text fontsize="90%">(e)</text></tag></caption>
      </figure>
      <toccaption class="ltx_centering"><tag close=" ">6</tag>Evaluation game performance during finetuning of ALPT and DT<Math mode="inline" tex="1" text="1" xml:id="A1.F6.m1">
          <XMath>
            <XMTok meaning="1" role="NUMBER">1</XMTok>
          </XMath>
        </Math>-IDM. In these experiments we do not pretrain the DT. <Math mode="inline" tex="100k" text="100 * k" xml:id="A1.F6.m2">
          <XMath>
            <XMApp>
              <XMTok meaning="times" role="MULOP">⁢</XMTok>
              <XMTok meaning="100" role="NUMBER">100</XMTok>
              <XMTok font="italic" role="UNKNOWN">k</XMTok>
            </XMApp>
          </XMath>
        </Math> steps are shown.</toccaption>
      <caption class="ltx_centering"><tag close=": "><text fontsize="90%">Figure 6</text></tag><text fontsize="90%">Evaluation game performance during finetuning of ALPT and DT<Math mode="inline" tex="1" text="1" xml:id="A1.F6.m3">
            <XMath>
              <XMTok meaning="1" role="NUMBER">1</XMTok>
            </XMath>
          </Math>-IDM. In these experiments we do not pretrain the DT. <Math mode="inline" tex="100k" text="100 * k" xml:id="A1.F6.m4">
            <XMath>
              <XMApp>
                <XMTok fontsize="111%" meaning="times" role="MULOP">⁢</XMTok>
                <XMTok meaning="100" role="NUMBER">100</XMTok>
                <XMTok font="italic" role="UNKNOWN">k</XMTok>
              </XMApp>
            </XMath>
          </Math> steps are shown.</text></caption>
    </figure>
  </appendix>
  <appendix inlist="toc" xml:id="A2">
    <tags>
      <tag>Appendix B</tag>
      <tag role="autoref">Appendix B</tag>
      <tag role="refnum">B</tag>
      <tag role="typerefnum">Appendix B</tag>
    </tags>
    <title><tag close=" ">Appendix B</tag>Implementation Details</title>
    <toctitle><tag close=" ">B</tag>Implementation Details</toctitle>
    <para xml:id="A2.p1">
      <p>In Table <ref labelref="LABEL:tab:params"/> we give the implementation details of our IDM and DT transformer architectures.</p>
    </para>
    <para xml:id="A2.p2">
      <p>The IDM model is the same as the DT model, except that it is non-causal. This is enforced by changing the attention mask to a matrix of all <Math mode="inline" tex="1" text="1" xml:id="A2.p2.m1">
          <XMath>
            <XMTok meaning="1" role="NUMBER">1</XMTok>
          </XMath>
        </Math> values in the IDM.</p>
    </para>
    <table inlist="lot" labels="LABEL:tab:params" placement="H" xml:id="A2.T3">
      <tags>
        <tag><text fontsize="90%">Table 3</text></tag>
        <tag role="autoref">Table 3</tag>
        <tag role="refnum">3</tag>
        <tag role="typerefnum">Table 3</tag>
      </tags>
      <toccaption><tag close=" ">3</tag>A summary of the transformer model parameters.</toccaption>
      <caption><tag close=": "><text fontsize="90%">Table 3</text></tag><text fontsize="90%">A summary of the transformer model parameters.</text></caption>
      <tabular class="ltx_centering ltx_guessed_headers" vattach="middle">
        <thead>
          <tr>
            <td align="center" thead="column row"><text font="bold">Parameter</text></td>
            <td align="center" thead="column"><text font="bold">Value</text></td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left" border="t" thead="row">Layers</td>
            <td align="left" border="t"><Math mode="inline" tex="6" text="6" xml:id="A2.T3.m1">
                <XMath>
                  <XMTok meaning="6" role="NUMBER">6</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Hidden Size</td>
            <td align="left"><Math mode="inline" tex="512" text="512" xml:id="A2.T3.m2">
                <XMath>
                  <XMTok meaning="512" role="NUMBER">512</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Heads</td>
            <td align="left"><Math mode="inline" tex="8" text="8" xml:id="A2.T3.m3">
                <XMath>
                  <XMTok meaning="8" role="NUMBER">8</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Batch Size</td>
            <td align="left"><Math mode="inline" tex="256" text="256" xml:id="A2.T3.m4">
                <XMath>
                  <XMTok meaning="256" role="NUMBER">256</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Weight Decay</td>
            <td align="left"><Math mode="inline" tex="5\times 10^{-5}" text="5 * 10 ^ (- 5)" xml:id="A2.T3.m5">
                <XMath>
                  <XMApp>
                    <XMTok meaning="times" role="MULOP">×</XMTok>
                    <XMTok meaning="5" role="NUMBER">5</XMTok>
                    <XMApp>
                      <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                      <XMTok meaning="10" role="NUMBER">10</XMTok>
                      <XMApp>
                        <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                        <XMTok fontsize="70%" meaning="5" role="NUMBER">5</XMTok>
                      </XMApp>
                    </XMApp>
                  </XMApp>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Learning Rate</td>
            <td align="left"><Math mode="inline" tex="3\times 10^{-4}" text="3 * 10 ^ (- 4)" xml:id="A2.T3.m6">
                <XMath>
                  <XMApp>
                    <XMTok meaning="times" role="MULOP">×</XMTok>
                    <XMTok meaning="3" role="NUMBER">3</XMTok>
                    <XMApp>
                      <XMTok role="SUPERSCRIPTOP" scriptpos="post1"/>
                      <XMTok meaning="10" role="NUMBER">10</XMTok>
                      <XMApp>
                        <XMTok fontsize="70%" meaning="minus" role="ADDOP">-</XMTok>
                        <XMTok fontsize="70%" meaning="4" role="NUMBER">4</XMTok>
                      </XMApp>
                    </XMApp>
                  </XMApp>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Gradient Clipping</td>
            <td align="left"><Math mode="inline" tex="1.0" text="1.0" xml:id="A2.T3.m7">
                <XMath>
                  <XMTok meaning="1.0" role="NUMBER">1.0</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row"><Math mode="inline" tex="\beta_{1},\beta_{2}" text="list@(beta _ 1, beta _ 2)" xml:id="A2.T3.m8">
                <XMath>
                  <XMDual>
                    <XMApp>
                      <XMTok meaning="list"/>
                      <XMRef idref="A2.T3.m8.1"/>
                      <XMRef idref="A2.T3.m8.2"/>
                    </XMApp>
                    <XMWrap>
                      <XMApp xml:id="A2.T3.m8.1">
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="italic" name="beta" role="UNKNOWN">β</XMTok>
                        <XMTok fontsize="70%" meaning="1" role="NUMBER">1</XMTok>
                      </XMApp>
                      <XMTok role="PUNCT">,</XMTok>
                      <XMApp xml:id="A2.T3.m8.2">
                        <XMTok role="SUBSCRIPTOP" scriptpos="post1"/>
                        <XMTok font="italic" name="beta" role="UNKNOWN">β</XMTok>
                        <XMTok fontsize="70%" meaning="2" role="NUMBER">2</XMTok>
                      </XMApp>
                    </XMWrap>
                  </XMDual>
                </XMath>
              </Math></td>
            <td align="left"><Math mode="inline" tex="0.9,0.999" text="list@(0.9, 0.999)" xml:id="A2.T3.m9">
                <XMath>
                  <XMDual>
                    <XMApp>
                      <XMTok meaning="list"/>
                      <XMRef idref="A2.T3.m9.1"/>
                      <XMRef idref="A2.T3.m9.2"/>
                    </XMApp>
                    <XMWrap>
                      <XMTok meaning="0.9" role="NUMBER" xml:id="A2.T3.m9.1">0.9</XMTok>
                      <XMTok role="PUNCT">,</XMTok>
                      <XMTok meaning="0.999" role="NUMBER" xml:id="A2.T3.m9.2">0.999</XMTok>
                    </XMWrap>
                  </XMDual>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Warm-up Steps</td>
            <td align="left"><Math mode="inline" tex="4000" text="4000" xml:id="A2.T3.m10">
                <XMath>
                  <XMTok meaning="4000" role="NUMBER">4000</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Optimizer</td>
            <td align="left">LAMB</td>
          </tr>
        </tbody>
      </tabular>
    </table>
  </appendix>
  <appendix inlist="toc" xml:id="A3">
    <tags>
      <tag>Appendix C</tag>
      <tag role="autoref">Appendix C</tag>
      <tag role="refnum">C</tag>
      <tag role="typerefnum">Appendix C</tag>
    </tags>
    <title><tag close=" ">Appendix C</tag>Experiments with Conservative Q-Learning (CQL)</title>
    <toctitle><tag close=" ">C</tag>Experiments with Conservative Q-Learning (CQL)</toctitle>
    <para xml:id="A3.p1">
      <p>In this set of experiments, we examine the performance of Conservative Q-Learning (CQL) <cite class="ltx_citemacro_citep">(<bibref bibrefs="10.5555/3495724.3495824" separator=";" show="AuthorsPhrase1Year" yyseparator=",">
            <bibrefphrase>, </bibrefphrase>
          </bibref>)</cite> trained on a dataset of <Math mode="inline" tex="10,000" text="list@(10, 000)" xml:id="A3.p1.m1">
          <XMath>
            <XMDual>
              <XMApp>
                <XMTok meaning="list"/>
                <XMRef idref="A3.p1.m1.1"/>
                <XMRef idref="A3.p1.m1.2"/>
              </XMApp>
              <XMWrap>
                <XMTok meaning="10" role="NUMBER" xml:id="A3.p1.m1.1">10</XMTok>
                <XMTok role="PUNCT">,</XMTok>
                <XMTok meaning="000" role="NUMBER" xml:id="A3.p1.m1.2">000</XMTok>
              </XMWrap>
            </XMDual>
          </XMath>
        </Math> frames, as opposed to <Math mode="inline" tex="500,000" text="list@(500, 000)" xml:id="A3.p1.m2">
          <XMath>
            <XMDual>
              <XMApp>
                <XMTok meaning="list"/>
                <XMRef idref="A3.p1.m2.1"/>
                <XMRef idref="A3.p1.m2.2"/>
              </XMApp>
              <XMWrap>
                <XMTok meaning="500" role="NUMBER" xml:id="A3.p1.m2.1">500</XMTok>
                <XMTok role="PUNCT">,</XMTok>
                <XMTok meaning="000" role="NUMBER" xml:id="A3.p1.m2.2">000</XMTok>
              </XMWrap>
            </XMDual>
          </XMath>
        </Math> in the original work (Table 3 of CQL, <Math mode="inline" tex="1\%" text="1percent" xml:id="A3.p1.m3">
          <XMath>
            <XMApp>
              <XMTok meaning="percent" role="POSTFIX">%</XMTok>
              <XMTok meaning="1" role="NUMBER">1</XMTok>
            </XMApp>
          </XMath>
        </Math> dataset size), from various Atari games utilized in our experiments. In Table <ref labelref="LABEL:cql"/> we report the final evaluation performance on the game after training for <Math mode="inline" tex="100" text="100" xml:id="A3.p1.m4">
          <XMath>
            <XMTok meaning="100" role="NUMBER">100</XMTok>
          </XMath>
        </Math> iterations. All implementation details are consistent with the original implementation in the cited work. We utilize the CQL<Math class="ltx_math_unparsed" mode="inline" tex="(\mathcal{H}" xml:id="A3.p1.m5">
          <XMath>
            <XMTok role="OPEN" stretchy="false">(</XMTok>
            <XMTok font="caligraphic" role="UNKNOWN">H</XMTok>
          </XMath>
        </Math>) method.</p>
    </para>
    <table inlist="lot" labels="LABEL:cql" placement="H" xml:id="A3.T4">
      <tags>
        <tag><text fontsize="90%">Table 4</text></tag>
        <tag role="autoref">Table 4</tag>
        <tag role="refnum">4</tag>
        <tag role="typerefnum">Table 4</tag>
      </tags>
      <toccaption><tag close=" ">4</tag>The final evaluation game performance after training CQL for 100 iterations on a dataset of 10,000 labelled frames from each Atari game.</toccaption>
      <caption><tag close=": "><text fontsize="90%">Table 4</text></tag><text fontsize="90%">The final evaluation game performance after training CQL for 100 iterations on a dataset of 10,000 labelled frames from each Atari game.</text></caption>
      <tabular class="ltx_centering ltx_guessed_headers" vattach="middle">
        <thead>
          <tr>
            <td align="center" thead="column row"><text font="bold">Game Name</text></td>
            <td align="center" thead="column"><text font="bold">Final Performance</text></td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left" border="t" thead="row">Asterix</td>
            <td align="left" border="t"><Math mode="inline" tex="227.5" text="227.5" xml:id="A3.T4.m1">
                <XMath>
                  <XMTok meaning="227.5" role="NUMBER">227.5</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Breakout</td>
            <td align="left"><Math mode="inline" tex="12.3" text="12.3" xml:id="A3.T4.m2">
                <XMath>
                  <XMTok meaning="12.3" role="NUMBER">12.3</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Freeway</td>
            <td align="left"><Math mode="inline" tex="10.2" text="10.2" xml:id="A3.T4.m3">
                <XMath>
                  <XMTok meaning="10.2" role="NUMBER">10.2</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">Seaquest</td>
            <td align="left"><Math mode="inline" tex="236.0" text="236.0" xml:id="A3.T4.m4">
                <XMath>
                  <XMTok meaning="236.0" role="NUMBER">236.0</XMTok>
                </XMath>
              </Math></td>
          </tr>
          <tr>
            <td align="left" thead="row">SpaceInvaders</td>
            <td align="left"><Math mode="inline" tex="250.9" text="250.9" xml:id="A3.T4.m5">
                <XMath>
                  <XMTok meaning="250.9" role="NUMBER">250.9</XMTok>
                </XMath>
              </Math></td>
          </tr>
        </tbody>
      </tabular>
    </table>
  </appendix>
</document>
