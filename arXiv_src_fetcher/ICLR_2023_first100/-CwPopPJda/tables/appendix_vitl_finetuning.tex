\begin{table}[htb]
\small
\centering
\caption{\textbf{Impact of encoder size on finetuned performance.} 
After pretraining, models are equipped with task-specific decoders and finetuned for that task on the entire downstream dataset.}
\vspace{-0.5em}
\begin{tabularx}{\columnwidth}{l *{6}{Y}}

\multicolumn{3}{c}{} & \multicolumn{2}{c}{Finetuned accuracy (mIoU)} \\
\cmidrule(l){4-5}
Method & Encoder & Dataset & PASCAL $\uparrow$ & ADE20K $\uparrow$ \\
\midrule										
\rowcolor{DnCBG}\oursb	&	ViT-B	&	IN1K	&	80.0	&	44.9	\\
\rowcolor{DnCBG}\oursb	&	ViT-L	&	IN1K	&	82.4	&	47.1	\\
\\
\rowcolor{DnCBG}\oursupb	&	ViT-B	&	IN1K	&	81.2	&	44.9	\\
\rowcolor{DnCBG}\oursupb	&	ViT-L	&	IN1K	&	81.8	&	47.3	\\
\\
\rowcolor{DnCBG}\oursb	&	ViT-B	&	IN22K	&	81.6	&	46.9	\\
\rowcolor{DnCBG}\oursb	&	ViT-L	&	IN22K	&	84.1	&	50.8	\\
\\
\rowcolor{DnCBG}\oursupb	&	ViT-B	&	IN22K	&	82.1	&	48.2	\\
\rowcolor{DnCBG}\oursupb	&	ViT-L	&	IN22K	&	\textbf{85.3}	&	\textbf{52.0}	\\
\\
\end{tabularx}
\vspace{-1em}
\label{tab:appendix_vitl_finetuning}
\end{table}