\begin{table}[t]
\vspace{1.em}
\small
\centering
\caption{\textbf{Fast adaptation to new scene understanding tasks.} After pretraining, models are transferred to downstream tasks with the full dataset, but a small amount of computation: 1 epoch. Models perform the task either with a linear classifier (\evalfrozen), end-to-end fine-tuning (\evalft) or with our mechanism for in-context scene understanding (\nneval).}
\begin{tabularx}{\columnwidth}{l *{7}{Y}} &
                    & \multicolumn{2}{c}{PASCAL $\uparrow$}                                   & \multicolumn{2}{c}{ADE20K $\uparrow$}                                           \\ \cmidrule(l){3-4} \cmidrule(l){5-6} 
                    \multicolumn{1}{l}{Method} & \multicolumn{1}{c}{Decoder} & \evalfrozen &  \evalft & \evalfrozen & \evalft \\ \hline
Supervised \cite{touvron2022deit}	&	Linear	&	61.5	&	66.3	&	27.6	&	15.1	\\
DINO \cite{caron2021emerging}	&	Linear	&	54.9	&	64.0	&	25.6	&	23.4	\\
MoCo-v3 \cite{chen2021empirical}	&	Linear	&	41.2	&	4.8	&	14.6	&	3.2	\\
MAE \cite{he2021masked}	&	Linear	&	20.1	&	42.5	&	8.3	&	7.9	\\
LOCA \cite{caron2022location}	&	Linear	&	61.9	&	62.9	&	25.4	&	14.6	\\
\rowcolor{DnCBG}\oursb 	&	\nneval	    &	\multicolumn{2}{c}{70.5}	&	\multicolumn{2}{c}{28.3} \\
\rowcolor{DnCBG}\oursupb 	&	\nneval	&	\multicolumn{2}{c}{\textbf{72.1}}	&	\multicolumn{2}{c}{\textbf{30.5}} \\                   
\end{tabularx}
\label{tab:4_fast_adapt}
\end{table}