
@article{zhang2019theoretically,
author = {Zhang, Hongyang  and   Yu, Yaodong and Jiao, Jiantao and P Xing, Eric  and El Ghaoui, Laurent and  I Jordan, Michael},
journal = {In International Conference on Machine Learning (ICML)},
title = {Theoretically principled trade-off between robustness and accuracy},
volume = {},
year = {2019}
}


@article{wang2020improving,
	author = {Wang, Yisen and Zou, Difan and Yi, Jinfeng and Bailey, James and Ma, Xingjun and Gu, Quanquan},
	journal = {In International Conference on Learning  Representations (ICLR)},
	title = {Improving adversarial robustness requires revisiting misclassified examples},
	volume = {},
	year = {2020}
}



@article{ding2020mma,
	author={Ding, Gavin Weiguang and Sharma, Yash and Lui, Kry Yik Chau and Huang, Ruitong},
	journal = {In International Conference on Learning  Representataions(ICLR)},
	title = {MMA Training:
	Direct Input Space Margin Maximization through Adversarial Training.},
	volume = {},
	year = {2020}
}


@article{kurakin2017adversarial,
	author = {Kurakin, Alexey  and J Goodfellow, Ian and Bengio, Samy},
	journal = {In International Conference on Learning  Representataions(ICLR)},
	title = {Adversarial Machine Learning at Scale},
	volume = {},
	year = {2017}
}

@article{kurakin2016adversarial,
	author = {Kurakin, Alexey  and J Goodfellow, Ian and Bengio, Samy},
	journal = {In International Conference on Learning Representations (ICLR)},
	title = {Adversarial examples in the physical world},
	volume = {},
	year = {2017}
}

@article{carmon2019unlabeled,
	author = {Carmon, Yair and Raghunathan, Aditi and Ludwig, Schmidt and C Duchi, John  and Liang, Percy S},
	journal = {In Conference on Neural Information Processing Systems (NeurIPS)},
	title = {Unlabeled Data Improves Adversarial Robustness},
	volume = {},
	year = {2019}
}

@article{ilyas2019adversarial,
	author = {Ilyas, Andrew and Santurkar, Shibani  and Tsipras, Dimitris and Engstrom, Logan and Tran,   Brandon  and  Madry, Aleksander},
	journal = {In Conference on Neural Information Processing Systems (NeurIPS)},
	title = {Adversarial examples are not bugs, they are features},
	volume = {},
	year = {2019}
}

@article{kannan2018adversarial,
	author = {Kannan, Harini and Kurakin, Alexey and
	Goodfellow, Ian J},
	journal = {arXiv preprint arXiv:1803.06373},
	title = {Adversarial Logit Pairing},
	volume = {},
	year = {2018}
}

@article{tramer2018ensemble,
	author = {Tramer, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian J  and Dan Boneh and Patrick D
	McDaniel},
	journal = {In International Conference on Learning Representations (ICLR)},
	title = {Ensemble Adversarial Training: Attacks and Defenses},
	volume = {},
	year = {2018}
}

@article{goodfellow2015explaining,
	author = {Goodfellow, Ian J and Shlens, Jonathon  and Szegedy, Christian},
	journal = {In International Conference on Learning Representations (ICLR)},
	title = {Explaining and Harnessing Adversarial Examples},
	volume = {},
	year = {2015}
}


@misc{maini2020adversarial,
      title={Adversarial Robustness Against the Union of Multiple Perturbation Models}, 
      author={Pratyush Maini and Eric Wong and J. Zico Kolter},
      year={2020},
      eprint={1909.04068},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{rice2020overfitting,
	author = {Rice, Leslie and  Wong, Ericg and J. Zico	Kolter},
	journal = {In International Conference on Machine Learning (ICML)},
	title = {Overfitting in adversarially robust deep learning},
	volume = {},
	year = {2020}
}

@article{ludwig2018adversarially,
	author = {Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and Aleksander Madry},
	journal = {In Conference on Neural Information Processing Systems (NeurIPS)},
	title = {Adversarially robust generalization requires more data},
	volume = {},
	year = {2018}
}

@article{shafahi2019adversarial,
	author = {Shafahi, Ali  and Dickerson, John and Taylor, Gavin and Studer, Christoph and Goldstein, Tom  and Davis, Larry S and Mahyar, Najibi and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Christoph Studer and Larry S Davis and Gavin Taylor and
	Goldstein, Tom and Dickerson, John and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
	journal = {In Conference on Neural Information Processing Systems (NeurIPS)},
	title = {Adversarial training for free!},
	volume = {},
	year = {2018}
}

@article{song2020robust,
	author = {Chuanbiao Song, Kun He, Jiadong Lin, Liwei Wang, and John E. Hopcroft},
	journal = {In International Conference on Learning Representations (ICLR)},
	title = {Robust local features for improving the generalization of adversarial training},
	volume = {},
	year = {2018}
}


@article{wong2020fast,
	title={Fast is better than free: Revisiting adversarial training},
	author={Wong, Eric and Rice, Leslie and Kolter, J Zico},
	journal={In International Conference on Learning Representations (ICLR)},
	year={2020}
}


@article{xie2020smooth,
	title={Smooth adversarial training},
	author={Xie, Cihang and Tan, Mingxing and Gong, Boqing and Yuille, Alan and Le, Quoc V},
	journal={arXiv preprint arXiv:2006.14536},
	year={2020}
}

@inproceedings{xing2021on,
	title={On the Generalization Properties of Adversarial Training},
	author={Xing, Yue and Song, Qifan and Cheng, Guang},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={505--513},
	year={2021},
	organization={PMLR}
}

@article{yang2020closer,
	title={A closer look at accuracy vs. robustness},
	author={Yang, Yao-Yuan and Rashtchian, Cyrus and Zhang, Hongyang and Salakhutdinov, Ruslan and Chaudhuri, Kamalika},
	journal={In Conference on Neural Information Processing Systems (NeurIPS)},
	year={2020}
}

@inproceedings{lamb2019interpolated,
	title={Interpolated adversarial training: Achieving robust neural networks without sacrificing too much accuracy},
	author={Lamb, Alex and Verma, Vikas and Kannala, Juho and Bengio, Yoshua},
	booktitle={Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security},
	pages={95--103},
	year={2019}
}

@article{tsipras2018robustness,
	title={Robustness may be at odds with accuracy},
	author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
	journal={arXiv preprint arXiv:1805.12152},
	year={2018}
}

@article{stutz2020confidence,
	title={Confidence-calibrated adversarial training: Generalizing to unseen attacks},
	author={Stutz, David and Hein, Matthias and Schiele, Bernt},
	year={2020},
	journal={In International Conference on Machine Learning (ICML)}
}


@article{xie2019intriguing,
	title={Intriguing properties of adversarial training at scale},
	author={Xie, Cihang and Yuille, Alan},
	journal={In International Conference on Learning Representations (ICLR)},
	year={2020}
}

@article{wu2020adversarial,
	title={Adversarial weight perturbation helps robust generalization},
	author={Wu, Dongxian and Xia, Shu-Tao and Wang, Yisen},
	journal={In Conference on Neural Information Processing Systems (NeurIPS)},
	year={2020}
}

@article{izmailov2018averaging,
	title={Averaging weights leads to wider optima and better generalization},
	author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
	journal={Proceedings of the international conference on Uncertainty in Artificial Intelligence},
	year={2018}
}

@article{rebuffi2021fixing,
	title={Fixing data augmentation to improve adversarial robustness},
	author={Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan A and Stimberg, Florian and Wiles, Olivia and Mann, Timothy},
	journal={arXiv preprint arXiv:2103.01946},
	year={2021}
}

@article{gowal2020uncovering,
	title={Uncovering the limits of adversarial training against norm-bounded adversarial examples},
	author={Gowal, Sven and Qin, Chongli and Uesato, Jonathan and Mann, Timothy and Kohli, Pushmeet},
	journal={arXiv preprint arXiv:2010.03593},
	year={2020}
}

@article{garipov2018loss,
	title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
	author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry and Wilson, Andrew Gordon},
	journal={In Conference on Neural Information Processing Systems (NeurIPS)},
	year={2018}
}

@article{chen2021robust,
	title={Robust overfitting may be mitigated by properly learned smoothening},
	author={Chen, Tianlong and Zhang, Zhenyu and Liu, Sijia and Chang, Shiyu and Wang, Zhangyang},
	journal={In International Conference on Learning Representations (ICLR)},
	year={2021}
}

@article{yun2019cutmix,
	title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
	author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
	journal = {In CVPR},
	year={2019}
}

@article{yuan2020revisiting,
	title={Revisiting knowledge distillation via label smoothing regularization},
	author={Yuan, Li and Tay, Francis EH and Li, Guilin and Wang, Tao and Feng, Jiashi},
	journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	year={2020}
}

@article{szegedy2016rethinking,
	title={Rethinking the inception architecture for computer vision},
	author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	year={2016}
}

@article{madry2018towards,
	title={Towards deep learning models resistant to adversarial attacks},
	author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	journal={In International Conference on Learning Representations (ICLR)},
	year={2018}
}

@article{zhang2020attacks,
  author    = {Jingfeng Zhang and
               Xilie Xu and
               Bo Han and
               Gang Niu and
               Lizhen Cui and
               Masashi Sugiyama and
               Mohan S. Kankanhalli},
  title     = {Attacks Which Do Not Kill Training Make Adversarial Learning Stronger},
  journal   = {In International Conference on Machine Learning (ICML)},
  year      = {2020}
}

@article{zhang2021geometry,
  author    = {Jingfeng Zhang and
               Jianing Zhu and
               Gang Niu and
               Bo Han and
               Masashi Sugiyama and
               Mohan S. Kankanhalli},
  title     = {Geometry-aware Instance-reweighted Adversarial Training},
  journal   = {In International Conference on Learning Representations (ICLR)},
  year      = {2021}
}

@article{rade2022reducing,
  author    = {Rahul Rade and
               Seyed-Mohsen Moosavi-Dezfolli},
  title     = {Recuding Excessive Margin to Achieve
a Better Accuracy VS. Robustness Trade-off},
  journal   = {In International Conference on Learning Representations (ICLR)},
  year      = {2022}
}

@article{croce2020minimally,
  author    = {Francesco Croce and
               Matthias Hein},
  title     = {Minimally distorted Adversarial Examples with a Fast Adaptive Boundary
               Attack},
  journal   = {In The European Conference on Computer Vision(ECCV)},
  year      = {2020}
}

@article{pereyra2017regularzing,
  author    = {Gabriel Pereyra and
               George Tucker and
               Jan Chorowski and
               Lukasz Kaiser and
               Geoffrey E. Hinton},
  title     = {Regularizing Neural Networks by Penalizing Confident Output Distributions},
  journal   = {In International Conference on Learning Representations (ICLR)},
  year      = {2017}
}

@article{muller2019when,
  author    = {Rafael M{\"{u}}ller and
               Simon Kornblith and
               Geoffrey E. Hinton},
  title     = {When Does Label Smoothing Help?},
  journal   = {In Conference on Neural Information Processing Systems (NeurIPS)},
  year      = {2019}
}

@article{guo2017on,
  author    = {Chuan Guo and
               Geoff Pleiss and
               Yu Sun and
               Kilian Q. Weinberger},
  title     = {On Calibration of Modern Neural Networks},
  journal   = {In International Conference on Machine Learning (ICML)},
  year      = {2017}
}

@article{uesato2019are,
  author    = {Jonathan Uesato and
               Jean{-}Baptiste Alayrac and
               Po{-}Sen Huang and
               Robert Stanforth and
               Alhussein Fawzi and
               Pushmeet Kohli},
  title     = {Are Labels Required for Improving Adversarial Robustness?},
  journal   = {In Conference on Neural Information Processing Systems (NeurIPS)},
  year      = {2019}
}

@article{najafi2019robustness,
      title={Robustness to Adversarial Perturbations in Learning from Incomplete Data}, 
      author={Amir Najafi and Shin-ichi Maeda and Masanori Koyama and Takeru Miyato},
      journal={In Conference on Neural Information Processing Systems (NeurIPS)},
      year={2019}
     
}

@article{zhai2019adversarially,
      title={Adversarially Robust Generalization Just Requires More Unlabeled Data}, 
      author={Runtian Zhai and Tianle Cai and Di He and Chen Dan and Kun He and John Hopcroft and Liwei Wang},
      year={2019},
      journal={archive}
}

@article{schmidt2018adversarially,
      title={Adversarially Robust Generalization Requires More Data}, 
      author={Ludwig Schmidt and Shibani Santurkar and Dimitris Tsipras and Kunal Talwar and Aleksander Mądry},
      year={2018},
      journal={In Conference on Neural Information Processing Systems (NeurIPS)}
}

@article{papernot2017practical,
      title={Practical Black-Box Attacks against Machine Learning}, 
      author={Nicolas Papernot and Patrick McDaniel and Ian Goodfellow and Somesh Jha and Z. Berkay Celik and Ananthram Swami},
      year={2017},
      journal={In ACM}
}

@article{nakkiran2019adversarial,
      title={Adversarial Robustness May Be at Odds With Simplicity}, 
      author={Preetum Nakkiran},
      year={2019},
      archivePrefix={arXiv}
}

@article{szegedy2014intriguing,
      title={Intriguing properties of neural networks}, 
      author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
      year={2014},
      journal={In International Conference on Learning Representations (ICLR)}
}

@article{jiang2019blackbox,
      title={Black-box Adversarial Attacks on Video Recognition Models}, 
      author={Linxi Jiang and Xingjun Ma and Shaoxiang Chen and James Bailey and Yu-Gang Jiang},
      year={2019},
      journal={In ACM}
}

@article{finlayson2019adversarial,
      title={Adversarial Attacks Against Medical Deep Learning Systems}, 
      author={Samuel G. Finlayson and Hyung Won Chung and Isaac S. Kohane and Andrew L. Beam},
      year={2019},
      journal={In Science}
}

@article{ma2021understanding,
   title={Understanding adversarial attacks on deep learning based medical image analysis systems},
   journal={Pattern Recognition},
   publisher={Elsevier BV},
   author={Ma, Xingjun and Niu, Yuhao and Gu, Lin and Wang, Yisen and Zhao, Yitian and Bailey, James and Lu, Feng},
   year={2020}}
   
@article{chen2017zoo,
   title={ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models},
   url={http://dx.doi.org/10.1145/3128572.3140448},
   DOI={10.1145/3128572.3140448},
   journal={In ACM},
   author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
   year={2017}
}

@article{papernot2016transferability,
      title={Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples}, 
      author={Nicolas Papernot and Patrick McDaniel and Ian Goodfellow},
      year={2016},
      journal={arXiv}
}

@article{carlini2017evaluating,
      title={Towards Evaluating the Robustness of Neural Networks}, 
      author={Nicholas Carlini and David Wagner},
      year={2017},
      journal={IEEE Symposium on Security and Privacy}
}

@article{tsipras2019robustness,
      title={Robustness May Be at Odds with Accuracy}, 
      author={Dimitris Tsipras and Shibani Santurkar and Logan Engstrom and Alexander Turner and Aleksander Madry},
      year={2019},
      journal={In International Conference on Learning Representations (ICLR)}
}

@article{raghunathan2019adversarial,
      title={Adversarial Training Can Hurt Generalization}, 
      author={Aditi Raghunathan and Sang Michael Xie and Fanny Yang and John C. Duchi and Percy Liang},
      year={2019},
      journal={In International Conference on Machine Learning (ICML)}
}

@article{ilyas2018blackbox,
      title={Black-box Adversarial Attacks with Limited Queries and Information}, 
      author={Andrew Ilyas and Logan Engstrom and Anish Athalye and Jessy Lin},
      year={2018},
      journal={In International Conference on Machine Learning (ICML)}
}

@article{deng2020analysis,
      title={An Analysis of Adversarial Attacks and Defenses on Autonomous Driving Models}, 
      author={Yao Deng and Xi Zheng and Tianyi Zhang and Chen Chen and Guannan Lou and Miryung Kim},
      year={2020},
      journal={IEEE International Conference on Pervasive Computing and Communications(PerCom)}
}

@article{morgulis2019fooling,
      title={Fooling a Real Car with Adversarial Traffic Signs}, 
      author={Nir Morgulis and Alexander Kreines and Shachar Mendelowitz and Yuval Weisglass},
      year={2019},
      journal={ArXiv}
}

@article{li2020adaptive,
      title={Adaptive Square Attack: Fooling Autonomous Cars With Adversarial Traffic Signs}, 
      author={Yujie Li and Xing Xu and Jinhui Xiao and Siyuan Li and Heng Tao Shen},
      year={2020},
      journal={IEEE Internet of Things Journal}
}

@article{bartlett2006convexity,
 author = {Peter L. Bartlett and Michael I. Jordan and Jon D. Mcauliffe},
 journal = {Journal of the American Statistical Association},
 number = {473},
 pages = {138--156},
 publisher = {American Statistical Association, Taylor & Francis, Ltd.},
 title = {Convexity, Classification, and Risk Bounds},
 volume = {101},
 year = {2006}
}

@article{papernot2016science,
      title={Towards the Science of Security and Privacy in Machine Learning}, 
      author={Nicolas Papernot and Patrick McDaniel and Arunesh Sinha and Michael Wellman},
      year={2018},
      journal={2018 IEEE European Symposium on Security and Privacy (EuroS\&P)}
}

@misc{croce2020reliable,
      title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks}, 
      author={Francesco Croce and Matthias Hein},
      year={2020},
      journal={ICML}
}


@misc{krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@article{zagoruyko2016wide,
  author    = {Sergey Zagoruyko and
               Nikos Komodakis},
  title     = {Wide Residual Networks},
  journal   = {Proceedings of the British Machine Vision Conference 2016},
  year      = {2016}
}

@article{cheng2020cat,
  author    = {Minhao Cheng and
               Qi Lei and
               Pin{-}Yu Chen and
               Inderjit S. Dhillon and
               Cho{-}Jui Hsieh},
  title     = {{CAT:} Customized Adversarial Training for Improved Robustness},
  journal   = {arXiv},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.06789}
}

@article{hua2021bullet,
      title={BulletTrain: Accelerating Robust Neural Network Training via Boundary Example Mining}, 
      author={Weizhe Hua and Yichi Zhang and Chuan Guo and Zhiru Zhang and G. Edward Suh},
      year={2021},
      journal={In Conference on Neural Information Processing Systems (NeurIPS)}
}

@article{andriushchenko2020square,
      title={Square Attack: a query-efficient black-box adversarial attack via random searchg}, 
      author={Maksym Andriushchenko and Francesco Croce and Nicolas Flammarion and Matthias Hein},
      year={2020},
      journal={In ECCV}
}

@article{hitaj2021evaluating,
  title = {Evaluating the Robustness of Geometry-Aware Instance-Reweighted Adversarial Training},
  author = {Hitaj, Dorjan and Pagnotta, Giulio and Masi, Iacopo and Mancini, Luigi V.},
  year={2021},
  journal={archive}
}
  
  
@article{xu2021to,
  author = {Xu, Han and Liu, Xiaorui and Li, Yaxin and Jain, Anil K. and Tang, Jiliang},
  title = {To be Robust or to be Fair: Towards Fairness in Adversarial Training},
  journal={In International Conference on Machine Learning (ICML)},
  year = {2021}
}

@article{van2008visualizing,
  author = {van der Maaten, L.J.P},
  title = {Visualizing Data Using t-SNE},
  journal={In Journal of Machine Learning Research},
  year = {2008}
}

@article{he2016deep,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep Residual Learning for Image Recognition},
  journal = {In CVPR},
  year = {2016}
}

@article{xiao2017fahsion,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  year         = {2017},
  journal      = {archive}
}

@article{netzer2011svhn,
    title	= {Reading Digits in Natural Images with Unsupervised Feature Learning},
    author	= {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
    year	= {2011},
    Journal	= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}


@article{loshchilov2017sgdr,
  author = {Loshchilov, Ilya and Hutter, Frank},
  title = {SGDR: Stochastic Gradient Descent with Warm Restarts},
  journal = {In International Conference on Learning Representations (ICLR)},
  year = {2017}
}

@article{pang2021bag,
  author = {Pang, Tianyu and Yang, Xiao and Dong, Yinpeng and Su, Hang and Zhu, Jun},
  title = {Bag of Tricks for Adversarial Training},
  journal = {In International Conference on Learning Representations (ICLR)},
  year = {2021}
}

@article{rebuffi2021data,
 author = {Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan Andrei and Stimberg, Florian and Wiles, Olivia and Mann, Timothy A},
 title = {Data Augmentation Can Improve Robustness},
 journal = {In Conference on Neural Information Processing Systems (NeurIPS)},
 year = {2021}
}

@article{ho2020denoising,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 title = {Denoising Diffusion Probabilistic Models},
 journal = {In Conference on Neural Information Processing Systems (NeurIPS)},
 year = {2020}
}

@article{he2016identity,
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 title = {Identity Mappings in Deep Residual Networks},
 journal = {In ICCV},
 year = {2016}
}

@article{ma2022on,
 author = {Ma, Xinsong and, Wang, Zekai and Liu, Weiwei},
 title = {On the Tradeoff between Robustness and Fairness},
 journal = {In NeuIPS},
 year = {2022}
}

@article{yu2022understanding,
    author={Chaojian Yu and Bo Han and Li Shen and Jun Yu and Chen Gong and Mingming Gong and Tongliang Liu},
    title={Understanding Robust Overfitting of Adversarial Training and Beyond}, 
    journal={In International Conference on Machine Learning (ICML)},
    year = {2022}
}

@article{jantre2022sequential,
      title={Sequential Bayesian Neural Subnetwork Ensembles}, 
      author={Sanket Jantre and Sandeep Madireddy and Shrijita Bhattacharya and Tapabrata Maiti and Prasanna Balaprakash},
      year={2022},
      journal={arXiv},
}