\section{Theoretical Analysis}
\label{theoretical analysis}
In this part, we mainly introduce the theoretical analysis of the optimization and generalization efficiency of our proposed \textit{A-FedPD} method. We first introduce the assumptions adopted in our proofs. Optimization analysis is stated in Sec.\ref{Optimization} and generalization analysis is stated in Sec.\ref{Generalization}.

\begin{assumption}[Smoothness]
\label{as:smoothness}
    The local function $f_i(\cdot)$ satisfies the $L$-smoothness property, i.e., $\Vert\nabla f_i(\theta_1) - \nabla f_i(\theta_2)\Vert\leq L\Vert \theta_1 - \theta_2\Vert$.
\end{assumption}

\begin{assumption}[Lipschitz continuity]
\label{as:lipschitz}
    For $\forall \ \theta_1, \theta_2 \in \mathbb{R}^d$, the global function $f(\cdot)$ satisfies the Lipschitz-continuity, i.e., $\Vert f(\theta_1) - f(\theta_2)\Vert\leq G\Vert \theta_1 - \theta_2\Vert$.
\end{assumption}

Optimization analysis only adopts Assumption~\ref{as:smoothness}. Generalization analysis adopts both assumptions that were followed from the previous work on analyzing the stability~\citep{hardt2016train,lei2020fine,zhou2021towards,sun2023understanding,sun2023mode,sun2023efficient}. Moreover, we consider that the minimization of each local Lagrangian problem achieves the $\epsilon$-inexact solution during each local training process, i.e. $\Vert \nabla \mathcal{L}_i \Vert^2 \leq \epsilon$~\citep{zhang2021fedpd,li2023dfedadmm,gong2022fedadmm,wang2022fedadmm}. This consideration is more aligned with the practical scenarios encountered in the empirical studies for non-convex optimization. In fact, it is precisely because the errors from local inexact solutions can be excessively large that the \textit{dual drift} problem is further exacerbated.

\subsection{Optimization}
\label{Optimization}

In this part, we introduce the convergence analysis of the proposed \textit{A-FedPD} method.
\begin{theorem}
    Let non-convex objective $f$ satisfies Assumption~\ref{as:smoothness}, let $\rho$ be selected as a non-zero positive constant, $\{\overline{\theta}^t\}_{t=0}^{T}$ sequence generated by algorithm~\ref{algorithm} satisfies:
    \begin{equation}
    \small
    \frac{1}{T}\sum_{t=1}^{T}\mathbb{E}\Vert\nabla f(\overline{\theta}^{t})\Vert^2 
    \leq \frac{\rho\left[ f(\overline{\theta}^1) - f^\star\right] + R_{0}}{T} + \mathcal{O}\left(\epsilon\right),
    \end{equation}
    where $f^\star$ is the optimum and $R_{0} = \frac{1}{C}\sum_{i\in\mathcal{C}}\mathbb{E}_t\Vert\theta_i^{1} - \theta^{0}\Vert^2$ is the first local training volumes.
\end{theorem}
\begin{remark}
    To achieve the $\epsilon$ error, the \textit{A-FedPD} requires $\mathcal{O}(\epsilon^{-1})$ rounds, yielding $\mathcal{O}(1/T)$ convergence rate. Concretely, the \textit{federated primal dual} methods can locally train more and communicate less, which empowers it a great potential in the applications. Our analysis is consistent with the previous understandings~\citep{zhang2021fedpd,durmus2021federated,gong2022fedadmm,li2023dfedadmm}.
\end{remark}

\begin{remark}
     Generally, the federated primal-dual methods require a long local interval. \citet{zhang2021fedpd,gong2022fedadmm,wang2022fedadmm} have summarized the corresponding selections of $K$ for different local optimizers. To complete the analysis, we just list a general selection of the local interval $K$. Specifically, to achieve the $\epsilon$ error, local interval $K$ of \textit{A-FedPD} can be selected as $\mathcal{O}(\epsilon^{-1})$ with total $\mathcal{O}(\epsilon^{-2})$ sample complexity in the training. Due to the page limitation, we state more discussions in the Appendix~\ref{ap:opt discuss}.
\end{remark}

\subsection{Generalization}
\label{Generalization}
In this part, we explore the efficiency of \textit{A-FedPD} from the stability and generalization perspective, which could also be extended to the common \textit{primal dual}-family in the federated learning community. We first introduce the setups and assumptions and then demonstrate the main theorem and discussions.

\textbf{Setups.} To understand the stability and generalization efficiency, we follow \citet{hardt2016train,lei2020fine,zhou2021towards,sun2023understanding} to adopt the uniform stability analysis to measure its error bound. To learn the generalization gap $\mathbb{E}\left[F(\theta^T)-f(\theta^T)\right]$ where $\theta^T$ is generated by a stochastic algorithm, we could study its stability gaps. We consider a joint client set $\mathcal{C}$~(union dataset) for training. Each client $i$ has a private dataset $\mathcal{S}_i$ with total $S$ samples which are sampled from the unknown distribution $\mathcal{D}_i$. To explore the stability gaps, we construct a mirror dataset $\hat{\mathcal{C}}$ that there is at most one different data sample from the raw dataset $\mathcal{C}$. Let $\theta^T$ and $\hat{\theta}^T$ be two models trained on $\mathcal{C}$ and $\hat{\mathcal{C}}$ respectively.
Therefore, the generalization of a uniformly stable method satisfies:
\begin{equation}
    \label{stability}
    \small
    \mathbb{E}\left[\vert F(\theta^T)-f(\theta^T)\vert \right]\leq\sup_{\xi}\mathbb{E}\left[\vert f(\theta^T,\xi) - f(\hat{\theta}^T,\xi)\vert\right]\leq \varepsilon.
\end{equation}

\textbf{Key properties.} From the local training, we can first upper bound the local stability. To compare the difference between vanilla \textit{SGD} updates and \textit{primal dual}-family updates, we can reformulate them:
\begin{eqnarray}
\label{local_iteration}
\small
\begin{cases}
\theta_{i,k+1}^{t}-\theta^t &= (\theta_{i,k}^{t}-\theta^t) + \eta^t g_{i,k}^t, \\
\theta_{i,k+1}^{t}-\theta^t &= (1 - \eta^t\rho)(\theta_{i,k}^{t}-\theta^t) + \eta^t(g_{i,k}^t + \lambda_i).
\end{cases}
\end{eqnarray}
The above update is for vanilla \textit{FedAvg} and the below update is for \textit{primal dual}-family. When the dual variables are ignored, local update $\theta_{i,k}^t-\theta^t$ in \textit{primal dual} could be considered as a stable decayed sequence with $1-\eta^t\rho$ that has a constant upper bound. Based on this, we can provide a tighter generalization error bound for the \textit{primal dual}-family methods in FL than the vanilla \textit{FedAvg} method.

\begin{theorem}
    Let non-convex objective $f$ satisfies Assumption~\ref{as:smoothness} and \ref{as:lipschitz} and $H=\sup_{\theta,\xi} f(\theta,\xi)$, after $T$ communication rounds training with Algorithm~\ref{algorithm}, the generalization error bound achieves:
    \begin{equation}
    \small
    \mathbb{E}\left[F(\theta^T)-f(\theta^T)\right] \leq \frac{\kappa_c}{CS}\left(HPT\right)^{\frac{\mu L}{1+\mu L}},
    \end{equation}
    where $\mu$ is a constant related to the learning rate and $\kappa_c = 4\left(G^2/L\right)^{\frac{1}{1+\mu L}}$ is a constant.
\end{theorem}

\begin{remark}
We assume that the total number of data samples participating in the training is $CS$ and the total iterations of the training are $KT$. \citet{hardt2016train} prove that on non-convex objectives, vanilla \textit{SGD} method achieves $\mathcal{O}((TK)^{\frac{\mu L}{1 + \mu L}}/CS)$ error bound. Compared with \textit{SGD}, FL adopts the cyclical local training and partial participation mechanism which further increases the stability error. \citet{sun2023mode} learn a fast rate on sample size as $\mathcal{O}((PKT)^{\frac{\mu L}{1+\mu L}}/CS)$ under the Lipschitz assumption only. However, \textit{primal dual}-family can achieve faster rate $\mathcal{O}((PT)^{\frac{\mu L}{1 + \mu L}}/CS)$ in FL, which is due to the stable iterations in Eq.(\ref{local_iteration}). It guarantees that the local training could be bounded in a constant order even under the fixed learning rate. From the local training perspective, \textit{primal dual}-family in FL can support a very long local interval $K$ without losing stability. This property is also proven in its optimization progress, that the \textit{primal dual}-family could adopt a larger local interval to accelerate the training and reduce the communication rounds. In general training, especially in situations where communication bandwidth is limited and frequent communication is not possible, the \textit{primal dual}-family in FL could achieve a more stable result than the general methods. Our analysis further confirms its good adaptivity in FL. Due to page limitation, we summarize some recent results of the generalization error bound in Appendix~\ref{ap:gen discussion}.
\end{remark}