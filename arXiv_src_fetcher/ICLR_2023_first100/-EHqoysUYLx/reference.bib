%% ===================== generalization
@inproceedings{hardt2016train,
  title={Train faster, generalize better: Stability of stochastic gradient descent},
  author={Hardt, Moritz and Recht, Ben and Singer, Yoram},
  booktitle={International conference on machine learning},
  pages={1225--1234},
  year={2016},
  organization={PMLR}
}
@inproceedings{lei2020fine,
  title={Fine-grained analysis of stability and generalization for stochastic gradient descent},
  author={Lei, Yunwen and Ying, Yiming},
  booktitle={International Conference on Machine Learning},
  pages={5809--5819},
  year={2020},
  organization={PMLR}
}
@article{zhou2021towards,
  title={Towards understanding why lookahead generalizes better than sgd and beyond},
  author={Zhou, Pan and Yan, Hanshu and Yuan, Xiaotong and Feng, Jiashi and Yan, Shuicheng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27290--27304},
  year={2021}
}
@article{sun2023understanding,
  title={Understanding How Consistency Works in Federated Learning via Stage-wise Relaxed Initialization},
  author={Sun, Yan and Shen, Li and Tao, Dacheng},
  journal={arXiv preprint arXiv:2306.05706},
  year={2023}
}

@article{sun2023mode,
  title={Which mode is better for federated learning? Centralized or Decentralized},
  author={Sun, Yan and Shen, Li and Tao, Dacheng},
  journal={arXiv preprint arXiv:2310.03461},
  year={2023}
}

@inproceedings{hu2022generalization,
  title={Generalization bounds for federated learning: Fast rates, unparticipating clients and unbounded losses},
  author={Hu, Xiaolin and Li, Shaojie and Liu, Yong},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}
@article{wu2023information,
  title={Information-Theoretic Generalization Analysis for Topology-aware Heterogeneous Federated Edge Learning over Noisy Channels},
  author={Wu, Zheshun and Xu, Zenglin and Yu, Hongfang and Liu, Jie},
  journal={IEEE Signal Processing Letters},
  year={2023},
  publisher={IEEE}
}
@inproceedings{mohri2019agnostic,
  title={Agnostic federated learning},
  author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={4615--4625},
  year={2019},
  organization={PMLR}
}
@article{sun2023generalization,
  title={Understanding Generalization of Federated Learning via Stability: Heterogeneity Matters},
  author={Sun, Zhenyu and Niu, Xiaochun and Wei, Ermin},
  journal={arXiv preprint arXiv:2306.03824},
  year={2023}
}
%% ===================== ADMM
@article{boyd2011distributed,
  title={Distributed optimization and statistical learning via the alternating direction method of multipliers},
  author={Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan and others},
  journal={Foundations and Trends{\textregistered} in Machine learning},
  volume={3},
  number={1},
  pages={1--122},
  year={2011},
  publisher={Now Publishers, Inc.}
}

%% ===================== SAM
@article{foret2020sharpness,
  title={Sharpness-aware minimization for efficiently improving generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.01412},
  year={2020}
}

%% ===================== model and dataset
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}
@article{hsu2019measuring,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}
@article{zhang2021connection,
  title={On the Connection Between Fed-Dyn and FedPD},
  author={Zhang, Xinwei and Hong, Mingyi},
  journal={FedDyn\_FedPD. pdf},
  year={2021}
}

%% ===================== FL
@article{zhang2021fedpd,
  title={FedPD: A federated learning framework with adaptivity to non-iid data},
  author={Zhang, Xinwei and Hong, Mingyi and Dhople, Sairaj and Yin, Wotao and Liu, Yang},
  journal={IEEE Transactions on Signal Processing},
  volume={69},
  pages={6055--6070},
  year={2021},
  publisher={IEEE}
}
@inproceedings{durmus2021federated,
  title={Federated Learning Based on Dynamic Regularization},
  author={Durmus, Alp Emre and Yue, Zhao and Ramon, Matas and Matthew, Mattina and Paul, Whatmough and Venkatesh, Saligrama},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@inproceedings{wang2022fedadmm,
  title={Fedadmm: A federated primal-dual algorithm allowing partial participation},
  author={Wang, Han and Marella, Siddartha and Anderson, James},
  booktitle={2022 IEEE 61st Conference on Decision and Control (CDC)},
  pages={287--294},
  year={2022},
  organization={IEEE}
}
@inproceedings{gong2022fedadmm,
  title={FedADMM: A robust federated deep learning framework with adaptivity to system heterogeneity},
  author={Gong, Yonghai and Li, Yichuan and Freris, Nikolaos M},
  booktitle={2022 IEEE 38th International Conference on Data Engineering (ICDE)},
  pages={2575--2587},
  year={2022},
  organization={IEEE}
}
@article{zhou2023federated,
  title={Federated learning via inexact ADMM},
  author={Zhou, Shenglong and Li, Geoffrey Ye},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}
@article{sun2023fedspeed,
  title={Fedspeed: Larger local interval, less communication round, and higher generalization accuracy},
  author={Sun, Yan and Shen, Li and Huang, Tiansheng and Ding, Liang and Tao, Dacheng},
  journal={arXiv preprint arXiv:2302.10429},
  year={2023}
}

@article{sun2023dynamic,
  title={Dynamic Regularized Sharpness Aware Minimization in Federated Learning: Approaching Global Consistency and Smooth Landscape},
  author={Sun, Yan and Shen, Li and Chen, Shixiang and Ding, Liang and Tao, Dacheng},
  journal={arXiv preprint arXiv:2305.11584},
  year={2023}
}
@article{tran2021feddr,
  title={FedDR--randomized Douglas-Rachford splitting algorithms for nonconvex federated composite optimization},
  author={Tran Dinh, Quoc and Pham, Nhan H and Phan, Dzung and Nguyen, Lam},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={30326--30338},
  year={2021}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International conference on machine learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@article{xu2021fedcm,
  title={Fedcm: Federated learning with client-level momentum},
  author={Xu, Jing and Wang, Sen and Wang, Liwei and Yao, Andrew Chi-Chih},
  journal={arXiv preprint arXiv:2106.10874},
  year={2021}
}

@inproceedings{qu2022generalized,
  title={Generalized federated learning via sharpness aware minimization},
  author={Qu, Zhe and Li, Xingyu and Duan, Rui and Liu, Yao and Tang, Bo and Lu, Zhuo},
  booktitle={International Conference on Machine Learning},
  pages={18250--18280},
  year={2022},
  organization={PMLR}
}

@article{he2023communication,
  title={Communication-Efficient Federated Learning with Adaptive Consensus ADMM},
  author={He, Siyi and Zheng, Jiali and Feng, Minyu and Chen, Yixin},
  journal={Applied Sciences},
  volume={13},
  number={9},
  pages={5270},
  year={2023},
  publisher={MDPI}
}

@article{niu2023fedhybrid,
  title={FedHybrid: A hybrid federated optimization method for heterogeneous clients},
  author={Niu, Xiaochun and Wei, Ermin},
  journal={IEEE Transactions on Signal Processing},
  volume={71},
  pages={150--163},
  year={2023},
  publisher={IEEE}
}

@inproceedings{yuan2021federated,
  title={Federated composite optimization},
  author={Yuan, Honglin and Zaheer, Manzil and Reddi, Sashank},
  booktitle={International Conference on Machine Learning},
  pages={12253--12266},
  year={2021},
  organization={PMLR}
}

@inproceedings{wang2023beyond,
  title={Beyond ADMM: a unified client-variance-reduced adaptive federated learning framework},
  author={Wang, Shuai and Xu, Yanqing and Wang, Zhiguo and Chang, Tsung-Hui and Quek, Tony QS and Sun, Defeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={8},
  pages={10175--10183},
  year={2023}
}

@article{li2023dfedadmm,
  title={Dfedadmm: Dual constraints controlled model inconsistency for decentralized federated learning},
  author={Li, Qinglun and Shen, Li and Li, Guanghao and Yin, Quanjun and Tao, Dacheng},
  journal={arXiv preprint arXiv:2308.08290},
  year={2023}
}

@article{tyou2023localized,
  title={A Localized Primal-Dual Method for Centralized/Decentralized Federated Learning Robust to Data Heterogeneity},
  author={Tyou, Iifan and Murata, Tomoya and Fukami, Takumi and Takezawa, Yuki and Niwa, Kenta},
  journal={IEEE Transactions on Signal and Information Processing over Networks},
  year={2023},
  publisher={IEEE}
}

@inproceedings{sarcheshmehpour2021federated,
  title={Federated learning from big data over networks},
  author={Sarcheshmehpour, Yasmin and Leinonen, M and Jung, Alexander},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3055--3059},
  year={2021},
  organization={IEEE}
}

@inproceedings{shen2021agnostic,
  title={An agnostic approach to federated learning with class imbalance},
  author={Shen, Zebang and Cervino, Juan and Hassani, Hamed and Ribeiro, Alejandro},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{li2023privacy,
  title={Privacy-Preserving Federated Primal-Dual Learning for Non-Convex Problems With Non-Smooth Regularization},
  author={Li, Yiwei and Huang, Chien-Wei and Wang, Shuai and Chi, Chong-Yung and Quek, Tony QS},
  booktitle={2023 IEEE 33rd International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2023},
  organization={IEEE}
}

@article{li2020federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of Machine learning and systems},
  volume={2},
  pages={429--450},
  year={2020}
}

@inproceedings{jhunjhunwala2022fedvarp,
  title={Fedvarp: Tackling the variance due to partial client participation in federated learning},
  author={Jhunjhunwala, Divyansh and Sharma, Pranay and Nagarkatti, Aushim and Joshi, Gauri},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={906--916},
  year={2022},
  organization={PMLR}
}

@article{dieuleveut2021federated,
  title={Federated-EM with heterogeneity mitigation and variance reduction},
  author={Dieuleveut, Aymeric and Fort, Gersende and Moulines, Eric and Robin, Genevi{\`e}ve},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29553--29566},
  year={2021}
}

@inproceedings{ozfatura2021fedadc,
  title={Fedadc: Accelerated federated learning with drift control},
  author={Ozfatura, Emre and Ozfatura, Kerem and G{\"u}nd{\"u}z, Deniz},
  booktitle={2021 IEEE International Symposium on Information Theory (ISIT)},
  pages={467--472},
  year={2021},
  organization={IEEE}
}

@inproceedings{remedios2020federated,
  title={Federated gradient averaging for multi-site training with momentum-based optimizers},
  author={Remedios, Samuel W and Butman, John A and Landman, Bennett A and Pham, Dzung L},
  booktitle={Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning: Second MICCAI Workshop, DART 2020, and First MICCAI Workshop, DCL 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4--8, 2020, Proceedings 2},
  pages={170--180},
  year={2020},
  organization={Springer}
}

@article{kim2022communication,
  title={Communication-efficient federated learning with acceleration of global momentum},
  author={Kim, Geeho and Kim, Jinkyu and Han, Bohyung},
  journal={arXiv preprint arXiv:2201.03172},
  year={2022}
}

@article{wang2020tackling,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7611--7623},
  year={2020}
}

@article{horvath2022fedshuffle,
  title={Fedshuffle: Recipes for better use of local work in federated learning},
  author={Horv{\'a}th, Samuel and Sanjabi, Maziar and Xiao, Lin and Richt{\'a}rik, Peter and Rabbat, Michael},
  journal={arXiv preprint arXiv:2204.13169},
  year={2022}
}

@article{liu2023enhance,
  title={Enhance local consistency in federated learning: A multi-step inertial momentum approach},
  author={Liu, Yixing and Sun, Yan and Ding, Zhengtao and Shen, Li and Liu, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2302.05726},
  year={2023}
}

@inproceedings{caldarola2023window,
  title={Window-based Model Averaging Improves Generalization in Heterogeneous Federated Learning},
  author={Caldarola, Debora and Caputo, Barbara and Ciccone, Marco},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2263--2271},
  year={2023}
}

@inproceedings{caldarola2022improving,
  title={Improving generalization in federated learning by seeking flat minima},
  author={Caldarola, Debora and Caputo, Barbara and Ciccone, Marco},
  booktitle={European Conference on Computer Vision},
  pages={654--672},
  year={2022},
  organization={Springer}
}

@article{slowmo,
  title={SlowMo: Improving communication-efficient distributed SGD with slow momentum},
  author={Wang, Jianyu and Tantia, Vinayak and Ballas, Nicolas and Rabbat, Michael},
  journal={arXiv preprint arXiv:1910.00643},
  year={2019}
}
@inproceedings{inconsistency1,
  title={Convergence and accuracy trade-offs in federated learning and meta-learning},
  author={Charles, Zachary and Kone{\v{c}}n{\`y}, Jakub},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2575--2583},
  year={2021},
  organization={PMLR}
}

@inproceedings{inconsistency2,
  title={From local SGD to local fixed-point methods for federated learning},
  author={Malinovskiy, Grigory and Kovalev, Dmitry and Gasanov, Elnur and Condat, Laurent and Richtarik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={6692--6701},
  year={2020},
  organization={PMLR}
}

@article{inconsistency3,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7611--7623},
  year={2020}
}

@article{yang2021achieving,
  title={Achieving linear speedup with partial worker participation in non-iid federated learning},
  author={Yang, Haibo and Fang, Minghong and Liu, Jia},
  journal={arXiv preprint arXiv:2101.11203},
  year={2021}
}

@article{reddi2020adaptive,
  title={Adaptive federated optimization},
  author={Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, H Brendan},
  journal={arXiv preprint arXiv:2003.00295},
  year={2020}
}

@article{asad2020fedopt,
  title={FedOpt: Towards communication efficiency and privacy preservation in federated learning},
  author={Asad, Muhammad and Moustafa, Ahmed and Ito, Takayuki},
  journal={Applied Sciences},
  volume={10},
  number={8},
  pages={2864},
  year={2020},
  publisher={MDPI}
}

@inproceedings{grudzien2023can,
  title={Can 5th generation local training methods support client sampling? yes!},
  author={Grudzie{\'n}, Micha{\l} and Malinovsky, Grigory and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1055--1092},
  year={2023},
  organization={PMLR}
}
@inproceedings{mishchenko2022proxskip,
  title={Proxskip: Yes! local gradient steps provably lead to communication acceleration! finally!},
  author={Mishchenko, Konstantin and Malinovsky, Grigory and Stich, Sebastian and Richt{\'a}rik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={15750--15769},
  year={2022},
  organization={PMLR}
}
@article{condat2022randprox,
  title={RandProx: Primal-dual optimization algorithms with randomized proximal updates},
  author={Condat, Laurent and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2207.12891},
  year={2022}
}
@article{condat2023tamuna,
  title={Tamuna: Doubly accelerated federated learning with local training, compression, and partial participation},
  author={Condat, Laurent and Agarsk{\`y}, Ivan and Malinovsky, Grigory and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2302.09832},
  year={2023}
}
@article{grudzien2023improving,
  title={Improving accelerated federated learning with compression and importance sampling},
  author={Grudzie{\'n}, Micha{\l} and Malinovsky, Grigory and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2306.03240},
  year={2023}
}
@article{kang2024fedand,
  title={FedAND: Federated Learning Exploiting Consensus ADMM by Nulling Drift},
  author={Kang, Heejoo and Kim, Minsoo and Lee, Bumsuk and Kim, Hongseok},
  journal={IEEE Transactions on Industrial Informatics},
  year={2024},
  publisher={IEEE}
}
@article{sun2023efficient,
  title={Efficient federated learning via local adaptive amended optimizer with linear speedup},
  author={Sun, Yan and Shen, Li and Sun, Hao and Ding, Liang and Tao, Dacheng},
  journal={arXiv preprint arXiv:2308.00522},
  year={2023}
}
@article{fan2024locally,
  title={Locally Estimated Global Perturbations are Better than Local Perturbations for Federated Sharpness-aware Minimization},
  author={Fan, Ziqing and Hu, Shengchao and Yao, Jiangchao and Niu, Gang and Zhang, Ya and Sugiyama, Masashi and Wang, Yanfeng},
  journal={arXiv preprint arXiv:2405.18890},
  year={2024}
}
@article{fan2024federated,
  title={Federated learning with bilateral curation for partially class-disjoint data},
  author={Fan, Ziqing and Yao, Jiangchao and Han, Bo and Zhang, Ya and Wang, Yanfeng and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{fan2022fedskip,
  title={Fedskip: Combatting statistical heterogeneity with federated skip aggregation},
  author={Fan, Ziqing and Wang, Yanfeng and Yao, Jiangchao and Lyu, Lingjuan and Zhang, Ya and Tian, Qi},
  booktitle={2022 IEEE International Conference on Data Mining (ICDM)},
  pages={131--140},
  year={2022},
  organization={IEEE}
}
@article{zhang2024domain,
  title={Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts},
  author={Zhang, Ruipeng and Fan, Ziqing and Yao, Jiangchao and Zhang, Ya and Wang, Yanfeng},
  journal={arXiv preprint arXiv:2405.18861},
  year={2024}
}
@article{fan2023federated,
  title={Federated learning under partially disjoint data via manifold reshaping},
  author={Fan, Ziqing and Yao, Jiangchao and Zhang, Ruipeng and Lyu, Lingjuan and Wang, Yanfeng and Zhang, Ya},
  journal={Transactions on Machine Learning Research},
  year={2023}
}
@article{pathak2020fedsplit,
  title={FedSplit: An algorithmic framework for fast federated optimization},
  author={Pathak, Reese and Wainwright, Martin J},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7057--7066},
  year={2020}
}