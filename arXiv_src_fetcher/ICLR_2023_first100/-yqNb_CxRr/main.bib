@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@article{ji20123d,
  title={3D convolutional neural networks for human action recognition},
  author={Ji, Shuiwang and Xu, Wei and Yang, Ming and Yu, Kai},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={1},
  pages={221--231},
  year={2012},
  publisher={IEEE}
}

@inproceedings{feichtenhofer2016convolutional,
  title={Convolutional two-stream network fusion for video action recognition},
  author={Feichtenhofer, Christoph and Pinz, Axel and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1933--1941},
  year={2016}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@article{yang2019asymmetric,
  title={Asymmetric 3d convolutional neural networks for action recognition},
  author={Yang, Hao and Yuan, Chunfeng and Li, Bing and Du, Yang and Xing, Junliang and Hu, Weiming and Maybank, Stephen J},
  journal={Pattern recognition},
  volume={85},
  pages={1--12},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{li2019actional,
  title={Actional-structural graph convolutional networks for skeleton-based action recognition},
  author={Li, Maosen and Chen, Siheng and Chen, Xu and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3595--3603},
  year={2019}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

@inproceedings{beluch2018power,
  title={The power of ensembles for active learning in image classification},
  author={Beluch, William H and Genewein, Tim and N{\"u}rnberger, Andreas and K{\"o}hler, Jan M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9368--9377},
  year={2018}
}

@article{gorriz2017cost,
  title={Cost-effective active learning for melanoma segmentation},
  author={Gorriz, Marc and Carlier, Axel and Faure, Emmanuel and Gir{\'o}-i-Nieto, Xavier},
  journal={arXiv preprint arXiv:1711.09168},
  year={2017}
}

@inproceedings{yang2017suggestive,
  title={Suggestive annotation: A deep active learning framework for biomedical image segmentation},
  author={Yang, Lin and Zhang, Yizhe and Chen, Jianxu and Zhang, Siyuan and Chen, Danny Z},
  booktitle={Medical Image Computing and Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part III 20},
  pages={399--407},
  year={2017},
  organization={Springer}
}

@inproceedings{nguyen2004active,
  title={Active learning using pre-clustering},
  author={Nguyen, Hieu T and Smeulders, Arnold},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={79},
  year={2004}
}

@article{aggarwal2014human,
  title={Human activity recognition from 3d data: A review},
  author={Aggarwal, Jake K and Xia, Lu},
  journal={Pattern Recognition Letters},
  volume={48},
  pages={70--80},
  year={2014},
  publisher={Elsevier}
}

@article{escalera2017challenges,
  title={Challenges in multi-modal gesture recognition},
  author={Escalera, Sergio and Athitsos, Vassilis and Guyon, Isabelle},
  journal={Gesture recognition},
  pages={1--60},
  year={2017},
  publisher={Springer}
}

@article{han2017space,
  title={Space-time representation of people based on 3D skeletal data: A review},
  author={Han, Fei and Reily, Brian and Hoff, William and Zhang, Hao},
  journal={Computer Vision and Image Understanding},
  volume={158},
  pages={85--105},
  year={2017},
  publisher={Elsevier}
}

@article{wang2018rgb,
  title={RGB-D-based human motion recognition with deep learning: A survey},
  author={Wang, Pichao and Li, Wanqing and Ogunbona, Philip and Wan, Jun and Escalera, Sergio},
  journal={Computer vision and image understanding},
  volume={171},
  pages={118--139},
  year={2018},
  publisher={Elsevier}
}

@article{shorten2019survey,
  title={A survey on image data augmentation for deep learning},
  author={Shorten, Connor and Khoshgoftaar, Taghi M},
  journal={Journal of big data},
  volume={6},
  number={1},
  pages={1--48},
  year={2019},
  publisher={SpringerOpen}
}

@inproceedings{he2019parametric,
  title={Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack},
  author={He, Zhezhi and Rakin, Adnan Siraj and Fan, Deliang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={588--597},
  year={2019}
}

@inproceedings{choi2018stargan,
  title={Stargan: Unified generative adversarial networks for multi-domain image-to-image translation},
  author={Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8789--8797},
  year={2018}
}

@inproceedings{choi2020stargan,
  title={Stargan v2: Diverse image synthesis for multiple domains},
  author={Choi, Yunjey and Uh, Youngjung and Yoo, Jaejun and Ha, Jung-Woo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8188--8197},
  year={2020}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4401--4410},
  year={2019}
}

@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8110--8119},
  year={2020}
}

@inproceedings{wang2018unregularized,
  title={Unregularized auto-encoder with generative adversarial networks for image generation},
  author={Wang, Jiayu and Zhou, Wengang and Tang, Jinhui and Fu, Zhongqian and Tian, Qi and Li, Houqiang},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={709--717},
  year={2018}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{lopez2018information,
  title={Information constraints on auto-encoding variational bayes},
  author={Lopez, Romain and Regier, Jeffrey and Jordan, Michael I and Yosef, Nir},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{lopez2020decision,
  title={Decision-making with auto-encoding variational Bayes},
  author={Lopez, Romain and Boyeau, Pierre and Yosef, Nir and Jordan, Michael and Regier, Jeffrey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5081--5092},
  year={2020}
}

@inproceedings{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo and Mohamed, Shakir},
  booktitle={International conference on machine learning},
  pages={1530--1538},
  year={2015},
  organization={PMLR}
}

@article{kingma2018glow,
  title={Glow: Generative flow with invertible 1x1 convolutions},
  author={Kingma, Durk P and Dhariwal, Prafulla},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{liu2022compositional,
  title={Compositional visual generation with composable diffusion models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  booktitle={European Conference on Computer Vision},
  pages={423--439},
  year={2022},
  organization={Springer}
}

@inproceedings{zhang2023inversion,
  title={Inversion-based style transfer with diffusion models},
  author={Zhang, Yuxin and Huang, Nisha and Tang, Fan and Huang, Haibin and Ma, Chongyang and Dong, Weiming and Xu, Changsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10146--10156},
  year={2023}
}

@article{antoniou2017data,
  title={Data augmentation generative adversarial networks},
  author={Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
  journal={arXiv preprint arXiv:1711.04340},
  year={2017}
}

@inproceedings{hong2022deltagan,
  title={Deltagan: Towards diverse few-shot image generation with sample-specific delta},
  author={Hong, Yan and Niu, Li and Zhang, Jianfu and Zhang, Liqing},
  booktitle={European Conference on Computer Vision},
  pages={259--276},
  year={2022},
  organization={Springer}
}

@article{clouatre2019figr,
  title={Figr: Few-shot image generation with reptile},
  author={Clou{\^a}tre, Louis and Demers, Marc},
  journal={arXiv preprint arXiv:1901.02199},
  year={2019}
}

@inproceedings{hong2020matchinggan,
  title={Matchinggan: Matching-based few-shot image generation},
  author={Hong, Yan and Niu, Li and Zhang, Jianfu and Zhang, Liqing},
  booktitle={2020 IEEE International conference on multimedia and expo (ICME)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{nichol2018reptile,
  title={Reptile: a scalable metalearning algorithm},
  author={Nichol, Alex and Schulman, John},
  journal={arXiv preprint arXiv:1803.02999},
  volume={2},
  number={3},
  pages={4},
  year={2018}
}

@article{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1501--1510},
  year={2017}
}

@inproceedings{hong2020f2gan,
  title={F2gan: Fusing-and-filling gan for few-shot image generation},
  author={Hong, Yan and Niu, Li and Zhang, Jianfu and Zhao, Weijie and Fu, Chen and Zhang, Liqing},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={2535--2543},
  year={2020}
}

@inproceedings{pan2023drag,
  title={Drag your gan: Interactive point-based manipulation on the generative image manifold},
  author={Pan, Xingang and Tewari, Ayush and Leimk{\"u}hler, Thomas and Liu, Lingjie and Meka, Abhimitra and Theobalt, Christian},
  booktitle={ACM SIGGRAPH 2023 Conference Proceedings},
  pages={1--11},
  year={2023}
}

@InProceedings{Redmon_2016_CVPR,
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
title = {You Only Look Once: Unified, Real-Time Object Detection},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@inproceedings{wang2023yolov7,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7464--7475},
  year={2023}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{deng2023catch,
  title={Catch You and I Can: Revealing source voiceprint against voice conversion},
  author={Deng, Jiangyi and Chen, Yanjiao and Zhong, Yinan and Miao, Qianhao and Gong, Xueluan and Xu, Wenyuan},
  journal={arXiv preprint arXiv:2302.12434},
  year={2023}
}

@inproceedings{yan2018spatial,
  title={Spatial temporal graph convolutional networks for skeleton-based action recognition},
  author={Yan, Sijie and Xiong, Yuanjun and Lin, Dahua},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{shi2019two,
  title={Two-stream adaptive graph convolutional networks for skeleton-based action recognition},
  author={Shi, Lei and Zhang, Yifan and Cheng, Jian and Lu, Hanqing},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12026--12035},
  year={2019}
}

@article{bai2022skeleton,
  title={Skeleton-based similar action recognition through integrating the salient image feature into a center-connected graph convolutional network},
  author={Bai, Zhongyu and Ding, Qichuan and Xu, Hongli and Chi, Jianning and Zhang, Xiangyue and Sun, Tiansheng},
  journal={Neurocomputing},
  volume={507},
  pages={40--53},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{cai2021jolo,
  title={JOLO-GCN: mining joint-centered light-weight information for skeleton-based action recognition},
  author={Cai, Jinmiao and Jiang, Nianjuan and Han, Xiaoguang and Jia, Kui and Lu, Jiangbo},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2735--2744},
  year={2021}
}

@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{liu2019wasserstein,
  title={Wasserstein GAN with quadratic transport cost},
  author={Liu, Huidong and Gu, Xianfeng and Samaras, Dimitris},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4832--4841},
  year={2019}
}

@inproceedings{mao2017least,
  title={Least squares generative adversarial networks},
  author={Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond YK and Wang, Zhen and Paul Smolley, Stephen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2794--2802},
  year={2017}
}

@article{jang2022motion,
  title={Motion puzzle: Arbitrary motion style transfer by body part},
  author={Jang, Deok-Kyeong and Park, Soomin and Lee, Sung-Hee},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={3},
  pages={1-16},
  year={2022},
  publisher={ACM New York, NY}
}

@article{aberman2020unpaired,
  title={Unpaired motion style transfer from video to animation},
  author={Aberman, Kfir and Weng, Yijia and Lischinski, Dani and Cohen-Or, Daniel and Chen, Baoquan},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={4},
  pages={64--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{ParkSoomin2021Diverse,
  title={Diverse Motion Stylization for Multiple Style Domains via Spatial-Temporal Graph-Based Generative Model},
  author={ParkSoomin and JangDeok-Kyeong and LeeSung-Hee},
  journal={Proceedings of the ACM on Computer Graphics and Interactive Techniques},
  year={2021},
}

@article{2016A,
  title={A deep learning framework for character motion synthesis and editing},
  author={ Holden, Daniel  and  Saito, Jun  and  Komura, Taku },
  journal={Acm Transactions on Graphics},
  volume={35},
  number={4},
  pages={1-11},
  year={2016},
}

@inproceedings{du2021contrastive,
  title={Contrastive coding for active learning under class distribution mismatch},
  author={Du, Pan and Zhao, Suyun and Chen, Hui and Chai, Shuwen and Chen, Hong and Li, Cuiping},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8927--8936},
  year={2021}
}

@inproceedings{sinha2019variational,
  title={Variational adversarial active learning},
  author={Sinha, Samarth and Ebrahimi, Sayna and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5972--5981},
  year={2019}
}

@inproceedings{zhang2020state,
  title={State-relabeling adversarial active learning},
  author={Zhang, Beichen and Li, Liang and Yang, Shijie and Wang, Shuhui and Zha, Zheng-Jun and Huang, Qingming},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8756--8765},
  year={2020}
}

@inproceedings{vinker2021image,
  title={Image shape manipulation from a single augmented training sample},
  author={Vinker, Yael and Horwitz, Eliahu and Zabari, Nir and Hoshen, Yedid},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13769--13778},
  year={2021}
}

@inproceedings{patashnik2021styleclip,
  title={Styleclip: Text-driven manipulation of stylegan imagery},
  author={Patashnik, Or and Wu, Zongze and Shechtman, Eli and Cohen-Or, Daniel and Lischinski, Dani},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2085--2094},
  year={2021}
}

@inproceedings{shao2021spatchgan,
  title={Spatchgan: A statistical feature based discriminator for unsupervised image-to-image translation},
  author={Shao, Xuning and Zhang, Weidong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6546--6555},
  year={2021}
}

@article{vondrick2016generating,
  title={Generating videos with scene dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{saito2017temporal,
  title={Temporal generative adversarial nets with singular value clipping},
  author={Saito, Masaki and Matsumoto, Eiichi and Saito, Shunta},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2830--2839},
  year={2017}
}

@article{mogren2016c,
  title={C-RNN-GAN: Continuous recurrent neural networks with adversarial training},
  author={Mogren, Olof},
  journal={arXiv preprint arXiv:1611.09904},
  year={2016}
}

@inproceedings{tulyakov2018mocogan,
  title={Mocogan: Decomposing motion and content for video generation},
  author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1526--1535},
  year={2018}
}

@inproceedings{gatys2016image,
  title={Image style transfer using convolutional neural networks},
  author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2414--2423},
  year={2016}
}

@inproceedings{saito2020coco,
  title={Coco-funit: Few-shot unsupervised image translation with a content conditioned style encoder},
  author={Saito, Kuniaki and Saenko, Kate and Liu, Ming-Yu},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16},
  pages={382--398},
  year={2020},
  organization={Springer}
}

@article{xia2015realtime,
  title={Realtime style transfer for unlabeled heterogeneous human motion},
  author={Xia, Shihong and Wang, Congyi and Chai, Jinxiang and Hodgins, Jessica},
  journal={ACM Transactions on Graphics (TOG)},
  volume={34},
  number={4},
  pages={1--10},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{yumer2016spectral,
  title={Spectral style transfer for human motion between independent actions},
  author={Yumer, M Ersin and Mitra, Niloy J},
  journal={ACM Transactions on Graphics (TOG)},
  volume={35},
  number={4},
  pages={1--8},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{du2019stylistic,
  title={Stylistic locomotion modeling and synthesis using variational generative models},
  author={Du, Han and Herrmann, Erik and Sprenger, Janis and Fischer, Klaus and Slusallek, Philipp},
  booktitle={Proceedings of the 12th ACM SIGGRAPH Conference on Motion, Interaction and Games},
  pages={1--10},
  year={2019}
}

@article{ebrahimi2019uncertainty,
  title={Uncertainty-guided continual learning with bayesian neural networks},
  author={Ebrahimi, Sayna and Elhoseiny, Mohamed and Darrell, Trevor and Rohrbach, Marcus},
  journal={arXiv preprint arXiv:1906.02425},
  year={2019}
}

@inproceedings{gal2017deep,
  title={Deep bayesian active learning with image data},
  author={Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  booktitle={International conference on machine learning},
  pages={1183--1192},
  year={2017},
  organization={PMLR}
}

@inproceedings{mahapatra2018efficient,
  title={Efficient active learning for image classification and segmentation using a sample selection and conditional generative adversarial network},
  author={Mahapatra, Dwarikanath and Bozorgtabar, Behzad and Thiran, Jean-Philippe and Reyes, Mauricio},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={580--588},
  year={2018},
  organization={Springer}
}

@article{zhu2017generative,
  title={Generative adversarial active learning},
  author={Zhu, Jia-Jie and Bento, Jos{\'e}},
  journal={arXiv preprint arXiv:1702.07956},
  year={2017}
}

@inproceedings{mayer2020adversarial,
  title={Adversarial sampling for active learning},
  author={Mayer, Christoph and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3071--3079},
  year={2020}
}

@inproceedings{shahroudy2016ntu,
  title={Ntu rgb+ d: A large scale dataset for 3d human activity analysis},
  author={Shahroudy, Amir and Liu, Jun and Ng, Tian-Tsong and Wang, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1010--1019},
  year={2016}
}

@inproceedings{yan2019convolutional,
  title={Convolutional sequence generation for skeleton-based action synthesis},
  author={Yan, Sijie and Li, Zhizhong and Xiong, Yuanjun and Yan, Huahan and Lin, Dahua},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4394--4402},
  year={2019}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}