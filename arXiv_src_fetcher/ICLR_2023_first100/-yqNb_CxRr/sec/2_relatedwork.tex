
\section{Related work}

\textbf{Generative Adversarial Networks. }
Generative Adversarial Networks (GAN) is a generative models which is trained by adversarial learning. 
In the early days, unconditional GAN \cite{karras2019style,karras2020analyzing} recovered images from random noise. Developed to the present, conditional GAN \cite{pan2023drag} utilizes text and images for guidance to generate images. GAN has performed strongly on tasks of generating static data such as image generation \cite{karras2019style, karras2020analyzing}, image editing \cite{vinker2021image, patashnik2021styleclip}, and image translation \cite{shao2021spatchgan}.
The generation of dynamic data, such as videos and action sequences, has also been studied. Carl et al. \cite{vondrick2016generating} proposed a video generation network with a spatial-temporal two-stream convolutional architecture based on DCGAN \cite{radford2015unsupervised}. This work is the first application of GAN to video generation. 
TGAN \cite{saito2017temporal} followed, which first generates a set of latent vectors from noise vectors, then generates pictures and synthesizes videos separately.
RNN-GAN \cite{mogren2016c} is based on the temporal modeling capability of RNNs to predict video from a single frame. It has a more robust motion prediction capability compared to the work of Carl et al. However, these impressive results are mainly attributed to the support of many training samples. With limited data, GANs are prone to overfitting, leading to a lack of diversity in the generated data. 

% \textbf{Few-shot Generation. }

\textbf{Motion Style Transfer. }
Image Style Transfer \cite{gatys2016image, saito2020coco} combines style and content features from two images to form a new image. Motion Style Transfer refers to Image Style Transfer to form a new action by transferring one action's style features to another that contains only content features. Early motion style transfer was done by manually defining style features and inferring them through machine learning \cite{xia2015realtime, yumer2016spectral}. This method is effective only for the actions in the training data with limited scope of usefulness. 
Deep learning-based methods have greatly improved the quality and application of motion style transfer. Both Holden et al. \cite{2016A} and Du et al. \cite{du2019stylistic} applied the Gram matrix method to convey motion styles through the distribution of actions in the hidden space. These methods are time-consuming and have limited the quality of action generation for relatively significant motion differences.
Recently, Aberman et al. \cite{aberman2020unpaired} proposed a motion transfer network that combines GAN and AdaIN. 
The method can learn from unpaired data with different styles to migrate model unseen actions. 
Park et al. \cite{ParkSoomin2021Diverse} used a spatio-temporal graph convolutional network to model actions. The method adds random noise in the decoder to enhance action diversity. 
Jang et al. \cite{jang2022motion} proposed a novel motion style transfer network called Motion Puzzle. 
Motion Puzzle divides the human skeleton into five parts, allowing flexible control over the migration of specified parts during generation. This approach is effective for single-action generation tasks.
However, it is usually time-consuming to control parts for generation when generating many actions. In addition, Motion Puzzle's target motion encoder is connected to the decoder at multiple scales, which may constrain the diversity of action.

\textbf{Active Learning. }
Existing active learning methods are categorized into pool-based and synthetic methods \cite{gal2016dropout,beluch2018power,gorriz2017cost,yang2017suggestive,nguyen2004active}. Pool-based methods use different sampling strategies to determine how to select the most informative samples, with uncertainty sampling methods being the most common.
Ebrahimi et al. \cite{ebrahimi2019uncertainty} used a Bayesian neural network for uncertainty evaluation. Gal \cite{gal2016dropout} and Gharamani \cite{gal2017deep} also showed the relationship between uncertainty and dropout to estimate uncertainty in neural network prediction.
Pool-based methods select samples conditional on a large amount of unlabeled data. In the case of scarcity of data, synthetic methods are more suitable than pool-based methods. Synthetic methods use a generative model to generate samples, then sample based on the uncertainty of the model.
The work of Zhu et al.  \cite{zhu2017generative}, Mahapatra et al.  \cite{mahapatra2018efficient}, and Mayer et al. \cite{mayer2020adversarial} uses GAN to generate a sample and then query using the uncertainty principle. Our work uses this same strategy to guide human action generation using the amount of sample information.