\IEEEraisesectionheading{\section{Introduction}}
\label{sec:introduction}
Deep learning has reached state-of-the-art performance in a large variety of tasks, for example in computer vision and natural language processing~\cite{voulodimos2018deep, NEURIPS2020_1457c0d6}.
Furthermore, the broad availability of computational resources allowed researchers to train increasingly larger models~\cite{dosovitskiy2020vit, NEURIPS2020_1457c0d6}, resulting in better generalization capabilities. 
Deep learning based tools are impacting more and more everyday life and decision making~\cite{laumer2015impact}. This is one of the reason why AI trustworthiness has been recognized as major prerequisite for its use in society~\cite{hleg2019ethics, zhang2019artificial}. 
Following the guidelines of the European Commission of 2019~\cite{hleg2019ethics}, these tools should be \emph{lawful}, \emph{ethical} and \emph{robust}.
Providing a warranty on this topic is currently a matter of study and discussion~\cite{schramowski2020making, stock2020eccv, teso2019aies_XIML, revisetool, barbano2021bridging}.

In recent years, it has also become apparent how deep neural networks often rely on erroneous correlations and biased features present in the training data. Many works have proposed solutions for this matter, for example addressing gender biases when dealing with facial images~\cite{nam2020learning, Kim_2019_CVPR, zhao2021learning, lee2021learning} or with medical data~\cite{tartaglione2021end, dufumier2021brain}. 
When dealing with biases, many of the proposed techniques often work in a \emph{supervised} manner, assuming that each sample can be labeled with a corresponding bias class~\cite{alvi2018turning, tartaglione2021end,Kim_2019_CVPR}.
Other works, on the other hand, only make assumptions about the nature of bias~\cite{bahng2019rebias,cadene2019rubi}, for example, for designing the model architecture. Compared to the fully supervised setting, this is a more realistic scenario, however it still requires some form of prior knowledge about the bias.


In this work we propose an \emph{unsupervised} debiasing strategy, which allows us to obtain an unbiased model when the data contain biases that are either unknown or not labelled. 
We present a framework for retrieving information about bias classes in the data, in a completely unsupervised manner. First, we show how to exploit the naturally biased representations to retrieve the presence of unknown biases. 
Then, by performing a pseudo-labeling step, we are able to employ traditional supervised debiasing techniques for learning an unbiased model. For this purpose, we focus on the recently proposed EnD~\cite{tartaglione2021end} technique which obtains state-of-the-art results in different debiasing tasks, and we name the unsupervised extension~\emph{U-EnD} (Unsupervised EnD), although our framework is general and can be adapted to different supervised techniques with minimal effort. 
We also study the effect of the strength of biases on the learning process, by developing a mathematical framework which allows us to determine how \emph{biased} a model is, backed by empirical experimentation, on controlled cases.
Our results also further back up the findings about how neural networks tend to prefer simpler and easier patterns during the learning process~\cite{arpit2017memorization,nam2020learning}.
In a summary, with U-EnD:
\begin{enumerate}
    \item we propose an unsupervised framework for learning unbiased representations, with no need for explicit supervision on the bias features;
    \item we propose a simple but effective mathematical model which can be used to quantitatively measure how much a model is biased;
    \item we validate our proposed framework and model on state-of-the art synthetic and real-world datasets.
\end{enumerate}

The rest of the work is structured as follows: In Section~\ref{sec:related} we review the literature related to debiasing in deep neural networks; in Section~\ref{sec:supervised-end} we introduce the EnD debiasing technique and provide a detailed explanation of its functioning in an explicitly supervised setting; in Section~\ref{sec:unsupervised-end} we present the extension for our proposed unsupervised framework for debiasing; in Section~\ref{sec:analysis-mnist} we conduct a detailed empirical and theoretical analysis on controlled cases with state-of-the-art synthetic datasets; finally, in Section~\ref{sec:experiments} we provide empirical results on real-world data and in Section~\ref{sec:conclusion}, the conclusions are drawn.

