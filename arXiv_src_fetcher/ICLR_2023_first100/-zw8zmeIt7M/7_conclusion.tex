\section{Conclusion}
\label{sec:conclusion}

In this work we proposed an unsupervised framework for learning unbiased representations from biased data. Our framework consists in three separate steps: \emph{i.)} training a bias-capturing model \emph{ii.)} training a bias predictor \emph{iii.)} training an unbiased model. 
We obtain the bias-capturing model by exploiting the tendency of optimization and neural networks to prefer simpler patterns over more complex ones. We show that when such patterns exist, and they represent spurious correlation with the target features, then the model will rely on these confouding factors. 
In Section~\ref{sec:phase1} we show that such case correspond to converging towards a local minimum for the target tasks, which however provides an optimal solver if we consider instead the task of predicting bias features. Furthermore, we the theoretical framework presented in Section~\ref{sec:bias-theoretical-model} we are able to empirically measure the biasness of the model, which can be a useful insights dealing with potentially biased data. We leverage this findings for adapting fully supervised debiasing techniques in unsupervised context, via a pseudo-labeling step on the biased latent space. Thanks to this approach, we are able to use state-of-the art debiasing algorithms such as EnD, which is a strong regularizer for driving the model towards the selection of unbiased features. With experiments on real-world data, we also show how sometimes it is even possible to achieve better results with an unsupervised approach, addressing the issue of noisy labels (both regarding target classes and bias classes) in datasets.
We believe that our approach could be of potentially great interest for other researchers in the area, and also for practical applications, as it can be easily adapted to different techniques for building bias-capturing models and for obtaining unbiased predictors.

