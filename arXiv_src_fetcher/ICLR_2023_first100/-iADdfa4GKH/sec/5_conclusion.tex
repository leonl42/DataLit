\section{Conclusion}
\vspace{-2mm}
\quad We propose a novel framework - \textbf{MonoSelfRecon} that for the first time achieves \textbf{explicit 3D mesh} reconstruction for \textbf{generalizable} indoor scenes with monocular RGB views by purely \textbf{self-supervision} on voxel-SDF. We propose novel self-supervised losses corresponding to our novel framework design, and test with thorough experiments on ScanNet and 7Scenes. Our method outperforms the best indoor self-supervised methods so far and is comparable to fully-supervised works. With few-shot learning, it is easily transferred to other domains. The framework is not limited to model design but extensive to any voxel-SDF models, which keeps the advantages of the original model. 


