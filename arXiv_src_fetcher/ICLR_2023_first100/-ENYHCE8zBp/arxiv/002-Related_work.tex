\vspace{-1mm}
\section{Related Work}
\vspace{-1mm}
%We aim to train networks towards the goal of optimality for every encountered instance as well as making use of heuristics from historical graphs, and thus we introduce meta learning to the unsupervised learning for CO framework. Related works of learning for CO and meta learning are discussed below.
In the following, we review two groups of works: unsupervised learning for CO and meta learning. %and its better model OOD generalization.  

%\pan{The biggest things are how to balance something you have introduced in other parts of the paper, and something presented here. Practical paper writing only has limited pages. So, often such tradeoff should be made.}

%kwon2020pomo,kwon2021matrix,delarue2020reinforcement,nandwani2021neural

%Most previous LCO approaches are based on RL~\cite{bello2016neural,chen2019learning,kwon2020pomo,kwon2021matrix,khalil2017learning,delarue2020reinforcement,wang2021bi,kool2018attention,nandwani2021neural} or supervised learning~\cite{khalil2016learning,gasse2019exact,yehuda2020s}, as these two frameworks do not hold any special requirements on the formulation of CO problems. However, they often suffer from the issues of training instability and subpar generalization. Previous works on unsupervised learning for CO have studied satisfaction problems~\cite{amizadeh2018learning,toenshoff2019run}. Applying these approaches to general CO problems requires problem reductions. Others have considered max-cut~\cite{yao2019experimental} and TSP problems~\cite{hudson2021graph}, while these works depend on carefully selected problem-specific objectives.

%\textbf{Learning for Combinatorial optimization:}
%Among the learning for CO methods, some guide neural networks by the optimal solutions~\citep{joshi2019efficient,hudson2021graph,selsam2018learning,wang2019learning,wang2020combinatorial}, the others train their models with the expert inference from traditional CO solvers~\citep{khalil2016learning,gasse2019exact,nair2020solving}. Yet the dependence on labels requires considerable time effort and may lead to poor generalization ability~\citep{joshi2020learning}. ~\cite{yehuda2020s} proves that having solutions for polynomial many CO problems only gives the labels of a subset of the settings for the original CO problem. If these labels are used for training, the obtained network may not be well generalized to the problem beyond the subset of the settings.
%RL approach is an alternative solution~\citep{mazyavkina2021reinforcement,bello2016neural,chen2019learning,khalil2017learning,yolcu2019learning}. Although RL gets rid of the dependence on labels, the high variance, higher time complexity and hard explorations are still concerns. 

Previous works on unsupervised learning for CO have studied max-cut~\citep{yao2019experimental} and TSP problems~\citep{hudson2021graph}, while these works depend on carefully selected problem-specific objectives. Some works have investigated satisfaction problems~\citep{amizadeh2018learning,toenshoff2019run}. Applying these approaches to general CO problems requires problem reductions. The works most relevant to us are \citep{karalias2020erdos}, \citep{wang2022unsupervised} and \citep{schuetz2022combinatorial}. \cite{karalias2020erdos} propose an unsupervised learning framework EGN for general CO problems based on the Erd\H{o}s' probabilistic method, which bonds the quality of the final solutions with probability. \cite{wang2022unsupervised} generalize EGN and prove that if the CO objective can be relaxed into an entry-wise concave form, a solution of good quality can be deterministically achieved. This further inspires the design of proxy objectives for CO problems that may not have closed-form objectives, such as those in circuit design. \cite{schuetz2022combinatorial} have recently extended EGN to large-scale max independent set problems on random-regular graphs.

%relaxation-and-rounding principle in the objective design

%satisfaction problems~\cite{amizadeh2018learning,toenshoff2019run}. Applying these approaches to general CO problems requires problem reductions. Others have considered max-cut~\cite{yao2019experimental} and TSP problems~\cite{hudson2021graph}, while these works depend on carefully selected problem-specific objectives. \cite{karalias2020erdos} and \cite{wang2022unsupervised} are most relevant to us. \cite{karalias2020erdos} propose an unsupervised learning framework EGN for general CO problems based on the Erd\H{o}s's probabilistic method, which could bond the model's performance with high probability once a satisfactory loss is obtained. \cite{wang2022unsupervised} further generalizes the theoretical analysis of EGN and proves that if the objective sati \emph{entry-wise concave} relaxation-and-rounding principle in the objective design

%Among works on unsupervised learning for CO,~\cite{yao2019experimental} relax the objective and trained GNNs for the max-cut problem, ~\cite{amizadeh2018learning} mimic RL to learn the solution structure for circuit SAT problem, ~\cite{toenshoff2021graph} train RNN for max-SAT problems by maximizing the probability of prediction. ~\cite{karalias2020erdos} propose an unsupervised learning framework for CO based on the Erd\H{o}s's probabilistic method, which could bond the model's performance with high probability once a satisfying loss is obtained. ~\cite{wang2022unsupervised} further generalize the framework to achieve performance guarantee via the \emph{entry-wise concave} relaxation-and-rounding principle in the objective design \pan{this sentence needs revision}. ~\cite{schuetz2022combinatorial} extend the framework to large scale max independent set problems on random-regular graphs. Nevertheless, unsupervised learning frameworks above adopt a learning objective whose goal is to obtain optimality in the expectation sense over a certain data distribution, instead of optimality for every single instance, therefore yielding a performance gap.
%To the best of our knowledge, we are the first to consider narrowing such gap.

%\textbf{Meta Learning:} 
Meta learning is proposed to learn hyper-parameters or initialization from historical tasks and achieve fast adaption to new tasks. ~\cite{finn2017model} propose model-agnostic meta learning (MAML), which aimed to obtain good parameter initialization and be accommodated to few-shot learning tasks with limited steps of fine-tuning. ~\cite{nichol2018first} accelerate MAML by adopting first-order approximation on the gradient estimation. ~\cite{rajeswaran2019meta} introduce implicit-MAML that adopts an objective with fine-tuning till the stationary points on new tasks. Implicit-MAML does not fit our case because we try to avoid long-time fine-tuning. ~\cite{hsu2018unsupervised} study unsupervised learning under the meta learning framework and focused exclusively on vision tasks. To the best of our knowledge, our work is the first one to apply meta learning to unsupervised learning for CO. %~\cite{jeong2020ood} brings the MAML framework to out of distribution detection vision tasks, ~\cite{conklin2021meta} utilizes meta learning in out-of-distribution natural language processing tasks, marking the success of meta learning in improving out-of-distribution generalization.

%Meta learning aims to learn how to learn. In other words, meta learning learns hyper-parameters or initialization from historical tasks to achieve fast adaption to new tasks as well as better out-of-distribution generalization ability. ~\cite{finn2017model} propose model-agnostic meta learning (MAML), which aims to obtain good parameter initialization and accommodate to unseen few-shot learning tasks with limited steps of fine-tuning. On one hand, MAML and its following works have achieved excellent performance in various fields thanks to the meta learning's ability of fast adaption to new tasks. \pan{The following sounds like a loosely related list. It is better to claim how they are related to us.} E.g. ~\cite{nichol2018first} perform first-order approximation on the gradient estimation of MAML for time-efficiency, ~\cite{rajeswaran2019meta} introduce implicit-MAML by changing the objective for the optimality after infinite fine-tuning steps on new tasks. ~\cite{hsu2018unsupervised} perform unsupervised learning under the meta learning framework to better learn the representations and achieve high performance in down-stream vision tasks. On the other hand, ~\cite{jeong2020ood} brings the MAML framework to out of distribution detection vision tasks, ~\cite{conklin2021meta} utilizes meta learning in out-of-distribution natural language processing tasks, marking the success of meta learning in improving out-of-distribution generalization.

%As to CO problem specifically, we find a concurrent work~\citep{manchanda2022generalization} which utilizes MAML to help improve the across distribution or scale generalization of the supervised learning and RL methods in routing problems \pan{do we even want to review? as it is published so close.}. But it still requires extra training data in testing distribution for adaption to the unseen testing task. To the best of our knowledge, we are the first to align the distinct characteristic of CO instances with the meta learning's advantage in fast adaption and out-of-distribution generalization \pan{this statement is not fully clear.}. We formulate each training instance as an independent task \pan{this is duplicated}, after obtaining the initialization from these historical instances, we no longer require any further training data on the unseen distribution but instead directly fine-tune the model thanks to our unsupervised learning structure.

\iffalse
Early meta learning works either learn black-box \pan{why emphasize black-box?} recurrent \pan{recurrent models are what they call?} models to make predictions on only a few examples from the new tasks~\citep{andrychowicz2016learning,chen2017learning,hochreiter2001learning,schmidhuber1993neural} or learn shared representations from different tasks \pan{do you mean multi task? Are shared representations the goal?}~\citep{snell2017prototypical,vinyals2016matching}. Since ~\cite{finn2017model} introduced the model-agnostic meta learning which aims to obtain good parameter initialization that could rapidly adapt to new tasks with limited steps of fine-tuning, MAML has been one of the most prevailing optimization-based meta learning tools to resolve few-shot learning problem \pan{the previous sentence is so long.}. MAML and its following works'~\citep{rajeswaran2019meta,nichol2018first,rothfuss2018promp} empirical success in few-shot learning also arises the researchers' interest in meta learning from the theoretical side. ~\cite{finn2017meta} proves the approximation ability of meta-guided deep learning \pan{review the theory of meta is kind of useless and out of the scope}. ~\cite{farid2021generalization,rothfuss2021pacoh,chen2021generalization,fallah2021generalization} focus on theoretically analyzing the generalization ability of MAML, while ~\cite{park2019meta,gonzalez2020improved,denevi2018learning} work to further improve MAML's generalization ability. ~\cite{wang2021fast,goldblum2020adversarially} investigate the stability of few shot learning against adversarial attacks and further improve it with the help of meta learning. 

\hl{no meta for RL here} \pan{Are you sure?}
~\cite{manchanda2022generalization} propose a concurrent work which utilizes meta-learning to help improve the generalization ability of supervised learning and RL methods in routing CO problems. \pan{Beyond SL and RL v.s. USL? Any other key differences? For example, SL formulation still follows ERM. We are the first to propose per-instance optimality. Can we claim this?}
In our unsupervised learning for CO case, we also find that MAML could further improve the performance as well as generalization ability across distribution or scales, we attribute the phenomenon to the reason that the meta objective could find the initialization of much better local optima among the intricate optimization landscape, which largely benefit the CO problems with very distinct instances.


$\bullet$ Before: supervised for CO: poor generalization ability, time-costly to collect data \pan{Remember Also cite a few core RL papers}

$\bullet$ then:Erd\H{o}s goes neural(EGN), unsupervised comparable results, but not a proper training goal 

~\cite{karalias2020erdos} introduces an unsupervised probabilistic method which is very likely to obtain good solutions once a low loss value is acquired, while ~\cite{wang2022unsupervised} generalizes the method into a 'relaxation and rounding' framework, which is guaranteed to achieve high performance under a low loss value with the proposed 'entry-wise concave' principle. 

\pan{Short. I suggest to discuss the principle observed in proxy-CO paper. }

$\bullet$ recently: nature (just an extension of Erd\H{o}s), arises the question from cracking: not that efficient and reliable as simple baselines.  \pan{Short; I suggest put intro.}

$\bullet$ We extend Erd\H{o}s and open it in the correct way, (nature is wrong in random regular graph) and address the question from cracking.  \pan{Short; I suggest put intro.}

\subsection{Meta learning}
$\bullet$ what is meta learning \pan{What tasks meta learning has been typically to solve? How are they related to our case}
\pan{Meta learning for RL. Please review. }
$\bullet$ MAML and its followers shows good performance

$\bullet$ Recent some questions raised by sharp-MAML, MAML with negative learning rate... poor generalization ability? \pan{I think we should not discuss this point here. This point should be put when we use exp to verify our generalization and explain why previous theory is not applied.}

$\bullet$ Surprisingly, in CO problems, we do not observe such poor generalization, by contrast, we found it could even further boost the performance as well as improve generalization. The reason could be: CO is essentially a zero-shot task \pan{Avoid using terminology to explain another terminology. Use intuition to explain}.
\fi