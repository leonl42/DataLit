\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2019)Alayrac, Uesato, Huang, Fawzi, Stanforth, and
  Kohli]{alayrac19}
Alayrac, J.-B., Uesato, J., Huang, P.-S., Fawzi, A., Stanforth, R., and Kohli,
  P.
\newblock Are labels required for improving adversarial robustness?
\newblock \emph{Advances in Neural Information Processing Systems}, pp.\
  12214--12223, 2019.

\bibitem[Andriushchenko \& Flammarion(2020)Andriushchenko and
  Flammarion]{andriushchenko20}
Andriushchenko, M. and Flammarion, N.
\newblock Understanding and improving fast adversarial training.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Bai et~al.(2021)Bai, Luo, Zhao, Wen, and Wang]{Bai21}
Bai, T., Luo, J., Zhao, J., Wen, B., and Wang, Q.
\newblock Recent advances in adversarial training for adversarial robustness.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  pp.\  4312--4321, Aug 2021.

\bibitem[Balaji et~al.(2019)Balaji, Goldstein, and Hoffman]{balaji19}
Balaji, Y., Goldstein, T., and Hoffman, J.
\newblock Instance adaptive adversarial training: Improved accuracy tradeoffs
  in neural nets.
\newblock \emph{arXiv preprint arXiv:1910.08051}, 2019.

\bibitem[Bradski(2000)]{opencv_library}
Bradski, G.
\newblock {The OpenCV Library}.
\newblock \emph{Dr. {D}obb's Journal of Software Tools}, 2000.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Liang, and
  Duchi]{Carmon19}
Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., and Duchi, J.~C.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{International Conference on Neural Information Processing
  Systems}, pp.\  11192--11203, Dec 2019.

\bibitem[Chen et~al.(2020)Chen, Min, Zhang, and Karbasi]{chen20}
Chen, L., Min, Y., Zhang, M., and Karbasi, A.
\newblock More data can expand the generalization gap between adversarially
  robust and standard models.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1670--1680, Jun 2020.

\bibitem[Cheng et~al.(2020)Cheng, Lei, Chen, Dhillon, and Hsieh]{Cheng20}
Cheng, M., Lei, Q., Chen, P.-Y., Dhillon, I., and Hsieh, C.-J.
\newblock {CAT}: Customized adversarial training for improved robustness.
\newblock \emph{arXiv preprint arXiv:2002.06789}, 2020.

\bibitem[Chizat \& Bach(2020)Chizat and Bach]{Chizat20}
Chizat, L. and Bach, F.
\newblock Implicit bias of gradient descent for wide two-layer neural networks
  trained with the logistic loss.
\newblock In \emph{International Conference on Learning Theory}, pp.\
  1305--1338, Jul 2020.

\bibitem[Ding et~al.(2020)Ding, Sharma, Lui, and Huang]{Ding20}
Ding, G.~W., Sharma, Y., Lui, K. Y.~C., and Huang, R.
\newblock {MMA} training: Direct input space margin maximization through
  adversarial training.
\newblock In \emph{International Conference on Learning Representations}, Apr
  2020.

\bibitem[Dobriban et~al.(2020)Dobriban, Hassani, Hong, and Robey]{dobriban20}
Dobriban, E., Hassani, H., Hong, D., and Robey, A.
\newblock Provable tradeoffs in adversarially robust classification.
\newblock \emph{arXiv preprint arXiv:2006.05161}, 2020.

\bibitem[Donhauser et~al.(2021)Donhauser, Tifrea, Aerni, Heckel, and
  Yang]{donhauser21}
Donhauser, K., Tifrea, A., Aerni, M., Heckel, R., and Yang, F.
\newblock Interpolation can hurt robust generalization even when there is no
  noise.
\newblock In \emph{Advances in Neural Information Processing Systems}, Dec
  2021.

\bibitem[Engstrom et~al.(2019)Engstrom, Tran, Tsipras, Schmidt, and
  Madry]{Logan19}
Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., and Madry, A.
\newblock Exploring the landscape of spatial robustness.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1802--1811, Jun 2019.

\bibitem[Eykholt et~al.(2018)Eykholt, Evtimov, Fernandes, Li, Rahmati, Xiao,
  Prakash, Kohno, and Song]{Eykholt18}
Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C.,
  Prakash, A., Kohno, T., and Song, D.
\newblock Robust physical-world attacks on deep learning visual classification.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  1625--1634, Jun 2018.

\bibitem[Ghiasi et~al.(2019)Ghiasi, Shafahi, and Goldstein]{ghiasi19}
Ghiasi, A., Shafahi, A., and Goldstein, T.
\newblock Breaking certified defenses: semantic adversarial examples with
  spoofed robustness certificates.
\newblock In \emph{International Conference on Learning Representations}, Apr
  2019.

\bibitem[Gilmer et~al.(2018)Gilmer, Adams, Goodfellow, Andersen, and
  Dahl]{gilmer18b}
Gilmer, J., Adams, R.~P., Goodfellow, I., Andersen, D., and Dahl, G.~E.
\newblock Motivating the rules of the game for adversarial example research.
\newblock \emph{arXiv preprint arXiv:1807.06732}, 2018.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{goodfellow15}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, pp.\
  1--10, Jan 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He16}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  770--778, Jun 2016.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas19}
Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., and Madry, A.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  125--136, Dec 2019.

\bibitem[Javanmard et~al.(2020)Javanmard, Soltanolkotabi, and
  Hassani]{javanmard20}
Javanmard, A., Soltanolkotabi, M., and Hassani, H.
\newblock Precise tradeoffs in adversarial training for linear regression.
\newblock In \emph{Conference on Learning Theory}, pp.\  2034--2078, Apr 2020.

\bibitem[Ji \& Telgarsky(2019)Ji and Telgarsky]{Ji19}
Ji, Z. and Telgarsky, M.
\newblock The implicit bias of gradient descent on nonseparable data.
\newblock In \emph{Conference on Learning Theory}, pp.\  1772--1798, Jun 2019.

\bibitem[Khim \& Loh(2018)Khim and Loh]{Khim18}
Khim, J. and Loh, P.-L.
\newblock Adversarial risk bounds via function transformation.
\newblock \emph{arXiv preprint arXiv:1810.09519}, 2018.

\bibitem[Laidlaw et~al.(2021)Laidlaw, Singla, and Feizi]{laidlaw21}
Laidlaw, C., Singla, S., and Feizi, S.
\newblock Perceptual adversarial robustness: Defense against unseen threat
  models.
\newblock In \emph{International Conference on Learning Representation}, Jun
  2021.

\bibitem[Lamb et~al.(2019)Lamb, Verma, Kannala, and Bengio]{lamb19}
Lamb, A., Verma, V., Kannala, J., and Bengio, Y.
\newblock Interpolated adversarial training: Achieving robust neural networks
  without sacrificing too much accuracy.
\newblock In \emph{ACM Workshop on Artificial Intelligence and Security}, pp.\
  95--103, 2019.

\bibitem[Lee et~al.(2020)Lee, Lee, and Yoon]{lee20}
Lee, S., Lee, H., and Yoon, S.
\newblock Adversarial {V}ertex {M}ixup: Toward better adversarially robust
  generalization.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  272--281, Jun 2020.

\bibitem[Li et~al.(2021)Li, Wang, Jana, and Carin]{li21}
Li, B., Wang, S., Jana, S., and Carin, L.
\newblock Towards understanding fast adversarial training.
\newblock \emph{arXiv preprint arXiv:2006.03089}, 2021.

\bibitem[Lin et~al.(2020)Lin, Lau, Levine, Chellappa, and Feizi]{Lin20}
Lin, W.-A., Lau, C.~P., Levine, A., Chellappa, R., and Feizi, S.
\newblock Dual manifold adversarial robustness: Defense against {L}p and
  non-{L}p adversarial attacks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3487--3498, Dec 2020.

\bibitem[Liu et~al.(2020)Liu, Salzmann, Lin, Tomioka, and S\"{u}sstrunk]{liu20}
Liu, C., Salzmann, M., Lin, T., Tomioka, R., and S\"{u}sstrunk, S.
\newblock On the loss landscape of adversarial training: Identifying challenges
  and how to overcome them.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  21476--21487, 2020.

\bibitem[Luo et~al.(2018)Luo, Liu, Wei, and Xu]{Luo18}
Luo, B., Liu, Y., Wei, L., and Xu, Q.
\newblock Towards imperceptible and robust adversarial example attacks against
  neural networks.
\newblock In \emph{AAAI Conference on Artificial Intelligence and Innovative
  Applications}, Feb 2018.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry18}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Mantecón et~al.(2019)Mantecón, del Blanco, Jaureguizar, and
  García]{Mantecon19}
Mantecón, T., del Blanco, C.~R., Jaureguizar, F., and García, N.
\newblock A real-time gesture recognition system using near-infrared imagery.
\newblock \emph{PLOS ONE}, pp.\  1--17, Oct 2019.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and
  Frossard]{moosavi16}
Moosavi-Dezfooli, S.-M., Fawzi, A., and Frossard, P.
\newblock {D}eepfool: a simple and accurate method to fool deep neural
  networks.
\newblock In \emph{IEEE conference on computer vision and pattern recognition},
  pp.\  2574--2582, Jun 2016.

\bibitem[Mujahid et~al.(2021)Mujahid, Awan, Yasin, Mohammed, Damaševičius,
  Maskeliūnas, and Abdulkareem]{Mujahid21}
Mujahid, A., Awan, M.~J., Yasin, A., Mohammed, M.~A., Damaševičius, R.,
  Maskeliūnas, R., and Abdulkareem, K.~H.
\newblock Real-time hand gesture recognition based on deep learning {YOLO}v3
  model.
\newblock \emph{Applied Sciences}, 2021.

\bibitem[Nacson et~al.(2019)Nacson, Srebro, and Soudry]{nacson19}
Nacson, M.~S., Srebro, N., and Soudry, D.
\newblock Stochastic gradient descent on separable data: Exact convergence with
  a fixed learning rate.
\newblock In \emph{The 22th International Conference on Artificial Intelligence
  and Statistics}, pp.\  3051--3059, Apr 2019.

\bibitem[Nagarajan \& Kolter(2019)Nagarajan and Kolter]{kolter19}
Nagarajan, V. and Kolter, J.~Z.
\newblock Uniform convergence may be unable to explain generalization in deep
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  11611--11622, Dec 2019.

\bibitem[Oudah et~al.(2020)Oudah, Al-Naji, and Chahl]{Oudah20}
Oudah, M., Al-Naji, A., and Chahl, J.
\newblock Hand gesture recognition based on computer vision: A review of
  techniques.
\newblock \emph{Journal of Imaging}, 2020.

\bibitem[Phan(2021)]{Phan21}
Phan, H.
\newblock huyvnphan/pytorch\_cifar10, 1 2021.

\bibitem[Raghunathan et~al.(2020)Raghunathan, Xie, Yang, Duchi, and
  Liang]{raghunathan20}
Raghunathan, A., Xie, S.~M., Yang, F., Duchi, J., and Liang, P.
\newblock Understanding and mitigating the tradeoff between robustness and
  accuracy.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7909--7919, Jul 2020.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{rice20}
Rice, L., Wong, E., and Kolter, Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8093--8104, Jul 2020.

\bibitem[Sagawa* et~al.(2020)Sagawa*, Koh*, Hashimoto, and Liang]{Sagawa20}
Sagawa*, S., Koh*, P.~W., Hashimoto, T.~B., and Liang, P.
\newblock Distributionally robust neural networks.
\newblock In \emph{International Conference on Learning Representations}, Apr
  2020.

\bibitem[Sanyal et~al.(2020)Sanyal, Dokania, Kanade, and Torr]{sanyal20}
Sanyal, A., Dokania, P.~K., Kanade, V., and Torr, P.
\newblock How benign is benign overfitting?
\newblock In \emph{International Conference on Learning Representations}, Apr
  2020.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt18}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5019--5031, Dec 2018.

\bibitem[Schneider et~al.(2020)Schneider, Rusak, Eck, Bringmann, Brendel, and
  Bethge]{Schneider20}
Schneider, S., Rusak, E., Eck, L., Bringmann, O., Brendel, W., and Bethge, M.
\newblock Improving robustness against common corruptions by covariate shift
  adaptation.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems}, pp.\
  11539--11551, Dec 2020.

\bibitem[Springer et~al.(2021)Springer, Mitchell, and Kenyon]{springer21}
Springer, J.~M., Mitchell, M., and Kenyon, G.~T.
\newblock Adversarial perturbations are not so weird: Entanglement of robust
  and non-robust features in neural network classifiers.
\newblock \emph{arXiv preprint arXiv:2102.05110}, 2021.

\bibitem[Stutz et~al.(2019)Stutz, Hein, and Schiele]{Stutz19}
Stutz, D., Hein, M., and Schiele, B.
\newblock Disentangling adversarial robustness and generalization.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  6967--6987, Jun 2019.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy14}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, apr
  2014.

\bibitem[Telgarsky(2013)]{telgarsky13}
Telgarsky, M.
\newblock Margins, shrinkage, and boosting.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  307--315, Jun 2013.

\bibitem[Tsipras et~al.(2019)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras19}
Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and Madry, A.
\newblock Robustness may be at odds with accuracy.
\newblock In \emph{International Conference on Learning Representations}, May
  2019.

\bibitem[Vershynin(2010)]{vershynin12}
Vershynin, R.
\newblock Introduction to the non-asymptotic analysis of random matrices.
\newblock \emph{arXiv preprint arXiv:1011.3027}, 2010.

\bibitem[Welinder et~al.(2010)Welinder, Branson, Mita, Wah, Schroff, Belongie,
  and Perona]{Welinder10}
Welinder, P., Branson, S., Mita, T., Wah, C., Schroff, F., Belongie, S., and
  Perona, P.
\newblock {Caltech-UCSD Birds 200}.
\newblock Technical Report CNS-TR-2010-001, California Institute of Technology,
  2010.

\bibitem[Wong et~al.(2020)Wong, Rice, and Kolter]{Wong20Fast}
Wong, E., Rice, L., and Kolter, J.~Z.
\newblock Fast is better than free: Revisiting adversarial training.
\newblock In \emph{International Conference on Learning Representations}, Apr
  2020.

\bibitem[Wu et~al.(2020)Wu, Tong, and Vorobeychik]{Wu20}
Wu, T., Tong, L., and Vorobeychik, Y.
\newblock Defending against physically realizable attacks on image
  classification.
\newblock In \emph{International Conference on Learning Representations}, Apr
  2020.

\bibitem[Xu et~al.(2020)Xu, Zhang, Ni, Li, Wang, Tian, and Zhang]{xu20}
Xu, M., Zhang, J., Ni, B., Li, T., Wang, C., Tian, Q., and Zhang, W.
\newblock Adversarial domain adaptation with domain mixup.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, pp.\
  6502--6509, Feb 2020.

\bibitem[Yang et~al.(2013)Yang, Premaratne, and Vial]{Yang13}
Yang, S., Premaratne, P., and Vial, P.
\newblock Hand gesture recognition: An overview.
\newblock In \emph{IEEE International Conference on Broadband Network
  Multimedia Technology}, pp.\  63--69, 2013.

\bibitem[Yin et~al.(2019)Yin, Kannan, and Bartlett]{Yin19}
Yin, D., Kannan, R., and Bartlett, P.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In \emph{International conference on machine learning}, pp.\
  7085--7094, Jun 2019.

\bibitem[Zhai et~al.(2019)Zhai, Cai, He, Dan, He, Hopcroft, and Wang]{zhai20}
Zhai, R., Cai, T., He, D., Dan, C., He, K., Hopcroft, J., and Wang, L.
\newblock Adversarially robust generalization just requires more unlabeled
  data.
\newblock \emph{arXiv preprint arXiv:1906.00555}, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and Jordan]{zhang19}
Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L.~E., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7472--7482, Jun 2019.

\bibitem[Zhao et~al.(2020)Zhao, Liu, and Larson]{zhao20}
Zhao, Z., Liu, Z., and Larson, M.
\newblock Towards large yet imperceptible adversarial image perturbations with
  perceptual color distance.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  1039--1048, 2020.

\bibitem[Zhou et~al.(2017)Zhou, Lapedriza, Khosla, Oliva, and Torralba]{zhou17}
Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A.
\newblock Places: A 10 million image database for scene recognition.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2017.

\bibitem[Zhou et~al.(2020)Zhou, Liang, and Chen]{Zhou20}
Zhou, J., Liang, C., and Chen, J.
\newblock Manifold projection for adversarial defense on face recognition.
\newblock In \emph{European Conference on Computer Vision}, pp.\  288–305,
  Aug 2020.

\end{thebibliography}
