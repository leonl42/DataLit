

%%%%%%%%% ABSTRACT
\begin{abstract}

% To achieve accurate 3D object detection at a low cost for autonomous driving, many multi-camera methods have
% been proposed and solved the occlusion problem of monocular approaches. However, due to the lack of high precise spatial localization ability, these methods perform worse than LiDAR-based detectors. We consider that mimic to learn the foreground inner-geometry expression ability of the LiDAR-based detectors besides modeling depth can further improve the performance. Thus, in this work, we present a new cross-modality distillation with target inner-geometry aware for multi-view 3d object detection, named TIG-Distill. First, in addition to directly training an absolute depth prediction network, we introduce a foreground inner-geometry relative attention depth supervision module. The structured spatial position knowledge of target is modeled by supervising the relative depth relationships between different pixels in the foreground. Second, we introduce a foreground structured attention feature supervision module. Transfer more reliable relative spatial feature relationships from LiDAR-based detectors to improve the structured awareness ability of multi-view based detectors. Extensive experiments demonstrate that the proposed method outperforms current KD approaches on a highly-competitive baseline, BEVDepth. Notably, The proposed method achieves leading performance on the nuScenes test leaderboard for both object detection and the following object tracking task. 


% To achieve accurate 3D object detection following the low-cost and high-efficiency manner for autonomous driving, many cross-modality supervision methods have been proposed. However, the core issue of the mainstream methods is that the performance is limited by the direct supervision of the gap between the different modality information. Therefore, we consider that mimic to learn the foreground inner-geometry expression ability of the LiDAR based detectors to eliminate the gap, which can further improve the performance. Thus, in this work, we present a new cross-modality distillation with target inner-geometry aware for multi-view 3d object detection, named TIG-Distill. First, in addition, to directly training an absolute depth prediction network, we introduce a foreground inner-geometry relative attention depth supervision module. The structured spatial position knowledge of target is modeled by supervising the relative depth relationships between different pixels in the foreground. Second, we introduce a foreground structured attention feature supervision module. Transfer more reliable relative spatial feature relationships from LiDAR-based detectors to improve the structured awareness ability of camera-based detectors. Extensive experiments demonstrate that the proposed method outperforms current Knowledge Distillation~(KD) approaches on a highly-competitive baseline, e.g. BEVDepth. Notably, The proposed method achieves leading performance on the nuScenes test leaderboard for both object detection and the following object tracking task.


To achieve accurate multi-view 3D object detection, existing methods propose to benefit camera-based detectors with spatial cues provided by the LiDAR modality, e.g., dense depth supervision and bird-eye-view (BEV) feature distillation. However, they directly conduct point-to-point mimicking from LiDAR to camera, which neglects the inner-geometry of foreground targets and suffers from the modal gap between 2D-3D features. In this paper, we propose the learning scheme of \textbf{T}arget \textbf{I}nner-\textbf{G}eometry from the LiDAR modality into camera-based BEV detectors for both dense depth and BEV features, termed as \textbf{TiG-BEV}. First, we introduce an inner-depth supervision module to learn the low-level relative depth relations between different foreground pixels. This enables the camera-based detector to better understand the object-wise spatial structures. Second, we design an inner-feature BEV distillation module to imitate the high-level semantics of different keypoints within foreground targets. To further alleviate the BEV feature gap between two modalities, we adopt both inter-channel and inter-keypoint distillation for feature-similarity modeling. With our target inner-geometry learning, TiG-BEV can effectively boost student models by different margins on nuScenes val set, e.g., \textbf{+2.3\%} NDS and \textbf{+2.4\%} mAP for BEVDepth, along with \textbf{+9.1\%} NDS and \textbf{+10.3\%} mAP for BEVDet without CBGS. Code will be available at \url{https://github.com/ADLab3Ds/TiG-BEV}.
% Notably, The proposed method achieves leading performance on the nuScenes test leaderboard for both object detection and the following object tracking task.


% We dub this phenomenon as semantic mismatch. 
% Knowledge distillation aims to transfer representational knowledge from one model (a teacher) to another (a student) that is normally smaller. 
% Most of the previous works manually tie intermediate features of the teacher and student, and perform distillation through one-to-one spatial matching individually, ignoring the fact that semantic on the same spatial position of feature maps from the teacher and student models usually vary. We found the semantic mismatch hurts the effect of knowledge distillation. 

% To this end, we propose to guide the entire student feature to mimic each component of the teacher respectively. Specifically, given each spatial component of the teacher features, we develop a novel Target-aware Transformer to reconstruct the corresponding spatial component of the student from the entire student feature map. The aggregated student feature component will increase matching capability and boost knowledge distillation performance. To further apply the proposed method to different applications, we propose the patch-group and anchor-point distillation to address the issues of the inductive bias learning challenge and heavy computation burden.
  

\end{abstract}
%We have conducted extensive experiments on large-scale benchmarks, including ImageNet, Pascal VOC, and COCOStuff10k. The experimental results confirm the superiority of the proposed method. We will release our code upon acceptance.
  %Knowledge Distillation is a technique to transfer learned knowledge from teacher network to student network.
  %Knowledge distillation aims to transfer representational knowledge from one model (a teacher) to another model (a student) that is normally smaller. Most of previous works ...
  % Early works XXX, limitations of these early works. Recently, researchers XXX. However, they XXX.
  %Yet previous works attempt to transfer the representational knowledge in a factored form.
  %The representation is organized into ordered component set (\eg pixel set) and each component of student representation is associated with one of teacher representation by spatial order, which presumes that the student's components share the same semantic and expressivity with that of teacher.
  %Such one-to-one fashion overestimates the spatial prior while neglecting the semantic distance.
  %Hence, we propose the Semantic Position Encoding (SPE) to reconfigure the student feature by semantic distance with teacher.
  %The proposed SPE provides the direction and intensity of propagation and integration of the semantic over the feature map, thus referred to self-assembling.
  %In addition to image-level classification, our self-assembling KD can be extended to dense pixel-level classification with the proposed patch-group and anchor-point distillation, which can reduce the noise interference and computation complexity. 
  %Extensive experiments over large scale benchmarks including ImageNet and COCOStuff10k are conducted to validate the effectiveness of our model, which advances the state-of-the art.
  %We will release our code upon acceptance.
%However, manual selection without considering the correlation between teacher and student will deteriorate the subsequent distillation performance. There has been some efforts to solve this problem, but they still focus on one-to-one spatial matching, ignoring the fact that small students are unable to mimic large teachers. 
  
  %   To further apply the proposed method to different applications, we propose the patch-group and anchor-point distillation to address the issues of heavy computation burden and noise interference. 