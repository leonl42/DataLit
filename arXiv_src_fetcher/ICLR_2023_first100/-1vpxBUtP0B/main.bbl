\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bochkovskiy et~al.(2020)Bochkovskiy, Wang, and Liao]{yolov4}
Alexey Bochkovskiy, Chien{-}Yao Wang, and Hong{-}Yuan~Mark Liao.
\newblock {YOLOv4: O}ptimal speed and accuracy of object detection.
\newblock \emph{arXiv preprint arXiv:2004.10934}, 2020.

\bibitem[Cheung \& Yeung(2021)Cheung and Yeung]{modals}
Tsz~Him Cheung and Dit~Yan Yeung.
\newblock {MODALS}: Modality-agnostic automated data augmentation in the latent
  space.
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR 2021}}, 2021.

\bibitem[Cheung \& Yeung(2022)Cheung and Yeung]{adaaug}
Tsz~Him Cheung and Dit~Yan Yeung.
\newblock {AdaAug}: {L}earning class- and instance-adaptive data augmentation
  policies.
\newblock In \emph{10th International Conference on Learning Representations,
  {ICLR 2022}}, 2022.

\bibitem[Cheung \& Yeung(2023)Cheung and Yeung]{autoda}
Tsz-Him Cheung and Dit-Yan Yeung.
\newblock A survey of automated data augmentation for image classification:
  Learning to compose, mix, and generate.
\newblock \emph{IEEE transactions on neural networks and learning systems}, PP,
  06 2023.
\newblock \doi{10.1109/TNNLS.2023.3282258}.

\bibitem[Chrabaszcz et~al.(2017)Chrabaszcz, Loshchilov, and
  Hutter]{tinyimagenet}
Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter.
\newblock A downsampled variant of imagenet as an alternative to the {CIFAR}
  datasets.
\newblock \emph{arXiv preprint arXiv:1707.08819}, 2017.

\bibitem[Cubuk et~al.(2019)Cubuk, Zoph, Man{\'{e}}, Vasudevan, and Le]{aa}
Ekin~D. Cubuk, Barret Zoph, Dandelion Man{\'{e}}, Vijay Vasudevan, and Quoc~V.
  Le.
\newblock {AutoAugment}: Learning augmentation strategies from data.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2019}, pp.\  113--123. {IEEE}, 2019.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{randaug}
Ekin~D. Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V. Le.
\newblock {RandAugment:} {P}ractical automated data augmentation with a reduced
  search space.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition,
  {CVPR} Workshops 2020}, pp.\  3008--3017. {IEEE}, 2020.

\bibitem[Dabouei et~al.(2021)Dabouei, Soleymani, Taherkhani, and
  Nasrabadi]{supermix}
Ali Dabouei, Sobhan Soleymani, Fariborz Taherkhani, and Nasser~M. Nasrabadi.
\newblock {S}uper{M}ix: {S}upervising the mixing data augmentation.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2021}, pp.\  13794--13803. {IEEE}, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Li]{imagenet}
Jia Deng, Wei Dong, Richard Socher, Li{-}Jia Li, Kai Li, and Fei{-}Fei Li.
\newblock {ImageNet}: {A} large-scale hierarchical image database.
\newblock In \emph{2009 {IEEE} Computer Society Conference on Computer Vision
  and Pattern Recognition {(CVPR} 2009)}, pp.\  248--255. {IEEE}, 2009.

\bibitem[Em et~al.(2017)Em, Gao, Lou, Wang, Huang, and Duan]{pet}
Yan Em, Feng Gao, Yihang Lou, Shiqi Wang, Tiejun Huang, and Ling{-}Yu Duan.
\newblock Incorporating intra-class variance to fine-grained visual
  recognition.
\newblock In \emph{2017 {IEEE} International Conference on Multimedia and Expo,
  {ICME} 2017}, pp.\  1452--1457. {IEEE}, 2017.

\bibitem[Everingham et~al.(2010)Everingham, Van~Gool, Williams, Winn, and
  Zisserman]{voc}
M.~Everingham, L.~Van~Gool, C.~K.~I. Williams, J.~Winn, and A.~Zisserman.
\newblock The pascal visual object classes (voc) challenge.
\newblock \emph{International Journal of Computer Vision}, 88\penalty0
  (2):\penalty0 303--338, June 2010.

\bibitem[Guo et~al.(2019)Guo, Mao, and Zhang]{adamixup}
Hongyu Guo, Yongyi Mao, and Richong Zhang.
\newblock Mixup as locally linear out-of-manifold regularization.
\newblock In \emph{The Thirty-Third {AAAI} Conference on Artificial
  Intelligence, {AAAI} 2019, The Thirty-First Innovative Applications of
  Artificial Intelligence Conference, {IAAI} 2019, The Ninth {AAAI} Symposium
  on Educational Advances in Artificial Intelligence, {EAAI} 2019}, pp.\
  3714--3722. {AAAI} Press, 2019.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and Sun]{presnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{Computer Vision - {ECCV} 2016 - 14th European Conference},
  volume 9908, pp.\  630--645. Springer, 2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2016}, pp.\  770--778. {IEEE}, 2016{\natexlab{b}}.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and
  Lakshminarayanan]{augmix}
Dan Hendrycks, Norman Mu, Ekin~Dogus Cubuk, Barret Zoph, Justin Gilmer, and
  Balaji Lakshminarayanan.
\newblock {AugMix:} {A} simple data processing method to improve robustness and
  uncertainty.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020}, 2020.

\bibitem[Ho et~al.(2019)Ho, Liang, Chen, Stoica, and Abbeel]{pba}
Daniel Ho, Eric Liang, Xi~Chen, Ion Stoica, and Pieter Abbeel.
\newblock {Population Based Augmentation: } efficient learning of augmentation
  policy schedules.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning, {ICML} 2019}, volume~97, pp.\  2731--2741. {PMLR}, 2019.

\bibitem[Jaderberg et~al.(2015)Jaderberg, Simonyan, Zisserman, and
  Kavukcuoglu]{stn}
Max Jaderberg, Karen Simonyan, Andrew Zisserman, and Koray Kavukcuoglu.
\newblock Spatial transformer networks.
\newblock In \emph{Advances in Neural Information Processing Systems 28: Annual
  Conference on Neural Information Processing Systems 2015}, pp.\  2017--2025,
  2015.

\bibitem[Kim et~al.(2020)Kim, Choo, and Song]{puzzlemix}
Jang{-}Hyun Kim, Wonho Choo, and Hyun~Oh Song.
\newblock {P}uzzle {M}ix: {E}xploiting saliency and local statistics for
  optimal mixup.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020}, volume 119 of \emph{Proceedings of Machine Learning
  Research}, pp.\  5275--5285. {PMLR}, 2020.

\bibitem[Kim et~al.(2021)Kim, Choo, Jeong, and Song]{comixup}
Jang{-}Hyun Kim, Wonho Choo, Hosan Jeong, and Hyun~Oh Song.
\newblock {C}o-{M}ixup: {S}aliency guided joint mixup with supermodular
  diversity.
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR} 2021}, 2021.

\bibitem[Krause et~al.(2013)Krause, Deng, Stark, and Fei-Fei]{car}
J.~Krause, Jun Deng, Michael Stark, and Li~Fei-Fei.
\newblock Collecting a large-scale dataset of fine-grained cars.
\newblock In \emph{Second Workshop on Fine-Grained Visual Categorization},
  2013.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and Hinton]{cifar10}
A.~Krizhevsky and G.~Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{alexnet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock {ImageNet} classification with deep convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 25: 26th
  Annual Conference on Neural Information Processing Systems 2012.}, pp.\
  1106--1114, 2012.

\bibitem[Lim et~al.(2019)Lim, Kim, Kim, Kim, and Kim]{fastaa}
Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, and Sungwoong Kim.
\newblock {Fast AutoAugment}.
\newblock In \emph{Advances in Neural Information Processing Systems 32: Annual
  Conference on Neural Information Processing Systems 2019, NeurIPS 2019}, pp.\
   6662--6672, 2019.

\bibitem[Liu et~al.(2021)Liu, Li, Wu, Chen, Wu, Guo, and Li]{automix}
Zicheng Liu, Siyuan Li, Di~Wu, Zhiyuan Chen, Lirong Wu, Jianzhu Guo, and
  Stan~Z. Li.
\newblock {AutoMix: U}nveiling the power of mixup.
\newblock \emph{arXiv preprint arXiv:2103.13027}, 2021.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and
  Vedaldi]{aircraft}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew~B. Blaschko, and Andrea
  Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[Nilsback \& Zisserman(2008)Nilsback and Zisserman]{flower}
Maria{-}Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{Sixth Indian Conference on Computer Vision, Graphics {\&}
  Image Processing, {ICVGIP} 2008}, pp.\  722--729. {IEEE}, 2008.

\bibitem[Qin et~al.(2020)Qin, Fang, Zhang, Liu, Wang, and Wang]{resizemix}
Jie Qin, Jiemin Fang, Qian Zhang, Wenyu Liu, Xingang Wang, and Xinggang Wang.
\newblock Resizemix: Mixing data with preserved object information and true
  labels.
\newblock \emph{arXiv preprint arXiv:2012.11101}, 2020.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{fasterrcnn}
Shaoqing Ren, Kaiming He, Ross~B. Girshick, and Jian Sun.
\newblock Faster {R-CNN:} {T}owards real-time object detection with region
  proposal networks.
\newblock In \emph{Advances in Neural Information Processing Systems 28: Annual
  Conference on Neural Information Processing Systems 2015}, pp.\  91--99,
  2015.

\bibitem[Shorten \& Khoshgoftaar(2019)Shorten and Khoshgoftaar]{da}
Connor Shorten and Taghi~M. Khoshgoftaar.
\newblock A survey on image data augmentation for deep learning.
\newblock \emph{Journal of Big Data}, 6:\penalty0 60, 2019.

\bibitem[Uddin et~al.(2021)Uddin, Monira, Shin, Chung, and Bae]{smix}
A.~F. M.~Shahab Uddin, Mst.~Sirazam Monira, Wheemyung Shin, TaeChoong Chung,
  and Sung{-}Ho Bae.
\newblock {S}aliency{M}ix: {A} saliency guided data augmentation strategy for
  better regularization.
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR} 2021}, 2021.

\bibitem[Verma et~al.(2019)Verma, Lamb, Beckham, Najafi, Mitliagkas,
  Lopez{-}Paz, and Bengio]{manifoldmixup}
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas,
  David Lopez{-}Paz, and Yoshua Bengio.
\newblock Manifold {M}ixup: {B}etter representations by interpolating hidden
  states.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning, {ICML} 2019}, volume~97 of \emph{Proceedings of Machine Learning
  Research}, pp.\  6438--6447. {PMLR}, 2019.

\bibitem[Yun et~al.(2019)Yun, Han, Chun, Oh, Yoo, and Choe]{cutmix}
Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Seong~Joon Oh, Youngjoon Yoo, and
  Junsuk Choe.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{2019 {IEEE} International Conference on Computer Vision,
  {ICCV} 2019}, pp.\  6022--6031. {IEEE}, 2019.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{wrn}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock In \emph{Proceedings of the British Machine Vision Conference 2016,
  {BMVC} 2016}. {BMVA} Press, 2016.

\bibitem[Zhang et~al.(2018)Zhang, Ciss{\'{e}}, Dauphin, and Lopez{-}Paz]{mixup}
Hongyi Zhang, Moustapha Ciss{\'{e}}, Yann~N. Dauphin, and David Lopez{-}Paz.
\newblock {Mixup:} {B}eyond empirical risk minimization.
\newblock In \emph{6th International Conference on Learning Representations,
  {ICLR} 2018}, 2018.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, Lapedriza, Oliva, and Torralba]{cam}
Bolei Zhou, Aditya Khosla, {\`{A}}gata Lapedriza, Aude Oliva, and Antonio
  Torralba.
\newblock Learning deep features for discriminative localization.
\newblock In \emph{2016 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2016}, pp.\  2921--2929. {IEEE}, 2016.

\end{thebibliography}
