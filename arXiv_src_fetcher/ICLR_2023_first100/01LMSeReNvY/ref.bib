@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
} 
@inproceedings{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  booktitle={NeurIPS $EMC^2$ Workshop},
  year={2019}
}




@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{shin2020autoprompt,
  title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4222--4235},
  year={2020}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020},
}

@article{yuan2021bartscore,
  title={Bartscore: Evaluating generated text as text generation},
  author={Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27263--27277},
  year={2021}
}

@inproceedings{ding2022openprompt,
  title={OpenPrompt: An Open-source Framework for Prompt-learning},
  author={Ding, Ning and Hu, Shengding and Zhao, Weilin and Chen, Yulin and Liu, Zhiyuan and Zheng, Haitao and Sun, Maosong},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  pages={105--113},
  year={2022}
}

@inproceedings{schick2021exploiting,
  title={Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference},
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  booktitle={Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
  pages={255--269},
  year={2021}
}

@article{schick2020few,
  title={Few-shot text generation with pattern-exploiting training},
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2012.11926},
  year={2020}
}

@inproceedings{qin2021learning,
  title={Learning How to Ask: Querying LMs with Mixtures of Soft Prompts},
  author={Qin, Guanghui and Eisner, Jason},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={5203--5212},
  year={2021}
}

@inproceedings{schick2021s,
  title={Itâ€™s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners},
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2339--2352},
  year={2021}
}

@inproceedings{gao2021making,
  title={Making Pre-trained Language Models Better Few-shot Learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={3816--3830},
  year={2021}
}

@inproceedings{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4582--4597},
  year={2021}
}

@article{liu2021gpt,
title={GPT Understands, Too},
author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
journal={arXiv:2103.10385},
year={2021}
}

@inproceedings{lester2021power,
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={3045--3059},
  year={2021}
}

@inproceedings{zhang2021differentiable,
  title={Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners},
  author={Zhang, Ningyu and Li, Luoqiu and Chen, Xiang and Deng, Shumin and Bi, Zhen and Tan, Chuanqi and Huang, Fei and Chen, Huajun},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{liu2022ptuningv2,
    title = "{P}-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks",
    author = "Liu, Xiao  and
      Ji, Kaixuan  and
      Fu, Yicheng  and
      Tam, Weng  and
      Du, Zhengxiao  and
      Yang, Zhilin  and
      Tang, Jie",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    year = "2022",
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer.},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{han2021ptr,
  title={Ptr: Prompt tuning with rules for text classification},
  author={Han, Xu and Zhao, Weilin and Ding, Ning and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2105.11259},
  year={2021}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}


% black-box tuning
@inproceedings{sun2022bbt,
  title={Black-Box Tuning for Language-Model-as-a-Service}, 
  author={Tianxiang Sun and Yunfan Shao and Hong Qian and Xuanjing Huang and Xipeng Qiu},
  booktitle = {Proceedings of {ICML}},
  year={2022}
}

@inproceedings{sun2022bbtv2,
  title={BBTv2: Towards a Gradient-Free Future with Large Language Models},
  author={Tianxiang Sun and Zhengfu He and Hong Qian and Yunhua Zhou and Xuanjing Huang and Xipeng Qiu},
  booktitle = {Proceedings of {EMNLP}},
  year={2022}
}

@article{diao2022black,
  title={Black-box prompt learning for pre-trained language models},
  author={Diao, Shizhe and Li, Xuechun and Lin, Yong and Huang, Zhichao and Zhang, Tong},
  journal={arXiv preprint arXiv:2201.08531},
  year={2022}
}
@article{prasad2022grips,
  title={Grips: Gradient-free, edit-based instruction search for prompting large language models},
  author={Prasad, Archiki and Hase, Peter and Zhou, Xiang and Bansal, Mohit},
  journal={arXiv preprint arXiv:2203.07281},
  year={2022}
}

@article{deng2022rlprompt,
  title={RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning},
  author={Deng, Mingkai and Wang, Jianyu and Hsieh, Cheng-Ping and Wang, Yihan and Guo, Han and Shu, Tianmin and Song, Meng and Xing, Eric P and Hu, Zhiting},
  journal={arXiv preprint arXiv:2205.12548},
  year={2022}
}

@article{chai2022clip,
  title={Clip-Tuning: Towards Derivative-free Prompt Learning with a Mixture of Rewards},
  author={Chai, Yekun and Wang, Shuohuan and Sun, Yu and Tian, Hao and Wu, Hua and Wang, Haifeng},
  journal={arXiv preprint arXiv:2210.12050},
  year={2022}
}

@article{zhang2022tempera,
  title={TEMPERA: Test-Time Prompting via Reinforcement Learning},
  author={Zhang, Tianjun and Wang, Xuezhi and Zhou, Denny and Schuurmans, Dale and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2211.11890},
  year={2022}
}

% Model Ensemble Background

@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={24},
  number={2},
  pages={123--140},
  year={1996},
  publisher={Springer}
}

@article{freund1997decision,
  title={A decision-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Journal of computer and system sciences},
  volume={55},
  pages={119--139},
  year={1997},
}

@article{hastie2009multi,
  title={Multi-class adaboost},
  author={Hastie, Trevor and Rosset, Saharon and Zhu, Ji and Zou, Hui},
  journal={Statistics and its Interface},
  volume={2},
  pages={349--360},
  year={2009},
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{friedman2001greedy,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}




% dataset

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@inproceedings{williams2018broad,
  title={A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={1112--1122},
  year={2018}
}

@inproceedings{rajpurkar2016squad,
  title={SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={2383--2392},
  year={2016}
}

@inproceedings{dagan2005pascal,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine learning challenges workshop},
  pages={177--190},
  year={2005},
}

@inproceedings{pang2005seeing,
  title={Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales},
  author={Pang, Bo and Lee, Lillian},
  booktitle={Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACLâ€™05)},
  pages={115--124},
  year={2005}
}

@inproceedings{voorhees2000building,
  title={Building a question answering test collection},
  author={Voorhees, Ellen M and Tice, Dawn M},
  booktitle={Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={200--207},
  year={2000}
}

@inproceedings{Zhang2015CharacterlevelCN,
  title={Character-level Convolutional Networks for Text Classification},
  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},
  booktitle={NIPS},
  year={2015}
}

@inproceedings{bowman2015large,
  title={A large annotated corpus for learning natural language inference},
  author={Bowman, Samuel and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},
  booktitle={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  pages={632--642},
  year={2015}
}

@inproceedings{wang2018glue,
  title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  booktitle={Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  year={2018}
}

@inproceedings{hu2004mining,
  title={Mining and summarizing customer reviews},
  author={Hu, Minqing and Liu, Bing},
  booktitle={Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={168--177},
  year={2004}
}

@article{pang2004sentimental,
  title={A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts},
  author={Pang, Bo and Lee, Lillian},
  journal={arXiv preprint cs/0409058},
  year={2004}
}

@article{wiebe2005annotating,
  title={Annotating expressions of opinions and emotions in language},
  author={Wiebe, Janyce and Wilson, Theresa and Cardie, Claire},
  journal={Language resources and evaluation},
  year={2005},
}

@inproceedings{dolan2005automatically,
  title={Automatically constructing a corpus of sentential paraphrases},
  author={Dolan, Bill and Brockett, Chris},
  booktitle={Third International Workshop on Paraphrasing (IWP2005)},
  year={2005}
}

% libray
@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}


@inproceedings{tramer2016stealing,
  title={Stealing machine learning models via prediction $\{$APIs$\}$},
  author={Tram{\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
  booktitle={25th USENIX security symposium (USENIX Security 16)},
  pages={601--618},
  year={2016}
}

