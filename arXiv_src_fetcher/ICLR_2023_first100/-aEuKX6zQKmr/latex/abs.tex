\begin{abstract}
Recent research has explored distilling knowledge from large language models (LLMs) to optimize retriever models, especially within the retrieval-augmented generation (RAG) framework. 
However, most existing training methods rely on extracting supervision signals from LLMs' weights or their output probabilities, which is not only resource-intensive but also incompatible with black-box LLMs. 
In this paper, we introduce \textit{Intermediate Distillation}, a data-efficient knowledge distillation training scheme that treats LLMs as black boxes and distills their knowledge via an innovative LLM-ranker-retriever pipeline, solely using LLMs' ranking generation as the supervision signal. 
Extensive experiments demonstrate that our proposed method can significantly improve the performance of retriever models with only 1,000 training instances. 
Moreover, our distilled retriever model significantly boosts performance in question-answering tasks within the RAG framework, demonstrating the potential of LLMs to economically and effectively train smaller models.
% The remarkable semantic alignment ability of large language models (LLMs) has been demonstrated and widely used for knowledge distillation in training the information retriever models, especially those used in the retrieval-augmented generation (RAG) framework.
% However, most of the existing training methods are limited by their dependence on extracting supervision signals from the weights of LLMs, which is not only resource-intensive but also restricts the use of closed-source language models.
% In this paper, we propose an easy and efficient distillation method named Light LLM-Guider, which treats LLMs as black-box and leverages their semantic alignment capabilities through a LLM-ranker-retriever distillation pipeline, thereby only uses the ranking list generation from LLMs as supervision signals.
% Our empirical experiments demonstrate that our proposed method significantly improves the performance of retrieval models with just about 1,000 training examples, surpassing other distillation methods that rely on different training signals. Additionally, our distilled retriever model boosts performance in question-answering tasks within the RAG framework, which underscore the ability of LLMs to effectively and economically enhance the training of smaller models.
% With the empirical experiments show that our proposed method significantly enhances the performance of retrieval models using only a small amount of training data (\textasciitilde 1k) and outperforms distillation methods that utilize other training signals.
% In addition, we demonstrate that our well-trained retriever model enhances performance in question-answering tasks within the RAG framework. 
% Our findings highlight the potential of LLMs to improve the training of smaller models both effectively and economically.
\end{abstract}


% In this paper, we propose an alternative, more efficient method for leveraging the supervision capabilities of LLMs without direct access to their weights. We introduce a multi-step training technique that employs natural language outputs from LLMs as supervision signals. Our experimental results indicate that this method not only improves the performance of information retrievers more than traditional signals but also demonstrates significant advancements in question-answering tasks within the Retrieval-Augmented Generation (RAG) framework. These findings underscore the potential of LLMs to enhance smaller models' training effectively and economically.