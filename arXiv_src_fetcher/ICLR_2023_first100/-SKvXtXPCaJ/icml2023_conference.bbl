\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel \& Ng(2004)Abbeel and Ng]{abbeel2004apprenticeship}
Abbeel, P. and Ng, A.~Y.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, pp.\ ~1, 2004.

\bibitem[Argall et~al.(2009)Argall, Chernova, Veloso, and
  Browning]{argall2009survey}
Argall, B.~D., Chernova, S., Veloso, M., and Browning, B.
\newblock A survey of robot learning from demonstration.
\newblock \emph{Robotics and autonomous systems}, 57\penalty0 (5):\penalty0
  469--483, 2009.

\bibitem[Baker et~al.(2022)Baker, Akkaya, Zhokhov, Huizinga, Tang, Ecoffet,
  Houghton, Sampedro, and Clune]{baker2022video}
Baker, B., Akkaya, I., Zhokhov, P., Huizinga, J., Tang, J., Ecoffet, A.,
  Houghton, B., Sampedro, R., and Clune, J.
\newblock Video pretraining (vpt): Learning to act by watching unlabeled online
  videos.
\newblock \emph{arXiv preprint arXiv:2206.11795}, 2022.

\bibitem[Bertsekas(1995)]{bertsekas1995dynamic}
Bertsekas, D.~P.
\newblock \emph{Dynamic programming and optimal control}, volume~1.
\newblock Athena Scientific, 1995.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{1606.01540}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym, 2016.

\bibitem[Calandra et~al.(2015)Calandra, Ivaldi, Deisenroth, Rueckert, and
  Peters]{calandra2015learning}
Calandra, R., Ivaldi, S., Deisenroth, M.~P., Rueckert, E., and Peters, J.
\newblock Learning inverse dynamics models with contacts.
\newblock In \emph{2015 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  3186--3191. IEEE, 2015.

\bibitem[Christiano et~al.(2016)Christiano, Shah, Mordatch, Schneider,
  Blackwell, Tobin, Abbeel, and Zaremba]{christiano2016transfer}
Christiano, P., Shah, Z., Mordatch, I., Schneider, J., Blackwell, T., Tobin,
  J., Abbeel, P., and Zaremba, W.
\newblock Transfer from simulation to real world through learning deep inverse
  dynamics model.
\newblock \emph{arXiv preprint arXiv:1610.03518}, 2016.

\bibitem[Ding et~al.(2019)Ding, Florensa, Abbeel, and Phielipp]{ding2019goal}
Ding, Y., Florensa, C., Abbeel, P., and Phielipp, M.
\newblock Goal-conditioned imitation learning.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Ecoffet et~al.(2019)Ecoffet, Huizinga, Lehman, Stanley, and
  Clune]{ecoffet2019go}
Ecoffet, A., Huizinga, J., Lehman, J., Stanley, K.~O., and Clune, J.
\newblock Go-explore: a new approach for hard-exploration problems.
\newblock \emph{arXiv preprint arXiv:1901.10995}, 2019.

\bibitem[Edwards et~al.(2019)Edwards, Sahni, Schroecker, and
  Isbell]{edwards2019imitating}
Edwards, A., Sahni, H., Schroecker, Y., and Isbell, C.
\newblock Imitating latent policies from observation.
\newblock In \emph{International conference on machine learning}, pp.\
  1755--1763. PMLR, 2019.

\bibitem[Fu et~al.(2019)Fu, Korattikara, Levine, and
  Guadarrama]{fu2019language}
Fu, J., Korattikara, A., Levine, S., and Guadarrama, S.
\newblock From language to goals: Inverse reinforcement learning for
  vision-based instruction following.
\newblock \emph{arXiv preprint arXiv:1902.07742}, 2019.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{fu2020d4rl}
Fu, J., Kumar, A., Nachum, O., Tucker, G., and Levine, S.
\newblock D4rl: Datasets for deep data-driven reinforcement learning, 2020.

\bibitem[Ghosh et~al.(2019)Ghosh, Gupta, Reddy, Fu, Devin, Eysenbach, and
  Levine]{ghosh2019learning}
Ghosh, D., Gupta, A., Reddy, A., Fu, J., Devin, C., Eysenbach, B., and Levine,
  S.
\newblock Learning to reach goals via iterated supervised learning.
\newblock \emph{arXiv preprint arXiv:1912.06088}, 2019.

\bibitem[Hausknecht \& Wagener(2022)Hausknecht and
  Wagener]{hausknecht2022consistent}
Hausknecht, M. and Wagener, N.
\newblock Consistent dropout for policy gradient reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2202.11818}, 2022.

\bibitem[Hazan et~al.(2019)Hazan, Kakade, Singh, and
  Van~Soest]{hazan2019provably}
Hazan, E., Kakade, S., Singh, K., and Van~Soest, A.
\newblock Provably efficient maximum entropy exploration.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2681--2691. PMLR, 2019.

\bibitem[Ho \& Ermon(2016)Ho and Ermon]{ho2016generative}
Ho, J. and Ermon, S.
\newblock Generative adversarial imitation learning.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Hong et~al.(2020)Hong, Fu, Shann, and Lee]{hong2020adversarial}
Hong, Z.-W., Fu, T.-J., Shann, T.-Y., and Lee, C.-Y.
\newblock Adversarial active exploration for inverse dynamics model learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  552--565. PMLR, 2020.

\bibitem[Horn \& Johnson(2012)Horn and Johnson]{matrixanalysisbook}
Horn, R.~A. and Johnson, C.~R.
\newblock \emph{Matrix analysis}.
\newblock Cambridge university press, 2012.

\bibitem[Hunter(2007)]{Hunter:2007}
Hunter, J.~D.
\newblock Matplotlib: A 2d graphics environment.
\newblock \emph{Computing in Science \& Engineering}, 9\penalty0 (3):\penalty0
  90--95, 2007.
\newblock \doi{10.1109/MCSE.2007.55}.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kostrikov(2018)]{pytorchrl}
Kostrikov, I.
\newblock Pytorch implementations of reinforcement learning algorithms.
\newblock \url{https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail}, 2018.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Meier et~al.(2016)Meier, Kappler, Ratliff, and
  Schaal]{meier2016towards}
Meier, F., Kappler, D., Ratliff, N., and Schaal, S.
\newblock Towards robust online inverse dynamics learning.
\newblock In \emph{2016 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pp.\  4034--4039. IEEE, 2016.

\bibitem[Mendonca et~al.(2021)Mendonca, Rybkin, Daniilidis, Hafner, and
  Pathak]{mendonca2021discovering}
Mendonca, R., Rybkin, O., Daniilidis, K., Hafner, D., and Pathak, D.
\newblock Discovering and achieving goals via world models.
\newblock \emph{arXiv preprint arXiv:2110.09514}, 2021.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Nair et~al.(2008)Nair, Susskind, and Hinton]{nair2008analysis}
Nair, V., Susskind, J., and Hinton, G.~E.
\newblock Analysis-by-synthesis by learning to invert generative black boxes.
\newblock In \emph{International conference on artificial neural networks},
  pp.\  971--981. Springer, 2008.

\bibitem[Nguyen-Tuong \& Peters(2010)Nguyen-Tuong and Peters]{nguyen2010using}
Nguyen-Tuong, D. and Peters, J.
\newblock Using model knowledge for learning inverse dynamics.
\newblock In \emph{2010 IEEE international conference on robotics and
  automation}, pp.\  2677--2682. IEEE, 2010.

\bibitem[Ortega \& Rheinboldt(2000)Ortega and Rheinboldt]{ortega2000iterative}
Ortega, J.~M. and Rheinboldt, W.~C.
\newblock \emph{Iterative Solution of Nonlinear Equations in Several
  Variables}.
\newblock Society for Industrial and Applied Mathematics, 2000.
\newblock \doi{10.1137/1.9780898719468}.

\bibitem[Parisotto et~al.(2020)Parisotto, Song, Rae, Pascanu, Gulcehre,
  Jayakumar, Jaderberg, Kaufman, Clark, Noury,
  et~al.]{parisotto2020stabilizing}
Parisotto, E., Song, F., Rae, J., Pascanu, R., Gulcehre, C., Jayakumar, S.,
  Jaderberg, M., Kaufman, R.~L., Clark, A., Noury, S., et~al.
\newblock Stabilizing transformers for reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  7487--7498. PMLR, 2020.

\bibitem[Pathak et~al.(2018)Pathak, Mahmoudieh, Luo, Agrawal, Chen, Shentu,
  Shelhamer, Malik, Efros, and Darrell]{pathak2018zero}
Pathak, D., Mahmoudieh, P., Luo, G., Agrawal, P., Chen, D., Shentu, Y.,
  Shelhamer, E., Malik, J., Efros, A.~A., and Darrell, T.
\newblock Zero-shot visual imitation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition workshops}, pp.\  2050--2053, 2018.

\bibitem[Peng et~al.(2022)Peng, Guo, Halper, Levine, and Fidler]{peng2022ase}
Peng, X.~B., Guo, Y., Halper, L., Levine, S., and Fidler, S.
\newblock Ase: Large-scale reusable adversarial skill embeddings for physically
  simulated characters.
\newblock \emph{ACM Trans. Graph.}, 41\penalty0 (4), July 2022.

\bibitem[Pomerleau(1988)]{pomerleau1988alvinn}
Pomerleau, D.~A.
\newblock Alvinn: An autonomous land vehicle in a neural network.
\newblock \emph{Advances in neural information processing systems}, 1, 1988.

\bibitem[Rombach et~al.(2021)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2021highresolution}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models, 2021.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{ross2011reduction}
Ross, S., Gordon, G., and Bagnell, D.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pp.\  627--635. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Seber(2003)]{linearregbook2003}
Seber, G. A. F. G. A.~F.
\newblock \emph{Linear regression analysis George A.F. Seber, Alan J. Lee.}
\newblock Wiley series in probability and statistics. Wiley-Interscience,
  Hoboken, N.J, 2nd ed. edition, 2003.
\newblock ISBN 1-280-58916-7.

\bibitem[Sekar et~al.(2020)Sekar, Rybkin, Daniilidis, Abbeel, Hafner, and
  Pathak]{sekar2020planning}
Sekar, R., Rybkin, O., Daniilidis, K., Abbeel, P., Hafner, D., and Pathak, D.
\newblock Planning to explore via self-supervised world models.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8583--8592. PMLR, 2020.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Torabi et~al.(2018)Torabi, Warnell, and Stone]{torabi2018generative}
Torabi, F., Warnell, G., and Stone, P.
\newblock Generative adversarial imitation from observation.
\newblock \emph{arXiv preprint arXiv:1807.06158}, 2018.

\bibitem[Van Den~Oord et~al.(2017)Van Den~Oord, Vinyals, et~al.]{van2017neural}
Van Den~Oord, A., Vinyals, O., et~al.
\newblock Neural discrete representation learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Yan et~al.(2021)Yan, Zhang, Abbeel, and Srinivas]{yan2021videogpt}
Yan, W., Zhang, Y., Abbeel, P., and Srinivas, A.
\newblock Videogpt: Video generation using vq-vae and transformers, 2021.

\end{thebibliography}
