\vspace{-.5em}
\section{Conclusion}
\vspace{-.5em}
In this paper, we aim to answer the question of how to efficiently learn and utilize a reward function for training the E2E ToD agents. 
We answer this question by introducing two generalized reward-learning objectives, and utilize a stable policy-gradient method to guide the training of the E2E ToD agents. 
%With the proposed techniques, we can achieve competitive results on the E2E dialogue task on the Multiwoz 2.0 dataset. 
Future work includes extending our reward-learning objectives to other applications, such as the question-answering with verification. 
