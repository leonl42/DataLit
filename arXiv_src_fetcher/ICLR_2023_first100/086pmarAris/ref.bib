@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {{Large Scale Kernel Machines}},
publisher = {MIT Press},
title = {{Scaling Learning Algorithms Towards {AI}}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {{A Fast Learning Algorithm for Deep Belief Nets}},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={{Deep learning}},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}
@inproceedings{wu2019transferable,
  title={Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems},
  author={Wu, Chien-Sheng and Madotto, Andrea and Hosseini-Asl, Ehsan and Xiong, Caiming and Socher, Richard and Fung, Pascale},
  booktitle={ACL},
  pages={808--819},
  year={2019}
}
@inproceedings{casanueva2020efficient,
  title={Efficient Intent Detection with Dual Sentence Encoders},
  author={Casanueva, I{\~n}igo and Tem{\v{c}}inas, Tadas and Gerz, Daniela and Henderson, Matthew and Vuli{\'c}, Ivan},
  booktitle={Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI},
  pages={38--45},
  year={2020}
}
@article{yang2020off,
  title={Off-policy evaluation via the regularized lagrangian},
  author={Yang, Mengjiao and Nachum, Ofir and Dai, Bo and Li, Lihong and Schuurmans, Dale},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6551--6561},
  year={2020}
}

@article{kallus2020double,
  title={Double Reinforcement Learning for Efficient Off-Policy Evaluation in Markov Decision Processes.},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={167},
  pages={1--63},
  year={2020}
}


@inproceedings{li11unbiased,
  author	= {Lihong Li and Wei Chu and John Langford and Xuanhui Wang},
  title		= {Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms},
  booktitle	= {Proceedings of the 4th International Conference on Web Search and Data Mining (WSDM)},
  year		= {2011},
  pages		= {297--306}
}


@article{fu2021d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}






@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{dabney2018distributional,
  title={{Distributional reinforcement learning with quantile regression}},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{wu2019switch,
  title={Switch-based active deep dyna-q: Efficient adaptive planning for task-completion dialogue policy learning},
  author={Wu, Yuexin and Li, Xiujun and Liu, Jingjing and Gao, Jianfeng and Yang, Yiming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={7289--7296},
  year={2019}
}

@article{fan2020bayesian,
  title={Bayesian attention modules},
  author={Fan, Xinjie and Zhang, Shujian and Chen, Bo and Zhou, Mingyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16362--16376},
  year={2020}
}

@inproceedings{idac2020,
  author    = {Yuguang Yue and
               Zhendong Wang and
               Mingyuan Zhou},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {{Implicit Distributional Reinforcement Learning}},
  booktitle = {{Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual}},
  year      = {2020},
  timestamp = {Tue, 19 Jan 2021 15:57:35 +0100},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{villani2008optimal,
  title={{Optimal Transport: Old and New}},
  author={Villani, C{\'e}dric},
  volume={338},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@inproceedings{fujimoto2018addressing,
  title={{Addressing Function Approximation Error in Actor-Critic Methods}},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={{International Conference on Machine Learning}},
  pages={1587--1596},
  year={2018}
}

@InProceedings{bcq2019, 
title = {{Off-Policy Deep Reinforcement Learning without Exploration}}, 
author = {Fujimoto, Scott and Meger, David and Precup, Doina}, 
booktitle = {{Proceedings of the 36th International Conference on Machine Learning}}, 
pages = {2052--2062}, 
year = {2019}, 
editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, 
volume = {97}, 
series = {Proceedings of Machine Learning Research}, 
month = {09--15 Jun}, 
publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/fujimoto19a/fujimoto19a.pdf}, 
}

@inproceedings{bear2019,
 author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
 booktitle = {{Advances in Neural Information Processing Systems}},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction}},
 volume = {32},
 year = {2019}
}


@InProceedings{td32018,
  title = 	 {{Addressing Function Approximation Error in Actor-Critic Methods}},
  author =       {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {{Proceedings of the 35th International Conference on Machine Learning}},
  pages = 	 {1587--1596},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf},
}

@article{offlinetutorial2020,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{cql2020,
 author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
 booktitle = {{Advances in Neural Information Processing Systems}},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {1179--1191},
 publisher = {Curran Associates, Inc.},
 title = {{Conservative Q-Learning for Offline Reinforcement Learning}},
 volume = {33},
 year = {2020}
}


@InProceedings{sac2018,
  title = 	 {{Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic {Actor}}},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {{Proceedings of the 35th International Conference on Machine Learning}},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf},
}

@inproceedings{qrdqn2017,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, R{\'e}mi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@book{rlintro2018,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}


@InProceedings{iqn2018,
  title = 	 {{Implicit Quantile Networks for Distributional Reinforcement Learning}},
  author =       {Dabney, Will and Ostrovski, Georg and Silver, David and Munos, Remi},
  booktitle = 	 {{Proceedings of the 35th International Conference on Machine Learning}},
  pages = 	 {1096--1105},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/dabney18a/dabney18a.pdf},
}

@inproceedings{jiang16doubly,
  author	= {Nan Jiang and Lihong Li},
  title		= {Doubly Robust Off-policy Evaluation for Reinforcement Learning},
  booktitle	= {Proceedings of the 23rd International Conference on Machine Learning },
  year		= {2016},
  pages		= {652--661}
}



@inproceedings{
zhang2020gendice,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Zhang, Ruiyi and Dai, Bo and Li, Lihong and Schuurmans, Dale},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{dqn2015,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {{Human-level control through deep reinforcement learning}},
  volume = 518,
  year = 2015
}


@article{liao2020batch,
  title={Batch policy learning in average reward markov decision processes},
  author={Liao, Peng and Qi, Zhengling and Klasnja, Predrag and Murphy, Susan},
  journal={arXiv preprint arXiv:2007.11771},
  year={2020}
}


@article{dqn2013,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}


@inproceedings{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{alphago2016,
  added-at = {2016-03-11T14:36:05.000+0100},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  doi = {10.1038/nature16961},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  journal = {Nature},
  keywords = {baduk go google},
  month = jan,
  number = 7587,
  pages = {484--489},
  publisher = {Nature Publishing Group},
  timestamp = {2016-03-11T14:37:40.000+0100},
  title = {{Mastering the Game of {Go} with Deep Neural Networks and Tree Search}},
  volume = 529,
  year = 2016
}


@article{huber1964huber,
author = {Peter J. Huber},
title = {{Robust Estimation of a Location Parameter}},
volume = {35},
journal = {The Annals of Mathematical Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {73 -- 101},
year = {1964},
}


@article{alphazero2017,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy P. and Simonyan, Karen and Hassabis, Demis},
  ee = {http://arxiv.org/abs/1712.01815},
  interhash = {892ea10be9037d2047238ef1630126c0},
  intrahash = {4176099ce3f99a7afc8db13526eb823e},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T13:53:40.000+0200},
  title = {{Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm.}},
  volume = {abs/1712.01815},
  year = 2017
}


@inproceedings{uehara2020minimax,
  title={Minimax weight and q-function learning for off-policy evaluation},
  author={Uehara, Masatoshi and Huang, Jiawei and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={9659--9668},
  year={2020},
  organization={PMLR}
}

@inproceedings{qtopt,
  added-at = {2019-04-03T00:00:00.000+0200},
  author = {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and Levine, Sergey},
  booktitle = {{CoRL}},
  ee = {http://proceedings.mlr.press/v87/kalashnikov18a.html},
  interhash = {1eb54be5f5e8a112b2fc3e4b0d94c2fa},
  intrahash = {594a68c8247227c100444ed51856c32f},
  keywords = {dblp},
  pages = {651-673},
  publisher = {PMLR},
  series = {Proceedings of Machine Learning Research},
  timestamp = {2019-04-04T11:46:55.000+0200},
  title = {{Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation.}},
  volume = 87,
  year = 2018
}

@article{deepLoco2017,
	author = {Peng, Xue Bin and Berseth, Glen and Yin, Kangkang and Van De Panne, Michiel},
	title = {{DeepLoco: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning}},
	journal = {ACM Trans. Graph.},
	issue_date = {July 2017},
	volume = {36},
	number = {4},
	month = jul,
	year = {2017},
	issn = {0730-0301},
	pages = {41:1--41:13},
	articleno = {41},
	numpages = {13},
	doi = {10.1145/3072959.3073602},
	acmid = {3073602},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {locomotion skills, motion control, physics-based character animation},
} 

@Inbook{batchrl2012,
author="Lange, Sascha
and Gabel, Thomas
and Riedmiller, Martin",
title={{Batch Reinforcement Learning}},
bookTitle={{Reinforcement Learning: State-of-the-Art}},
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="45--73",
isbn="978-3-642-27645-3",
doi="10.1007/978-3-642-27645-3_2",
}


@article{treerl2005,
  added-at = {2019-07-10T00:00:00.000+0200},
  author = {Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  ee = {http://jmlr.org/papers/v6/ernst05a.html},
  interhash = {38745243dd2ef20db53b5df558a54ecc},
  intrahash = {37a14e0dae9e8207402185059403fa15},
  journal = {{J. Mach. Learn. Res.}},
  keywords = {dblp},
  pages = {503-556},
  timestamp = {2019-07-11T11:42:24.000+0200},
  title = {{Tree-Based Batch Mode Reinforcement Learning.}},
  volume = 6,
  year = 2005
}

@inproceedings{rem2020,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

@article{abm2020,
  title={Keep doing what worked: Behavioral modelling priors for offline reinforcement learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}


@article{brac2019,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{crr2020,
 author = {Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and de Freitas, Nando},
 booktitle = {{Advances in Neural Information Processing Systems}},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {7768--7778},
 publisher = {Curran Associates, Inc.},
 title = {{Critic Regularized Regression}},
 volume = {33},
 year = {2020}
}

@article{drl1973,
author = {Stratton C. Jaquette},
title = {{Markov Decision Processes with a New Optimality Criterion: Discrete Time}},
volume = {1},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {496 -- 505},
year = {1973},
doi = {10.1214/aos/1176342415},
}

@article{drl1982,
 ISSN = {00219002},
 abstract = {Formulae are presented for the variance and higher moments of the present value of single-stage rewards in a finite Markov decision process. Similar formulae are exhibited for a semi-Markov decision process. There is a short discussion of the obstacles to using the variance formula in algorithms to maximize the mean minus a multiple of the standard deviation.},
 author = {Matthew J. Sobel},
 journal = {Journal of Applied Probability},
 number = {4},
 pages = {794--802},
 publisher = {Applied Probability Trust},
 title = {{The Variance of Discounted Markov Decision Processes}},
 volume = {19},
 year = {1982}
}

@article{drl1988,
  title={{Mean, variance, and probabilistic criteria in finite Markov decision processes: A review}},
  author={D. J. White},
  journal={Journal of Optimization Theory and Applications},
  year={1988},
  volume={56},
  pages={1-29}
}

@inproceedings{drl2010,
  title={{Nonparametric Return Distribution Approximation for Reinforcement Learning}},
  author={T. Morimura and Masashi Sugiyama and H. Kashima and H. Hachiya and Toshiyuki TANAKA},
  booktitle={{International Conference on Machine Learning}},
  year={2010}
}

@inproceedings{c512017,
  title={{A Distributional Perspective on Reinforcement Learning}},
  author={Marc G. Bellemare and Will Dabney and R. Munos},
  booktitle={{International Conference on Machine Learning}},
  year={2017}
}

@article{atari2012,
  added-at = {2019-12-30T13:47:50.000+0100},
  author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  doi = {10.1613/jair.3912},
  interhash = {ad133244b4e33eda52c994d9b6174f27},
  intrahash = {0ab3dc05ba807da8085ca30679390cde},
  journal = {Journal of Artificial Intelligence Research},
  keywords = {ALE Atari DRLAlgoComparison ReinforcementLearning reinforcement},
  note = {cite arxiv:1207.4708},
  pages = {253-279},
  timestamp = {2019-12-30T13:55:38.000+0100},
  title = {{The Arcade Learning Environment: An Evaluation Platform for General
  Agents}},
  volume = {Vol. 47},
  year = 2012
}

@inproceedings{d4pg2018,
  added-at = {2019-07-25T00:00:00.000+0200},
  author = {Barth-Maron, Gabriel and Hoffman, Matthew W. and Budden, David and Dabney, Will and Horgan, Dan and TB, Dhruva and Muldal, Alistair and Heess, Nicolas and Lillicrap, Timothy P.},
  booktitle = {{International Conference on Learning Representations}},
  ee = {https://openreview.net/forum?id=SyZipzbCb},
  interhash = {3fb1ced1b733a5b2383d0db65fafb94a},
  intrahash = {581aab50fbb3db484434b62d28ece4a9},
  keywords = {dblp},
  publisher = {OpenReview.net},
  timestamp = {2019-07-26T11:43:51.000+0200},
  title = {{Distributed Distributional Deterministic Policy Gradients.}},
  year = 2018
}

@article{sdpg2020,
      title={{Sample-based Distributional Policy Gradient}}, 
      author={Rahul Singh and Keuntaek Lee and Yongxin Chen},
      year={2020},
      eprint={2001.02652},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{bellemare2017distributional,
  title={{A distributional perspective on reinforcement learning}},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={{International Conference on Machine Learning}},
  pages={449--458},
  year={2017},
  organization={PMLR}
}

@inproceedings{s4rl2021,
  title={S4RL: Surprisingly simple self-supervision for offline reinforcement learning in robotics},
  author={Sinha, Samarth and Mandlekar, Ajay and Garg, Animesh},
  booktitle={Conference on Robot Learning},
  pages={907--917},
  year={2022},
  organization={PMLR}
}

@inproceedings{adam2014,
  added-at = {2021-04-28T08:17:30.000+0200},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  description = {Adam: A Method for Stochastic Optimization - 1412.6980.pdf},
  interhash = {57d2ac873f398f21bb94790081e80394},
  intrahash = {d53bcfff0fe1a1d3a4a171352ee6e92c},
  keywords = {adabelief adam optimizer sgd},
  booktitle={{International Conference on Learning Representations}},
  timestamp = {2021-04-28T08:17:30.000+0200},
  title = {{Adam: A Method for Stochastic Optimization}},
  year = 2014
}

@article{vae2013,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{betavae2017,
  title={{beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework}},
  author={I. Higgins and Lo{\"i}c Matthey and A. Pal and Christopher P. Burgess and Xavier Glorot and M. Botvinick and S. Mohamed and Alexander Lerchner},
  booktitle={{International Conference on Learning Representations}},
  year={2017}
}

@inproceedings{gail2016,
 author = {Ho, Jonathan and Ermon, Stefano},
 booktitle = {{Advances in Neural Information Processing Systems}},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{Generative Adversarial Imitation Learning}},
 volume = {29},
 year = {2016}
}

@article{deeppagerank2004,
   added-at = {2009-12-09T11:38:18.000+0100},
  author = {Langville, Amy N. and Meyer, Carl D.},
  interhash = {ee90e6dabf6645028ff3905a6fea3356},
  intrahash = {6f7e377aad77931106f38284f107de8d},
  issn = {1542-7951},
  journal = {Internet Mathematics},
  keywords = {ranking search survey web pagerank},
  number = 3,
  pages = {335--380},
  timestamp = {2014-07-28T15:57:31.000+0200},
  title = {{Deeper inside {P}age{R}ank}},
  volume = 1,
  year = 2004
}

@inproceedings{pagerank1998,
  added-at = {2008-01-09T21:02:24.000+0100},
  address = {Brisbane, Australia},
  author = {Page, L. and Brin, S. and Motwani, R. and Winograd, T.},
  booktitle = {{Proceedings of the 7th International World Wide Web Conference}},
  interhash = {ca10cf0b0dd668c64b1f378ff0775849},
  intrahash = {ac49c33e114ca171db40cece6a0ae4d6},
  keywords = {2007 kde pagerank seminar web},
  pages = {161--172},
  timestamp = {2008-01-09T21:02:24.000+0100},
  title = {{The PageRank Citation Ranking: Bringing order to the Web}},
  year = 1998
}

@book{matrixanalysis2000,
author = {Meyer, Carl D.},
title = {{Matrix Analysis and Applied Linear Algebra}},
year = {2000},
isbn = {0898714540},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA}
}

@article{confoundingrobust2020,
  title={{Confounding-robust policy evaluation in infinite-horizon reinforcement learning}},
  author={Kallus, Nathan and Zhou, Angela},
  journal={{Advances in Neural Information Processing Systems}},
  volume={33},
  pages={22293--22304},
  year={2020}
}

@article{harris2011,
 ISSN = {00911798},
 abstract = {This is a brief survey of T. E. Harris's work on recurrent Markov processes and on stochastic flows, and of some more recent work in these fields.},
 author = {Peter Baxendale},
 journal = {The Annals of Probability},
 number = {2},
 pages = {417--428},
 publisher = {Institute of Mathematical Statistics},
 title = {{T. E. Harris's Contributions to Recurrent Markov Processes and Stochastic Flows}},
 volume = {39},
 year = {2011}
}

@article{blackope2020,
  title={{Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning}},
  author={A. Mousavi and Lihong Li and Qiang Liu and Denny Zhou},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.11126}
}

@article{gendice2020,
  title={{GenDICE: Generalized Offline Estimation of Stationary Values}},
  author={Ruiyi Zhang and Bo Dai and Lihong Li and D. Schuurmans},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.09072}
}

@article{algaedice2019,
  title={{AlgaeDICE: Policy Gradient from Arbitrary Experience}},
  author={Ofir Nachum and Bo Dai and Ilya Kostrikov and Yinlam Chow and Lihong Li and D. Schuurmans},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.02074}
}

@article{optidice2021,
  title={{OptiDICE: Offline Policy Optimization via Stationary Distribution Correction Estimation}},
  author={Jongmin Lee and Wonseok Jeon and Byung-Jun Lee and J. Pineau and Kee-Eung Kim},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.10783}
}

@inproceedings{breakingcurse2018,
  title={{Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation}},
  author={Q. Liu and Lihong Li and Ziyang Tang and Dengyong Zhou},
  booktitle={{Advances in neural information processing systems}},
  year={2018}
}

@inproceedings{diagbottleneck2019,
  title={{Diagnosing Bottlenecks in Deep Q-learning Algorithms}},
  author={Justin Fu and Aviral Kumar and Matthew Soh and Sergey Levine},
  booktitle={{International Conference on Machine Learning}},
  year={2019}
}

@article{offpolicyac2012,
  title={{Off-Policy Actor-Critic}},
  author={T. Degris and Martha White and R. Sutton},
  journal={ArXiv},
  year={2012},
  volume={abs/1205.4839}
}

@inproceedings{dpg2014,
  title={{Deterministic Policy Gradient Algorithms}},
  author={D. Silver and Guy Lever and N. Heess and T. Degris and Daan Wierstra and Martin A. Riedmiller},
  booktitle={{International Conference on Machine Learning}},
  year={2014}
}

@article{trpo2015,
  title={{Trust Region Policy Optimization}},
  author={J. Schulman and Sergey Levine and P. Abbeel and Michael I. Jordan and Philipp Moritz},
  journal={ArXiv},
  year={2015},
  volume={abs/1502.05477}
}

@article{ddpg2016,
  title={{Continuous Control with Deep Reinforcement Learning}},
  author={T. Lillicrap and Jonathan J. Hunt and A. Pritzel and N. Heess and T. Erez and Yuval Tassa and D. Silver and Daan Wierstra},
  journal={CoRR},
  year={2016},
  volume={abs/1509.02971}
}

@inproceedings{gan2014,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {{Advances in Neural Information Processing Systems}},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{Generative Adversarial Nets}},
 volume = {27},
 year = {2014}
}

@article{rlhealth2018,
  title={{Evaluating Reinforcement Learning Algorithms in Observational Health Settings}},
  author={Omer Gottesman and Fredrik D. Johansson and J. Meier and Jack Dent and Donghun Lee and Srivatsan Srinivasan and Linying Zhang and Yi Ding and David Wihl and Xuefeng Peng and Jiayu Yao and Isaac Lage and C. Mosch and Li-wei H. Lehman and M. Komorowski and A. Faisal and L. Celi and D. Sontag and Finale Doshi-Velez},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.12298}
}

@article{whentotreat2019,
  title={{Learning When-to-Treat Policies}},
  author={Xinkun Nie and Emma Brunskill and Stefan Wager},
  journal={Journal of the American Statistical Association},
  year={2019},
  volume={116},
  pages={392 - 409}
}

@article{rllungcancer2017,
  title={{Deep Reinforcement Learning for Automated Radiation Adaptation in Lung Cancer}},
  author={H. Tseng and Yi Luo and Sunan Cui and Jen-Tzung Chien and R. Ten Haken and I. Naqa},
  journal={Medical Physics},
  year={2017},
  volume={44},
  pages={6690?6705}
}

@article{autodrivesurvey2020,
  title={{A Survey of Autonomous Driving: Common Practices and Emerging Technologies}},
  author={Ekim Yurtsever and Jacob Lambert and Alexander Carballo and K. Takeda},
  journal={IEEE Access},
  year={2020},
  volume={8},
  pages={58443-58469}
}

@inproceedings{operecom2017,
  title={{Off-policy Evaluation for Slate Recommendation}},
  author={Adith Swaminathan and A. Krishnamurthy and Alekh Agarwal and Miroslav Dud{\'i}k and J. Langford and D. Jose and I. Zitouni},
  booktitle={{Advances in neural information processing systems}},
  year={2017}
}

@article{offlineabtest2018,
  title={{Offline A/B Testing for Recommender Systems}},
  author={Alexandre Gilotte and Cl{\'e}ment Calauz{\`e}nes and Thomas Nedelec and Alexandre Abraham and Simon Doll{\'e}},
  journal={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  year={2018}
}

@inproceedings{uwac2021,
  title={{Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning}},
  author={Yue Wu and Shuangfei Zhai and Nitish Srivastava and J. Susskind and Jian Zhang and R. Salakhutdinov and Hanlin Goh},
  booktitle={{International Conference on Machine Learning}},
  year={2021}
}

@inproceedings{cvae2015,
  title={{Learning Structured Output Representation using Deep Conditional Generative Models}},
  author={Kihyuk Sohn and Honglak Lee and Xinchen Yan},
  booktitle={{Advances in neural information processing systems}},
  year={2015}
}

@article{mabe2021,
  title={{Behavioral Priors and Dynamics Models: Improving Performance and Domain Transfer in Offline RL}},
  author={Catherine Cang and Aravind Rajeswaran and P. Abbeel and M. Laskin},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.09119}
}

@inproceedings{sibb2019,
  title={{Safe Policy Improvement with Baseline Bootstrapping}},
  author={Romain Laroche and P. Trichelair},
  booktitle={{International Conference on Machine Learning}},
  year={2019}
}

@article{offlinerldialog2019,
  title={{Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog}},
  author={Natasha Jaques and Asma Ghandeharioun and Judy Hanwen Shen and Craig Ferguson and {\`A}. Lapedriza and Noah J. Jones and S. Gu and Rosalind W. Picard},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.00456}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7768--7778},
  year={2020}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{chen2017survey,
  title={A survey on dialogue systems: Recent advances and new frontiers},
  author={Chen, Hongshen and Liu, Xiaorui and Yin, Dawei and Tang, Jiliang},
  journal={Acm Sigkdd Explorations Newsletter},
  volume={19},
  number={2},
  pages={25--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{georgila2011reinforcement,
  title={Reinforcement learning of argumentation dialogue policies in negotiation},
  author={Georgila, Kallirroi and Traum, David},
  booktitle={Twelfth Annual Conference of the International Speech Communication Association},
  year={2011}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{oraac2021,
  title={{Risk-Averse Offline Reinforcement Learning}},
  author={N\'uria Armengol Urp\'i and S. Curi and A. Krause},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.05371}
}

@article{Chen2019InformationTheoreticCI,
  title={{Information-Theoretic Considerations in Batch Reinforcement Learning}},
  author={Jinglin Chen and Nan Jiang},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.00360}
}

@article{Sutton2005ReinforcementLA,
  title={{Reinforcement Learning: An Introduction}},
  author={R. Sutton and A. Barto},
  journal={IEEE Transactions on Neural Networks},
  year={2005},
  volume={16},
  pages={285-286}
}

@inproceedings{acbias2014,
  title={{Bias in Natural Actor-Critic Algorithms}},
  author={P. Thomas},
  booktitle={{International Conference on Machine Learning}},
  year={2014}
}

@article{combo2021,
  title={{COMBO: Conservative Offline Model-Based Policy Optimization}},
  author={Tianhe Yu and Aviral Kumar and Rafael Rafailov and Aravind Rajeswaran and Sergey Levine and Chelsea Finn},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.08363}
}

@article{morel2020,
  title={{MOReL : Model-Based Offline Reinforcement Learning}},
  author={Rahul Kidambi and Aravind Rajeswaran and Praneeth Netrapalli and T. Joachims},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.05951}
}

@article{jsd1991,
    author = {Jianhua Lin},
    title = {{Divergence Measures Based on the Shannon Entropy}},
    journal = {IEEE Transactions on Information theory},
    year = {1991},
    volume = {37},
    pages = {145--151}
}

@inproceedings{doubleq2010,
  title={{Double Q-learning}},
  author={H. V. Hasselt},
  booktitle={{Advances in neural information processing systems}},
  year={2010}
}

@article{cgan2014,
  title={{Conditional Generative Adversarial Nets}},
  author={Mehdi Mirza and Simon Osindero},
  journal={ArXiv},
  year={2014},
  volume={abs/1411.1784}
}

@book{nonparamstat2006,
title={{All of Nonparametric Statistics}},
author={Wasserman, Larry},
year={2006},
publisher={Springer}
}

@article{adroit2018,
  title={{Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}},
  author={Aravind Rajeswaran and Vikash Kumar and Abhishek Gupta and J. Schulman and E. Todorov and Sergey Levine},
  journal={ArXiv},
  year={2018},
  volume={abs/1709.10087}
}

@article{dcgan2016,
  title={{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
  author={Alec Radford and Luke Metz and Soumith Chintala},
  journal={CoRR},
  year={2016},
  volume={abs/1511.06434}
}

@inproceedings{improvetechgan2016,
  title={{Improved Techniques for Training GANs}},
  author={Tim Salimans and I. Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen},
  booktitle={{Advances in neural information processing systems}},
  year={2016}
}

@article{gantutorial2017,
  title={Nips 2016 tutorial: Generative adversarial networks},
  author={Goodfellow, Ian},
  journal={arXiv preprint arXiv:1701.00160},
  year={2016}
}

@article{samplegenerative2016,
  title={Sampling generative networks},
  author={White, Tom},
  journal={arXiv preprint arXiv:1609.04468},
  year={2016}
}

@article{decisiontrans2021,
  title={{Decision Transformer: Reinforcement Learning via Sequence Modeling}},
  author={Lili Chen and Kevin Lu and Aravind Rajeswaran and Kimin Lee and Aditya Grover and M. Laskin and P. Abbeel and A. Srinivas and Igor Mordatch},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.01345}
}

@article{addressingextra2021,
title={{Addressing Extrapolation Error in Deep Offline Reinforcement Learning}},
author={Caglar Gulcehre and Sergio G{\'o}mez Colmenarejo and ziyu wang and Jakub Sygnowski and Thomas Paine and Konrad Zolna and Yutian Chen and Matthew Hoffman and Razvan Pascanu and Nando de Freitas},
year={2021}
}

@article{spectralnorm2018,
  title={{Spectral Normalization for Generative Adversarial Networks}},
  author={Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.05957}
}

@article{sinkhorn2013,
  title={{Sinkhorn Distances: Lightspeed Computation of Optimal Transportation Distances}},
  author={Marco Cuturi},
  journal={arXiv: Machine Learning},
  year={2013}
}

@inproceedings{sinkhorndiv2019,
    title={{Interpolating between Optimal Transport and MMD using Sinkhorn Divergences}},
    author={Feydy, Jean and S{\'e}journ{\'e}, Thibault and Vialard, Fran{\c{c}}ois-Xavier and Amari, Shun-ichi and Trouve, Alain and Peyr{\'e}, Gabriel},
    booktitle={{The 22nd International Conference on Artificial Intelligence and Statistics}},
    pages={2681--2690},
    year={2019}
}

@inproceedings{wgangp2017,
  title={{Improved Training of Wasserstein GANs}},
  author={Ishaan Gulrajani and Faruk Ahmed and Mart{\'i}n Arjovsky and Vincent Dumoulin and Aaron C. Courville},
  booktitle={{Advances in neural information processing systems}},
  year={2017}
}

@article{wgan2017,
  title={{Wasserstein GAN}},
  author={Mart{\'i}n Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  journal={ArXiv},
  year={2017},
  volume={abs/1701.07875}
}

@article{mmdgangp2018,
  title={{Demystifying MMD GANs}},
  author={Mikolaj Binkowski and Danica J. Sutherland and Michael Arbel and A. Gretton},
  journal={ArXiv},
  year={2018},
  volume={abs/1801.01401}
}

@inproceedings{mmdganweightclip2017,
  title={{MMD GAN: Towards Deeper Understanding of Moment Matching Network}},
  author={Chun-Liang Li and Wei-Cheng Chang and Yu Cheng and Yiming Yang and B. P{\'o}czos},
  booktitle={{Advances in neural information processing systems}},
  year={2017}
}

@article{cramerdist2017,
  title={{The Cramer Distance as a Solution to Biased Wasserstein Gradients}},
  author={Marc G. Bellemare and Ivo Danihelka and Will Dabney and S. Mohamed and Balaji Lakshminarayanan and Stephan Hoyer and R. Munos},
  journal={ArXiv},
  year={2017},
  volume={abs/1705.10743}
}

@article{kerneltwosampletest2012,
  title={{A Kernel Two-Sample Test}},
  author={A. Gretton and K. Borgwardt and M. Rasch and B. Sch{\"o}lkopf and Alex Smola},
  journal={J. Mach. Learn. Res.},
  year={2012},
  volume={13},
  pages={723-773}
}

@article{computationalot2019,
  title={{Computational Optimal Transport}},
  author={G. Peyr{\'e} and Marco Cuturi},
  journal={Found. Trends Mach. Learn.},
  year={2019},
  volume={11},
  pages={355-607}
}

@article{act2021,
  title={{Exploiting Chain Rule and Bayes' Theorem to Compare Probability Distributions}},
  author={Zheng, Huangjie and Zhou, Mingyuan},
  journal={{Advances in Neural Information Processing Systems}},
  volume={34},
  year={2021}
}

@article{otschrodinger1933,
  title={{Sur la th{\'e}orie relativiste de l'{\'e}lectron et l'interpr{\'e}tation de la m{\'e}canique quantique}},
  author={Erwin Schr{\"o}dinger},
  journal={Annales de l'institut Henri Poincar{\'e}},
  volume={2},
  pages={269–310},
  year={1932}
}

@article{ipm1997,
  title={{Integral Probability Metrics and Their Generating Classes of Functions}},
  author={A. M{\"u}ller},
  journal={Advances in Applied Probability},
  year={1997},
  volume={29},
  pages={429-443}
}

@article{energydistmmd2013,
 ISSN = {00905364, 21688966},
 author = {Dino Sejdinovic and Bharath Sriperumbudur and Arthur Gretton and Kenji Fukumizu},
 journal = {The Annals of Statistics},
 number = {5},
 pages = {2263--2291},
 publisher = {Institute of Mathematical Statistics},
 title = {{Equivalence of Distance-based and RKHS-based Statistics in Hypothesis Testing}},
 volume = {41},
 year = {2013}
}

@article{replaybuffer1992,
  author =       "Lin, Long-Ji",
  title =        {{Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching}},
  journal =      "Machine Learning",
  year =         "1992",
  volume =    "8",
  number =    "3--4",
  pages =     "293--321",
  publisher = "Kluwer Academic Publishers",
  address = "Hingham, MA, USA"
}

@article{tqc2020,
  title={{Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics}},
  author={Arsenii Kuznetsov and Pavel Shvechikov and Alexander Grishin and D. Vetrov},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.04269}
}

@inproceedings{sunrise2021,
  title={{SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning}},
  author={Kimin Lee and M. Laskin and A. Srinivas and P. Abbeel},
  booktitle={{International Conference on Machine Learning}},
  year={2021}
}

@article{sacnew2018,
  title={{Soft Actor-Critic Algorithms and Applications}},
  author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and G. Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and P. Abbeel and Sergey Levine},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.05905}
}

@inproceedings{rlenergypolicy2017,
  title={{Reinforcement Learning with Deep Energy-Based Policies}},
  author={Tuomas Haarnoja and Haoran Tang and P. Abbeel and Sergey Levine},
  booktitle={{International Conference on Machine Learning}},
  year={2017}
}

@article{bremen2021,
  title={{Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization}},
  author={Tatsuya Matsushima and Hiroki Furuta and Yutaka Matsuo and Ofir Nachum and Shixiang Shane Gu},
  journal={{International Conference on Learning Representations}},
  year={2021},
  volume={abs/2006.03647}
}

@article{iql2021,
  title={{Offline Reinforcement Learning with Implicit Q-Learning}},
  author={Ilya Kostrikov and Ashvin Nair and Sergey Levine},
  journal={{ArXiv}},
  year={2021},
  volume={abs/2110.06169}
}

@inproceedings{fisherbrc2021,
  title={{Offline Reinforcement Learning with Fisher Divergence Critic Regularization}},
  author={Ilya Kostrikov and Jonathan Tompson and Rob Fergus and Ofir Nachum},
  booktitle={{International Conference on Machine Learning}},
  year={2021}
}

@article{td3bc2021,
  title={{A Minimalist Approach to Offline Reinforcement Learning}},
  author={Scott Fujimoto and Shixiang Shane Gu},
  journal={{ArXiv}},
  year={2021},
  volume={abs/2106.06860}
}

@book{markovdp1994,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{mbpo2019,
  title={{When to Trust Your Model: Model-Based Policy Optimization}},
  author={Michael Janner and Justin Fu and Marvin Zhang and Sergey Levine},
  journal={{ArXiv}},
  year={2019},
  volume={abs/1906.08253}
}

@article{mopo2020,
  title={{MOPO: Model-based Offline Policy Optimization}},
  author={Tianhe Yu and Garrett Thomas and Lantao Yu and Stefano Ermon and James Y. Zou and Sergey Levine and Chelsea Finn and Tengyu Ma},
  journal={{ArXiv}},
  year={2020},
  volume={abs/2005.13239}
}

@article{moose2021,
  title={{Overcoming Model Bias for Robust Offline Deep Reinforcement Learning}},
  author={Phillip Swazinna and Steffen Udluft and Thomas A. Runkler},
  journal={{Eng. Appl. Artif. Intell.}},
  year={2021},
  volume={104},
  pages={104366}
}

@inproceedings{repbsde2021,
  title={{Representation Balancing Offline Model-based Reinforcement Learning}},
  author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
  booktitle={{International Conference on Learning Representations}},
  year={2021}
}

@article{offlinerlsequence2021,
  title={{Reinforcement Learning as One Big Sequence Modeling Problem}},
  author={Michael Janner and Qiyang Li and Sergey Levine},
  journal={{ArXiv}},
  year={2021},
  volume={abs/2106.02039}
}

@inproceedings{pets2018,
  title={{Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models}},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  booktitle={{Advances in neural information processing systems}},
  year={2018}
}

@inproceedings{wmopo2021,
  title={{Weighted model estimation for offline model-based reinforcement learning}},
  author={Toru Hishinuma and Kei Senda},
  booktitle={{Advances in neural information processing systems}},
  year={2021}
}

@inproceedings{gamembrl2020,
  title={{A Game Theoretic Framework for Model Based Reinforcement Learning}},
  author={Aravind Rajeswaran and Igor Mordatch and Vikash Kumar},
  booktitle={{International Conference on Machine Learning}},
  year={2020}
}

@article{metrpo2018,
  title={{Model-Ensemble Trust-Region Policy Optimization}},
  author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and P. Abbeel},
  journal={{International Conference on Learning Representations}},
  year={2018},
  volume={abs/1802.10592}
}

@article{mbmpo2018,
  title={{Model-Based Reinforcement Learning via Meta-Policy Optimization}},
  author={Ignasi Clavera and Jonas Rothfuss and John Schulman and Yasuhiro Fujita and Tamim Asfour and P. Abbeel},
  journal={{ArXiv}},
  year={2018},
  volume={abs/1809.05214}
}

@article{asi2012,
  title={{Agnostic System Identification for Model-Based Reinforcement Learning}},
  author={St{\'e}phane Ross and J. Andrew Bagnell},
  journal={{International Conference on Machine Learning}},
  year={2012},
  volume={abs/1203.1007}
}

@article{ipm2009,
  title={{On integral probability metrics, $\phi$-divergences and binary classification}},
  author={Bharath K. Sriperumbudur and Kenji Fukumizu and Arthur Gretton and Bernhard Scholkopf and Gert R. G. Lanckriet},
  journal={{arXiv: Information Theory}},
  year={2009}
}

@inproceedings{dualdice2019,
  title={{DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections}},
  author={Ofir Nachum and Yinlam Chow and Bo Dai and Lihong Li},
  booktitle={{Advances in neural information processing systems}},
  year={2019}
}

@article{trajectorytransformer2021,
  title={{Reinforcement Learning as One Big Sequence Modeling Problem}},
  author={Michael Janner and Qiyang Li and Sergey Levine},
  journal={{ArXiv}},
  year={2021},
  volume={abs/2106.02039}
}

@inproceedings{gpt2018,
    title={{Improving Language Understanding by Generative Pre-Training}},
    author={Alec Radford and Ilya Sutskever},
    booktitle={{arxiv}},
    year={2018}
}

@book{ferguson1996,
    AUTHOR = {Ferguson, Thomas S.},
     TITLE = {{A Course in Large Sample Theory}},
 PUBLISHER = {{Chapman \& Hall}},
   ADDRESS = {London},
      YEAR = {1996},
}

@book{casellaberger2001,
  author = {Casella, George and Berger, Roger},
  month = {June},
  publisher = {{Duxbury Resource Center}},
  title = {Statistical Inference},
  year = 2001
}

@article{zhang2021alignment,
  title={Alignment attention by matching key and query distributions},
  author={Zhang, Shujian and Fan, Xinjie and Zheng, Huangjie and Tanwisuth, Korawat and Zhou, Mingyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{slbo2019,
title={{Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees}},
author={Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},
booktitle={{International Conference on Learning Representations}},
year={2019}
}

@inproceedings{mml2021,
  title={{Minimax model learning}},
  author={Voloshin, Cameron and Jiang, Nan and Yue, Yisong},
  booktitle={{International Conference on Artificial Intelligence and Statistics}},
  pages={1612--1620},
  year={2021},
  organization={PMLR}
}

@article{revisitdesignchoice2021,
  title={{Revisiting Design Choices in Model-Based Offline Reinforcement Learning}},
  author={Cong Lu and Philip J. Ball and Jack Parker-Holder and Michael A. Osborne and Stephen J. Roberts},
  journal={{ArXiv}},
  year={2021},
  volume={abs/2110.04135}
}

@article{sern2022,
  title={{Learning Synthetic Environments and Reward Networks for Reinforcement Learning}},
  author={F{\'a}bio Ferreira and Thomas Nierhoff and Andreas Saelinger and Frank Hutter},
  journal={{ArXiv}},
  year={2022},
  volume={abs/2202.02790}
}

@article{objectivemismatch2020,
  title={Objective mismatch in model-based reinforcement learning},
  author={Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  journal={arXiv preprint arXiv:2002.04523},
  year={2020}
}

@inproceedings{stochasticmuzero,
title={{Planning in Stochastic Environments with a Learned Model}},
author={Ioannis Antonoglou and Julian Schrittwieser and Sherjil Ozair and Thomas K Hubert and David Silver},
booktitle={{International Conference on Learning Representations}},
year={2022}
}

@inproceedings{pareto2022,
title={{Pareto Policy Pool for Model-based Offline Reinforcement Learning}},
author={Yijun Yang and Jing Jiang and Tianyi Zhou and Jie Ma and Yuhui Shi},
booktitle={{International Conference on Learning Representations}},
year={2022}
}

@inproceedings{dara2022,
title={{DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning}},
author={Jinxin Liu and Zhang Hongyin and Donglin Wang},
booktitle={{International Conference on Learning Representations}},
year={2022}
}

@article{neuralodesemilarkov2020,
  title={{Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs}},
  author={Jianzhun Du and Joseph D. Futoma and Finale Doshi-Velez},
  journal={{Advances in neural information processing systems}},
  year={2020},
  volume={abs/2006.16210}
}

@article{mnm2021,
  title={{Mismatched No More: Joint Model-Policy Optimization for Model-Based RL}},
  author={Benjamin Eysenbach and Alexander Khazatsky and Sergey Levine and Ruslan Salakhutdinov},
  journal={{ArXiv}},
  year={2021},
  volume={abs/2110.02758}
}

@article{invariantrepresentation2021,
  title={{Learning Invariant Representations for Reinforcement Learning without Reconstruction}},
  author={Amy Zhang and Rowan McAllister and Roberto Calandra and Yarin Gal and Sergey Levine},
  journal={{ArXiv}},
  year={2021},
  volume={abs/2006.10742}
}

@article{Hjalmarsson1996ForMC,
  title={{For model-based control design, closed-loop identification gives better performance}},
  author={H{\aa}kan Hjalmarsson and Michel Gevers and Franky De Bruyne},
  journal={{Automatica}},
  year={1996},
  volume={32},
  pages={1659-1673}
}

@article{opposd2019,
  title={{Off-Policy Policy Gradient with State Distribution Correction}},
  author={Yao Liu and Adith Swaminathan and Alekh Agarwal and Emma Brunskill},
  journal={{ArXiv}},
  year={2019},
  volume={abs/1904.08473}
}

@article{dyna1991,
  title={{Dyna, an integrated architecture for learning, planning, and reacting}},
  author={Richard S. Sutton},
  journal={{ACM Sigart Bulletin}},
  year={1991},
  volume={2},
  pages={160-163}
}

@book{Bertsekas1995DynamicPA,
title={{Dynamic Programming and Optimal Control}},
author={Dimitri P. Bertsekas},
volume={1},
year={1995},
publisher={Belmont, MA: Athena Scientific}
}

@article{edac2021,
  title={{Uncertainty-based offline reinforcement learning with diversified q-ensemble}},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={{Advances in Neural Information Processing Systems}},
  volume={34},
  year={2021}
}

@inproceedings{gamps2020,
  title={Gradient-aware model-based policy search},
  author={D'Oro, Pierluca and Metelli, Alberto Maria and Tirinzoni, Andrea and Papini, Matteo and Restelli, Marcello},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={3801--3808},
  year={2020}
}

@article{vagram2022,
  title={{Value Gradient weighted Model-Based Reinforcement Learning}},
  author={Voelcker, Claas and Liao, Victor and Garg, Animesh and Farahmand, Amir-massoud},
  journal={arXiv preprint arXiv:2204.01464},
  year={2022}
}

@inproceedings{vaml2017,
  title={{Value-aware loss function for model-based reinforcement learning}},
  author={Farahmand, Amir-massoud and Barreto, Andre and Nikovski, Daniel},
  booktitle={{Artificial Intelligence and Statistics}},
  pages={1486--1494},
  year={2017},
  organization={PMLR}
}

@article{itervaml2018,
  title={Iterative value-aware model learning},
  author={Farahmand, Amir-massoud},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{barrierlexico2021,
  title={{Bi-objective Trade-off with Dynamic Barrier Gradient Descent}},
  author={Gong, Chengyue and Liu, Xingchao and Liu, Qiang},
  journal={{Advances in Neural Information Processing Systems}},
  volume={34},
  year={2021}
}

@article{coindice2020,
  title={{Coindice: Off-policy confidence interval estimation}},
  author={Dai, Bo and Nachum, Ofir and Chow, Yinlam and Li, Lihong and Szepesv{\'a}ri, Csaba and Schuurmans, Dale},
  journal={{Advances in neural information processing systems}},
  volume={33},
  pages={9398--9411},
  year={2020}
}

@inproceedings{errapi2003,
  title={Error bounds for approximate policy iteration},
  author={Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  volume={3},
  pages={560--567},
  year={2003}
}

@article{vpm2020,
  title={Batch stationary distribution estimation},
  author={Wen, Junfeng and Dai, Bo and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:2003.00722},
  year={2020}
}



@article{kldual1983,
  title={Asymptotic evaluation of certain Markov process expectations for large time. IV},
  author={Donsker, Monroe D and Varadhan, SR Srinivasa},
  journal={Communications on pure and applied mathematics},
  volume={36},
  number={2},
  pages={183--212},
  year={1983},
  publisher={Wiley Online Library}
}

@article{lapo2022,
  title={Latent-Variable Advantage-Weighted Policy Optimization for Offline RL},
  author={Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Gao, Yuan and Wang, Jianhao and Li, Wenzhe and Liang, Bin and Finn, Chelsea and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2203.08949},
  year={2022}
}

@inproceedings{
gptcritic2022,
title={{GPT}-Critic: Offline Reinforcement Learning for End-to-End Task-Oriented Dialogue Systems},
author={Youngsoo Jang and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2022}
}

@inproceedings{lompo2021,
  title={Offline reinforcement learning from images with latent space models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  booktitle={Learning for Dynamics and Control},
  pages={1154--1168},
  year={2021},
  organization={PMLR}
}

@article{repbmdp2018,
  title={Representation balancing mdps for off-policy policy evaluation},
  author={Liu, Yao and Gottesman, Omer and Raghu, Aniruddh and Komorowski, Matthieu and Faisal, Aldo A and Doshi-Velez, Finale and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{romi2021,
  title={Offline Reinforcement Learning with Reverse Model-based Imagination},
  author={Wang, Jianhao and Li, Wenzhe and Jiang, Haozhe and Zhu, Guangxiang and Li, Siyuan and Zhang, Chongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{pevi2021,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{bestdice2020,
  title={Off-policy evaluation via the regularized lagrangian},
  author={Yang, Mengjiao and Nachum, Ofir and Dai, Bo and Li, Lihong and Schuurmans, Dale},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6551--6561},
  year={2020}
}

@article{opeduality2020,
  title={Reinforcement learning via fenchel-rockafellar duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{opetrajectoryis2001,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning},
  pages={417--424},
  year={2001}
}

@inproceedings{minimaxope2015,
  title={Toward minimax off-policy value estimation},
  author={Li, Lihong and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  booktitle={Artificial Intelligence and Statistics},
  pages={608--616},
  year={2015},
  organization={PMLR}
}

@article{optope2019,
  title={Towards optimal off-policy evaluation for reinforcement learning with marginalized importance sampling},
  author={Xie, Tengyang and Ma, Yifei and Wang, Yu-Xiang},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{jointmatching2022,
  title={A Regularized Implicit Policy for Offline Reinforcement Learning},
  author={Yang, Shentao and Wang, Zhendong and Zheng, Huangjie and Feng, Yihao and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2202.09673},
  year={2022}
}

@inproceedings{sdmgan2022,
  title={Regularizing a Model-based Policy Stationary Distribution to Stabilize Offline Reinforcement Learning},
  author={Yang, Shentao and Feng, Yihao and Zhang, Shujian and Zhou, Mingyuan},
  booktitle={International Conference on Machine Learning},
  pages={24980--25006},
  year={2022},
  organization={PMLR}
}


@article{kaelbling1998planning,
  title={Planning and acting in partially observable stochastic domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998},
  publisher={Elsevier}
}

@inproceedings{listnet2007,
  title={Learning to rank: from pairwise approach to listwise approach},
  author={Cao, Zhe and Qin, Tao and Liu, Tie-Yan and Tsai, Ming-Feng and Li, Hang},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={129--136},
  year={2007}
}

@inproceedings{listmle2008,
  title={Listwise approach to learning to rank: theory and algorithm},
  author={Xia, Fen and Liu, Tie-Yan and Wang, Jue and Zhang, Wensheng and Li, Hang},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1192--1199},
  year={2008}
}

@article{escort2020,
  title={Escaping the gravitational pull of softmax},
  author={Mei, Jincheng and Xiao, Chenjun and Dai, Bo and Li, Lihong and Szepesv{\'a}ri, Csaba and Schuurmans, Dale},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21130--21140},
  year={2020}
}

@article{ranksvm1999,
  title={Support vector learning for ordinal regression},
  author={Herbrich, Ralf and Graepel, Thore and Obermayer, Klaus},
  year={1999},
  journal={IET}
}

@article{maddison2016concrete,
  title={The concrete distribution: A continuous relaxation of discrete random variables},
  author={Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1611.00712},
  year={2016}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{rankingboosting2003,
  title={An efficient boosting algorithm for combining preferences},
  author={Freund, Yoav and Iyer, Raj and Schapire, Robert E and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={4},
  number={Nov},
  pages={933--969},
  year={2003}
}

@inproceedings{ranknet2005,
  title={Learning to rank using gradient descent},
  author={Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={89--96},
  year={2005}
}

@article{wu2019alternating,
  title={Alternating recurrent dialog model with large-scale pre-trained language models},
  author={Wu, Qingyang and Zhang, Yichi and Li, Yu and Yu, Zhou},
  journal={arXiv preprint arXiv:1910.03756},
  year={2019}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{menick2022teaching,
  title={Teaching language models to support answers with verified quotes},
  author={Menick, Jacob and Trebacz, Maja and Mikulik, Vladimir and Aslanides, John and Song, Francis and Chadwick, Martin and Glaese, Mia and Young, Susannah and Campbell-Gillingham, Lucy and Irving, Geoffrey and others},
  journal={arXiv preprint arXiv:2203.11147},
  year={2022}
}


@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}


@article{nakano2021webgpt,
  title={WebGPT: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{russell1998learning,
  title={Learning agents for uncertain environments},
  author={Russell, Stuart},
  booktitle={Proceedings of the eleventh annual conference on Computational learning theory},
  pages={101--103},
  year={1998}
}

@article{verma2022chai,
  title={CHAI: A CHatbot AI for Task-Oriented Dialogue with Offline Reinforcement Learning},
  author={Verma, Siddharth and Fu, Justin and Yang, Mengjiao and Levine, Sergey},
  journal={arXiv preprint arXiv:2204.08426},
  year={2022}
}

@article{weisz2018sample,
  title={Sample efficient deep reinforcement learning for dialogue systems with large action spaces},
  author={Weisz, Gell{\'e}rt and Budzianowski, Pawe{\l} and Su, Pei-Hao and Ga{\v{s}}i{\'c}, Milica},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={26},
  number={11},
  pages={2083--2097},
  year={2018},
  publisher={IEEE}
}


@inproceedings{wang2020learning,
  title={Learning efficient dialogue policy from demonstrations through shaping},
  author={Wang, Huimin and Peng, Baolin and Wong, Kam-Fai},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={6355--6365},
  year={2020}
}

@article{takanobu2019guided,
  title={Guided dialog policy learning: Reward estimation for multi-domain task-oriented dialog},
  author={Takanobu, Ryuichi and Zhu, Hanlin and Huang, Minlie},
  journal={arXiv preprint arXiv:1908.10719},
  year={2019}
}

@article{wang2020modelling,
  title={Modelling hierarchical structure between dialogue policy and natural language generator with option framework for task-oriented dialogue system},
  author={Wang, Jianhong and Zhang, Yuan and Kim, Tae-Kyun and Gu, Yunjie},
  journal={arXiv preprint arXiv:2006.06814},
  year={2020}
}


@article{snell2022offline,
  title={Offline RL for Natural Language Generation with Implicit Language Q Learning},
  author={Snell, Charlie and Kostrikov, Ilya and Su, Yi and Yang, Mengjiao and Levine, Sergey},
  journal={arXiv preprint arXiv:2206.11871},
  year={2022}
}

@article{snell2022context,
  title={Context-Aware Language Modeling for Goal-Oriented Dialogue Systems},
  author={Snell, Charlie and Yang, Sherry and Fu, Justin and Su, Yi and Levine, Sergey},
  journal={arXiv preprint arXiv:2204.10198},
  year={2022}
}

@inproceedings{gao2018neural,
  title={Neural approaches to conversational AI},
  author={Gao, Jianfeng and Galley, Michel and Li, Lihong},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={1371--1374},
  year={2018}
}


@article{young2013pomdp,
  title={Pomdp-based statistical spoken dialog systems: A review},
  author={Young, Steve and Ga{\v{s}}i{\'c}, Milica and Thomson, Blaise and Williams, Jason D},
  journal={Proceedings of the IEEE},
  volume={101},
  number={5},
  pages={1160--1179},
  year={2013},
  publisher={IEEE}
}



@article{jaques2020human,
  title={Human-centric dialog training via offline reinforcement learning},
  author={Jaques, Natasha and Shen, Judy Hanwen and Ghandeharioun, Asma and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang Shane and Picard, Rosalind},
  journal={arXiv preprint arXiv:2010.05848},
  year={2020}
}


@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{kwan2022survey,
  title={A Survey on Recent Advances and Challenges in Reinforcement LearningMethods for Task-Oriented Dialogue Policy Learning},
  author={Kwan, Wai-Chung and Wang, Hongru and Wang, Huimin and Wong, Kam-Fai},
  journal={arXiv preprint arXiv:2202.13675},
  year={2022}
}
@inproceedings{ham2020end,
  title={End-to-end neural pipeline for goal-oriented dialogue systems using GPT-2},
  author={Ham, Donghoon and Lee, Jeong-Gwan and Jang, Youngsoo and Kim, Kee-Eung},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={583--592},
  year={2020}
}

@book{luce2012individual,
  title={Individual choice behavior: A theoretical analysis},
  author={Luce, R Duncan},
  year={2012},
  publisher={Courier Corporation}
}

@article{plackett1975analysis,
  title={The analysis of permutations},
  author={Plackett, Robin L},
  journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume={24},
  number={2},
  pages={193--202},
  year={1975},
  publisher={Wiley Online Library}
}

@article{liu2009learning,
  title={Learning to rank for information retrieval},
  author={Liu, Tie-Yan},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={3},
  pages={225--331},
  year={2009},
  publisher={Now Publishers, Inc.}
}

@inproceedings{trex2019,
  title={Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations},
  author={Brown, Daniel and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott},
  booktitle={International conference on machine learning},
  pages={783--792},
  year={2019},
  organization={PMLR}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{drex2020,
  title={Better-than-demonstrator imitation learning via automatically-ranked demonstrations},
  author={Brown, Daniel S and Goo, Wonjoon and Niekum, Scott},
  booktitle={Conference on robot learning},
  pages={330--359},
  year={2020},
  organization={PMLR}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}
@book{tur2011spoken,
  title={Spoken language understanding: Systems for extracting semantic information from speech},
  author={Tur, Gokhan and De Mori, Renato},
  year={2011},
  publisher={John Wiley \& Sons}
}
@article{sfnrl2019,
  title={Structured fusion networks for dialog},
  author={Mehri, Shikib and Srinivasan, Tejas and Eskenazi, Maxine},
  journal={arXiv preprint arXiv:1907.10016},
  year={2019}
}

@inproceedings{damd2020,
  title={Task-oriented dialog systems that consider multiple appropriate responses under the same context},
  author={Zhang, Yichi and Ou, Zhijian and Yu, Zhou},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={9604--9611},
  year={2020}
}
@inproceedings{peng2017composite,
  title={Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning},
  author={Peng, Baolin and Li, Xiujun and Li, Lihong and Gao, Jianfeng and Celikyilmaz, Asli and Lee, Sungjin and Wong, Kam-Fai},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={2231--2240},
  year={2017}
}
@article{williams2007partially,
  title={Partially observable Markov decision processes for spoken dialog systems},
  author={Williams, Jason D and Young, Steve},
  journal={Computer Speech \& Language},
  volume={21},
  number={2},
  pages={393--422},
  year={2007},
  publisher={Elsevier}
}


@article{zhu2020convlab,
  title={Convlab-2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems},
  author={Zhu, Qi and Zhang, Zheng and Fang, Yan and Li, Xiang and Takanobu, Ryuichi and Li, Jinchao and Peng, Baolin and Gao, Jianfeng and Zhu, Xiaoyan and Huang, Minlie},
  journal={arXiv preprint arXiv:2002.04793},
  year={2020}
}

@article{zhang2019find,
  title={Find or classify? dual strategy for slot-value predictions on multi-domain dialog state tracking},
  author={Zhang, Jian-Guo and Hashimoto, Kazuma and Wu, Chien-Sheng and Wan, Yao and Yu, Philip S and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:1910.03544},
  year={2019}
}
@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}
@article{zhao2019rethinking,
  title={Rethinking action spaces for reinforcement learning in end-to-end dialog agents with latent variable models},
  author={Zhao, Tiancheng and Xie, Kaige and Eskenazi, Maxine},
  journal={arXiv preprint arXiv:1902.08858},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{mintl2020,
    title = "{M}in{TL}: Minimalist Transfer Learning for Task-Oriented Dialogue Systems",
    author = "Lin, Zhaojiang  and
      Madotto, Andrea  and
      Winata, Genta Indra  and
      Fung, Pascale",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.emnlp-main.273",
    pages = "3391--3405",
}

@article{wen2015semantically,
  title={Semantically conditioned lstm-based natural language generation for spoken dialogue systems},
  author={Wen, Tsung-Hsien and Gasic, Milica and Mrksic, Nikola and Su, Pei-Hao and Vandyke, David and Young, Steve},
  journal={arXiv preprint arXiv:1508.01745},
  year={2015}
}

@article{zhang2022allsh,
  title={Allsh: Active learning guided by local sensitivity and hardness},
  author={Zhang, Shujian and Gong, Chengyue and Liu, Xingchao and He, Pengcheng and Chen, Weizhu and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2205.04980},
  year={2022}
}


@article{simpletod2020,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20179--20191},
  year={2020}
}

@article{soloist2021,
  title={Soloist: Buildingtask bots at scale with transfer learning and machine teaching},
  author={Peng, Baolin and Li, Chunyuan and Li, Jinchao and Shayandeh, Shahin and Liden, Lars and Gao, Jianfeng},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={807--824},
  year={2021},
  publisher={MIT Press}
}


@inproceedings{ubar2021,
  title={Ubar: Towards fully end-to-end task-oriented dialog system with gpt-2},
  author={Yang, Yunyi and Li, Yunhao and Quan, Xiaojun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={14230--14238},
  year={2021}
}



@article{caspi2021,
  title={Causal-aware Safe Policy Improvement for Task-oriented dialogue},
  author={Ramachandran, Govardana Sachithanandam and Hashimoto, Kazuma and Xiong, Caiming},
  journal={arXiv preprint arXiv:2103.06370},
  year={2021}
}

@inproceedings{qian2021annotation,
  title={Annotation Inconsistency and Entity Bias in MultiWOZ},
  author={Qian, Kun and Beirami, Ahmad and Lin, Zhouhan and De, Ankita and Geramifard, Alborz and Yu, Zhou and Sankar, Chinnadhurai},
  booktitle={Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  pages={326--337},
  year={2021}
}
@article{licoco2021,
  title={CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers},
  author={Li, Shiyang and Yavuz, Semih and Rajani, Nazneen and Yan, Xifeng and Zhou, Yingbo and Xiong, Caiming},
  journal={ICLR},
  year={2021}
}

@article{multiwoz2018,
  title={MultiWOZ--a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling},
  author={Budzianowski, Pawe{\l} and Wen, Tsung-Hsien and Tseng, Bo-Hsiang and Casanueva, Inigo and Ultes, Stefan and Ramadan, Osman and Ga{\v{s}}i{\'c}, Milica},
  journal={arXiv preprint arXiv:1810.00278},
  year={2018}
}

@inproceedings{bleu2002,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@article{wen2016network,
  title={A network-based end-to-end trainable task-oriented dialogue system},
  author={Wen, Tsung-Hsien and Vandyke, David and Mrksic, Nikola and Gasic, Milica and Rojas-Barahona, Lina M and Su, Pei-Hao and Ultes, Stefan and Young, Steve},
  journal={arXiv preprint arXiv:1604.04562},
  year={2016}
}

@article{bart2019,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{huggingface2019,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}
@article{zhang2022passage,
  title={Passage-Mask: A Learnable Regularization Strategy for Retriever-Reader Models},
  author={Zhang, Shujian and Gong, Chengyue and Liu, Xingchao},
  journal={arXiv preprint arXiv:2211.00915},
  year={2022}
}

@inproceedings{arsm2019,
  title={ARSM: Augment-REINFORCE-swap-merge estimator for gradient backpropagation through categorical variables},
  author={Yin, Mingzhang and Yue, Yuguang and Zhou, Mingyuan},
  booktitle={International Conference on Machine Learning},
  pages={7095--7104},
  year={2019},
  organization={PMLR}
}

@article{reinforce1992,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{finn2016connection,
  title={A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models},
  author={Finn, Chelsea and Christiano, Paul and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.03852},
  year={2016}
}
@article{zhang2021knowing,
  title={Knowing more about questions can help: Improving calibration in question answering},
  author={Zhang, Shujian and Gong, Chengyue and Choi, Eunsol},
  journal={arXiv preprint arXiv:2106.01494},
  year={2021}
}

@article{fu2017learning,
  title={Learning robust rewards with adversarial inverse reinforcement learning},
  author={Fu, Justin and Luo, Katie and Levine, Sergey},
  journal={arXiv preprint arXiv:1710.11248},
  year={2017}
}

@inproceedings{ghasemipour2020divergence,
  title={A divergence minimization perspective on imitation learning methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  booktitle={Conference on Robot Learning},
  pages={1259--1277},
  year={2020},
  organization={PMLR}
}

@book{smith1994spoken,
  title={Spoken natural language dialog systems: A practical approach},
  author={Smith, Ronnie W and Hipp, D Richard},
  year={1994},
  publisher={Oxford University Press on Demand}
}
@article{zhang2021learning,
  title={Learning with different amounts of annotation: From zero to many labels},
  author={Zhang, Shujian and Gong, Chengyue and Choi, Eunsol},
  journal={arXiv preprint arXiv:2109.04408},
  year={2021}
}

@article{aim2021,
  title={Adversarial intrinsic motivation for reinforcement learning},
  author={Durugkar, Ishan and Tec, Mauricio and Niekum, Scott and Stone, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8622--8636},
  year={2021}
}


@inproceedings{
liu2018competitive,
title={Competitive experience replay},
author={Hao Liu and Alexander Trott and Richard Socher and Caiming Xiong},
booktitle={International Conference on Learning Representations},
year={2019},
}


@inproceedings{saito2018curriculum,
  title={Curriculum learning based on reward sparseness for deep reinforcement learning of task completion dialogue management},
  author={Saito, Atsushi},
  booktitle={Proceedings of the 2018 EMNLP workshop SCAI: The 2nd international workshop on search-oriented conversational AI},
  pages={46--51},
  year={2018}
}

@article{hu2018playing,
  title={Playing 20 question game with policy-based reinforcement learning},
  author={Hu, Huang and Wu, Xianchao and Luo, Bingfeng and Tao, Chongyang and Xu, Can and Wu, Wei and Chen, Zhan},
  journal={arXiv preprint arXiv:1808.07645},
  year={2018}
}

@article{li2020guided,
  title={Guided dialog policy learning without adversarial learning in the loop},
  author={Li, Ziming and Lee, Sungjin and Peng, Baolin and Li, Jinchao and Kiseleva, Julia and de Rijke, Maarten and Shayandeh, Shahin and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2004.03267},
  year={2020}
}

@inproceedings{he2022galaxy,
  title={Galaxy: A generative pre-trained model for task-oriented dialog with semi-supervised learning and explicit policy injection},
  author={He, Wanwei and Dai, Yinpei and Zheng, Yinhe and Wu, Yuchuan and Cao, Zheng and Liu, Dermot and Jiang, Peng and Yang, Min and Huang, Fei and Si, Luo and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={10749--10757},
  year={2022}
}

@inproceedings{
wmbrl2022,
title={A Unified Framework for Alternating Offline Model Training and Policy Learning},
author={Shentao Yang and Shujian Zhang and Yihao Feng and Mingyuan Zhou},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022}
}
@article{fan2021contextual,
  title={Contextual dropout: An efficient sample-dependent dropout module},
  author={Fan, Xinjie and Zhang, Shujian and Tanwisuth, Korawat and Qian, Xiaoning and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2103.04181},
  year={2021}
}
