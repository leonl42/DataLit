\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Background}{}% 2
\BOOKMARK [1][-]{section.3}{Main Method}{}% 3
\BOOKMARK [2][-]{subsection.3.1}{Two Generalized Objectives for Reward Learning}{section.3}% 4
\BOOKMARK [2][-]{subsection.3.2}{Policy Gradient Update with Learned Reward Function}{section.3}% 5
\BOOKMARK [1][-]{section.4}{Related Work}{}% 6
\BOOKMARK [1][-]{section.5}{Experiments}{}% 7
\BOOKMARK [2][-]{subsection.5.1}{Main Results}{section.5}% 8
\BOOKMARK [2][-]{subsection.5.2}{Ablation Study}{section.5}% 9
\BOOKMARK [2][-]{subsection.5.3}{Further Analysis}{section.5}% 10
\BOOKMARK [1][-]{section.6}{Conclusion}{}% 11
\BOOKMARK [1][-]{appendix.A}{Examples of the generated dialogues}{}% 12
\BOOKMARK [1][-]{appendix.B}{Algorithmic details}{}% 13
\BOOKMARK [1][-]{appendix.C}{Comparison with some other reward-learning methods in RL-based dialogue agents}{}% 14
\BOOKMARK [1][-]{appendix.D}{Detailed comparison with CASPI}{}% 15
\BOOKMARK [1][-]{appendix.E}{Experiments with the GALAXY}{}% 16
\BOOKMARK [1][-]{appendix.F}{Experiments on the MultiWOZ 2.1 dataset}{}% 17
\BOOKMARK [1][-]{appendix.G}{Implementation details}{}% 18
