% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{workshop2023bloom}
B.~Workshop, ``Bloom: A 176b-parameter open-access multilingual language model,'' 2023.

\bibitem{muennighoff2023crosslingual}
N.~Muennighoff, T.~Wang, L.~Sutawika, A.~Roberts, S.~Biderman, T.~L. Scao, M.~S. Bari, S.~Shen, Z.-X. Yong, H.~Schoelkopf, X.~Tang, D.~Radev, A.~F. Aji, K.~Almubarak, S.~Albanie, Z.~Alyafeai, A.~Webson, E.~Raff, and C.~Raffel, ``Crosslingual generalization through multitask finetuning,'' 2023.

\bibitem{xue2021mt5}
L.~Xue, N.~Constant, A.~Roberts, M.~Kale, R.~Al-Rfou, A.~Siddhant, A.~Barua, and C.~Raffel, ``mt5: A massively multilingual pre-trained text-to-text transformer,'' 2021.

\bibitem{conneau2020unsupervised}
A.~Conneau, K.~Khandelwal, N.~Goyal, V.~Chaudhary, G.~Wenzek, F.~Guzmán, E.~Grave, M.~Ott, L.~Zettlemoyer, and V.~Stoyanov, ``Unsupervised cross-lingual representation learning at scale,'' 2020.

\bibitem{goyal2021largerscale}
N.~Goyal, J.~Du, M.~Ott, G.~Anantharaman, and A.~Conneau, ``Larger-scale transformers for multilingual masked language modeling,'' 2021.

\bibitem{shliazhko2022mgpt}
O.~Shliazhko, A.~Fenogenova, M.~Tikhonova, V.~Mikhailov, A.~Kozlova, and T.~Shavrina, ``mgpt: Few-shot learners go multilingual,'' 2022.

\bibitem{lin2022fewshot}
X.~V. Lin, T.~Mihaylov, M.~Artetxe, T.~Wang, S.~Chen, D.~Simig, M.~Ott, N.~Goyal, S.~Bhosale, J.~Du, R.~Pasunuru, S.~Shleifer, P.~S. Koura, V.~Chaudhary, B.~O'Horo, J.~Wang, L.~Zettlemoyer, Z.~Kozareva, M.~Diab, V.~Stoyanov, and X.~Li, ``Few-shot learning with multilingual language models,'' 2022.

\bibitem{xu2021bert}
H.~Xu, B.~V. Durme, and K.~Murray, ``Bert, mbert, or bibert? a study on contextualized embeddings for neural machine translation,'' 2021.

\bibitem{yong2023bloom1}
Z.-X. Yong, H.~Schoelkopf, N.~Muennighoff, A.~F. Aji, D.~I. Adelani, K.~Almubarak, M.~S. Bari, L.~Sutawika, J.~Kasai, A.~Baruwa, G.~I. Winata, S.~Biderman, E.~Raff, D.~Radev, and V.~Nikoulina, ``Bloom+1: Adding language support to bloom for zero-shot prompting,'' 2023.

\bibitem{phang2020english}
J.~Phang, I.~Calixto, P.~M. Htut, Y.~Pruksachatkun, H.~Liu, C.~Vania, K.~Kann, and S.~R. Bowman, ``English intermediate-task training improves zero-shot cross-lingual transfer too,'' 2020.

\bibitem{ebrahimi2021adapt}
A.~Ebrahimi and K.~Kann, ``How to adapt your pretrained multilingual model to 1600 languages,'' 2021.

\bibitem{ye2023language}
J.~Ye, X.~Tao, and L.~Kong, ``Language versatilists vs. specialists: An empirical revisiting on multilingual transfer ability,'' 2023.

\bibitem{armengolestapé2021multilingual}
J.~Armengol-Estapé, O.~de~Gibert~Bonet, and M.~Melero, ``On the multilingual capabilities of very large-scale english language models,'' 2021.

\bibitem{ogueji2021small}
K.~Ogueji, Y.~Zhu, and J.~Lin, ``Small data? no problem! exploring the viability of pretrained multilingual language models for low-resourced languages,'' in \emph{Proceedings of the 1st Workshop on Multilingual Representation Learning}, 2021, pp. 116--126.

\bibitem{gage1994new}
\BIBentryALTinterwordspacing
P.~Gage, ``A new algorithm for data compression,'' \emph{The C Users Journal Archive}, vol.~12, pp. 23--38, 1994. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:59804030}
\BIBentrySTDinterwordspacing

\bibitem{radford2019language}
A.~Radford, J.~Wu, R.~Child, D.~Luan, D.~Amodei, I.~Sutskever \emph{et~al.}, ``Language models are unsupervised multitask learners,'' \emph{OpenAI blog}, vol.~1, no.~8, p.~9, 2019.

\bibitem{brown2020language}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss, G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~M. Ziegler, J.~Wu, C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess, J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei, ``Language models are few-shot learners,'' 2020.

\bibitem{touvron2023llama}
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.-A. Lachaux, T.~Lacroix, B.~Rozière, N.~Goyal, E.~Hambro, F.~Azhar, A.~Rodriguez, A.~Joulin, E.~Grave, and G.~Lample, ``Llama: Open and efficient foundation language models,'' 2023.

\bibitem{touvron2023llama2}
H.~Touvron, L.~Martin, K.~Stone, P.~Albert, A.~Almahairi, Y.~Babaei, N.~Bashlykov, S.~Batra, P.~Bhargava, S.~Bhosale, D.~Bikel, L.~Blecher, C.~C. Ferrer, M.~Chen, G.~Cucurull, D.~Esiobu, J.~Fernandes, J.~Fu, W.~Fu, B.~Fuller, C.~Gao, V.~Goswami, N.~Goyal, A.~Hartshorn, S.~Hosseini, R.~Hou, H.~Inan, M.~Kardas, V.~Kerkez, M.~Khabsa, I.~Kloumann, A.~Korenev, P.~S. Koura, M.-A. Lachaux, T.~Lavril, J.~Lee, D.~Liskovich, Y.~Lu, Y.~Mao, X.~Martinet, T.~Mihaylov, P.~Mishra, I.~Molybog, Y.~Nie, A.~Poulton, J.~Reizenstein, R.~Rungta, K.~Saladi, A.~Schelten, R.~Silva, E.~M. Smith, R.~Subramanian, X.~E. Tan, B.~Tang, R.~Taylor, A.~Williams, J.~X. Kuan, P.~Xu, Z.~Yan, I.~Zarov, Y.~Zhang, A.~Fan, M.~Kambadur, S.~Narang, A.~Rodriguez, R.~Stojnic, S.~Edunov, and T.~Scialom, ``Llama 2: Open foundation and fine-tuned chat models,'' 2023.

\bibitem{rust2021good}
P.~Rust, J.~Pfeiffer, I.~Vulić, S.~Ruder, and I.~Gurevych, ``How good is your tokenizer? on the monolingual performance of multilingual language models,'' 2021.

\bibitem{stollenwerk2023training}
F.~Stollenwerk, ``Training and evaluation of a multilingual tokenizer for gpt-sw3,'' 2023.

\bibitem{acs2019}
\BIBentryALTinterwordspacing
J.~Ács. (2019, February) Exploring bert's vocabulary. [Online]. Available: \url{https://juditacs.github.io/2019/02/19/bert-tokenization-stats.html}
\BIBentrySTDinterwordspacing

\bibitem{french1999catastrophic}
R.~M. French, ``Catastrophic forgetting in connectionist networks,'' \emph{Trends in cognitive sciences}, vol.~3, no.~4, pp. 128--135, 1999.

\bibitem{cahyawijaya2023instructalign}
S.~Cahyawijaya, H.~Lovenia, T.~Yu, W.~Chung, and P.~Fung, ``Instruct-align: Teaching novel languages with to llms through alignment-based cross-lingual instruction,'' 2023.

\bibitem{chalkidis2021multieurlex}
I.~Chalkidis, M.~Fergadiotis, and I.~Androutsopoulos, ``Multieurlex -- a multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer,'' 2021.

\bibitem{vu2022overcoming}
T.~Vu, A.~Barua, B.~Lester, D.~Cer, M.~Iyyer, and N.~Constant, ``Overcoming catastrophic forgetting in zero-shot cross-lingual generation,'' 2022.

\bibitem{pfeiffer-etal-2020-mad}
\BIBentryALTinterwordspacing
J.~Pfeiffer, I.~Vuli{\'c}, I.~Gurevych, and S.~Ruder, ``{MAD-X}: {A}n {A}dapter-{B}ased {F}ramework for {M}ulti-{T}ask {C}ross-{L}ingual {T}ransfer,'' in \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}.\hskip 1em plus 0.5em minus 0.4em\relax Online: Association for Computational Linguistics, Nov. "2020", pp. 7654--7673. [Online]. Available: \url{https://aclanthology.org/2020.emnlp-main.617}
\BIBentrySTDinterwordspacing

\bibitem{liu2022few}
H.~Liu, D.~Tam, M.~Muqeeth, J.~Mohta, T.~Huang, M.~Bansal, and C.~A. Raffel, ``Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning,'' \emph{Advances in Neural Information Processing Systems}, vol.~35, pp. 1950--1965, 2022.

\bibitem{pires2023sabia}
R.~Pires, H.~Abonizio, T.~S. Almeida, and R.~Nogueira, ``Sabi\'a: Portuguese large language models,'' 2023.

\bibitem{sengupta2023jais}
N.~Sengupta, S.~K. Sahu, B.~Jia, S.~Katipomu, H.~Li, F.~Koto, O.~M. Afzal, S.~Kamboj, O.~Pandit, R.~Pal \emph{et~al.}, ``Jais and jais-chat: Arabic-centric foundation and instruction-tuned open generative large language models,'' \emph{arXiv preprint arXiv:2308.16149}, 2023.

\bibitem{Nemeskey:2020}
\BIBentryALTinterwordspacing
D.~M. Nemeskey, ``Natural language processing methods for language modeling,'' Ph.D. dissertation, E\"otv\"os Lor\'and University, 2020. [Online]. Available: \url{https://hlt.bme.hu/media/pdf/nemeskey_thesis.pdf}
\BIBentrySTDinterwordspacing

\bibitem{nivre-etal-2016-universal}
\BIBentryALTinterwordspacing
J.~Nivre, M.-C. de~Marneffe, F.~Ginter, Y.~Goldberg, J.~Haji{\v{c}}, C.~D. Manning, R.~McDonald, S.~Petrov, S.~Pyysalo, N.~Silveira, R.~Tsarfaty, and D.~Zeman, ``{U}niversal {D}ependencies v1: A multilingual treebank collection,'' in \emph{Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)}.\hskip 1em plus 0.5em minus 0.4em\relax Portoro{\v{z}}, Slovenia: European Language Resources Association (ELRA), May 2016, pp. 1659--1666. [Online]. Available: \url{https://aclanthology.org/L16-1262}
\BIBentrySTDinterwordspacing

\bibitem{vincze-etal-2010-hungarian}
\BIBentryALTinterwordspacing
V.~Vincze, D.~Szauter, A.~Alm{\'a}si, G.~M{\'o}ra, Z.~Alexin, and J.~Csirik, ``{H}ungarian dependency treebank,'' in \emph{Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)}.\hskip 1em plus 0.5em minus 0.4em\relax Valletta, Malta: European Language Resources Association (ELRA), May 2010. [Online]. Available: \url{http://www.lrec-conf.org/proceedings/lrec2010/pdf/465_Paper.pdf}
\BIBentrySTDinterwordspacing

\bibitem{zeman-etal-2017-conll}
\BIBentryALTinterwordspacing
D.~Zeman, M.~Popel, M.~Straka, J.~Haji{\v{c}}, J.~Nivre, F.~Ginter, J.~Luotolahti, S.~Pyysalo, S.~Petrov, M.~Potthast, F.~Tyers, E.~Badmaeva, M.~Gokirmak, A.~Nedoluzhko, S.~Cinkov{\'a}, J.~Haji{\v{c}}~jr., J.~Hlav{\'a}{\v{c}}ov{\'a}, V.~Kettnerov{\'a}, Z.~Ure{\v{s}}ov{\'a}, J.~Kanerva, S.~Ojala, A.~Missil{\"a}, C.~D. Manning, S.~Schuster, S.~Reddy, D.~Taji, N.~Habash, H.~Leung, M.-C. de~Marneffe, M.~Sanguinetti, M.~Simi, H.~Kanayama, V.~de~Paiva, K.~Droganova, H.~Mart{\'\i}nez~Alonso, {\c{C}}.~{\c{C}}{\"o}ltekin, U.~Sulubacak, H.~Uszkoreit, V.~Macketanz, A.~Burchardt, K.~Harris, K.~Marheinecke, G.~Rehm, T.~Kayadelen, M.~Attia, A.~Elkahky, Z.~Yu, E.~Pitler, S.~Lertpradit, M.~Mandl, J.~Kirchner, H.~F. Alcalde, J.~Strnadov{\'a}, E.~Banerjee, R.~Manurung, A.~Stella, A.~Shimada, S.~Kwak, G.~Mendon{\c{c}}a, T.~Lando, R.~Nitisaroj, and J.~Li, ``{C}o{NLL} 2017 shared task: Multilingual parsing from raw text to {U}niversal {D}ependencies,'' in \emph{Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing
  from Raw Text to Universal Dependencies}.\hskip 1em plus 0.5em minus 0.4em\relax Vancouver, Canada: Association for Computational Linguistics, Aug. 2017, pp. 1--19. [Online]. Available: \url{https://aclanthology.org/K17-3001}
\BIBentrySTDinterwordspacing

\bibitem{silveira14gold}
N.~Silveira, T.~Dozat, M.-C. de~Marneffe, S.~Bowman, M.~Connor, J.~Bauer, and C.~D. Manning, ``A gold standard dependency corpus for {E}nglish,'' in \emph{Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014)}, 2014.

\bibitem{gao2020pile}
L.~Gao, S.~Biderman, S.~Black, L.~Golding, T.~Hoppe, C.~Foster, J.~Phang, H.~He, A.~Thite, N.~Nabeshima, S.~Presser, and C.~Leahy, ``The pile: An 800gb dataset of diverse text for language modeling,'' 2020.

\bibitem{raffel2023exploring}
C.~Raffel, N.~Shazeer, A.~Roberts, K.~Lee, S.~Narang, M.~Matena, Y.~Zhou, W.~Li, and P.~J. Liu, ``Exploring the limits of transfer learning with a unified text-to-text transformer,'' 2023.

\bibitem{longpre2023flan}
S.~Longpre, L.~Hou, T.~Vu, A.~Webson, H.~W. Chung, Y.~Tay, D.~Zhou, Q.~V. Le, B.~Zoph, J.~Wei \emph{et~al.}, ``The flan collection: Designing data and methods for effective instruction tuning,'' \emph{arXiv preprint arXiv:2301.13688}, 2023.

\bibitem{Nguyen_2023}
\BIBentryALTinterwordspacing
H.~Nguyen, ``The oig dataset,'' Mar 2023. [Online]. Available: \url{https://laion.ai/blog/oig-dataset/}
\BIBentrySTDinterwordspacing

\bibitem{iyer2023optiml}
S.~Iyer, X.~V. Lin, R.~Pasunuru, T.~Mihaylov, D.~Simig, P.~Yu, K.~Shuster, T.~Wang, Q.~Liu, P.~S. Koura, X.~Li, B.~O'Horo, G.~Pereyra, J.~Wang, C.~Dewan, A.~Celikyilmaz, L.~Zettlemoyer, and V.~Stoyanov, ``Opt-iml: Scaling language model instruction meta learning through the lens of generalization,'' 2023.

\bibitem{abadji2022cleaner}
J.~Abadji, P.~O. Suarez, L.~Romary, and B.~Sagot, ``Towards a cleaner document-oriented multilingual crawled corpus,'' 2022.

\bibitem{xue-etal-2021-mt5}
\BIBentryALTinterwordspacing
L.~Xue, N.~Constant, A.~Roberts, M.~Kale, R.~Al-Rfou, A.~Siddhant, A.~Barua, and C.~Raffel, ``m{T}5: A massively multilingual pre-trained text-to-text transformer,'' in \emph{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}.\hskip 1em plus 0.5em minus 0.4em\relax Online: Association for Computational Linguistics, Jun. 2021, pp. 483--498. [Online]. Available: \url{https://aclanthology.org/2021.naacl-main.41}
\BIBentrySTDinterwordspacing

\bibitem{wenzek2019ccnet}
G.~Wenzek, M.-A. Lachaux, A.~Conneau, V.~Chaudhary, F.~Guzmán, A.~Joulin, and E.~Grave, ``Ccnet: Extracting high quality monolingual datasets from web crawl data,'' 2019.

\bibitem{chenghao_mou_2023_8364980}
\BIBentryALTinterwordspacing
C.~Mou, C.~Ha, K.~Enevoldsen, and P.~Liu, ``Chenghaomou/text-dedup: Reference snapshot,'' Sep. 2023. [Online]. Available: \url{https://doi.org/10.5281/zenodo.8364980}
\BIBentrySTDinterwordspacing

\bibitem{666900}
A.~Broder, ``On the resemblance and containment of documents,'' in \emph{Proceedings. Compression and Complexity of SEQUENCES 1997 (Cat. No.97TB100171)}, 1997, pp. 21--29.

\bibitem{Nomoto2019InterpersonalMA}
\BIBentryALTinterwordspacing
H.~Nomoto, ``Interpersonal meaning annotation for asian language corpora: The case of tufs asian language parallel corpus (talpco),'' 2019. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:209441604}
\BIBentrySTDinterwordspacing

\bibitem{BuschbeckWolf2020APE}
\BIBentryALTinterwordspacing
B.~Buschbeck-Wolf and M.~Exel, ``A parallel evaluation data set of software documentation with document structure annotation,'' in \emph{Workshop on Asian Translation}, 2020. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:221095497}
\BIBentrySTDinterwordspacing

\bibitem{Riza2016IntroductionOT}
\BIBentryALTinterwordspacing
H.~Riza, M.~Purwoadi, Gunarso, T.~Uliniansyah, A.~A. Ti, S.~M. Aljunied, L.~C. Mai, V.~T. Thang, N.~P. Thai, V.~Chea, R.~Sun, S.~Sam, S.~Seng, K.~M. Soe, K.~T. Nwet, M.~Utiyama, and C.~Ding, ``Introduction of the asian language treebank,'' \emph{2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA)}, pp. 1--6, 2016. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:45848332}
\BIBentrySTDinterwordspacing

\bibitem{Ladhak2020WikiLinguaAN}
\BIBentryALTinterwordspacing
F.~Ladhak, E.~Durmus, C.~Cardie, and K.~McKeown, ``Wikilingua: A new benchmark dataset for multilingual abstractive summarization,'' \emph{ArXiv}, vol. abs/2010.03093, 2020. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:222177239}
\BIBentrySTDinterwordspacing

\bibitem{cettolo-etal-2012-wit3}
\BIBentryALTinterwordspacing
M.~Cettolo, C.~Girardi, and M.~Federico, ``{WIT}3: Web inventory of transcribed and translated talks,'' in \emph{Proceedings of the 16th Annual conference of the European Association for Machine Translation}.\hskip 1em plus 0.5em minus 0.4em\relax Trento, Italy: European Association for Machine Translation, May 28{--}30 "2012", pp. 261--268. [Online]. Available: \url{https://www.aclweb.org/anthology/2012.eamt-1.60}
\BIBentrySTDinterwordspacing

\bibitem{team2022NoLL}
\BIBentryALTinterwordspacing
N.~team, M.~R. Costa-juss{\`a}, J.~Cross, O.~cCelebi, M.~Elbayad, K.~Heafield, K.~Heffernan, E.~Kalbassi, J.~Lam, D.~Licht, J.~Maillard, A.~Sun, S.~Wang, G.~Wenzek, A.~Youngblood, B.~Akula, L.~Barrault, G.~M. Gonzalez, P.~Hansanti, J.~Hoffman, S.~Jarrett, K.~R. Sadagopan, D.~Rowe, S.~L. Spruit, C.~Tran, P.~Y. Andrews, N.~F. Ayan, S.~Bhosale, S.~Edunov, A.~Fan, C.~Gao, V.~Goswami, F.~Guzm'an, P.~Koehn, A.~Mourachko, C.~Ropers, S.~Saleem, H.~Schwenk, and J.~Wang, ``No language left behind: Scaling human-centered machine translation,'' \emph{ArXiv}, vol. abs/2207.04672, 2022. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:250425961}
\BIBentrySTDinterwordspacing

\bibitem{Conneau2018XNLIEC}
\BIBentryALTinterwordspacing
A.~Conneau, G.~Lample, R.~Rinott, A.~Williams, S.~R. Bowman, H.~Schwenk, and V.~Stoyanov, ``Xnli: Evaluating cross-lingual sentence representations,'' in \emph{Conference on Empirical Methods in Natural Language Processing}, 2018. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:52271711}
\BIBentrySTDinterwordspacing

\bibitem{Artetxe:etal:2019}
M.~Artetxe, S.~Ruder, and D.~Yogatama, ``On the cross-lingual transferability of monolingual representations,'' \emph{CoRR}, vol. abs/1910.11856, 2019.

\bibitem{kobkrit_viriyayudhakorn_2021_4539916}
\BIBentryALTinterwordspacing
K.~Viriyayudhakorn and C.~Polpanumas, ``iapp\_wiki\_qa\_squad,'' Feb. 2021. [Online]. Available: \url{https://doi.org/10.5281/zenodo.4539916}
\BIBentrySTDinterwordspacing

\bibitem{bact_2019_3457447}
\BIBentryALTinterwordspacing
A.~Suriyawongkul, E.~Chuangsuwanich, P.~Chormai, and C.~Polpanumas, ``Pythainlp/wisesight-sentiment: First release,'' Sep. 2019. [Online]. Available: \url{https://doi.org/10.5281/zenodo.3457447}
\BIBentrySTDinterwordspacing

\bibitem{chumpolsathien_2020}
N.~Chumpolsathien, ``Using knowledge distillation from keyword extraction to improve the informativeness of neural cross-lingual summarization,'' Master's thesis, Beijing Institute of Technology, 2020.

\bibitem{hasan-etal-2021-xl}
\BIBentryALTinterwordspacing
T.~Hasan, A.~Bhattacharjee, M.~S. Islam, K.~Mubasshir, Y.-F. Li, Y.-B. Kang, M.~S. Rahman, and R.~Shahriyar, ``{XL}-sum: Large-scale multilingual abstractive summarization for 44 languages,'' in \emph{Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021}.\hskip 1em plus 0.5em minus 0.4em\relax Online: Association for Computational Linguistics, Aug. 2021, pp. 4693--4703. [Online]. Available: \url{https://aclanthology.org/2021.findings-acl.413}
\BIBentrySTDinterwordspacing

\bibitem{alpaca}
R.~Taori, I.~Gulrajani, T.~Zhang, Y.~Dubois, X.~Li, C.~Guestrin, P.~Liang, and T.~B. Hashimoto, ``Stanford alpaca: An instruction-following llama model,'' \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem{DatabricksBlog2023DollyV2}
\BIBentryALTinterwordspacing
M.~Conover, M.~Hayes, A.~Mathur, J.~Xie, J.~Wan, S.~Shah, A.~Ghodsi, P.~Wendell, M.~Zaharia, and R.~Xin. (2023) Free dolly: Introducing the world's first truly open instruction-tuned llm. [Online]. Available: \url{https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm}
\BIBentrySTDinterwordspacing

\bibitem{guo-etal-2023-hc3}
B.~Guo, X.~Zhang, Z.~Wang, M.~Jiang, J.~Nie, Y.~Ding, J.~Yue, and Y.~Wu, ``How close is chatgpt to human experts? comparison corpus, evaluation, and detection,'' \emph{arXiv preprint arxiv:2301.07597}, 2023.

\bibitem{Kopf2023OpenAssistantC}
\BIBentryALTinterwordspacing
A.~Kopf, Y.~Kilcher, D.~von Rutte, S.~Anagnostidis, Z.~R. Tam, K.~Stevens, A.~Barhoum, N.~M. Duc, O.~Stanley, R.~Nagyfi, E.~Shahul, S.~Suri, D.~Glushkov, A.~Dantuluri, A.~Maguire, C.~Schuhmann, H.~Nguyen, and A.~Mattick, ``Openassistant conversations - democratizing large language model alignment,'' \emph{ArXiv}, vol. abs/2304.07327, 2023. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:258179434}
\BIBentrySTDinterwordspacing

\bibitem{9567250}
R.~Prabhakar and S.~Jairath, ``Sambanova sn10 rdu:accelerating software 2.0 with dataflow,'' in \emph{2021 IEEE Hot Chips 33 Symposium (HCS)}, 2021, pp. 1--37.

\bibitem{eval-harness}
\BIBentryALTinterwordspacing
L.~Gao, J.~Tow, S.~Biderman, S.~Black, A.~DiPofi, C.~Foster, L.~Golding, J.~Hsu, K.~McDonell, N.~Muennighoff, J.~Phang, L.~Reynolds, E.~Tang, A.~Thite, B.~Wang, K.~Wang, and A.~Zou, ``A framework for few-shot language model evaluation,'' Sep. 2021. [Online]. Available: \url{https://doi.org/10.5281/zenodo.5371628}
\BIBentrySTDinterwordspacing

\bibitem{paperno2016lambada}
D.~Paperno, G.~Kruszewski, A.~Lazaridou, Q.~N. Pham, R.~Bernardi, S.~Pezzelle, M.~Baroni, G.~Boleda, and R.~Fernández, ``The lambada dataset: Word prediction requiring a broad discourse context,'' 2016.

\bibitem{zellers2019hellaswag}
R.~Zellers, A.~Holtzman, Y.~Bisk, A.~Farhadi, and Y.~Choi, ``Hellaswag: Can a machine really finish your sentence?'' in \emph{Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, 2019.

\bibitem{mihaylov2018suit}
T.~Mihaylov, P.~Clark, T.~Khot, and A.~Sabharwal, ``Can a suit of armor conduct electricity? a new dataset for open book question answering,'' 2018.

\bibitem{clark2019boolq}
C.~Clark, K.~Lee, M.-W. Chang, T.~Kwiatkowski, M.~Collins, and K.~Toutanova, ``Boolq: Exploring the surprising difficulty of natural yes/no questions,'' 2019.

\bibitem{clark2018think}
P.~Clark, I.~Cowhey, O.~Etzioni, T.~Khot, A.~Sabharwal, C.~Schoenick, and O.~Tafjord, ``Think you have solved question answering? try arc, the ai2 reasoning challenge,'' 2018.

\bibitem{bisk2019piqa}
Y.~Bisk, R.~Zellers, R.~L. Bras, J.~Gao, and Y.~Choi, ``Piqa: Reasoning about physical commonsense in natural language,'' 2019.

\bibitem{nie2020adversarial}
Y.~Nie, A.~Williams, E.~Dinan, M.~Bansal, J.~Weston, and D.~Kiela, ``Adversarial nli: A new benchmark for natural language understanding,'' 2020.

\bibitem{sakaguchi2019winogrande}
K.~Sakaguchi, R.~L. Bras, C.~Bhagavatula, and Y.~Choi, ``Winogrande: An adversarial winograd schema challenge at scale,'' 2019.

\bibitem{ligetinagy2022hulu}
N.~Ligeti-Nagy, G.~Ferenczi, E.~Héja, K.~Jelencsik-Mátyus, L.~J. Laki, N.~Vadász, Z.~G. Yang, and T.~Vadász, ``Hulu: magyar nyelvű benchmark adatbázis kiépítése a neurális nyelvmodellek kiértékelése céljából,'' in \emph{XVIII. Magyar Számítógépes Nyelvészeti Konferencia}, 2022, pp. 431--446.

\bibitem{ponti2020xcopa}
\BIBentryALTinterwordspacing
E.~M. Ponti, G.~G. {s}, O.~Majewska, Q.~Liu, I.~Vuli'{c}, and A.~Korhonen, ``{XCOPA: A} multilingual dataset for causal commonsense reasoning,'' \emph{arXiv preprint}, 2020. [Online]. Available: \url{https://ducdauge.github.io/files/xcopa.pdf}
\BIBentrySTDinterwordspacing

\bibitem{MultiRC2018}
D.~Khashabi, S.~Chaturvedi, M.~Roth, S.~Upadhyay, and D.~Roth, ``Looking beyond the surface:a challenge set for reading comprehension over multiple sentences,'' in \emph{Proceedings of North American Chapter of the Association for Computational Linguistics (NAACL)}, 2018.

\bibitem{wang2019superglue}
A.~Wang, Y.~Pruksachatkun, N.~Nangia, A.~Singh, J.~Michael, F.~Hill, O.~Levy, and S.~R. Bowman, ``Superglue: A stickier benchmark for general-purpose language understanding systems,'' \emph{arXiv preprint arXiv:1905.00537}, 2019.

\bibitem{47761}
T.~Kwiatkowski, J.~Palomaki, O.~Redfield, M.~Collins, A.~Parikh, C.~Alberti, D.~Epstein, I.~Polosukhin, M.~Kelcey, J.~Devlin, K.~Lee, K.~N. Toutanova, L.~Jones, M.-W. Chang, A.~Dai, J.~Uszkoreit, Q.~Le, and S.~Petrov, ``Natural questions: a benchmark for question answering research,'' \emph{Transactions of the Association of Computational Linguistics}, 2019.

\bibitem{Zhang2018ReCoRDBT}
\BIBentryALTinterwordspacing
S.~Zhang, X.~Liu, J.~Liu, J.~Gao, K.~Duh, and B.~V. Durme, ``Record: Bridging the gap between human and machine commonsense reading comprehension,'' \emph{ArXiv}, vol. abs/1810.12885, 2018. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:53116244}
\BIBentrySTDinterwordspacing

\bibitem{narayan2018dont}
S.~Narayan, S.~B. Cohen, and M.~Lapata, ``Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization,'' 2018.

\end{thebibliography}
