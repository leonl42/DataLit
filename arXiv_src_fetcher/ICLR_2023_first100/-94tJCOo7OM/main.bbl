\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbate et~al.(2021)Abbate, Conlin, and Kolemen]{abbate2021data}
Joseph Abbate, Rory Conlin, and Egemen Kolemen.
\newblock Data-driven profile prediction for diii-d.
\newblock \emph{Nuclear Fusion}, 61\penalty0 (4):\penalty0 046027, 2021.

\bibitem[AlphaProof \& AlphaGeometry(2024)AlphaProof and AlphaGeometry]{deepmind2024ai}
AlphaProof and AlphaGeometry.
\newblock Ai achieves silver-medal standard solving international mathematical olympiad problems.
\newblock \url{https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/}, 2024.
\newblock Accessed: 2024-09-28.

\bibitem[Antonoglou et~al.(2022)Antonoglou, Schrittwieser, Ozair, Hubert, and Silver]{DBLP:conf/iclr/AntonoglouSOHS22}
Ioannis Antonoglou, Julian Schrittwieser, Sherjil Ozair, Thomas~K. Hubert, and David Silver.
\newblock Planning in stochastic environments with a learned model.
\newblock In \emph{International Conference on Learning Representations}. OpenReview.net, 2022.

\bibitem[Argenson \& Dulac{-}Arnold(2021)Argenson and Dulac{-}Arnold]{DBLP:conf/iclr/ArgensonD21}
Arthur Argenson and Gabriel Dulac{-}Arnold.
\newblock Model-based offline planning.
\newblock In \emph{International Conference on Learning Representations}. OpenReview.net, 2021.

\bibitem[Ariola et~al.(2008)Ariola, Pironti, et~al.]{ariola2008magnetic}
Marco Ariola, Alfredo Pironti, et~al.
\newblock \emph{Magnetic control of tokamak plasmas}, volume 187.
\newblock Springer, 2008.

\bibitem[Asmuth \& Littman(2011)Asmuth and Littman]{asmuth2011approaching}
John Asmuth and Michael~L Littman.
\newblock Approaching bayes-optimalilty using monte-carlo tree search.
\newblock In \emph{International Conference on Automated Planning and Scheduling}, 2011.

\bibitem[Asmuth et~al.(2009)Asmuth, Li, Littman, Nouri, and Wingate]{DBLP:conf/uai/AsmuthLLNW09}
John Asmuth, Lihong Li, Michael~L. Littman, Ali Nouri, and David Wingate.
\newblock A bayesian sampling approach to exploration in reinforcement learning.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pp.\  19--26. {AUAI} Press, 2009.

\bibitem[Auger et~al.(2013)Auger, Cou{\"{e}}toux, and Teytaud]{DBLP:conf/pkdd/AugerCT13}
David Auger, Adrien Cou{\"{e}}toux, and Olivier Teytaud.
\newblock Continuous upper confidence trees with polynomial exploration - consistency.
\newblock In \emph{European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases}, volume 8188, pp.\  194--209. Springer, 2013.

\bibitem[Bertsekas \& Casta{\~{n}}{\'{o}}n(1999)Bertsekas and Casta{\~{n}}{\'{o}}n]{DBLP:journals/heuristics/BertsekasC99}
Dimitri~P. Bertsekas and David~A. Casta{\~{n}}{\'{o}}n.
\newblock Rollout algorithms for stochastic scheduling problems.
\newblock \emph{Journal of Heuristics}, 5\penalty0 (1):\penalty0 89--108, 1999.

\bibitem[Browne et~al.(2012)Browne, Powley, Whitehouse, Lucas, Cowling, Rohlfshagen, Tavener, Perez, Samothrakis, and Colton]{browne2012survey}
Cameron~B Browne, Edward Powley, Daniel Whitehouse, Simon~M Lucas, Peter~I Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis, and Simon Colton.
\newblock A survey of monte carlo tree search methods.
\newblock \emph{IEEE Transactions on Computational Intelligence and AI in Games}, 4\penalty0 (1):\penalty0 1--43, 2012.

\bibitem[Castro \& Precup(2010)Castro and Precup]{DBLP:conf/pkdd/CastroP10}
Pablo~Samuel Castro and Doina Precup.
\newblock Smarter sampling in model-based bayesian reinforcement learning.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge Discovery in Databases}, volume 6321, pp.\  200--214. Springer, 2010.

\bibitem[Char et~al.(2023)Char, Abbate, Bardoczi, Boyer, Chung, Conlin, Erickson, Mehta, Richner, Kolemen, and Schneider]{DBLP:conf/l4dc/CharABBCCEMRKS23}
Ian Char, Joseph Abbate, Laszlo Bardoczi, Mark~D. Boyer, Youngseog Chung, Rory Conlin, Keith Erickson, Viraj Mehta, Nathan Richner, Egemen Kolemen, and Jeff~G. Schneider.
\newblock Offline model-based reinforcement learning for tokamak control.
\newblock In \emph{Learning for Dynamics and Control Conference}, volume 211, pp.\  1357--1372, 2023.

\bibitem[Char et~al.(2024)Char, Chung, Abbate, Kolemen, and Schneider]{DBLP:journals/corr/abs-2404-12416}
Ian Char, Youngseog Chung, Joseph Abbate, Egemen Kolemen, and Jeff~G. Schneider.
\newblock Full shot predictions for the {DIII-D} tokamak via deep recurrent networks.
\newblock \emph{CoRR}, abs/2404.12416, 2024.

\bibitem[Chen et~al.(2023)Chen, Lan, and Aggarwal]{DBLP:journals/corr/abs-2305-17327}
Jiayu Chen, Tian Lan, and Vaneet Aggarwal.
\newblock Hierarchical deep counterfactual regret minimization.
\newblock \emph{CoRR}, abs/2305.17327, 2023.

\bibitem[Chen et~al.(2024)Chen, Ganguly, Xu, Mei, Lan, and Aggarwal]{DBLP:journals/corr/abs-2402-13777}
Jiayu Chen, Bhargav Ganguly, Yang Xu, Yongsheng Mei, Tian Lan, and Vaneet Aggarwal.
\newblock Deep generative models for offline policy learning: Tutorial, survey, and perspectives on future directions.
\newblock \emph{Transactions on Machine Learning Research}, 2024.
\newblock ISSN 2835-8856.

\bibitem[Cou{\"{e}}toux et~al.(2011)Cou{\"{e}}toux, Hoock, Sokolovska, Teytaud, and Bonnard]{DBLP:conf/lion/CouetouxHSTB11}
Adrien Cou{\"{e}}toux, Jean{-}Baptiste Hoock, Nataliya Sokolovska, Olivier Teytaud, and Nicolas Bonnard.
\newblock Continuous upper confidence trees.
\newblock In \emph{International Conference on Learning and Intelligent Optimization}, volume 6683, pp.\  433--445. Springer, 2011.

\bibitem[Danihelka et~al.(2022)Danihelka, Guez, Schrittwieser, and Silver]{DBLP:conf/iclr/DanihelkaGSS22}
Ivo Danihelka, Arthur Guez, Julian Schrittwieser, and David Silver.
\newblock Policy improvement by planning with gumbel.
\newblock In \emph{International Conference on Learning Representations}. OpenReview.net, 2022.

\bibitem[Diehl et~al.(2023)Diehl, Sievernich, Kr{\"{u}}ger, Hoffmann, and Bertram]{DBLP:journals/ral/DiehlSKHB23}
Christopher Diehl, Timo Sievernich, Martin Kr{\"{u}}ger, Frank Hoffmann, and Torsten Bertram.
\newblock Uncertainty-aware model-based offline reinforcement learning for automated driving.
\newblock \emph{{IEEE} Robotics Automation Letters}, 8\penalty0 (2):\penalty0 1167--1174, 2023.

\bibitem[Duff(2002)]{duff2002optimal}
Michael~O'Gordon Duff.
\newblock \emph{Optimal Learning: Computational procedures for Bayes-adaptive Markov decision processes}.
\newblock University of Massachusetts Amherst, 2002.

\bibitem[Fonteneau et~al.(2013)Fonteneau, Busoniu, and Munos]{DBLP:conf/adprl/FonteneauBM13}
Rapha{\"{e}}l Fonteneau, Lucian Busoniu, and R{\'{e}}mi Munos.
\newblock Optimistic planning for belief-augmented markov decision processes.
\newblock In \emph{{IEEE} Symposium on Adaptive Dynamic Programming and Reinforcement Learning}, pp.\  77--84. {IEEE}, 2013.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{DBLP:journals/corr/abs-2004-07219}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock {D4RL:} datasets for deep data-driven reinforcement learning.
\newblock \emph{CoRR}, abs/2004.07219, 2020.

\bibitem[Garcia et~al.(1989)Garcia, Prett, and Morari]{garcia1989model}
Carlos~E Garcia, David~M Prett, and Manfred Morari.
\newblock Model predictive control: Theory and practice—a survey.
\newblock \emph{Automatica}, 25\penalty0 (3):\penalty0 335--348, 1989.

\bibitem[Ghavamzadeh et~al.(2015)Ghavamzadeh, Mannor, Pineau, and Tamar]{DBLP:journals/ftml/GhavamzadehMPT15}
Mohammad Ghavamzadeh, Shie Mannor, Joelle Pineau, and Aviv Tamar.
\newblock Bayesian reinforcement learning: {A} survey.
\newblock \emph{Foundations and Trends® in Machine Learning}, 8\penalty0 (5-6):\penalty0 359--483, 2015.

\bibitem[Ghosh et~al.(2022)Ghosh, Ajay, Agrawal, and Levine]{DBLP:conf/icml/GhoshAAL22}
Dibya Ghosh, Anurag Ajay, Pulkit Agrawal, and Sergey Levine.
\newblock Offline {RL} policies should be trained to be adaptive.
\newblock In \emph{International Conference on Machine Learning}, volume 162, pp.\  7513--7530. {PMLR}, 2022.

\bibitem[Guez et~al.(2013)Guez, Silver, and Dayan]{DBLP:journals/jair/GuezSD13}
Arthur Guez, David Silver, and Peter Dayan.
\newblock Scalable and efficient bayes-adaptive reinforcement learning based on monte-carlo tree search.
\newblock \emph{Journal of Artificial Intelligence Research}, 48:\penalty0 841--883, 2013.

\bibitem[Guez et~al.(2014)Guez, Heess, Silver, and Dayan]{DBLP:conf/nips/GuezHSD14}
Arthur Guez, Nicolas Heess, David Silver, and Peter Dayan.
\newblock Bayes-adaptive simulation-based search with value function approximation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  451--459, 2014.

\bibitem[Guo et~al.(2022)Guo, Shao, and Geng]{DBLP:conf/nips/GuoSG22}
Kaiyang Guo, Yunfeng Shao, and Yanhui Geng.
\newblock Model-based offline reinforcement learning with pessimism-modulated dynamics belief.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and Levine]{DBLP:conf/icml/HaarnojaZAL18}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.
\newblock In \emph{International Conference on Machine Learning}, volume~80, pp.\  1856--1865. {PMLR}, 2018.

\bibitem[Hamrick et~al.(2021)Hamrick, Friesen, Behbahani, Guez, Viola, Witherspoon, Anthony, Buesing, Velickovic, and Weber]{DBLP:conf/iclr/HamrickFBGVWABV21}
Jessica~B. Hamrick, Abram~L. Friesen, Feryal M.~P. Behbahani, Arthur Guez, Fabio Viola, Sims Witherspoon, Thomas Anthony, Lars~Holger Buesing, Petar Velickovic, and Theophane Weber.
\newblock On the role of planning in model-based deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}. OpenReview.net, 2021.

\bibitem[Hoang \& Vien(2020)Hoang and Vien]{DBLP:journals/corr/abs-2010-15948}
Tai Hoang and Ngo~Anh Vien.
\newblock Bayes-adaptive deep model-based policy optimisation.
\newblock \emph{CoRR}, abs/2010.15948, 2020.

\bibitem[Hubert et~al.(2021)Hubert, Schrittwieser, Antonoglou, Barekatain, Schmitt, and Silver]{DBLP:conf/icml/HubertSABSS21}
Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Mohammadamin Barekatain, Simon Schmitt, and David Silver.
\newblock Learning and planning in complex action spaces.
\newblock In \emph{International Conference on Machine Learning}, volume 139 of \emph{Proceedings of Machine Learning Research}, pp.\  4476--4486. {PMLR}, 2021.

\bibitem[Kidambi et~al.(2020)Kidambi, Rajeswaran, Netrapalli, and Joachims]{DBLP:conf/nips/KidambiRNJ20}
Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli, and Thorsten Joachims.
\newblock Morel: Model-based offline reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Kocsis \& Szepesv{\'{a}}ri(2006)Kocsis and Szepesv{\'{a}}ri]{DBLP:conf/ecml/KocsisS06}
Levente Kocsis and Csaba Szepesv{\'{a}}ri.
\newblock Bandit based monte-carlo planning.
\newblock In \emph{European Conference on Machine Learning}, volume 4212, pp.\  282--293. Springer, 2006.

\bibitem[Kumar et~al.(2019)Kumar, Fu, Soh, Tucker, and Levine]{DBLP:conf/nips/KumarFSTL19}
Aviral Kumar, Justin Fu, Matthew Soh, George Tucker, and Sergey Levine.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  11761--11771, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{DBLP:conf/nips/KumarZTL20}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and Blundell]{DBLP:conf/nips/Lakshminarayanan17}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep ensembles.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  6402--6413, 2017.

\bibitem[Lee et~al.(2020)Lee, Jeon, Kim, and Kim]{DBLP:conf/aaai/LeeJKK20}
Jongmin Lee, Wonseok Jeon, Geon{-}Hyeong Kim, and Kee{-}Eung Kim.
\newblock Monte-carlo tree search in continuous action spaces with value gradients.
\newblock In \emph{The Thirty-Fourth {AAAI} Conference on Artificial Intelligence}, pp.\  4561--4568. {AAAI} Press, 2020.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{DBLP:journals/corr/abs-2005-01643}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on open problems.
\newblock \emph{CoRR}, abs/2005.01643, 2020.

\bibitem[Littman(2009)]{littman2009tutorial}
Michael~L Littman.
\newblock A tutorial on partially observable markov decision processes.
\newblock \emph{Journal of Mathematical Psychology}, 53\penalty0 (3):\penalty0 119--125, 2009.

\bibitem[Liu et~al.(2023)Liu, Li, Lee, Yan, and Xu]{DBLP:conf/iclr/LiuLLYX23}
Zichen Liu, Siyi Li, Wee~Sun Lee, Shuicheng Yan, and Zhongwen Xu.
\newblock Efficient offline policy optimization with a learned model.
\newblock In \emph{International Conference on Learning Representations}. OpenReview.net, 2023.

\bibitem[Lu et~al.(2022)Lu, Ball, Parker{-}Holder, Osborne, and Roberts]{DBLP:conf/iclr/LuBPOR22}
Cong Lu, Philip~J. Ball, Jack Parker{-}Holder, Michael~A. Osborne, and Stephen~J. Roberts.
\newblock Revisiting design choices in offline model based reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}. OpenReview.net, 2022.

\bibitem[Ma{\'c}kiewicz \& Ratajczak(1993)Ma{\'c}kiewicz and Ratajczak]{mackiewicz1993principal}
Andrzej Ma{\'c}kiewicz and Waldemar Ratajczak.
\newblock Principal components analysis (pca).
\newblock \emph{Computers \& Geosciences}, 19\penalty0 (3):\penalty0 303--342, 1993.

\bibitem[Niu et~al.(2023)Niu, Pu, Yang, Li, Zhou, Ren, Hu, Li, and Liu]{DBLP:conf/nips/NiuPYLZRHLL23}
Yazhe Niu, Yuan Pu, Zhenjie Yang, Xueyan Li, Tong Zhou, Jiyuan Ren, Shuai Hu, Hongsheng Li, and Yu~Liu.
\newblock Lightzero: {A} unified benchmark for monte carlo tree search in general sequential decision scenarios.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Oren et~al.(2022)Oren, Spaan, and B{\"o}hmer]{oren2022mcts}
Yaniv Oren, Matthijs~TJ Spaan, and Wendelin B{\"o}hmer.
\newblock E-mcts: Deep exploration in model-based reinforcement learning by planning with epistemic uncertainty.
\newblock \emph{arXiv preprint arXiv:2210.13455}, 2022.

\bibitem[Pironti \& Walker(2005)Pironti and Walker]{1512794}
A.~Pironti and M.~Walker.
\newblock Fusion, tokamaks, and plasma control: an introduction and tutorial.
\newblock \emph{IEEE Control Systems Magazine}, 25\penalty0 (5):\penalty0 30--43, 2005.

\bibitem[Puterman(2014)]{puterman2014markov}
Martin~L Puterman.
\newblock \emph{Markov decision processes: discrete stochastic dynamic programming}.
\newblock John Wiley \& Sons, 2014.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan, Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel, Lillicrap, and Silver]{DBLP:journals/nature/SchrittwieserAH20}
Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, Timothy~P. Lillicrap, and David Silver.
\newblock Mastering atari, go, chess and shogi by planning with a learned model.
\newblock \emph{Nature}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Schrittwieser et~al.(2021)Schrittwieser, Hubert, Mandhane, Barekatain, Antonoglou, and Silver]{DBLP:conf/nips/SchrittwieserHM21}
Julian Schrittwieser, Thomas Hubert, Amol Mandhane, Mohammadamin Barekatain, Ioannis Antonoglou, and David Silver.
\newblock Online and offline reinforcement learning by planning with a learned model.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  27580--27591, 2021.

\bibitem[Silver et~al.(2017{\natexlab{a}})Silver, Hubert, Schrittwieser, Antonoglou, Lai, Guez, Lanctot, Sifre, Kumaran, Graepel, Lillicrap, Simonyan, and Hassabis]{DBLP:journals/corr/abs-1712-01815}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy~P. Lillicrap, Karen Simonyan, and Demis Hassabis.
\newblock Mastering chess and shogi by self-play with a general reinforcement learning algorithm.
\newblock \emph{CoRR}, abs/1712.01815, 2017{\natexlab{a}}.

\bibitem[Silver et~al.(2017{\natexlab{b}})Silver, Schrittwieser, Simonyan, Antonoglou, Huang, Guez, Hubert, Baker, Lai, Bolton, Chen, Lillicrap, Hui, Sifre, van~den Driessche, Graepel, and Hassabis]{DBLP:journals/nature/SilverSSAHGHBLB17}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy~P. Lillicrap, Fan Hui, Laurent Sifre, George van~den Driessche, Thore Graepel, and Demis Hassabis.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nat.}, 550\penalty0 (7676):\penalty0 354--359, 2017{\natexlab{b}}.

\bibitem[Slade et~al.(2020)Slade, Sunberg, and Kochenderfer]{DBLP:journals/iet-cps/SladeSK20}
Patrick Slade, Zachary~N. Sunberg, and Mykel~J. Kochenderfer.
\newblock Estimation and control using sampling-based bayesian reinforcement learning.
\newblock \emph{{IET} Cyber-Physical Systems: Theory \& Applications}, 5\penalty0 (1):\penalty0 127--135, 2020.

\bibitem[Sorg et~al.(2010)Sorg, Singh, and Lewis]{DBLP:conf/uai/SorgSL10}
Jonathan Sorg, Satinder Singh, and Richard~L. Lewis.
\newblock Variance-based rewards for approximate bayesian reinforcement learning.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pp.\  564--571. {AUAI} Press, 2010.

\bibitem[Sunberg \& Kochenderfer(2018)Sunberg and Kochenderfer]{DBLP:conf/aips/SunbergK18}
Zachary~N. Sunberg and Mykel~J. Kochenderfer.
\newblock Online algorithms for pomdps with continuous state, action, and observation spaces.
\newblock In \emph{International Conference on Automated Planning and Scheduling}, pp.\  259--263. {AAAI} Press, 2018.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{Sutton1998}
Richard~S. Sutton and Andrew~G. Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock The MIT Press, second edition, 2018.

\bibitem[Wang et~al.(2012)Wang, Won, Hsu, and Lee]{DBLP:conf/icml/WangWHL12}
Yi~Wang, Kok~Sung Won, David Hsu, and Wee~Sun Lee.
\newblock Monte carlo bayesian reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2012.

\bibitem[Wu et~al.(2019)Wu, Tucker, and Nachum]{DBLP:journals/corr/abs-1911-11361}
Yifan Wu, George Tucker, and Ofir Nachum.
\newblock Behavior regularized offline reinforcement learning.
\newblock \emph{CoRR}, abs/1911.11361, 2019.
\newblock URL \url{http://arxiv.org/abs/1911.11361}.

\bibitem[Ye et~al.(2021)Ye, Liu, Kurutach, Abbeel, and Gao]{DBLP:conf/nips/YeLKAG21}
Weirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, and Yang Gao.
\newblock Mastering atari games with limited data.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  25476--25488, 2021.

\bibitem[Yu et~al.(2020)Yu, Thomas, Yu, Ermon, Zou, Levine, Finn, and Ma]{DBLP:conf/nips/YuTYEZLFM20}
Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James~Y. Zou, Sergey Levine, Chelsea Finn, and Tengyu Ma.
\newblock {MOPO:} model-based offline policy optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Yu et~al.(2021)Yu, Kumar, Rafailov, Rajeswaran, Levine, and Finn]{DBLP:conf/nips/YuKRRLF21}
Tianhe Yu, Aviral Kumar, Rafael Rafailov, Aravind Rajeswaran, Sergey Levine, and Chelsea Finn.
\newblock {COMBO:} conservative offline model-based policy optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  28954--28967, 2021.

\bibitem[Zhan et~al.(2022)Zhan, Zhu, and Xu]{DBLP:conf/ijcai/ZhanZX22}
Xianyuan Zhan, Xiangyu Zhu, and Haoran Xu.
\newblock Model-based offline planning with trajectory pruning.
\newblock In \emph{International Joint Conference on Artificial Intelligence}, pp.\  3716--3722. ijcai.org, 2022.

\bibitem[Zhao et~al.(2024)Zhao, Niu, Huang, Liu, and Yuan]{zhao2024a}
Chen Zhao, Yazhe Niu, Kaixin Huang, Yu~Liu, and Chun Yuan.
\newblock A perspective of improper dynamics on offline model-based planning, 2024.
\newblock URL \url{https://openreview.net/forum?id=7kubdPrlRY}.

\end{thebibliography}
