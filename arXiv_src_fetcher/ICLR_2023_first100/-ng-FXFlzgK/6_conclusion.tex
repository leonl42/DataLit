\section{Discussion}
\label{sec:discussion}
\noindent\textbf{Conclusion.}
We introduced a novel method that uses structured local radiance fields for generation of controllable clothed human avatars. It has expressive representation power for both appearance and motion, as we leverage the advantages of neural scene representation while explicitly accounting for the motion hierarchy of clothes. Compared to existing methods, ours can handle more general cloth styles and generate realistic dynamic details. 



\noindent\textbf{Limitation.}
The performance of our method depends on the pose variance in the training data, and our method may fail to generate plausible results when the animation poses starkly differ from the training poses; see Supp.Mat. for an example. 
In addition, the dynamic deformations and wrinkle changes of garments involve complex physics processes, which may be beyond the representation capability of our model. 
Finally, our method assumes accurate body pose estimation for the training images; that is why we mainly conduct experiments on multi-view dataset. For monocular videos, erroneous pose estimation caused by ambiguity may eventually lead to rendering artifacts.  
% Finally, currently we mainly focus on the garment motions when training the model; extending our approach to model hand gestures and facial expressions should be possible if we incorporate expressive body models like SMPL-X~\cite{SMPL-X:2019}. 



\noindent\textbf{Potential Social Impact.}
Our method enables automatic creation of a digital twin of any person. It can be combined with existing Deep Fake algorithms to generate fake videos through character animation and reenactment, which need to be addressed carefully before deploying the technology. 


\noindent\textbf{Acknowledgement.}
This paper is sponsed by National Key R\&D Program of China (2021ZD0113503) and the NSFC No. 62125107 and No. 62171255.