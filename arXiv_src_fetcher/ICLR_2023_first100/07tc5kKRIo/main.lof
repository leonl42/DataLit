\contentsline {figure}{\numberline {1}{\ignorespaces The features from "Bird" mapped by CNNs are concentrated on a low-dimensional manifold, and the three-color point sets represent the three sub-classes of "Bird". Among them, the \leavevmode {\color [RGB]{255,94,30}orange} point set represents "Swan", whose feature volume is obviously smaller than that of "Bird". The classification experiments on sample-balanced datasets show that the models are biased towards the classes with larger semantic scales, such as the decision surface shown by the \leavevmode {\color [RGB]{112,173,71}green} line. In this case, the re-weighting strategy based on the number of samples does NOT work, while our proposed re-weighting approach based on the semantic scale biases the decision surface toward the class with a larger feature volume (\leavevmode {\color [RGB]{255,0,0}red} line).}}{2}{figure.1}%
\contentsline {figure}{\numberline {2}{\ignorespaces \textbf {Left column}: curves of semantic scales with increasing number of samples for the first ten classes from different datasets. \textbf {Right column}: for different sub-datasets, curves of the sum of semantic scales for all classes and top-1 accuracy curves of trained ResNet-18 and ResNet-34. All models are trained using the Adam optimizer \cite {paper33} with an initial learning rate of 0.01 and then decayed by 0.98 at each epoch.}}{5}{figure.2}%
\contentsline {figure}{\numberline {3}{\ignorespaces Correlation study of accuracy with the number of samples and semantic scale on MNIST, MNIST-LT (Appendix \ref {B.3}), CIFAR-10-LT and CIFAR-100-LT datasets.}}{6}{figure.3}%
\contentsline {figure}{\numberline {4}{\ignorespaces \textbf {Top row}: correlation study between accuracy and semantic scale on the sample-balanced dataset. \textbf {Bottom row}: performance of different models \cite {paper9} trained on the CIFAR-10 dataset and performance of ResNet-18 trained on different sub-datasets of CIFAR-10 from Table \ref {table6} of Appendix \ref {B.1}.}}{6}{figure.4}%
\contentsline {figure}{\numberline {5}{\ignorespaces The performance of different models with different losses on different datasets for different values of $n$.}}{7}{figure.5}%
\contentsline {figure}{\numberline {6}{\ignorespaces Increase three Stanford point cloud manifolds, and calculate their semantic scales.}}{25}{figure.6}%
\contentsline {figure}{\numberline {7}{\ignorespaces Semantic scale and number of samples per class. Different angles of the radar plot represent different classes, and the number of samples in the largest class is normalized to 0.5 for ease of observation.}}{26}{figure.7}%
\contentsline {figure}{\numberline {8}{\ignorespaces Long-tailed CIFAR100 and Cars196 with different imbalance factors. We use the exponential function ${n_i} = N\!{\mu ^{{i \mathord {/ {\vphantom {i {( {1 - M} )}}} \kern -\nulldelimiterspace } {( {1 - M} )}}}}$ to yield the number of training samples for each class, where $i$ is the class index (0-indexed), $N$ is the number of training samples in the largest class, $\mu $ is the imbalance factor, and $M$ is the total number of classes.}}{27}{figure.8}%
\contentsline {figure}{\numberline {9}{\ignorespaces Eight fundus images in the OIA-ODIR dataset.}}{28}{figure.9}%
\contentsline {figure}{\numberline {10}{\ignorespaces The number of training and test samples for each category and the degree of semantic scale imbalance in OIA-ODIR and OIA-ODIR-B.}}{29}{figure.10}%
\contentsline {figure}{\numberline {11}{\ignorespaces The enhancement effect of our method for CE, BS, Focal, and LDAM on the OIA-ODIR.}}{29}{figure.11}%
\contentsline {figure}{\numberline {12}{\ignorespaces Performance gains from our approach for multiple backbone networks on OIA-ODIR.}}{30}{figure.12}%
\contentsline {figure}{\numberline {13}{\ignorespaces The seven scenarios are included in the RSSCN7 dataset.}}{31}{figure.13}%
\contentsline {figure}{\numberline {14}{\ignorespaces \textbf {Left column:} confusion matrix of VGG-16, GoogLeNet, and ResNet-34 on the RSSCN7 dataset. \textbf {Right column:} confusion matrix of VGG-16-DSB, GoogLeNet-DSB, and ResNet-34-DSB on the RSSCN7 dataset.}}{32}{figure.14}%
\contentsline {figure}{\numberline {15}{\ignorespaces Comparison of four backbone networks before and after combining with dynamic semantic scale-balanced learning on dataset NWPU-RESISC45.}}{33}{figure.15}%
\contentsline {figure}{\numberline {16}{\ignorespaces The three-stage training framework. The features in the storage pool are continuously updated during training and semantic scales are calculated using all the latest features.}}{34}{figure.16}%
\contentsline {figure}{\numberline {17}{\ignorespaces Accuracy comparison on ImageNet-LT.}}{38}{figure.17}%
\contentsline {figure}{\numberline {18}{\ignorespaces Accuracy comparison with other methods of measuring class-level difficulty.}}{39}{figure.18}%
\contentsline {figure}{\numberline {19}{\ignorespaces Comparison of CE and DSB-CE on ImageNet, where the backbone networks are VGG-16 and ResNet-34, respectively. It can be observed that dynamic semantic-scale-balanced learning significantly improves the tail class performance.}}{40}{figure.19}%
\contentsline {figure}{\numberline {20}{\ignorespaces Schematic diagram of pizza sampling. Yellow samples indicate the selected samples and green samples indicate the discarded samples.}}{40}{figure.20}%
\contentsline {figure}{\numberline {21}{\ignorespaces \textbf {Left column}: curves of semantic scales with increasing number of samples for the first ten classes from different datasets. \textbf {Right column}: for different sub-datasets, curves of the sum of semantic scales for all classes and top-1 accuracy curves of trained ResNet-18 and ResNet-34. All models are trained using the Adam optimizer \cite {paper33} with an initial learning rate of $0.01$ and then decayed by $0.98$ at each epoch.}}{42}{figure.21}%
\contentsline {figure}{\numberline {22}{\ignorespaces Image datasets typically contain multiple semantic hierarchies.}}{43}{figure.22}%
\contentsline {figure}{\numberline {23}{\ignorespaces Changes in the geometry of data manifolds as they are transformed in a deep neural network. The classification process of the data includes untangling the manifolds from each other and separating the different manifolds.}}{44}{figure.23}%
\contentsline {figure}{\numberline {24}{\ignorespaces Class-level long-tailed distribution and intra-class attribute long-tailed distribution.}}{45}{figure.24}%
\contentsline {figure}{\numberline {25}{\ignorespaces (a) When the samples uniformly cover the true data distribution, the model can learn the correct decision boundaries and can correctly classify unfamiliar samples to be tested. (b) When the samples cover only a portion of the true distribution, unfamiliar samples to be tested are highly likely to be misclassified due to the error in the decision boundary. (c) The direction in which the arrow points is the best direction to expand the sample.}}{46}{figure.25}%
\contentsline {figure}{\numberline {26}{\ignorespaces The frequency of the same class appearing in different domains may differ significantly, assuming a smaller sample of horses in the real world and a larger number of horses in cartoon form. Images from different domains can complement each other to form a dataset with a balanced sample number. The purpose of multi-domain deep long-tailed learning is to train unbiased models using data from multiple domains and generalize over all domains.}}{47}{figure.26}%
