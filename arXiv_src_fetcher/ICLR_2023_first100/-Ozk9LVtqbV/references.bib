
@inproceedings{2017_tcn,
  title={Time-contrastive networks: Self-supervised learning from video},
  author={Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={1134--1141},
  year={2018},
  organization={IEEE}
}

@inproceedings{2019_tcc,
  title={Temporal cycle-consistency learning},
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1801--1810},
  year={2019}
}

@article{polyanovsky2011comparative,
  title={Comparative analysis of the quality of a global algorithm and a local algorithm for alignment of two sequences},
  author={Polyanovsky, Valery O and Roytberg, Mikhail A and Tumanyan, Vladimir G},
  journal={Algorithms for molecular biology},
  volume={6},
  pages={1--12},
  year={2011},
  publisher={Springer}
}


@InProceedings{2020_aligningvideos,
author="Purushwalkam, Senthil
and Ye, Tian
and Gupta, Saurabh
and Gupta, Abhinav",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Aligning Videos in Space and Time",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="262--278",
abstract="In this paper, we focus on the task of extracting visual correspondences across videos. Given a query video clip from an action class, we aim to align it with training videos in space and time. Obtaining training data for such a fine-grained alignment task is challenging and often ambiguous. Hence, we propose a novel alignment procedure that learns such correspondence in space and time via cross video cycle-consistency. During training, given a pair of videos, we compute cycles that connect patches in a given frame in the first video by matching through frames in the second video. Cycles that connect overlapping patches together are encouraged to score higher than cycles that connect non-overlapping patches. Our experiments on the Penn Action and Pouring datasets demonstrate that the proposed method can successfully learn to correspond semantically similar patches across videos, and learns representations that are sensitive to object and action states.",
isbn="978-3-030-58574-7"
}


@INPROCEEDINGS{2014_languageactions,
  author={Kuehne, Hilde and Arslan, Ali and Serre, Thomas},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities}, 
  year={2014},
  volume={},
  number={},
  pages={780-787},
  keywords={Hidden Markov models;Dairy products;Accuracy;Speech recognition;Speech;Grammar;Sugar},
  doi={10.1109/CVPR.2014.105}
}

@article{2016_recognizing,
author = {Rohrbach, Marcus and Rohrbach, Anna and Regneri, Michaela and Amin, Sikandar and Andriluka, Mykhaylo and Pinkal, Manfred and Schiele, Bernt},
title = {Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data},
year = {2016},
issue_date = {September 2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {119},
number = {3},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-015-0851-8},
doi = {10.1007/s11263-015-0851-8},
journal = {Int. J. Comput. Vision},
month = {sep},
pages = {346–373},
numpages = {28},
keywords = {Activity recognition, Fine-grained recognition, Hand detection, Script data}
}

@InProceedings{Shao_2020_CVPR,
author = {Shao, Dian and Zhao, Yue and Dai, Bo and Lin, Dahua},
title = {FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
} 

@inproceedings{2021_lav,
  title={Learning by aligning videos in time},
  author={Haresh, Sanjay and Kumar, Sateesh and Coskun, Huseyin and Syed, Shahram N and Konin, Andrey and Zia, Zeeshan and Tran, Quoc-Huy},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5548--5558},
  year={2021}
}

@inproceedings{2021_gta,
  title={Representation learning via global temporal alignment and cycle-consistency},
  author={Hadji, Isma and Derpanis, Konstantinos G and Jepson, Allan D},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11068--11077},
  year={2021}
}

@inproceedings{2022_carl,
  title={Frame-wise action representations for long videos via sequence contrastive learning},
  author={Chen, Minghao and Wei, Fangyun and Li, Chong and Cai, Deng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13801--13810},
  year={2022}
}

@inproceedings{2024_lrprop,
  title={Weakly-supervised representation learning for video alignment and analysis},
  author={Bar-Shalom, Guy and Leifman, George and Elad, Michael},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6909--6919},
  year={2024}
}

@inproceedings{2016_tsn,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle={European conference on computer vision},
  pages={20--36},
  year={2016},
  organization={Springer}
}

@inproceedings{2015_wangaction,
  title={Action recognition with trajectory-pooled deep-convolutional descriptors},
  author={Wang, Limin and Qiao, Yu and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4305--4314},
  year={2015}
}

@inproceedings{2017_quovadis,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@article{1997_lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@article{2014_grus,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@article{2017_att_vaswani,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{2021_vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{2017_softdtw,
  title={Soft-dtw: a differentiable loss function for time-series},
  author={Cuturi, Marco and Blondel, Mathieu},
  booktitle={International conference on machine learning},
  pages={894--903},
  year={2017},
  organization={PMLR}
}

@article{2007_dtw,
  title={Dynamic time warping},
  author={M{\"u}ller, Meinard},
  journal={Information retrieval for music and motion},
  pages={69--84},
  year={2007},
  publisher={Springer}
}


@article{2023_sw1,
  title={End-to-end learning of multiple sequence alignments with differentiable Smith--Waterman},
  author={Petti, Samantha and Bhattacharya, Nicholas and Rao, Roshan and Dauparas, Justas and Thomas, Neil and Zhou, Juannan and Rush, Alexander M and Koo, Peter and Ovchinnikov, Sergey},
  journal={Bioinformatics},
  volume={39},
  number={1},
  pages={btac724},
  year={2023},
  publisher={Oxford University Press}
}

@article{2023_sw2,
  title={Deep embedding and alignment of protein sequences},
  author={Llinares-L{\'o}pez, Felipe and Berthet, Quentin and Blondel, Mathieu and Teboul, Olivier and Vert, Jean-Philippe},
  journal={Nature methods},
  volume={20},
  number={1},
  pages={104--111},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@inproceedings{2020_simclr,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{2015_activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the ieee conference on computer vision and pattern recognition},
  pages={961--970},
  year={2015}
}

@article{2019_moments,
  title={Moments in time dataset: one million videos for event understanding},
  author={Monfort, Mathew and Andonian, Alex and Zhou, Bolei and Ramakrishnan, Kandan and Bargal, Sarah Adel and Yan, Tom and Brown, Lisa and Fan, Quanfu and Gutfreund, Dan and Vondrick, Carl and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={2},
  pages={502--508},
  year={2019},
  publisher={IEEE}
}

@inproceedings{2016_hollywood,
  title={Hollywood in homes: Crowdsourcing data collection for activity understanding},
  author={Sigurdsson, Gunnar A and Varol, G{\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  pages={510--526},
  year={2016},
  organization={Springer}
}

@article{2020_ava,
  title={The ava-kinetics localized human actions video dataset},
  author={Li, Ang and Thotakuri, Meghana and Ross, David A and Carreira, Jo{\~a}o and Vostrikov, Alexander and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2005.00214},
  year={2020}
}


@article{1994_opticalflow,
  title={Performance of optical flow techniques},
  author={Barron, John L and Fleet, David J and Beauchemin, Steven S},
  journal={International journal of computer vision},
  volume={12},
  pages={43--77},
  year={1994},
  publisher={Springer}
}

@article{1998_condensation,
  title={Condensation—conditional density propagation for visual tracking},
  author={Isard, Michael and Blake, Andrew},
  journal={International journal of computer vision},
  volume={29},
  number={1},
  pages={5--28},
  year={1998},
  publisher={Springer}
}

@article{2005_stips,
  title={On space-time interest points},
  author={Laptev, Ivan},
  journal={International journal of computer vision},
  volume={64},
  pages={107--123},
  year={2005},
  publisher={Springer}
}

@inproceedings{2014_vc_karpathy,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1725--1732},
  year={2014}
}

@article{2014_vc_simonyan,
  title={Two-stream convolutional networks for action recognition in videos},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{2013_vc_ji,
  title={3D convolutional neural networks for human action recognition},
  author={Ji, Shuiwang and Xu, Wei and Yang, Ming and Yu, Kai},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={1},
  pages={221--231},
  year={2012},
  publisher={IEEE}
}

@inproceedings{2015_sscnn_tran,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@inproceedings{2017_ssac_tran,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

@inproceedings{2015_ss_srivastava,
  title={Unsupervised learning of video representations using lstms},
  author={Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
  booktitle={International conference on machine learning},
  pages={843--852},
  year={2015},
  organization={PMLR}
}

@article{2017_ss_tung,
  title={Self-supervised learning of motion capture},
  author={Tung, Hsiao-Yu and Tung, Hsiao-Wei and Yumer, Ersin and Fragkiadaki, Katerina},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{2019_ss_wang,
  title={Self-supervised spatio-temporal representation learning for videos by predicting motion and appearance statistics},
  author={Wang, Jiangliu and Jiao, Jianbo and Bao, Linchao and He, Shengfeng and Liu, Yunhui and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4006--4015},
  year={2019}
}

@inproceedings{2019_sscc_wang,
  title={Learning correspondence from the cycle-consistency of time},
  author={Wang, Xiaolong and Jabri, Allan and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2566--2576},
  year={2019}
}

@article{2020_ss_han,
  title={Self-supervised co-training for video representation learning},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5679--5690},
  year={2020}
}

@inproceedings{2019_slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@inproceedings{2018_trn,
  title={Temporal relational reasoning in videos},
  author={Zhou, Bolei and Andonian, Alex and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={803--818},
  year={2018}
}


@inproceedings{2019_actiontransnet,
  title={Video action transformer network},
  author={Girdhar, Rohit and Carreira, Joao and Doersch, Carl and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={244--253},
  year={2019}
}

@inproceedings{2021_vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6836--6846},
  year={2021}
}

@article{2023_videoclass_bert,
  title={A BERT-Based Joint Channel-Temporal Modeling for Action Recognition},
  author={Yang, Man and Gan, Lipeng and Cao, Runze and Li, Xiaochao},
  journal={IEEE Sensors Journal},
  year={2023},
  publisher={IEEE}
}

@article{2021_videoclass_actionclip,
  title={Actionclip: A new paradigm for video action recognition},
  author={Wang, Mengmeng and Xing, Jiazheng and Liu, Yong},
  journal={arXiv preprint arXiv:2109.08472},
  year={2021}
}

@inproceedings{2020_x3d,
  title={X3d: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={203--213},
  year={2020}
}

@inproceedings{2018_align_lamv,
  title={LAMV: Learning to align and match videos with kernelized temporal layers},
  author={Baraldi, Lorenzo and Douze, Matthijs and Cucchiara, Rita and J{\'e}gou, Herv{\'e}},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7804--7813},
  year={2018}
}

@inproceedings{2019_align_visil,
  title={Visil: Fine-grained spatio-temporal video similarity learning},
  author={Kordopatis-Zilos, Giorgos and Papadopoulos, Symeon and Patras, Ioannis and Kompatsiaris, Ioannis},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6351--6360},
  year={2019}
}

@article{1970_nw,
  title={A general method applicable to the search for similarities in the amino acid sequence of two proteins},
  author={Needleman, Saul B and Wunsch, Christian D},
  journal={Journal of molecular biology},
  volume={48},
  number={3},
  pages={443--453},
  year={1970},
  publisher={Elsevier}
}

@article{1981_sw,
  title={Identification of common molecular subsequences},
  author={Smith, Temple F and Waterman, Michael S and others},
  journal={Journal of molecular biology},
  volume={147},
  number={1},
  pages={195--197},
  year={1981},
  publisher={Elsevier Science}
}

@article{2020_diff_nw,
  title={Protein structural alignments from sequence},
  author={Morton, James T and Strauss, Charlie EM and Blackwell, Robert and Berenberg, Daniel and Gligorijevic, Vladimir and Bonneau, Richard},
  journal={BioRxiv},
  pages={2020--11},
  year={2020},
  publisher={Cold Spring Harbor Laboratory}
}

@inproceedings{2015_resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{2013_pennaction,
  title={From actemes to action: A strongly-supervised representation for detailed action understanding},
  author={Zhang, Weiyu and Zhu, Menglong and Derpanis, Konstantinos G},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2248--2255},
  year={2013}
}

@inproceedings{2016_davis,
  title={A benchmark dataset and evaluation methodology for video object segmentation},
  author={Perazzi, Federico and Pont-Tuset, Jordi and McWilliams, Brian and Van Gool, Luc and Gross, Markus and Sorkine-Hornung, Alexander},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={724--732},
  year={2016}
}

@inproceedings{2017_perazzi_objseg,
  title={Learning video object segmentation from static images},
  author={Perazzi, Federico and Khoreva, Anna and Benenson, Rodrigo and Schiele, Bernt and Sorkine-Hornung, Alexander},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2663--2672},
  year={2017}
}

@inproceedings{2021_dino,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{2017_caelles_objseg,
  title={One-shot video object segmentation},
  author={Caelles, Sergi and Maninis, Kevis-Kokitsi and Pont-Tuset, Jordi and Leal-Taix{\'e}, Laura and Cremers, Daniel and Van Gool, Luc},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={221--230},
  year={2017}
}

@inproceedings{2018_bsn,
  title={Bsn: Boundary sensitive network for temporal action proposal generation},
  author={Lin, Tianwei and Zhao, Xu and Su, Haisheng and Wang, Chongjing and Yang, Ming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{2022_actionformer,
  title={Actionformer: Localizing moments of actions with transformers},
  author={Zhang, Chen-Lin and Wu, Jianxin and Li, Yin},
  booktitle={European Conference on Computer Vision},
  pages={492--510},
  year={2022},
  organization={Springer}
}

@inproceedings{2017_actiondetect,
  title={Temporal action detection with structured segment networks},
  author={Zhao, Yue and Xiong, Yuanjun and Wang, Limin and Wu, Zhirong and Tang, Xiaoou and Lin, Dahua},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2914--2923},
  year={2017}
}

@article{2018_videocapsulenet,
  title={Videocapsulenet: A simplified network for action detection},
  author={Duarte, Kevin and Rawat, Yogesh and Shah, Mubarak},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}