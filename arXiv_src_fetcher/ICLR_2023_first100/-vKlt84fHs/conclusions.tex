\section{Conclusions}
\label{conclusions}

In this paper a modification of the unsupervised Isolation Forest named \approach has been suggested to improve the performance of the standard algorithm.
Due to the lack of fully labelled datasets, Anomaly Detection is often performed by means of unsupervised models. However, as anomalies heavily depend on the context and are very domain specific, unsupervised models may be unable to detect them because of different definition of anomaly.
To solve this problem we suggest a model that starting from an unsupervised model, iteratively tunes the model towards the user-definition of anomaly. This allows to enhance the detection performances, avoiding the need to fully label the training dataset and keeping as low as possible the number of required labels. Indeed this approach  takes advantage of the Active Learning framework where the model is able to query the user and select the most interesting samples to label.
\approach relies on two important and inter-connected steps: the query policy that selects the point to be labelled, and the model update policy that allows the model to actually learn from the new query. 
From experiments performed on real datasets  it turned out it is better to ask to label the most anomalous point, leading to a cheap and natural query strategy in practice. Concerning the update policy, the model does not need to fully retrain the forest, but needs just a simple update of the leaf depth, with a cost $O(n_T)$. Regarding the query strategy, the required cost is $O(n_X n_T)$. The cheap time complexity together with the fact that \approach does not need labels of both anomalies and normal points provides a great advantage compared to other state-of-art algorithms.
Comparing \approach with other methods, it turns out it is also generally much faster in the learning of the correct anomaly definition, when the labelling effort needs to be kept low.

Future works will investigate the different query and updating strategies: the information of the number of data points in each leaf might be included in the algorithm, to estimate the uncertainty on the leaf depth correction. Moreover, hybrid query strategies that use a combination of the previously described, might lead to even better results.
