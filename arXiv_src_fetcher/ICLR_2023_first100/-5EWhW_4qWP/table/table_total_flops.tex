\begin{table*}[h!]
    % TOTAL flops

    \begin{center}
    \caption{Total pruning + training FLOPs ($\times 10^{14}$) comparison on CIFAR-10(ResNet-20). Results with the largest FLOPs are in \textcolor{blue}{blue} and results with the smallest FLOPs are in \textbf{bold}.}     \label{tab:appendix-flops-total-cifar10}
    {
    \begin{tabular}{l ccccc}
    \\
    \hline
    \toprule
    Sparsity & 36.00\% & 73.80\% & 89.30\% & 95.60\% & 98.20\% \\
    \midrule
    SNIP & 7.65 & 4.67 & \textcolor{blue}{2.95} & \textcolor{blue}{1.77} & 0.91  \\
    GraSP & \textbf{5.81} & \textbf{3.24} & \textbf{2.08} & 1.19 & 0.77 \\
    Synflow & 7.98 & \textcolor{blue}{5.19} & 2.93 & 1.38 & \textbf{0.64}  \\
    Iterative SNIP & 7.75 & 4.25 & 2.12 & \textbf{1.08} & 0.75 \\
    NTK-SAP & \textcolor{blue}{8.01} & 4.86 & 2.91 & 1.77 & \textcolor{blue}{1.17} \\
    % NTK-SAP (small $T$) & $9.91 \times 10^{12}$ & $7.54 \times 10^{13}$ & $3.58 \times 10^{13}$  \\

    \bottomrule
    \end{tabular}
    }
    
    \end{center}
        \begin{center}
    \caption{Total pruning + training FLOPs ($\times 10^{15}$) comparison on CIFAR-100(VGG-16). Results with the largest FLOPs are in \textcolor{blue}{blue} and results with the smallest FLOPs are in \textbf{bold}.}     \label{tab:appendix-flops-total-cifar100}
    {
    \begin{tabular}{l ccccc}
    \\
    \hline
    \toprule
    Sparsity & 36.00\% & 73.80\% & 89.30\% & 95.60\% & 98.20\% \\
    \midrule
    SNIP & 6.13 & 4.09 & 2.83 & 1.97 & 1.28 \\
    GraSP & \textbf{4.39} & \textbf{2.47} & \textbf{1.48} & \textbf{0.90} & \textbf{0.60} \\
    Synflow & 6.19 & 4.23 & 2.76 & 1.67 & 0.89 \\
    Iterative SNIP & 6.24 & 3.99 & 2.51 & 1.51 & 0.90 \\
    NTK-SAP & \textcolor{blue}{6.65} & \textcolor{blue}{4.58} & \textcolor{blue}{3.17} & \textcolor{blue}{2.19} & \textcolor{blue}{1.48} \\
    % NTK-SAP (small $T$) & $9.91 \times 10^{12}$ & $7.54 \times 10^{13}$ & $3.58 \times 10^{13}$  \\

    \bottomrule
    \end{tabular}
    }
    
    \end{center}
        \begin{center}
    \caption{Total pruning + training FLOPs ($\times 10^{14}$) comparison on Tiny-ImageNet(ResNet-18). Results with the largest FLOPs are in \textcolor{blue}{blue} and results with the smallest FLOPs are in \textbf{bold}.}     \label{tab:appendix-flops-total-tiny}
    {
    \begin{tabular}{l ccccc}
    \\
    \hline
    \toprule
    Sparsity & 36.00\% & 73.80\% & 89.30\% & 95.60\% & 98.20\% \\
    \midrule
    SNIP & 73.70 & 51.70 & 36.80 & 24.80 & 15.10  \\
    GraSP & \textbf{48.80} & \textbf{31.80} & \textbf{21.50} & 14.70 & 9.91 \\
    Synflow & 76.70 & 57.00 & 40.60 & 25.90 & 14.10 \\
    Iterative SNIP & 73.90 & 48.40 & 27.30 & \textbf{12.90} & \textbf{5.71}\\
    NTK-SAP & \textcolor{blue}{78.20} & \textcolor{blue}{58.60} & \textcolor{blue}{42.40} & \textcolor{blue}{29.00} & \textcolor{blue}{18.10} \\
    % NTK-SAP (small $T$) & $9.91 \times 10^{12}$ & $7.54 \times 10^{13}$ & $3.58 \times 10^{13}$  \\

    \bottomrule
    \end{tabular}
    }
    
    \end{center}
\end{table*}