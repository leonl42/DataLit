\begin{thebibliography}{67}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Huh et~al.(2016)Huh, Agrawal, and Efros]{huh2016makes}
Minyoung Huh, Pulkit Agrawal, and Alexei~A Efros.
\newblock What makes imagenet good for transfer learning?
\newblock \emph{arXiv preprint arXiv:1608.08614}, 2016.

\bibitem[Yosinski et~al.(2014)Yosinski, Clune, Bengio, and
  Lipson]{yosinski2014transferable}
Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
\newblock How transferable are features in deep neural networks?
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Chu et~al.(2016)Chu, Madhavan, Beijbom, Hoffman, and
  Darrell]{chu2016best}
Brian Chu, Vashisht Madhavan, Oscar Beijbom, Judy Hoffman, and Trevor Darrell.
\newblock Best practices for fine-tuning visual classifiers to new domains.
\newblock In \emph{European Conference on Computer Vision}, pages 435--442,
  2016.

\bibitem[Kornblith et~al.(2019)Kornblith, Shlens, and Le]{kornblith2019better}
Simon Kornblith, Jonathon Shlens, and Quoc~V Le.
\newblock Do better imagenet models transfer better?
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 2661--2671, 2019.

\bibitem[Zhuang et~al.(2021)Zhuang, Qi, Duan, Xi, Zhu, Zhu, Xiong, and
  He]{Zhuang2021Comprehensive}
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui
  Xiong, and Qing He.
\newblock A comprehensive survey on transfer learning.
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (1):\penalty0 43--76,
  2021.

\bibitem[Caruana(1997)]{caruana1997multitask}
Rich Caruana.
\newblock Multitask learning.
\newblock \emph{Machine learning}, 28\penalty0 (1):\penalty0 41--75, 1997.

\bibitem[Ciliberto et~al.(2017)Ciliberto, Rudi, Rosasco, and
  Pontil]{ciliberto2017consistent}
Carlo Ciliberto, Alessandro Rudi, Lorenzo Rosasco, and Massimiliano Pontil.
\newblock Consistent multitask learning with nonlinear output relations.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Joshi et~al.(2012)Joshi, Dredze, Cohen, and Rose]{joshi2012multi}
Mahesh Joshi, Mark Dredze, William Cohen, and Carolyn Rose.
\newblock Multi-domain learning: when do domains matter?
\newblock In \emph{Proceedings of the 2012 Joint Conference on Empirical
  Methods in Natural Language Processing and Computational Natural Language
  Learning}, pages 1302--1312, 2012.

\bibitem[Tzeng et~al.(2017)Tzeng, Hoffman, Saenko, and
  Darrell]{tzeng2017adversarial}
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 7167--7176, 2017.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Liang et~al.(2020)Liang, Hu, and Feng]{liang2020we}
Jian Liang, Dapeng Hu, and Jiashi Feng.
\newblock Do we really need to access the source data? source hypothesis
  transfer for unsupervised domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  6028--6039, 2020.

\bibitem[Ding et~al.(2022)Ding, Xu, Tang, Xu, Wang, and Tao]{ding2022source}
Ning Ding, Yixing Xu, Yehui Tang, Chao Xu, Yunhe Wang, and Dacheng Tao.
\newblock Source-free domain adaptation via distribution estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 7212--7222, 2022.

\bibitem[Kim et~al.(2022)Kim, Wang, Sclaroff, and Saenko]{kim2022broad}
Donghyun Kim, Kaihong Wang, Stan Sclaroff, and Kate Saenko.
\newblock A broad study of pre-training for domain generalization and
  adaptation.
\newblock \emph{arXiv preprint arXiv:2203.11819}, 2022.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning}, pages
  448--456, 2015.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Yang et~al.(2021{\natexlab{a}})Yang, van~de Weijer, Herranz, Jui,
  et~al.]{yang2021exploiting}
Shiqi Yang, Joost van~de Weijer, Luis Herranz, Shangling Jui, et~al.
\newblock Exploiting the intrinsic neighborhood structure for source-free
  domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2021{\natexlab{a}}.

\bibitem[Blanchard et~al.(2011)Blanchard, Lee, and
  Scott]{blanchard2011generalizing}
Gilles Blanchard, Gyemin Lee, and Clayton Scott.
\newblock Generalizing from several related classification tasks to a new
  unlabeled sample.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2011.

\bibitem[Volpi et~al.(2018)Volpi, Namkoong, Sener, Duchi, Murino, and
  Savarese]{volpi2018generalizing}
Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John~C Duchi, Vittorio Murino,
  and Silvio Savarese.
\newblock Generalizing to unseen domains via adversarial data augmentation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Ilse et~al.(2020)Ilse, Tomczak, Louizos, and Welling]{ilse2020diva}
Maximilian Ilse, Jakub~M Tomczak, Christos Louizos, and Max Welling.
\newblock Diva: Domain invariant variational autoencoders.
\newblock In \emph{Proceedings of the Third Conference on Medical Imaging with
  Deep Learning}, pages 322--348. PMLR, 2020.

\bibitem[Wang et~al.(2021)Wang, Lan, Liu, Ouyang, and Qin]{ijcai2021-628}
Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, and Tao Qin.
\newblock Generalizing to unseen domains: A survey on domain generalization.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  pages 4627--4635, 8 2021.

\bibitem[Ben-David et~al.(2006)Ben-David, Blitzer, Crammer, and
  Pereira]{ben2006analysis}
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira.
\newblock Analysis of representations for domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2006.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1):\penalty0 151--175, 2010.

\bibitem[Mansour et~al.(2009)Mansour, Mohri, and
  Rostamizadeh]{mansour2009domain}
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.
\newblock Domain adaptation: Learning bounds and algorithms.
\newblock \emph{arXiv preprint arXiv:0902.3430}, 2009.

\bibitem[Na et~al.(2021)Na, Jung, Chang, and Hwang]{na2021fixbi}
Jaemin Na, Heechul Jung, Hyung~Jin Chang, and Wonjun Hwang.
\newblock Fixbi: Bridging domain spaces for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 1094--1103, 2021.

\bibitem[Kang et~al.(2019)Kang, Jiang, Yang, and
  Hauptmann]{kang2019contrastive}
Guoliang Kang, Lu~Jiang, Yi~Yang, and Alexander~G Hauptmann.
\newblock Contrastive adaptation network for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 4893--4902, 2019.

\bibitem[Oza et~al.(2021)Oza, Sindagi, VS, and Patel]{oza2021unsupervised}
Poojan Oza, Vishwanath~A Sindagi, Vibashan VS, and Vishal~M Patel.
\newblock Unsupervised domain adaptation of object detectors: A survey.
\newblock \emph{arXiv preprint arXiv:2105.13502}, 2021.

\bibitem[Toldo et~al.(2020)Toldo, Maracani, Michieli, and
  Zanuttigh]{toldo2020unsupervised}
Marco Toldo, Andrea Maracani, Umberto Michieli, and Pietro Zanuttigh.
\newblock Unsupervised domain adaptation in semantic segmentation: a review.
\newblock \emph{Technologies}, 8\penalty0 (2):\penalty0 35, 2020.

\bibitem[Li et~al.(2020)Li, Jiao, Cao, Wong, and Wu]{li2020model}
Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si~Wu.
\newblock Model adaptation: Unsupervised domain adaptation without source data.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9641--9650, 2020.

\bibitem[Yang et~al.(2021{\natexlab{b}})Yang, Wang, van~de Weijer, Herranz, and
  Jui]{yang2021generalized}
Shiqi Yang, Yaxing Wang, Joost van~de Weijer, Luis Herranz, and Shangling Jui.
\newblock Generalized source-free domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8978--8987, 2021{\natexlab{b}}.

\bibitem[Kundu et~al.(2020)Kundu, Venkat, Babu, et~al.]{kundu2020universal}
Jogendra~Nath Kundu, Naveen Venkat, R~Venkatesh Babu, et~al.
\newblock Universal source-free domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 4544--4553, 2020.

\bibitem[Huang et~al.(2021)Huang, Guan, Xiao, and Lu]{huang2021model}
Jiaxing Huang, Dayan Guan, Aoran Xiao, and Shijian Lu.
\newblock Model adaptation: Historical contrastive learning for unsupervised
  domain adaptation without source data.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 3635--3649, 2021.

\bibitem[Kurmi et~al.(2021)Kurmi, Subramanian, and Namboodiri]{kurmi2021domain}
Vinod~K Kurmi, Venkatesh~K Subramanian, and Vinay~P Namboodiri.
\newblock Domain impression: A source data free domain adaptation method.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pages 615--625, 2021.

\bibitem[Xia et~al.(2021)Xia, Zhao, and Ding]{xia2021adaptive}
Haifeng Xia, Handong Zhao, and Zhengming Ding.
\newblock Adaptive adversarial network for source-free domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9010--9019, 2021.

\bibitem[Chu et~al.(2022)Chu, Liu, Deng, Li, and Duan]{chu2022denoised}
Tong Chu, Yahao Liu, Jinhong Deng, Wen Li, and Lixin Duan.
\newblock Denoised maximum classifier discrepancy for sourcefree unsupervised
  domain adaptation.
\newblock In \emph{Thirty-Sixth AAAI Conference on Artificial Intelligence
  (AAAI-22)}, volume~2, 2022.

\bibitem[Kundu et~al.(2022)Kundu, Kulkarni, Bhambri, Mehta, Kulkarni, Jampani,
  and Radhakrishnan]{kundu2022balancing}
Jogendra~Nath Kundu, Akshay~R Kulkarni, Suvaansh Bhambri, Deepesh Mehta,
  Shreyas~Anand Kulkarni, Varun Jampani, and Venkatesh~Babu Radhakrishnan.
\newblock Balancing discriminability and transferability for source-free domain
  adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  11710--11728. PMLR, 2022.

\bibitem[Su et~al.(2022)Su, Zhao, and Bethard]{su2022comparison}
Xin Su, Yiyun Zhao, and Steven Bethard.
\newblock A comparison of strategies for source-free domain adaptation.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 8352--8367,
  2022.

\bibitem[Zhang and Davison(2020)]{zhang2020impact}
Youshan Zhang and Brian~D Davison.
\newblock Impact of imagenet model selection on domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision Workshops}, pages 173--182, 2020.

\bibitem[Chen et~al.(2021)Chen, Xie, and He]{chen2021empirical}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9640--9649, 2021.

\bibitem[Hornik et~al.(2012)Hornik, Feinerer, Kober, and
  Buchta]{hornik2012spherical}
Kurt Hornik, Ingo Feinerer, Martin Kober, and Christian Buchta.
\newblock Spherical k-means clustering.
\newblock \emph{Journal of statistical software}, 50:\penalty0 1--22, 2012.

\bibitem[Liang et~al.(2021)Liang, Hu, Wang, He, and Feng]{liang2021source}
Jian Liang, Dapeng Hu, Yunbo Wang, Ran He, and Jiashi Feng.
\newblock Source data-absent unsupervised domain adaptation through hypothesis
  transfer and labeling transfer.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2021.

\bibitem[Wightman(2019)]{rw2019timm}
Ross Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Simonyan and Zisserman(2015)]{vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 770--778, 2016.

\bibitem[Tan and Le(2019)]{efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  6105--6114, 2019.

\bibitem[Liu et~al.(2022)Liu, Mao, Wu, Feichtenhofer, Darrell, and
  Xie]{convnext}
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
  and Saining Xie.
\newblock A convnet for the 2020s.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 11976--11986, 2022.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10012--10022, 2021.

\bibitem[Touvron et~al.(2021)Touvron, Cord, Douze, Massa, Sablayrolles, and
  J{\'e}gou]{deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In \emph{International Conference on Machine Learning}, pages
  10347--10357, 2021.

\bibitem[Ali et~al.(2021)Ali, Touvron, Caron, Bojanowski, Douze, Joulin,
  Laptev, Neverova, Synnaeve, Verbeek, and Jegou]{xcit}
Alaaeldin Ali, Hugo Touvron, Mathilde Caron, Piotr Bojanowski, Matthijs Douze,
  Armand Joulin, Ivan Laptev, Natalia Neverova, Gabriel Synnaeve, Jakob
  Verbeek, and Herve Jegou.
\newblock Xcit: Cross-covariance image transformers.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 248--255, 2009.

\bibitem[Peng et~al.(2019)Peng, Bai, Xia, Huang, Saenko, and
  Wang]{peng2019moment}
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo~Wang.
\newblock Moment matching for multi-source domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1406--1415, 2019.

\bibitem[Long et~al.(2017)Long, Zhu, Wang, and Jordan]{long2017deep}
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael~I Jordan.
\newblock Deep transfer learning with joint adaptation networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  2208--2217, 2017.

\bibitem[Ringwald and Stiefelhagen(2021)]{ringwald2021adaptiope}
Tobias Ringwald and Rainer Stiefelhagen.
\newblock Adaptiope: A modern benchmark for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pages 101--110, 2021.

\bibitem[Saenko et~al.(2010)Saenko, Kulis, Fritz, and
  Darrell]{saenko2010adapting}
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell.
\newblock Adapting visual category models to new domains.
\newblock In \emph{European Conference on Computer Vision}, pages 213--226,
  2010.

\bibitem[Peng et~al.(2017)Peng, Usman, Kaushik, Hoffman, Wang, and
  Saenko]{peng2017visda}
Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate
  Saenko.
\newblock Visda: The visual domain adaptation challenge.
\newblock \emph{arXiv preprint arXiv:1710.06924}, 2017.

\bibitem[Venkateswara et~al.(2017)Venkateswara, Eusebio, Chakraborty, and
  Panchanathan]{venkateswara2017deep}
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman
  Panchanathan.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 5018--5027, 2017.

\bibitem[Kouw and Loog(2019)]{kouw2019review}
Wouter~M Kouw and Marco Loog.
\newblock A review of domain adaptation without target labels.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 43\penalty0 (3):\penalty0 766--785, 2019.

\bibitem[Ridnik et~al.(2021)Ridnik, Ben-Baruch, Noy, and
  Zelnik-Manor]{ridnik2021imagenet}
Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, and Lihi Zelnik-Manor.
\newblock Imagenet-21k pretraining for the masses.
\newblock In \emph{Proceedings of the Neural Information Processing Systems
  Track on Datasets and Benchmarks}, 2021.

\bibitem[Li et~al.(2017)Li, Wang, Shi, Liu, and Hou]{li2016revisiting}
Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou.
\newblock Revisiting batch normalization for practical domain adaptation.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Long et~al.(2016)Long, Zhu, Wang, and Jordan]{cdan}
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael~I Jordan.
\newblock Unsupervised domain adaptation with residual transfer networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Xu et~al.(2019)Xu, Li, Yang, and Lin]{afn}
Ruijia Xu, Guanbin Li, Jihan Yang, and Liang Lin.
\newblock Larger norm more transferable: An adaptive feature norm approach for
  unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1426--1435, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Liu, Long, and Jordan]{mdd}
Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan.
\newblock Bridging theory and algorithm for domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  7404--7413, 2019.

\bibitem[Jin et~al.(2020)Jin, Wang, Long, and Wang]{mcc}
Ying Jin, Ximei Wang, Mingsheng Long, and Jianmin Wang.
\newblock Minimum class confusion for versatile domain adaptation.
\newblock In \emph{European Conference on Computer Vision}, pages 464--480,
  2020.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal,
  Bojanowski, and Joulin]{dino}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9650--9660, 2021.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{mocov1}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 9729--9738, 2020.

\bibitem[Chen et~al.(2020)Chen, Fan, Girshick, and He]{mocov2}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock \emph{arXiv preprint arXiv:2003.04297}, 2020.

\end{thebibliography}
