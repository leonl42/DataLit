\appendix
\section{Proofs of Lemmas~\ref{lem:covariance-identity}, \ref{lem:positive-covariance} and \ref{lem:LstarvsLmax} in Section~\ref{subsec:preliminaries}}\label{sec:proofs-covariance}
% 把REF加上，如果有可能具体就别太泛泛
\begin{proof}[Proof of Lemma~\ref{lem:covariance-identity}]
A direct computation yields that
    \begin{align*}
        \mathbb{E}[(f(X)-f(Y))(g(X)-g(Y))] &= \mathbb{E}[f(X)g(X)] + \mathbb{E}[f(Y)g(Y)] - \mathbb{E}[f(X)g(Y)] - \mathbb{E}[f(Y)g(X)] \\
        &= 2\mathbb{E}[f(X)g(X)] - 2\mathbb{E}[f(X)]\mathbb{E}[g(X)] \\
        &= 2\mathrm{Cov}(f(X), g(X)),
    \end{align*}
    which completes the proof.
\end{proof}
\begin{proof}[Proof of Lemma~\ref{lem:positive-covariance}]
As $f$ and $g$ are both monotonically increasing, we have
    \begin{align*}
        \forall\, x, y \in \mathbb{R}, \quad (f(x) - f(y))(g(x) - g(y)) \geq 0.
    \end{align*}
   It follows that $\mathbb{E}[(f(X)-f(Y))(g(X)-g(Y))] \geq 0$ for arbitrary random variables $X, Y$. Considering $Y$ as an i.i.d. copy of $X$, we get $\mathrm{Cov}(f(X), g(X)) \geq 0$ from Lemma~\ref{lem:covariance-identity}.
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lem:LstarvsLmax}]
The first inequality follows from 
\begin{align*}
\mathcal{L}_k^* &= \frac{1}{1-\gamma}\sum_sd_\rho^*(s)\sum_a\pi^*(a|s)A^k(s,a)\leq \frac{1}{1-\gamma}\sum_sd_\rho^*(s)\max_a A^k(s,a).
\end{align*}
For the second inequality, noting that $\mathcal{L}_k^*=V^*(\rho)-V^k(\rho)$. Thus, if we let $\pi^{k,\mathrm{pi}}$ denote the greedy PI policy based on $\pi^k$ (see \eqref{eq:PI-update}), then 
\begin{align*}
\mathcal{L}_k^*&\geq V^{\pi^{k,\mathrm{pi}}}(\rho)-V^k(\rho)\\
&=\frac{1}{1-\gamma}\sum_s \frac{d_\rho^{\pi^{k,\mathrm{pi}}}(s)}{d_\rho^*(s)}d_\rho^*(s)\max_a A^k(s,a)\\
&\geq \tilde{\rho}\,\mathbb{E}_{s\sim d_\rho^*}\left[\max_a A^k(s,a)\right].
\end{align*}
Note that the inequality requires  $\max_a A^k(s,a)\geq 0$ which holds since $\sum_a\pi^k(a|s)A^k(s,a)=0$.
\end{proof}
%%%%%%%%%%%
\section{Proof of Theorem~\ref{thm:softmaxPG-global}}\label{sec:proof-softmaxPG-global}

In~\cite{Agarwal_Kakade_Lee_Mahajan_2019}, the global convergence of softmax PG algorithm is established when the step size satisfies $\eta \leq (1-\gamma)^2 / 5$. The proof leverages a series of lemmas (Lemmas 41-51 in~\cite{Agarwal_Kakade_Lee_Mahajan_2019}). Here we generalize the global convergence to an arbitrary  step size sequence $\{ \eta_k \}$ obeying $\inf_k \eta_k > \alpha>0$. %More precisely, one can verify the 
%following optimal conditions of softmax PG algorithm from~\cite{Agarwal_Kakade_Lee_Mahajan_2019}.
 Essentially, it can be seen that the following result has been established in~\cite{Agarwal_Kakade_Lee_Mahajan_2019}.
\begin{lemma} 
    Let $\{ \pi^k \}$ be the policies sequence generated by softmax PG. If the following conditions are satisfied,
    \begin{align*}
        \forall\, k\in\mathbb{N}, \, s\in\calS, \, a\in\calA: \quad V^{k+1}(s) - V^k(s) \geq 0, \quad Q^{k+1}(s,a) - Q^k(s,a) \geq 0\numberthis\label{eq:softmaxPG-global-condition01}
    \end{align*}
    and
    \begin{align*}
        \forall\, s\in\calS, \, a\in\calA: \quad \lim_{k\to\infty} \frac{\partial V^k(\mu)}{\partial \theta_{s,a}} = 0,\numberthis\label{eq:softmaxPG-global-condition02}
    \end{align*}
     then one has $V^k \to V^*$.
    \label{lem:softmax-PG-optimality-condition}
\end{lemma}
%The first condition comes from Lemma 41 and the second one comes from Lemma 44 in~\cite{Agarwal_Kakade_Lee_Mahajan_2019}. 
Indeed, it is shown respectively in \cite[Lemma 41]{Agarwal_Kakade_Lee_Mahajan_2019} and \cite[Lemma 44]{Agarwal_Kakade_Lee_Mahajan_2019} that  \eqref{eq:softmaxPG-global-condition01} and \eqref{eq:softmaxPG-global-condition02} hold provided $\eta < (1-\gamma)^2/5$ by leveraging the smoothness of the value function and the standard gradient ascent optimization results. Once these two conditions are satisfied,  one can verify that all the other lemmas are irrelevant to the step size $\eta_k$ and are also applicable for any positive step size sequence. Note that in the proof of \cite[Lemma 50]{Agarwal_Kakade_Lee_Mahajan_2019}, if we modify the definition of $Z_t$ from $Z_t = \sum_{t^\prime \in \calT} \frac{\partial V^{t^\prime} (\mu)}{\partial \theta_{s,a^\prime}}$ to $Z_t=\sum_{t^\prime \in \calT} \eta_{t^\prime} \frac{\partial V^{t^\prime} (\mu)}{\partial \theta_{s,a^\prime}}$, it can be shown the claim of the lemma  holds for any positive step size sequence.

%One can verify that all the other lemmas are irrelevant with the step size $\eta_k$, thus the global convergence follows once these two conditions are satisfied. Therefore the proof of our Lemma~\ref{lem:softmax-PG-optimality-condition} is omitted. 

%In~\cite{Agarwal_Kakade_Lee_Mahajan_2019} the authors verify these conditions by leveraging the smoothness of the improvement and the standard gradient ascent optimization results, therefore the constraint on step size $\eta < (1-\gamma)^2/5$ is necessary. As our analysis framework does not leverage the smoothness property, we can generalize the global convergence to the case of arbitrary positive step size sequence.

\begin{proof}[Proof of Theorem~\ref{thm:softmaxPG-global}]
    It suffices to verify the conditions in Lemma~\ref{lem:softmax-PG-optimality-condition} under the assumption $\inf_k \eta_k > \alpha>0$. For the first condition, note that the improvement lower bound in Lemma~\ref{lem:softmaxPG-improvement-lower} implies that
    \begin{align*}
        \forall\, k\in\mathbb{N}, \,s\in\calS, \, a\in\calA: \quad \sum_{a} \pi^{k+1}(a|s) A^k(s,a) \geq 0.
    \end{align*}
    Then $V^{k+1}(s) - V^k(s) \geq 0$ follows  by the performance difference lemma and $Q^{k+1}(s,a) - Q^k(s,a)\geq 0$ follows from $Q^t(s,a) = r(s,a) + \gamma \mathbb{E}_{s^\prime \sim P(\cdot|s,a)} \left[ V^t(s^\prime) \right]$.
    
    For the second condition, noting that $V^t(s)$ is monotonically increasing and $V^t(s) \leq 1/(1-\gamma)$, we know that the limit of $V^t(s)$ exists. Therefore
    \begin{align*}
        \lim_{t\to\infty} \left( V^{k+1}(\mu) - V^k(\mu) \right) = 0.
    \end{align*}
    Since $\inf_t \eta_t \geq \alpha> 0$, it follows from Lemma~\ref{lem:PDL} and Lemma~\ref{lem:softmaxPG-improvement-lower} that
    \begin{align*}
        V^{k+1}(\mu) - V^k(\mu) &= \frac{1}{1-\gamma} \sum_s d^{k+1}_\mu(s) \sum_{a} \pi^{k+1} A^k(s,a) \\
        &\geq \frac{1}{1-\gamma} \sum_s d^{k+1}_\mu(s) \frac{1}{|\mathcal{A}|}\left(\max_a|\hat{A}^k(s,a)|\right)\left(1-\exp\left(-\eta_k\,\tilde{\mu}\max_a|\hat{A}^k(s,a)|\right)\right)\\
        &\geq \frac{1}{1-\gamma} \sum_s d^{k+1}_\mu(s) \frac{1}{|\mathcal{A}|}\left(\max_a|\hat{A}^k(s,a)|\right)\left(1-\exp\left(-\alpha\,\tilde{\mu}\max_a|\hat{A}^k(s,a)|\right)\right).
    \end{align*}
    Noting that $d^{k+1}_\mu(s) \geq (1-\gamma)\tilde{\mu} > 0$, together with $\lim_{k\rightarrow\infty} \left( V^{k+1}(\mu) - V^k(\mu) \right) = 0$, there holds
    \begin{align*}
        &\forall s\in\calS: \quad \lim_{k\to\infty} \left(\max_{a} \left| \hat{A}^k(s,a) \right|\right) \left( 1 - \exp\left( -\alpha\,\tilde{\mu} \max_a \left| \hat{A}^k(s,a) \right| \right) \right) = 0, \\
        \Longleftrightarrow \quad &\forall s\in\calS: \quad \lim_{k\to\infty} \max_a \left| \hat{A}^k(s,a) \right| = 0, \\
        \Longleftrightarrow \quad &\forall s\in\calS,\; a\in\calA: \quad \lim_{k\to\infty} \hat{A}^k(s,a) = 0.
    \end{align*}
    Therefore the second condition further holds due to the expression of the gradient. 
\end{proof}

%%%%%%%%%%%
\section{Proof of Lemma~\ref{lem:bound-Atau}}\label{sec:proof-bound-Atau}
On the one hand,
\begin{align*}
\hat{A}^\pi_\tau(s,a) &= \pi(a|s)\left(Q^\pi_\tau(s,a)-\tau\log\pi(a|s)-V_\tau^\pi(s)\right)\\
&\leq  \pi(a|s)\left(Q^\pi_\tau(s,a)-\tau\log\pi(a|s)\right)\\
&\leq \frac{1+\gamma\,\tau\log|\mathcal{A}|}{1-\gamma}+\frac{\tau}{e}\\
&\leq \frac{1+\tau\log|\mathcal{A}|}{1-\gamma},
\end{align*}
where we assume $|\mathcal{A}|\geq 2$ for simplicity so that $\log|\mathcal{A}|\geq \log 2\geq 1/e$. On the other hand,
\begin{align*}
\hat{A}^\pi_\tau(s,a) \geq - V_\tau^\pi(s)\geq -\frac{1+\tau\log|\mathcal{A}|}{1-\gamma},
\end{align*}
which completes the proof.

%%%%%%%%%%%%%%%%%%%
\section{Proof of Lemma~\ref{lem:entropyPG-global}}\label{sec:proof-entropyPG-global}
    
    We are going to establish the global convergence of entropy softmax PG by proving the following four claims in order.
    \begin{enumerate}
        \item The sequence of $\{ V^k_\tau(s) \}$ and $\{ Q^k_\tau(s,a) \}$  converge for all $s, a$, with the limits denoted by $V^\infty_\tau(s)$ and $Q^\infty_\tau(s,a)$, respectively.
        \item For all $s,a$, the policy  sequence $\{\pi^k(a|s)\}$ has at most two limit points. 
        \item For all $s,a$, the limit of the policy sequence $\{ \pi^k(a|s) \}$ indeed exists, namely there  exists only one limit point.
        \item The limit of the value function is optimal, i.e. $V^\infty = V^*$.
    \end{enumerate}
    Note that once Claim~3 have been justified, the proof of Claim~4 is overall the same as the proof of \cite[Lemma~16]{Mei_Xiao_Szepesvari_Schuurmans_2020}. The details are included for completeness.

    \paragraph{Claim 1} As $\eta \in (0, \beta)$, Lemma \ref{lem:entropy-lower-bound} implies that 
    \begin{align*}
        \forall\, s\in\calS: \quad \calT_\tau^{k+1} V^k_\tau(s) - V^k_\tau(s) \geq 0.
    \end{align*}
    Hence, by the performance difference lemma (Lemma \ref{lem:entropyPDL}), $\left\{ V^k_{\tau}(s) \right\}$ is a monotonically increasing sequence. Noting that $|V^k_\tau(s)| \leq (1+\tau\log|\calA|) / (1-\gamma)$ is bounded, the limit exists,
    \begin{align*}
        \forall\, s\in\calS: \quad V^\infty_\tau(s) := \lim_{k\to\infty} V^k_\tau(s).
    \end{align*}
    By the relation of
    $
        Q^k_\tau(s,a) = r(s,a) + \gamma \mathbb{E}_{s^\prime \sim P(\cdot|s,a)} \left[ V^k_\tau(s^\prime) \right]
    $,
    we know that $Q^\infty_\tau(s,a):=\lim_{k\rightarrow\infty}Q^k_\tau(s,a)$ also exists, and \begin{align*}Q^\infty_\tau(s,a) = r(s,a) + \gamma\mathbb{E}_{s^\prime \sim P(\cdot|s,a)} \left[  V^\infty_\tau(s^\prime) \right].
    \end{align*}
    
    \paragraph{Claim 2} As the limit of $V^k_\tau(s)$ exists for any $s$, we have $\lim_{k\to\infty} \left(V^{k+1}_\tau(s) - V^k_\tau(s)\right) = 0$. Then
    \begin{align*}
        \lim_{k\to\infty} \left(V^{k+1}_\tau(\mu) - V^k_\tau(\mu)\right) = 0 .
    \end{align*}
    By Lemma \ref{lem:entropyPDL} and Lemma~\ref{lem:entropy-lower-bound}, one has 
    \begin{align*}
        V^{k+1}_\tau(\mu) - V^k_\tau(\mu)  &=  \frac{1}{1-\gamma} \sum_{s} d^{k+1}_\mu(s) \left( \calT_\tau^{k+1} V^k_\tau(s) - V^k_\tau(s) \right) \\
        &\geq \frac{1}{1-\gamma} \sum_{s} d^{k+1}_\mu(s) \cdot C(\eta) \cdot \max_a \left| \hat{A}^k_\tau(s,a) \right|^2, 
    \end{align*}
    where $C(\eta) := \eta \,\tilde{\mu}  \left[ \exp \left( -\frac{2\eta (1+ \tau \log |\calA|)}{(1-\gamma)^2} \right) - \frac{\tau \eta}{2(1-\gamma)} \right]$ is the constant given in  Lemma~\ref{lem:entropy-lower-bound}. Noting that $d^{k+1}_\mu(s) \geq (1-\gamma) \tilde{\mu} > 0$ and $C(\eta) > 0$, together with $\lim_{k}\left( V^{k+1}(\mu) - V^k(\mu)\right) = 0$, we get
    \begin{align*}
        &\forall\, s\in\calS: \quad \lim_{k\to\infty} \max_{a\in\calA} \left| \hat{A}^k_\tau(s,a) \right|^2 = 0 \\
        \Longleftrightarrow \quad &\forall\, s\in\calS, \; a\in\calA: \quad \lim_{k\to\infty} \hat{A}^k_\tau(s,a) = 0 \numberthis \label{appendix: limit A hat of entropy Softmax PG equals to zero} \\ 
        \Longleftrightarrow \quad &\forall\, s\in\calS, \; a\in\calA: \quad \lim_{k\to\infty} \pi^k(a|s) \cdot {A}^k_\tau(s,a) = 0 \\
        \Longleftrightarrow \quad &\forall\, s\in\calS, \; a\in\calA: \quad \lim_{k\to\infty} \pi^k(a|s) \cdot \left[ Q^k_\tau(s,a) - V^k_\tau(s) - \tau \log \pi^k(a|s) \right] = 0. \numberthis \label{appendix: limit condition of entropy Softmax PG}
    \end{align*}
    For any $a$, define $p(a)$ as
    \begin{align*}
        p(a) := \exp \left( \frac{1}{\tau} \cdot \left[ Q^\infty_\tau(s,a) - V^\infty_\tau(s) \right] \right). 
    \end{align*}
    Note that $p(a)$ satisfies $ Q^\infty_\tau(s,a) - V^\infty_\tau(s) - \tau \log p(a)  = 0$. 
    
    For the case that $p(a) > 1$, we have $Q^\infty_\tau(s,a) > V^\infty_\tau(s)$. Therefore there exists a constant $c_0>0$ and a finite time $T_0$ such that $Q^k_\tau(s,a) - V^k_\tau(s) \geq c_0$ for all $k > T_0$, so $Q^k_\tau(s,a) - V^k_\tau(s) -\tau \log \pi^k(a|s) \geq  c_0$  for all $k > T_0$. It follows from \eqref{appendix: limit condition of entropy Softmax PG} that
    $
      \lim_{k\to\infty} \pi^k(a|s) = 0
    $, i.e. only one limit point for $\{ \pi^k(a|s) \}$.
    
    For the case that $p(a) \in (0,1] $, we next show that  \eqref{appendix: limit condition of entropy Softmax PG} implies that $\pi^k(a|s)$ has at most two limit points $\{ 0, \, p(a) \}$, denoted $\pi^k(a|s) \to \{0, \, p(a) \}$. First we have
    \begin{align*}
        &\forall\, \epsilon > 0,\,  \exists\, T_0 > 0, \; \forall\, k > T_0: \quad \left| \pi^k(a|s) \right| \cdot \left| Q^k_\tau(s,a) - V^k_\tau(s) -\tau \log \pi^k(a|s) \right| \leq  \epsilon,
        \end{align*}
        which implies
        \begin{align*}
        &\forall\, \epsilon > 0, \; \exists\, T_0 > 0, \; \forall\, k > T_0: \quad \left| \pi^k(a|s) \right| \leq  \sqrt{\epsilon} \quad \mbox{or} \quad  \left| Q^k_\tau(s,a) - V^k_\tau(s) -\tau \log \pi^k(a|s) \right| \leq  \sqrt{\epsilon}. \numberthis \label{appendix: condition of two limit points}
    \end{align*}
    Define $\delta_k := \left( Q^\infty_\tau(s,a) - V^\infty_\tau(s) \right) - \left( Q^k_\tau(s,a) - V^k_\tau(s) \right)$. Noting that $\delta_k \to 0$, there exists a time $T_1 > 0$ such that $|\delta_k| \leq \sqrt{\epsilon}$ for all $k \geq T_1$. Under this condition,
    \begin{align*}
        \forall\, k \geq T_1 :\quad \left| Q^k_\tau(s,a) - V^k_\tau(s) -\tau \log \pi^k(a|s) \right| &= \left| \tau \log\frac{p(a)}{\pi^k(a|s)} - \delta_k \right| \\
        & \geq \tau \left| \log\frac{p(a)}{\pi^k(a|s)} \right| - \sqrt{\epsilon} \\
        &\geq \tau \left| \pi^k(a|s) - p(a) \right| - \sqrt{\epsilon},
    \end{align*}
    where the last inequality is due to $\left| \log x - \log p \right| \geq |x - p|$ when $x \in (0,1]$ and $p \in (0, 1]$. Plugging it back into \eqref{appendix: condition of two limit points} and letting $T := \max \{ T_0, T_1 \}$, we have
    \begin{align*}
        \forall\, \epsilon > 0, \; \exists\, T > 0, \; \forall\, k > T: \quad \left| \pi^k(a|s) \right| < \sqrt{\epsilon} \quad \mbox{or} \quad \left|  \pi^k(a|s) - p(a) \right| \leq \frac{2\sqrt{\epsilon}} {\tau},
    \end{align*}
    which implies that $\pi^k(a|s) \to \{0, \; p(a) \}$.

    \paragraph{Claim 3} We have shown in Claim 2 that for any $a$ such that $p(a) \in (0, 1]$,
    \begin{align*}
        \pi^k(a|s) \to \{ 0, \; p(a) \}.
    \end{align*}
    Next, we will further show that for these actions the limit of $\pi^k(a|s)$ indeed exists, i.e. it converges to one of the $\{0, \, p(a) \}$. Once it is done, we know that $\lim_k \pi^k(a|s)$ exists for any $s,a$. In the proof, we will leverage the fact that
    \begin{align*}
        \forall\, s: \quad  \left\|\frac{\partial V^k_\tau(\mu)}{\partial \theta_{s,a}}
        \right\|_\infty\to 0,
    \end{align*}
    which follows from the expression for the gradient in \eqref{eq:entropy-softmax-pg-expression} and the fact $\hat{A}^k_\tau(s,a) \to 0$ for all $(s,a)$. Thus there exists a finite time $T_1 > 0$ such that
    \begin{align*}
        \forall\, k \geq T_1: \quad \left\|\frac{\partial V^k_\tau(\mu)}{\partial \theta_{s,\cdot}} \right\|_\infty < \frac{1}{2\eta} \log \left( \frac{p(a)}{\epsilon} - 1 \right).
    \end{align*}
      In addition, since $\pi^k(a|s) \to \{ 0, \; p(a) \}$, for $\epsilon < p(a) / 2$, there exists a finite time $T_0 > 0$ such that
    \begin{align*}
        \forall\, k \geq T_0: \quad \pi^k(a|s) \leq \epsilon \quad \mathrm{or} \quad p(a) - \epsilon \leq \pi^k(a|s) \leq p(a) + \epsilon.
    \end{align*}
    Note that these two sets are disjointed. 
    
    The proof is then proceeded by contradiction.
    Suppose $\lim_{k\to\infty} \pi^k(a|s)$ does not exist.
    Then $\pi^k(a|s)$ will move between the $\epsilon$-neighborhood of $0$ and $p(a)$ infinite times since $\pi^k(a|s) \to \{0,p(a) \}$. Therefore there must exist a time $t \geq \max(T_0,T_1)$ such that $\pi^t(a|s) \leq \epsilon$ and $\pi^{t+1}(a|s) \geq p(a)-\epsilon$. According to the update rule of entropy softmax PG (let $l_t := \left\| \frac{\partial V^t_\tau(\mu)}{\partial \theta_{s,\cdot}} \right\|_\infty$),
    \begin{align*}
        \pi^{t+1}(a|s)& = \frac{\exp\left( \theta_{s,a}^t + \eta_t \frac{\partial V^t_\tau(\mu)}{\partial \theta_{s,a}} \right)}{\sum_{a'} \exp\left( \theta_{s,a'}^t + \eta_t \frac{\partial V^t_\tau(\mu)}{\partial \theta_{s,a'}} \right)} \\
        &\leq \frac{\exp \left( \theta_{s,a}^t + \eta_t \, l_t \right)}{\sum_{a'} \exp\left( \theta_{s,a'}^t - \eta_t \,l_t \right)} \\
        &= \exp(2\eta_t\, l_t) \cdot \pi^t(a|s) \\
        &\leq \exp(2\eta\, l_t) \cdot \epsilon \\
        &< p(a) - \epsilon,
    \end{align*}
    which contradicts  the claim  $\pi^{t+1}(a|s) \geq p(a) - \epsilon$. 

    \paragraph{Claim 4}  Denote by $\pi^\infty(a|s)$ the limit of $\pi^k(a|s)$, i.e.
    \begin{align*}
        \forall\, s\in\calS, \; a\in\calA: \quad \lim_{k\to\infty} \pi^k(a|s) = \pi^\infty(a|s).
    \end{align*}
   As in \cite{Mei_Xiao_Szepesvari_Schuurmans_2020}, we divide the action set into the following two subsets:
    \begin{align*}
        \calA_0(s) &:= \left\{ a: \pi^\infty(a|s) = 0 \right\} \\
        \calA_+(s) &:= \left\{ a: \pi^\infty(a|s) = p(a) \right\}.
    \end{align*}
    Next we show $\calA_0(s) = \varnothing$. Otherwise, for any $a_0 \in \calA_0(s)$, there exists a time $T\geq 0$ such that,
    \begin{align*}
        \forall\, k \geq T: \quad -\log \pi^k(a_0|s) \geq \frac{1+\tau \log |\calA|}{\tau (1-\gamma)}.
    \end{align*}
    Therefore,
    \begin{align*}
        \forall\, k \geq T: \quad \frac{\partial V^k_\tau(\mu)}{\partial \theta_{s,a_0}} &= \frac{1}{1-\gamma} d^k_\mu(s) \pi^k(a|s) \left[ Q^k_\tau(s,a) - V^k_\tau(s) - \tau \log \pi^k(a|s) \right] \\
        &\geq \frac{1}{1-\gamma} d^k_\mu(s) \pi^k(a|s) \left[ 0 - \frac{1+\tau \log |\calA|}{1-\gamma} 
        +\tau \frac{1+\tau \log |\calA|}{\tau (1-\gamma)} \right] \geq 0,\numberthis\label{eq:entropy-softmaxpg-global01}
    \end{align*}
    which implies that $\theta^k_{s,a_0}$ is increasing for any $k \geq T$.  Thus $\theta^k_{s,a_0}$ is lower bounded.  Then according to 
    \begin{align*}
        \pi^k(a_0|s) = \frac{\exp (\theta^k_{s,a_0})}{\sum_a \exp (\theta^k_{s,a})} \to 0,
    \end{align*}
    we know that
        $\sum_a \exp (\theta^k_{s,a}) \to \infty$.
    On the other hand, for any $a_+ \in \calA_+(s)$, by
    \begin{align*}
        \pi^k(a_+|s) = \frac{\exp(\theta^k_{s,a_+})}{\sum_{a} \exp(\theta^k_{s,a})} \to p(a) > 0
    \end{align*}
    we get $\exp(\theta^k_{s,a_+}) \to \infty$, so $\theta^k_{s,a_+} \to \infty$, leading to $\sum_{a_+\in\calA_+(s)} \theta^k_{s,a_+} \to \infty$.
    Note that since $\sum_a\hat{A}^k_\tau(s,a)=0$, one has
    \begin{align*}
        \sum_a \frac{\partial V^k_\tau(\mu)}{\partial \theta_{s,a}} = \sum_{a_0 \in \calA_0(s)} \frac{\partial V^k_\tau(\mu)}{\partial \theta_{s,a_0}} + \sum_{a_+ \in \calA_+(s)} \frac{\partial V^k_\tau(\mu)}{\partial \theta_{s,a_+}} = 0.
    \end{align*}
    Thus, the result in \eqref{eq:entropy-softmaxpg-global01} implies that $\sum_{a_+ \in \calA_+(s)} \frac{\partial V^k_\tau(\mu)}{\partial \theta_{s,a_+}}\leq 0,\,\forall\, k\ge T$, which means  
    $\sum_{a_+ \in \calA_+(s)} \theta^k_{s,a_+}$  eventually decreases, contradicting $\sum_{a_+\in\calA_+(s)} \theta^k_{s,a_+} \to \infty$.
    
    Since $\pi^\infty(a|s) > 0$ for all $s,\,a$, together  with  \eqref{appendix: limit condition of entropy Softmax PG}, one has
    \begin{align*}
        \forall\, s,a: \quad \lim_{k\to\infty} A^k_\tau(s,a) = \lim_{k\to\infty}\left[Q^k_\tau(s,a) - V^k_\tau(s) - \tau \log \pi^k(a|s)\right] = 0.
    \end{align*}
    It follows that 
    \begin{align*}
        \forall\, s,a: 
        \quad Q^\infty_\tau(s,a) - V^\infty_\tau(s) - \tau \log \pi^\infty(a|s)= r(s,a) + \gamma \mathbb{E}_{s^\prime \sim P(\cdot|s,a)} \left[ V^\infty_\tau(s^\prime) \right] - V^\infty_\tau(s) - \tau \log \pi^\infty(a|s) = 0.
    \end{align*}
    Thus, the application of \cite[Corollary~21]{Nachum2017softPI} implies that  $\pi^\infty = \pi^*$ and $V^\infty_\tau = V^*_\tau$, which concludes the proof.


%%%%%%%%%%%%%%%%%%
\section{Proof of Lemma~\ref{lem:KL-ratio}}\label{sec:proof-KL-ratio}
% first list two lemmas from the notes (proof of lemma a is not needed 简单说可以直接验证就好了)

In order to prove Lemma~\ref{lem:KL-ratio}, we first introduce the following two lemmas regarding the gradient and Hessian of the KL divergence. The first lemma can be verified directly.

\begin{lemma}
    Let $\pi_\theta$ and $\pi_{\theta'}$ be two smooth parameterized policies.
    \begin{enumerate}
        \item[\textup{1)}] For the gradient, we have
        \begin{align*}
            \left.\nabla_\theta\mathrm{KL}(\pi_\theta\|\pi_{\theta'})\right|_{\theta=\theta'}=\left.\nabla_\theta\mathrm{KL}(\pi_{\theta'}\|\pi_{\theta})\right|_{\theta=\theta'}=0.
        \end{align*}
        \item[\textup{2)}] For the Hessian, we have
        \begin{align*}
            \nabla_\theta^2\mathrm{KL}(\pi_\theta\|\pi_{\theta'})&=\sum_a\nabla_\theta^2\pi_\theta(a)(\log\pi_\theta(a)-\log\pi_{{\theta'}}(a))+F(\theta)
        \end{align*}
        and
        \begin{align*}
            \nabla_\theta^2\mathrm{KL}(\pi_{{\theta'}}\|\pi_{{\theta}})=-\sum_a\left(\pi_{{\theta'}}(a)-\pi_\theta(a)\right)\nabla_\theta^2\log\pi_\theta(a)+F(\theta),
        \end{align*}
        where $F(\theta)=\sum_a\pi_\theta(a)\nabla_\theta\log\pi_\theta(a)\nabla_\theta\log\pi_\theta(a)^T$ is the Fisher information matrix.
    \end{enumerate}
    \label{lem:KL-grad/Hessian}
\end{lemma}



\begin{lemma}
    Let $\pi_{\theta}=\mathrm{softmax}(\theta)$ and $\pi_{\theta'}=\mathrm{softmax}(\theta')$ be two softmax policies.
    \begin{enumerate}
        \item[\textup{1)}] The Fisher information matrix $F(\theta)$ has the following expression:
        \begin{align*}
            F(\theta) =\mathrm{diag}(\pi_\theta)-\pi_\theta\pi_\theta^T,            
        \end{align*}
        and there holds
        \begin{align*}
            \|F(\theta_1)-F(\theta_2)\|_2\leq 3\|\pi_{\theta_1}-\pi_{\theta_2}\|_2.
        \end{align*}
        Moreover, one has $1^TF(\theta)\,1=0$ and for any $x$ such that $1^Tx=0$,
        \begin{align*}
            x^TF(\theta)\,x\geq \min_a\pi_\theta(a) \cdot \|x\|_2^2.
        \end{align*}
        \item[\textup{2)}] The Hessian of $\mathrm{KL}(\pi_{\theta'}\|\pi_\theta)$ is equal to $F(\theta)$, i.e.,
        \begin{align*}
            \nabla_\theta^2\mathrm{KL}(\pi_{{\theta'}}\|\pi_{{\theta}}) = F(\theta).
        \end{align*}
        \item[\textup{3)}] For any $x$, the Hessian of $\mathrm{KL}(\pi_\theta\|\pi_{\theta'})$ satisfies
        \begin{align*}
            \left(1-c(\theta,\theta')\right)\left(x^TF(\theta)\,x\right)\leq x^T\nabla_\theta^2\mathrm{KL}(\pi_\theta\|\pi_{\theta'})\,x \leq
            \left(1+c(\theta,\theta')\right)\left(x^TF(\theta)\,x\right),
        \end{align*}    
        where $c(\theta,\theta')= \|\log\pi_\theta-\log\pi_{\theta'}\|_\infty+\mathrm{KL}(\pi_\theta\|\pi_{\theta'})$ is assumed to be sufficiently small.
    \end{enumerate}
    \label{lem:Softmax-KL-Hessian}
\end{lemma}

\begin{proof}
    1) The first one follows from $
    \nabla_\theta\log\pi_\theta(a)=e_a-\pi_\theta
    $ when $\pi_\theta$ is a softmax policy.
    Noting that
    \begin{align*}
    x^T(F(\theta_1)-F(\theta_2))\,x &=\sum_a\left(\pi_{\theta_1}(a)-\pi_{\theta_2}(a)\right)x_a^2-\left((\pi_{\theta_1}^Tx)^2-(\pi_{\theta_2}^Tx)^2\right),
    \end{align*}
    one has
    \begin{align*}
    \left|x^T(F(\theta_1)-F(\theta_2))\,x\right|&\leq \|\pi_{\theta_1}-\pi_{\theta_2}\|_\infty\|x\|_2^2+\|\pi_{\theta_1}+\pi_{\theta_2}\|_2\|\pi_{\theta_1}-\pi_{\theta_2}\|_2\|x\|_2^2\\
    &\leq 3\|\pi_{\theta_1}-\pi_{\theta_2}\|_2\,\|x\|_2^2.
    \end{align*}
    The fact $1^TF(\theta)\,1=0$ can be seen easily. For the other one, assume $a'=\arg\min_a \pi_{\theta}(a)$. One has
    \begin{align*}
    x^TF_\theta x-\pi_\theta(a') \sum_ax_a^2&=\sum_a\pi_\theta(a)x_a^2-\left(\sum_a\pi_\theta(a)x_a\right)^2-\pi_\theta(a') \sum_ax_a^2\\
    &=\sum_{a\neq a'}(\pi_\theta(a)-\pi_\theta(a'))x_a^2 - \left(\sum_{a\neq a'}(\pi_\theta(a)-\pi_\theta(a'))x_a\right)^2\\
    &\geq 0,
    \end{align*}
    where the second equality uses the fact $x_{a'}=-\sum_{a\neq a'} x_a$.

    2) This result follows immediately from
    \begin{align*}
        \nabla_\theta^2\log\pi_\theta(a)=-\mathrm{diag}(\pi_\theta)+\pi_\theta\pi_\theta^T=-F(\theta),
    \end{align*}
    which is independent of $a$.

    3) Note that
    \begin{align*}
        \frac{\nabla_\theta^2\pi_\theta(a)}{\pi_\theta(a)}=(e_a-\pi_\theta)(e_a-\pi_\theta)^T-\left(\mathrm{diag}(\pi_\theta)-\pi_\theta\pi_\theta^T\right).
    \end{align*}
    Therefore,
    \begin{align*}
        &x^T\left(\nabla_\theta^2\mathrm{KL}(\pi_\theta\|\pi_{\theta'})-F(\theta)\right)\,x\\&=x^T\mathbb{E}_{a\sim\pi_\theta}\left[\left[(e_a-\pi_\theta)(e_a-\pi_\theta)^T-\left(\mathrm{diag}(\pi_\theta)-\pi_\theta\pi_\theta^T\right)\right]\log\frac{\pi_\theta(a)}{\pi_{\theta'}(a)}\right]x\\
        &=\mathbb{E}_{a\sim\pi_\theta}\left[\left((e_a-\pi_\theta)^T x\right)^2\log\frac{\pi_\theta(a)}{\pi_{\theta'}(a)}\right]-\left[x^T\mathrm{diag}(\pi_\theta)\,x-\left(\pi_\theta^Tx\right)^2\right]\mathrm{KL}(\pi_\theta\|\pi_{\theta'}).
    \end{align*}
    It follows that
    \begin{align*}
        \left|x^T\left(\nabla_\theta^2\mathrm{KL}(\pi_\theta\|\pi_{\theta'})-F(\theta)\right)\,x\right|&\leq \|\log\pi_\theta-\log\pi_{\theta'}\|_\infty \,
        \mathbb{E}_{a\sim\pi_\theta}\left[\left((e_a-\pi_\theta)^T x\right)^2\right]\\
        &+\mathrm{KL}(\pi_\theta\|\pi_{\theta'})\left[x^T\mathrm{diag}(\pi_\theta)\,x-\left(\pi_\theta^Tx\right)^2\right].
    \end{align*}
    The proof is completed since $\left[x^T\mathrm{diag}(\pi_\theta)\,x-\left(\pi_\theta^Tx\right)^2\right]=\mathbb{E}_{a\sim\pi_\theta}\left[\left((e_a-\pi_\theta)^T x\right)^2\right]=x^TF(\theta)\,x$.    
\end{proof}

% 主要证明放这里

%Then we are ready to prove Lemma~\ref{lem:KL-ratio}. We prove it by Taylor's expansion of KL divergence.

\begin{proof}[Proof of Lemma~\ref{lem:KL-ratio}]
    We focus on the first one and the second one can be proved similarly. Define
    \begin{align*}
        \theta_k = \left(I-\frac{1}{n}11^T\right)\log \pi^k\quad\mathrm{and}\quad\theta^*=\left(I-\frac{1}{n}11^T\right)\log \pi^*.
    \end{align*}    
    Then
    \begin{align*}
        \pi^k=\pi_{\theta_k}, \quad  \pi^*=\pi_{\theta^*} \quad \mathrm{and}\quad \theta_k \to \theta^* ,
    \end{align*}    
    where $\pi_{\theta_k}$ and $\pi_{\theta^*}$ denote softmax policies with respect to $\theta_k$ and $\theta^*$, respectively.

    Due to the first result of Lemma~\ref{lem:KL-grad/Hessian}, one has
    \begin{align*}
        \mathrm{KL}(\pi^k\|\pi^{k+1})=\mathrm{KL}(\pi_{\theta_k}\|\pi_{\theta_{k+1}}) &= \frac{1}{2}(\theta_{k+1}-\theta_k)^T\left.\nabla_\theta^2\mathrm{KL}(\pi_\theta\|\pi_{\theta_{k+1}})\right|_{\theta=\xi_k}(\theta_{k+1}-\theta_k),\\
        \mathrm{KL}(\pi^{k+1}\|\pi^{k}) =\mathrm{KL}(\pi_{\theta_{k+1}}\|\pi_{\theta_{k}}) &=\frac{1}{2}(\theta_{k+1}-\theta_k)^T\left.\nabla_\theta^2\mathrm{KL}(\pi_{\theta_{k+1}}\|\pi_\theta)\right|_{\theta=\hat{\xi}_k}(\theta_{k+1}-\theta_k)
    \end{align*}    
    for two points $\xi_k$ and $\hat{\xi}_k$ between $\theta_k$ and $\theta_{k+1}$. By the third result of Lemma~\ref{lem:Softmax-KL-Hessian}, there exists a
    \begin{align*}
        -c(\xi_k,\theta_{k+1})\leq c_k\leq c(\xi_k,\theta_{k+1})
    \end{align*}
    such that 
    \begin{align*}
        \mathrm{KL}(\pi_{\theta_k}\|\pi_{\theta_{k+1}}) = \frac{1}{2}(1+c_k)(\theta_{k+1}-\theta_k)^TF(\xi_k)(\theta_{k+1}-\theta_k).
    \end{align*}    
    Since $\left.\nabla_\theta^2\mathrm{KL}(\pi_{\theta_{k+1}}\|\pi_\theta)\right|_{\theta=\hat{\xi}_k}=F(\hat{\xi}_k)$, one has
    \begin{align*}
        \mathrm{KL}(\pi_{\theta_{k+1}}\|\pi_{\theta_{k}}) &=\frac{1}{2}(\theta_{k+1}-\theta_k)^TF(\hat{\xi}_k)(\theta_{k+1}-\theta_k).
    \end{align*}    
    It follows that
    \begin{align*}
        \frac{\mathrm{KL}(\pi_{\theta_k}\|\pi_{\theta_{k+1}})}
        {\mathrm{KL}(\pi_{\theta_{k+1}}\|\pi_{\theta_{k}})}=(1+c_k) \cdot 
        \frac{(\theta_{k+1}-\theta_k)^TF(\xi_k)(\theta_{k+1}-\theta_k)} 
        {(\theta_{k+1}-\theta_k)^TF(\theta^*)(\theta_{k+1}-\theta_k)}
        \cdot
        \frac{(\theta_{k+1}-\theta_k)^TF(\theta^*)(\theta_{k+1}-\theta_k)}{(\theta_{k+1}-\theta_k)^TF(\hat{\xi}_k)(\theta_{k+1}-\theta_k)}.
    \end{align*}   
    By the construction of $\theta_k$, it is easy to see that
    \begin{align*}
        1^T\theta_k = 1^T\theta_{k+1} = 1^T(\theta_{k+1}-\theta_k)=0.
    \end{align*}
    Thus,
    \begin{align*}
        \left|\frac{(\theta_{k+1}-\theta_k)^TF(\xi_k)(\theta_{k+1}-\theta_k)}{(\theta_{k+1}-\theta_k)^TF(\theta^*)(\theta_{k+1}-\theta_k)}-1\right|&=\left|\frac{\left(\theta_{k+1}-\theta_k)^T(F(\xi_k)-F(\theta^*)\right)(\theta_{k+1}-\theta_k)}{(\theta_{k+1}-\theta_k)^TF(\theta^*)(\theta_{k+1}-\theta_k)}\right|\\
        &\leq \frac{3\|\pi_{\xi_k}-\pi_{\theta^*}\|_2\,\|\theta_{k+1}-\theta_k\|_2^2}{\min_a\pi_{\theta^*}(a)\,\|\theta_{k+1}-\theta_k\|_2^2}\\
        &=\frac{3\|\pi_{\xi_k}-\pi_{\theta^*}\|_2}{\min_a\pi_{\theta^*}(a)}.
    \end{align*}
    Similarly, there holds
    \begin{align*}
        \left|\frac{(\theta_{k+1}-\theta_k)^TF(\theta^*)(\theta_{k+1}-\theta_k)}{(\theta_{k+1}-\theta_k)^TF(\hat{\xi}_k)(\theta_{k+1}-\theta_k)} - 1\right|\leq \frac{3\|\pi_{\hat{\xi}_k}-\pi_{\theta^*}\|_2}{\min_a\pi_{\hat{\xi}_k}(a)}\leq\frac{3\|\pi_{\hat{\xi}_k}-\pi_{\theta^*}\|_2}{\min_a\pi_{\theta^*}(a)-\|\pi_{\hat{\xi}_k}-\pi_{\theta^*}\|_\infty}
    \end{align*}
    for sufficiently large $k$. Noting that when $\pi^k\rightarrow \pi^*$, we have $\theta_k\rightarrow \theta^*$ and $\theta_{k+1}\rightarrow \theta^*$. It follows that $\xi_k\rightarrow \theta^*$, $\hat{\xi}_k\rightarrow\theta^*$, and $\xi_k-\theta_{k+1}\rightarrow 0$. Therefore,
    \begin{align*}
        c_k\rightarrow 0, \quad \|\pi_{\xi_k}-\pi_{\theta^*}\|_2\rightarrow 0,\quad \|\pi_{\hat{\xi}_k}-\pi_{\theta^*}\|_2\rightarrow 0,\quad\mbox{and  }\|\pi_{\hat{\xi}_k}-\pi_{\theta^*}\|_\infty\rightarrow 0.
    \end{align*}    
    The proof is completed by combining the above results together.
\end{proof}
