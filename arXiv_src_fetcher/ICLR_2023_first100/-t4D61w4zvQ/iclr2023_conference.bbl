\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alizadeh et~al.(2020)Alizadeh, Behboodi, van Baalen, Louizos,
  Blankevoort, and Welling]{alizadeh2020gradient}
Milad Alizadeh, Arash Behboodi, Mart van Baalen, Christos Louizos, Tijmen
  Blankevoort, and Max Welling.
\newblock Gradient l1 regularization for quantization robustness.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Azimi et~al.(2022)Azimi, Palacio, Raue, Hees, Bertinetto, and
  Dengel]{azimi2022self}
Fatemeh Azimi, Sebastian Palacio, Federico Raue, J{\"o}rn Hees, Luca
  Bertinetto, and Andreas Dengel.
\newblock Self-supervised test-time adaptation on video data.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pp.\  3439--3448, 2022.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bekta{\c{s}} \& {\c{S}}i{\c{s}}man(2010)Bekta{\c{s}} and
  {\c{S}}i{\c{s}}man]{bektacs2010comparison}
Sebahattin Bekta{\c{s}} and Yasemin {\c{S}}i{\c{s}}man.
\newblock The comparison of l1 and l2-norm minimization methods.
\newblock \emph{International Journal of the Physical Sciences}, 5\penalty0
  (11):\penalty0 1721--1727, 2010.

\bibitem[Bertasius et~al.(2021)Bertasius, Wang, and
  Torresani]{bertasius2021space}
Gedas Bertasius, Heng Wang, and Lorenzo Torresani.
\newblock Is space-time attention all you need for video understanding?
\newblock In \emph{ICML}, volume~2, pp.\ ~4, 2021.

\bibitem[Carreira \& Zisserman(2017)Carreira and Zisserman]{carreira2017quo}
Joao Carreira and Andrew Zisserman.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In \emph{proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  6299--6308, 2017.

\bibitem[Chen et~al.(2021)Chen, Panda, Ramakrishnan, Feris, Cohn, Oliva, and
  Fan]{chen2020deep}
Chun-Fu Chen, Rameswar Panda, Kandan Ramakrishnan, Rogerio Feris, John Cohn,
  Aude Oliva, and Quanfu Fan.
\newblock Deep analysis of cnn-based spatio-temporal representations for action
  recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2021.

\bibitem[Chen et~al.(2019)Chen, Kira, AlRegib, Yoo, Chen, and
  Zheng]{chen2019temporal}
Min-Hung Chen, Zsolt Kira, Ghassan AlRegib, Jaekwon Yoo, Ruxin Chen, and Jian
  Zheng.
\newblock Temporal attentive alignment for large-scale video domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  6321--6330, 2019.

\bibitem[Chen et~al.(2022)Chen, Zhang, Wang, Balachandra, Ma, Wang, and
  Wang]{chen2022sparsity}
Tianlong Chen, Zhenyu Zhang, Pengjun Wang, Santosh Balachandra, Haoyu Ma, Zehao
  Wang, and Zhangyang Wang.
\newblock Sparsity winning twice: Better robust generaliztion from more
  efficient training.
\newblock \emph{arXiv preprint arXiv:2202.09844}, 2022.

\bibitem[Dwibedi et~al.(2019)Dwibedi, Aytar, Tompson, Sermanet, and
  Zisserman]{Dwibedi_2019_CVPR}
Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Pierre Sermanet, and Andrew
  Zisserman.
\newblock Temporal cycle-consistency learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2019.

\bibitem[Fan et~al.(2019)Fan, Chen, Kuehne, Pistoia, and Cox]{fan2019more}
Quanfu Fan, Chun-Fu~Richard Chen, Hilde Kuehne, Marco Pistoia, and David Cox.
\newblock More is less: Learning efficient video representations by big-little
  network and depthwise temporal aggregation.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Feichtenhofer(2020)]{feichtenhofer2020x3d}
Christoph Feichtenhofer.
\newblock X3d: Expanding architectures for efficient video recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  203--213, 2020.

\bibitem[Feichtenhofer et~al.(2019)Feichtenhofer, Fan, Malik, and
  He]{feichtenhofer2019slowfast}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock Slowfast networks for video recognition.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  6202--6211, 2019.

\bibitem[Geirhos et~al.(2017)Geirhos, Janssen, Sch{\"u}tt, Rauber, Bethge, and
  Wichmann]{geirhos2017comparing}
Robert Geirhos, David~HJ Janssen, Heiko~H Sch{\"u}tt, Jonas Rauber, Matthias
  Bethge, and Felix~A Wichmann.
\newblock Comparing deep neural networks against humans: object recognition
  when the signal gets weaker.
\newblock \emph{arXiv preprint arXiv:1706.06969}, 2017.

\bibitem[Geirhos et~al.(2018)Geirhos, Temme, Rauber, Sch{\"u}tt, Bethge, and
  Wichmann]{geirhos2018generalisation}
Robert Geirhos, Carlos R~Medina Temme, Jonas Rauber, Heiko~H Sch{\"u}tt,
  Matthias Bethge, and Felix~A Wichmann.
\newblock Generalisation in humans and deep neural networks.
\newblock In \emph{Proceedings of the Neural Information Processing Systems
  (NIPS)}, 2018.

\bibitem[Goroshin et~al.(2015)Goroshin, Bruna, Tompson, Eigen, and
  LeCun]{goroshin2015unsupervised}
Ross Goroshin, Joan Bruna, Jonathan Tompson, David Eigen, and Yann LeCun.
\newblock Unsupervised learning of spatiotemporally coherent metrics.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  4086--4093, 2015.

\bibitem[Goyal et~al.(2017)Goyal, Ebrahimi~Kahou, Michalski, Materzynska,
  Westphal, Kim, Haenel, Fruend, Yianilos, Mueller-Freitag,
  et~al.]{goyal2017something}
Raghav Goyal, Samira Ebrahimi~Kahou, Vincent Michalski, Joanna Materzynska,
  Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos,
  Moritz Mueller-Freitag, et~al.
\newblock The" something something" video database for learning and evaluating
  visual common sense.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  5842--5850, 2017.

\bibitem[Guo et~al.(2018)Guo, Zhang, Zhang, and Chen]{guo2018sparse}
Yiwen Guo, Chao Zhang, Changshui Zhang, and Yurong Chen.
\newblock Sparse dnns with improved adversarial robustness.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Hara et~al.(2017)Hara, Kataoka, and Satoh]{hara2017learning}
Kensho Hara, Hirokatsu Kataoka, and Yutaka Satoh.
\newblock Learning spatio-temporal features with 3d residual networks for
  action recognition.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision workshops}, pp.\  3154--3160, 2017.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, Kadavath, and
  Song]{hendrycks2019using}
Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song.
\newblock Using self-supervised learning can improve model robustness and
  uncertainty.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and
  Lakshminarayanan]{hendrycks2019augmix}
Dan Hendrycks, Norman Mu, Ekin~Dogus Cubuk, Barret Zoph, Justin Gilmer, and
  Balaji Lakshminarayanan.
\newblock Augmix: A simple data processing method to improve robustness and
  uncertainty.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Huang et~al.(2020)Huang, Gornet, Dai, Yu, Nguyen, Tsao, and
  Anandkumar]{huang2020neural}
Yujia Huang, James Gornet, Sihui Dai, Zhiding Yu, Tan Nguyen, Doris Tsao, and
  Anima Anandkumar.
\newblock Neural networks with recurrent generative feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 535--545, 2020.

\bibitem[Jayaraman \& Grauman(2015)Jayaraman and
  Grauman]{jayaraman2015learning}
Dinesh Jayaraman and Kristen Grauman.
\newblock Learning image representations tied to ego-motion.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  1413--1421, 2015.

\bibitem[Kamann \& Rother(2020)Kamann and Rother]{kamann2020benchmarking}
Christoph Kamann and Carsten Rother.
\newblock Benchmarking the robustness of semantic segmentation models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  8828--8838, 2020.

\bibitem[Kar et~al.(2022)Kar, Yeo, Atanov, and Zamir]{kar20223d}
O{\u{g}}uzhan~Fatih Kar, Teresa Yeo, Andrei Atanov, and Amir Zamir.
\newblock 3d common corruptions and data augmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  18963--18974, 2022.

\bibitem[Karpathy et~al.(2014)Karpathy, Toderici, Shetty, Leung, Sukthankar,
  and Fei-Fei]{karpathy2014large}
Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul
  Sukthankar, and Li~Fei-Fei.
\newblock Large-scale video classification with convolutional neural networks.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pp.\  1725--1732, 2014.

\bibitem[Kondratyuk et~al.(2021)Kondratyuk, Yuan, Li, Zhang, Tan, Brown, and
  Gong]{kondratyuk2021movinets}
Dan Kondratyuk, Liangzhe Yuan, Yandong Li, Li~Zhang, Mingxing Tan, Matthew
  Brown, and Boqing Gong.
\newblock Movinets: Mobile video networks for efficient video recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  16020--16030, 2021.

\bibitem[Li et~al.(2020)Li, Wang, Wan, Wang, Li, and Kot]{li2020domain}
Haoliang Li, YuFei Wang, Renjie Wan, Shiqi Wang, Tie-Qiang Li, and Alex Kot.
\newblock Domain generalization for medical imaging classification with
  linear-dependency regularization.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 3118--3129, 2020.

\bibitem[Li \& DiCarlo(2008)Li and DiCarlo]{li2008unsupervised}
Nuo Li and James~J DiCarlo.
\newblock Unsupervised natural experience rapidly alters invariant object
  representation in visual cortex.
\newblock \emph{science}, 321\penalty0 (5895):\penalty0 1502--1507, 2008.

\bibitem[Li et~al.(2022)Li, Wu, Fan, Mangalam, Xiong, Malik, and
  Feichtenhofer]{li2022mvitv2}
Yanghao Li, Chao-Yuan Wu, Haoqi Fan, Karttikeya Mangalam, Bo~Xiong, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Mvitv2: Improved multiscale vision transformers for classification
  and detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  4804--4814, 2022.

\bibitem[Liang et~al.(2020)Liang, Hu, and Feng]{pmlr-v119-liang20a}
Jian Liang, Dapeng Hu, and Jiashi Feng.
\newblock Do we really need to access the source data? {S}ource hypothesis
  transfer for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pp.\  6028--6039, 2020.

\bibitem[Lin et~al.(2019)Lin, Gan, and Han]{lin2019tsm}
Ji~Lin, Chuang Gan, and Song Han.
\newblock Tsm: Temporal shift module for efficient video understanding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  7083--7093, 2019.

\bibitem[Liu et~al.(2021)Liu, Kothari, van Delft, Bellot-Gurlet, Mordan, and
  Alahi]{NEURIPS2021_b618c321}
Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor
  Mordan, and Alexandre Alahi.
\newblock Ttt++: When does self-supervised test-time training fail or thrive?
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman
  Vaughan (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  21808--21820. Curran Associates, Inc., 2021.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2021/file/b618c3210e934362ac261db280128c22-Paper.pdf}.

\bibitem[Michaelis et~al.(2019)Michaelis, Mitzkus, Geirhos, Rusak, Bringmann,
  Ecker, Bethge, and Brendel]{michaelis2019benchmarking}
Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak, Oliver
  Bringmann, Alexander~S Ecker, Matthias Bethge, and Wieland Brendel.
\newblock Benchmarking robustness in object detection: Autonomous driving when
  winter is coming.
\newblock \emph{arXiv preprint arXiv:1907.07484}, 2019.

\bibitem[Niu et~al.(2022)Niu, Wu, Zhang, Chen, Zheng, Zhao, and
  Tan]{niu2022efficient}
Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin
  Zhao, and Mingkui Tan.
\newblock Efficient test-time model adaptation without forgetting.
\newblock \emph{arXiv preprint arXiv:2204.02610}, 2022.

\bibitem[Rusak et~al.(2020)Rusak, Schott, Zimmermann, Bitterwolf, Bringmann,
  Bethge, and Brendel]{rusak2020increasing}
Evgenia Rusak, Lukas Schott, Roland Zimmermann, Julian Bitterwolf, Oliver
  Bringmann, Matthias Bethge, and Wieland Brendel.
\newblock Increasing the robustness of dnns against image corruptions by
  playing the game of noise.
\newblock \emph{arXiv preprint arXiv:2001.06057}, 2020.

\bibitem[Schneider et~al.(2020)Schneider, Rusak, Eck, Bringmann, Brendel, and
  Bethge]{schneider2020improving}
Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel,
  and Matthias Bethge.
\newblock Improving robustness against common corruptions by covariate shift
  adaptation.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 11539--11551, 2020.

\bibitem[Shocher et~al.(2018)Shocher, Cohen, and Irani]{shocher2018zero}
Assaf Shocher, Nadav Cohen, and Michal Irani.
\newblock “zero-shot” super-resolution using deep internal learning.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  3118--3126, 2018.

\bibitem[Shu et~al.(2022)Shu, Nie, Huang, Yu, Goldstein, Anandkumar, and
  Xiao]{shu2022}
Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar,
  and Chaowei Xiao.
\newblock Test-time prompt tuning for zero-shot generalization in
  vision-language models.
\newblock \emph{arXiv preprint arXiv:2209.07511}, 2022.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014two}
Karen Simonyan and Andrew Zisserman.
\newblock Two-stream convolutional networks for action recognition in videos.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Sun et~al.(2020)Sun, Wang, Liu, Miller, Efros, and Hardt]{sun2020test}
Yu~Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.
\newblock Test-time training with self-supervision for generalization under
  distribution shifts.
\newblock In \emph{International conference on machine learning}, pp.\
  9229--9248. PMLR, 2020.

\bibitem[Tsipras et~al.(2018)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock \emph{arXiv preprint arXiv:1805.12152}, 2018.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Shelhamer, Liu, Olshausen, and
  Darrell]{wang2020tent}
Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell.
\newblock Tent: Fully test-time adaptation by entropy minimization.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Xiao, Kossaifi, Yu, Anandkumar,
  and Wang]{wang2021augmax}
Haotao Wang, Chaowei Xiao, Jean Kossaifi, Zhiding Yu, Anima Anandkumar, and
  Zhangyang Wang.
\newblock Augmax: Adversarial composition of random augmentations for robust
  training.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 237--250, 2021{\natexlab{b}}.

\bibitem[Wang et~al.(2016)Wang, Xiong, Wang, Qiao, Lin, Tang, and
  Gool]{wang2016temporal}
Limin Wang, Yuanjun Xiong, Zhe Wang, Yu~Qiao, Dahua Lin, Xiaoou Tang, and
  Luc~Van Gool.
\newblock Temporal segment networks: Towards good practices for deep action
  recognition.
\newblock In \emph{European conference on computer vision}, pp.\  20--36.
  Springer, 2016.

\bibitem[Wang et~al.(2021{\natexlab{c}})Wang, Tong, Ji, and Wu]{wang2021tdn}
Limin Wang, Zhan Tong, Bin Ji, and Gangshan Wu.
\newblock Tdn: Temporal difference networks for efficient action recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  1895--1904, 2021{\natexlab{c}}.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Fink, Van~Gool, and
  Dai]{wang2022continual}
Qin Wang, Olga Fink, Luc Van~Gool, and Dengxin Dai.
\newblock Continual test-time domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  7201--7211, 2022{\natexlab{a}}.

\bibitem[Wang et~al.(2018)Wang, Girshick, Gupta, and He]{wang2018non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  7794--7803, 2018.

\bibitem[Wang et~al.(2019)Wang, Jabri, and Efros]{wang2019learning}
Xiaolong Wang, Allan Jabri, and Alexei~A Efros.
\newblock Learning correspondence from the cycle-consistency of time.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2566--2576, 2019.

\bibitem[Wang et~al.(2020)Wang, Li, and Kot]{wang2020heterogeneous}
Yufei Wang, Haoliang Li, and Alex~C Kot.
\newblock Heterogeneous domain generalization via domain mixup.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  3622--3626. IEEE, 2020.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Li, Cheng, Wen, Chau, and
  Kot]{wang2022variational}
Yufei Wang, Haoliang Li, Hao Cheng, Bihan Wen, Lap-Pui Chau, and Alex Kot.
\newblock Variational disentanglement for domain generalization.
\newblock \emph{Transactions on Machine Learning Research}, 2022{\natexlab{b}}.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=fudOtITMIZ}.

\bibitem[Wiskott \& Sejnowski(2002)Wiskott and Sejnowski]{wiskott2002slow}
Laurenz Wiskott and Terrence~J Sejnowski.
\newblock Slow feature analysis: Unsupervised learning of invariances.
\newblock \emph{Neural computation}, 14\penalty0 (4):\penalty0 715--770, 2002.

\bibitem[Wood(2016)]{wood2016smoothness}
Justin~N Wood.
\newblock A smoothness constraint on the development of object recognition.
\newblock \emph{Cognition}, 153:\penalty0 140--145, 2016.

\bibitem[Wood \& Wood(2016)Wood and Wood]{wood2016development}
Justin~N Wood and Samantha~MW Wood.
\newblock The development of newborn object recognition in fast and slow visual
  worlds.
\newblock \emph{Proceedings of the Royal Society B: Biological Sciences},
  283\penalty0 (1829):\penalty0 20160166, 2016.

\bibitem[Wu \& Kwiatkowska(2020)Wu and Kwiatkowska]{Wu_2020_CVPR}
Min Wu and Marta Kwiatkowska.
\newblock Robustness guarantees for deep neural networks on videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2020.

\bibitem[Xie et~al.(2019)Xie, Wu, Maaten, Yuille, and He]{xie2019feature}
Cihang Xie, Yuxin Wu, Laurens van~der Maaten, Alan~L Yuille, and Kaiming He.
\newblock Feature denoising for improving adversarial robustness.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  501--509, 2019.

\bibitem[Xie et~al.(2018)Xie, Sun, Huang, Tu, and Murphy]{xie2018rethinking}
Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, and Kevin Murphy.
\newblock Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs
  in video classification.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pp.\  305--321, 2018.

\bibitem[Yang et~al.(2020)Yang, Liu, Lu, Er, and Kot]{ECCV2020ysy}
Siyuan Yang, Jun Liu, Shijian Lu, Meng~Hwa Er, and Alex~C. Kot.
\newblock Collaborative learning of gesture recognition and 3d hand pose
  estimation with multi-order feature analysis.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pp.\  769--786, 2020.

\bibitem[Yi et~al.(2021)Yi, Yang, Li, Tan, and Kot]{yi2021benchmarking}
Chenyu Yi, Siyuan Yang, Haoliang Li, Yap-peng Tan, and Alex Kot.
\newblock Benchmarking the robustness of spatial-temporal models against
  corruptions.
\newblock In \emph{Advance in Neural Information Processing Systems Track on
  Datasets and Benchmarks}, 2021.

\bibitem[Yu et~al.(2022)Yu, Yang, Tan, and Kot]{yu2022towards}
Yi~Yu, Wenhan Yang, Yap-Peng Tan, and Alex~C Kot.
\newblock Towards robust rain removal against adversarial attacks: A
  comprehensive benchmark analysis and beyond.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  6013--6022, 2022.

\bibitem[Zheng et~al.(2016)Zheng, Song, Leung, and
  Goodfellow]{zheng2016improving}
Stephan Zheng, Yang Song, Thomas Leung, and Ian Goodfellow.
\newblock Improving the robustness of deep neural networks via stability
  training.
\newblock In \emph{Proceedings of the ieee conference on computer vision and
  pattern recognition}, pp.\  4480--4488, 2016.

\end{thebibliography}
