\begin{thebibliography}{}

\bibitem[Arafa et~al., 2023]{arafa2023rn}
Arafa, A., El-Fishawy, N., Badawy, M., and Radad, M. (2023).
\newblock Rn-autoencoder: Reduced noise autoencoder for classifying imbalanced cancer genomic data.
\newblock {\em Journal of Biological Engineering}, 17(1):7.

\bibitem[Borisov et~al., 2022]{borisov2022deep}
Borisov, V., Leemann, T., Se{\ss}ler, K., Haug, J., Pawelczyk, M., and Kasneci, G. (2022).
\newblock Deep neural networks and tabular data: A survey.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}.

\bibitem[Branco et~al., 2016]{branco2016survey}
Branco, P., Torgo, L., and Ribeiro, R.~P. (2016).
\newblock A survey of predictive modeling on imbalanced domains.
\newblock {\em ACM computing surveys (CSUR)}, 49(2):1--50.

\bibitem[Branco et~al., 2017]{branco2017smogn}
Branco, P., Torgo, L., and Ribeiro, R.~P. (2017).
\newblock Smogn: a pre-processing approach for imbalanced regression.
\newblock In {\em First international workshop on learning with imbalanced domains: Theory and applications}, pages 36--50. PMLR.

\bibitem[Branco et~al., 2019]{branco2019pre}
Branco, P., Torgo, L., and Ribeiro, R.~P. (2019).
\newblock Pre-processing approaches for imbalanced distributions in regression.
\newblock {\em Neurocomputing}, 343:76--99.

\bibitem[Buda et~al., 2018]{buda2018}
Buda, M., Maki, A., and Mazurowski, M.~A. (2018).
\newblock A systematic study of the class imbalance problem in convolutional neural networks.
\newblock {\em Neural Networks}, 106:249–259.

\bibitem[Camacho et~al., 2022]{camacho2022geometric}
Camacho, L., Douzas, G., and Bacao, F. (2022).
\newblock Geometric smote for regression.
\newblock {\em Expert Systems with Applications}, page 116387.

\bibitem[Cao et~al., 2019]{cao2019}
Cao, K., Wei, C., Gaidon, A., Arechiga, N., and Ma, T. (2019).
\newblock Learning imbalanced datasets with label-distribution-aware margin loss.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Chen and Li, 2021]{chen2021self}
Chen, W. and Li, K. (2021).
\newblock Self-supervised learning for medical image classification using imbalanced training data.
\newblock In {\em International Symposium on Intelligence Computation and Applications}, pages 242--252. Springer.

\bibitem[Chen et~al., 2018]{chen2018autoencoder}
Chen, Z., Yeo, C.~K., Lee, B.~S., and Lau, C.~T. (2018).
\newblock Autoencoder-based network anomaly detection.
\newblock In {\em 2018 Wireless telecommunications symposium (WTS)}, pages 1--5. IEEE.

\bibitem[Cortez and Silva, 2008]{cortez2008using}
Cortez, P. and Silva, A. M.~G. (2008).
\newblock Using data mining to predict secondary school student performance.

\bibitem[Cui et~al., 2019]{cui2019}
Cui, Y., Jia, M., Lin, T.-Y., Song, Y., and Belongie, S. (2019).
\newblock Class-balanced loss based on effective number of samples.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 9268--9277.

\bibitem[Darabi et~al., 2021]{darabi2021contrastive}
Darabi, S., Fazeli, S., Pazoki, A., Sankararaman, S., and Sarrafzadeh, M. (2021).
\newblock Contrastive mixup: Self-and semi-supervised learning for tabular domain.
\newblock {\em arXiv preprint arXiv:2108.12296}.

\bibitem[Delong and Kozak, 2023]{delong2023use}
Delong, {\L}. and Kozak, A. (2023).
\newblock The use of autoencoders for training neural networks with mixed categorical and numerical features.
\newblock {\em ASTIN Bulletin: The Journal of the IAA}, 53(2):213--232.

\bibitem[Ding et~al., 2022]{ding2022deep}
Ding, Y., Jia, M., Zhuang, J., and Ding, P. (2022).
\newblock Deep imbalanced regression using cost-sensitive learning and deep feature transfer for bearing remaining useful life estimation.
\newblock {\em Applied Soft Computing}, 127:109271.

\bibitem[Eduardo et~al., 2020]{eduardo2020robust}
Eduardo, S., Naz{\'a}bal, A., Williams, C.~K., and Sutton, C. (2020).
\newblock Robust variational autoencoders for outlier detection and repair of mixed-type data.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 4056--4066. PMLR.

\bibitem[Elbatel et~al., 2023]{elbatel2023federated}
Elbatel, M., Wang, H., Mart, R., Fu, H., and Li, X. (2023).
\newblock Federated model aggregation via self-supervised priors for highly imbalanced medical image classification.
\newblock In {\em International Conference on Medical Image Computing and Computer-Assisted Intervention}, pages 334--346. Springer.

\bibitem[Fern{\'a}ndez et~al., 2018a]{fernandez2018learning}
Fern{\'a}ndez, A., Garc{\'\i}a, S., Galar, M., Prati, R.~C., Krawczyk, B., and Herrera, F. (2018a).
\newblock {\em Learning from imbalanced data sets}, volume~10.
\newblock Springer.

\bibitem[Fern{\'a}ndez et~al., 2018b]{fernandez2018smote}
Fern{\'a}ndez, A., Garcia, S., Herrera, F., and Chawla, N.~V. (2018b).
\newblock Smote for learning from imbalanced data: progress and challenges, marking the 15-year anniversary.
\newblock {\em Journal of artificial intelligence research}, 61:863--905.

\bibitem[Gong et~al., 2022]{gong2022ranksim}
Gong, Y., Mori, G., and Tung, F. (2022).
\newblock Ranksim: Ranking similarity regularization for deep imbalanced regression.
\newblock {\em arXiv preprint arXiv:2205.15236}.

\bibitem[Hajiramezanali et~al., 2022]{hajiramezanali2022stab}
Hajiramezanali, E., Diamant, N.~L., Scalia, G., and Shen, M.~W. (2022).
\newblock Stab: Self-supervised learning for tabular data.
\newblock In {\em NeurIPS 2022 First Table Representation Workshop}.

\bibitem[Hancock and Khoshgoftaar, 2020]{hancock2020survey}
Hancock, J.~T. and Khoshgoftaar, T.~M. (2020).
\newblock Survey on categorical data for neural networks.
\newblock {\em Journal of Big Data}, 7(1):1--41.

\bibitem[Hou et~al., 2022]{hou2022contrastive}
Hou, R., Chen, J., Feng, Y., Liu, S., He, S., and Zhou, Z. (2022).
\newblock Contrastive-weighted self-supervised model for long-tailed data classification with vision transformer augmented.
\newblock {\em Mechanical Systems and Signal Processing}, 177:109174.

\bibitem[Huang et~al., 2016]{huang2016}
Huang, C., Li, Y., Loy, C.~C., and Tang, X. (2016).
\newblock Learning deep representation for imbalanced classification.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 5375--5384.

\bibitem[Jaiswal et~al., 2020]{jaiswal2020survey}
Jaiswal, A., Babu, A.~R., Zadeh, M.~Z., Banerjee, D., and Makedon, F. (2020).
\newblock A survey on contrastive self-supervised learning.
\newblock {\em Technologies}, 9(1):2.

\bibitem[King and Zeng, 2001]{king2001logistic}
King, G. and Zeng, L. (2001).
\newblock Logistic regression in rare events data.
\newblock {\em Political analysis}, 9(2):137--163.

\bibitem[Krawczyk, 2016]{krawczyk2016learning}
Krawczyk, B. (2016).
\newblock Learning from imbalanced data: open challenges and future directions.
\newblock {\em Progress in Artificial Intelligence}, 5(4):221--232.

\bibitem[LeDell and Poirier, 2020]{H2OAutoML20}
LeDell, E. and Poirier, S. (2020).
\newblock {H2O} {A}uto{ML}: Scalable automatic machine learning.
\newblock {\em 7th ICML Workshop on Automated Machine Learning (AutoML)}.

\bibitem[Li et~al., 2021]{li2021imbalance}
Li, H., Xue, F.-F., Chaitanya, K., Luo, S., Ezhov, I., Wiestler, B., Zhang, J., and Menze, B. (2021).
\newblock Imbalance-aware self-supervised learning for 3d radiomic representations.
\newblock In {\em Medical Image Computing and Computer Assisted Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France, September 27--October 1, 2021, Proceedings, Part II 24}, pages 36--46. Springer.

\bibitem[Liu et~al., 2021a]{liu2021self}
Liu, H., HaoChen, J.~Z., Gaidon, A., and Ma, T. (2021a).
\newblock Self-supervised learning is more robust to dataset imbalance.
\newblock {\em arXiv preprint arXiv:2110.05025}.

\bibitem[Liu et~al., 2021b]{liu2021SSL}
Liu, X., Zhang, F., Hou, Z., Mian, L., Wang, Z., Zhang, J., and Tang, J. (2021b).
\newblock Self-supervised learning: Generative or contrastive.
\newblock {\em IEEE transactions on knowledge and data engineering}, 35(1):857--876.

\bibitem[Ma et~al., 2020]{ma2020vaem}
Ma, C., Tschiatschek, S., Turner, R., Hern{\'a}ndez-Lobato, J.~M., and Zhang, C. (2020).
\newblock Vaem: a deep generative model for heterogeneous mixed type data.
\newblock {\em Advances in Neural Information Processing Systems}, 33:11237--11247.

\bibitem[Mosley, 2013]{Mosley2013ABA}
Mosley, L. S.~D. (2013).
\newblock {\em A balanced approach to the multi-class imbalance problem}.
\newblock PhD thesis, Iowa State University.

\bibitem[Pag{\`e}s, 2004]{pages2004analyse}
Pag{\`e}s, J. (2004).
\newblock Analyse factorielle de donnees mixtes: principe et exemple d’application.
\newblock {\em Revue de statistique appliqu{\'e}e}, 52(4):93--111.

\bibitem[Palechor and de~la Hoz~Manotas, 2019]{palechor2019dataset}
Palechor, F.~M. and de~la Hoz~Manotas, A. (2019).
\newblock Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from colombia, peru and mexico.
\newblock {\em Data in brief}, 25:104344.

\bibitem[Potdar et~al., 2017]{potdar2017comparative}
Potdar, K., Pardawala, T.~S., and Pai, C.~D. (2017).
\newblock A comparative study of categorical variable encoding techniques for neural network classifiers.
\newblock {\em International journal of computer applications}, 175(4):7--9.

\bibitem[Ren et~al., 2022]{ren2022balanced}
Ren, J., Zhang, M., Yu, C., and Liu, Z. (2022).
\newblock Balanced mse for imbalanced visual regression.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7926--7935.

\bibitem[Ribeiro and Moniz, 2020]{ribeiro2020imbalanced}
Ribeiro, R.~P. and Moniz, N. (2020).
\newblock Imbalanced regression and extreme value prediction.
\newblock {\em Machine Learning}, 109:1803--1835.

\bibitem[Sen et~al., 2023]{sen2023dealing}
Sen, S., Singh, K.~P., and Chakraborty, P. (2023).
\newblock Dealing with imbalanced regression problem for large dataset using scalable artificial neural network.
\newblock {\em New Astronomy}, 99:101959.

\bibitem[Shwartz-Ziv and Armon, 2022]{shwartz2022tabular}
Shwartz-Ziv, R. and Armon, A. (2022).
\newblock Tabular data: Deep learning is not all you need.
\newblock {\em Information Fusion}, 81:84--90.

\bibitem[So et~al., 2021]{so2021synthetic}
So, B., Boucher, J.-P., and Valdez, E.~A. (2021).
\newblock Synthetic dataset generation of driver telematics.
\newblock {\em Risks}, 9(4):58.

\bibitem[Song et~al., 2022]{song2022distsmogn}
Song, X.~Y., Dao, N., and Branco, P. (2022).
\newblock Distsmogn: Distributed smogn for imbalanced regression problems.
\newblock In {\em Fourth International Workshop on Learning with Imbalanced Domains: Theory and Applications}, pages 38--52. PMLR.

\bibitem[Stocksieker et~al., 2023]{stocksieker2023data}
Stocksieker, S., Pommeret, D., and Charpentier, A. (2023).
\newblock Data augmentation for imbalanced regression.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 7774--7799. PMLR.

\bibitem[Timofeev et~al., 2021]{timofeev2021self}
Timofeev, A., Chrysos, G.~G., and Cevher, V. (2021).
\newblock Self-supervised neural architecture search for imbalanced datasets.
\newblock {\em arXiv preprint arXiv:2109.08580}.

\bibitem[Tomescu et~al., 2021]{tomescu2021study}
Tomescu, V.-I., Czibula, G., and Ni{\c{t}}ic{\u{a}}, {\c{S}}. (2021).
\newblock A study on using deep autoencoders for imbalanced binary classification.
\newblock {\em Procedia Computer Science}, 192:119--128.

\bibitem[Torgo and Ribeiro, 2007]{torgo2007utility}
Torgo, L. and Ribeiro, R. (2007).
\newblock Utility-based regression.
\newblock In {\em Knowledge Discovery in Databases: PKDD 2007: 11th European Conference on Principles and Practice of Knowledge Discovery in Databases, Warsaw, Poland, September 17-21, 2007. Proceedings 11}, pages 597--604. Springer.

\bibitem[Torgo et~al., 2013]{torgo2013smote}
Torgo, L., Ribeiro, R.~P., Pfahringer, B., and Branco, P. (2013).
\newblock Smote for regression.
\newblock In {\em Portuguese conference on artificial intelligence}, pages 378--389. Springer.

\bibitem[Ucar et~al., 2021]{ucar2021subtab}
Ucar, T., Hajiramezanali, E., and Edwards, L. (2021).
\newblock Subtab: Subsetting features of tabular data for self-supervised representation learning.
\newblock {\em Advances in Neural Information Processing Systems}, 34:18853--18865.

\bibitem[Vardhan and Kok, 2020]{vardhan2020synthetic}
Vardhan, L. V.~H. and Kok, S. (2020).
\newblock Synthetic tabular data generation with oblivious variational autoencoders: alleviating the paucity of personal tabular data for open research.
\newblock In {\em Proceedings of the 37th International conference on machine learning, ICML HSYS Workshop 2020}.

\bibitem[Xu et~al., 2019]{xu2019modeling}
Xu, L., Skoularidou, M., Cuesta-Infante, A., and Veeramachaneni, K. (2019).
\newblock Modeling tabular data using conditional gan.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Yamanaka et~al., 2019]{yamanaka2019autoencoding}
Yamanaka, Y., Iwata, T., Takahashi, H., Yamada, M., and Kanai, S. (2019).
\newblock Autoencoding binary classifiers for supervised anomaly detection.
\newblock In {\em PRICAI 2019: Trends in Artificial Intelligence: 16th Pacific Rim International Conference on Artificial Intelligence, Cuvu, Yanuca Island, Fiji, August 26--30, 2019, Proceedings, Part II 16}, pages 647--659. Springer.

\bibitem[Yang and Xu, 2020a]{yang2020}
Yang, Y. and Xu, Z. (2020a).
\newblock Rethinking the value of labels for improving class-imbalanced learning.
\newblock {\em NeurIPS}.

\bibitem[Yang and Xu, 2020b]{yang2020rethinking}
Yang, Y. and Xu, Z. (2020b).
\newblock Rethinking the value of labels for improving class-imbalanced learning.
\newblock {\em Advances in neural information processing systems}, 33:19290--19301.

\bibitem[Yang et~al., 2021]{yang2021}
Yang, Y., Zha, K., Chen, Y., Wang, H., and Katabi, D. (2021).
\newblock Delving into deep imbalanced regression.
\newblock In {\em International Conference on Machine Learning}, pages 11842--11851. PMLR.

\bibitem[Yoon et~al., 2020]{yoon2020vime}
Yoon, J., Zhang, Y., Jordon, J., and van~der Schaar, M. (2020).
\newblock Vime: Extending the success of self-and semi-supervised learning to tabular domain.
\newblock {\em Advances in Neural Information Processing Systems}, 33:11033--11043.

\bibitem[Zhang and Bom, 2021]{zhang2021auto}
Zhang, C. and Bom, S. (2021).
\newblock Auto-encoder based model for high-dimensional imbalanced industrial data.
\newblock In {\em International Conference on Neural Information Processing}, pages 265--273. Springer.

\bibitem[Zhang et~al., 2023]{zhang2023mixed}
Zhang, H., Zhang, J., Srinivasan, B., Shen, Z., Qin, X., Faloutsos, C., Rangwala, H., and Karypis, G. (2023).
\newblock Mixed-type tabular data synthesis with score-based diffusion in latent space.
\newblock {\em arXiv preprint arXiv:2310.09656}.

\end{thebibliography}
