%% BioMed_Central_Bib_Style_v1.01

\begin{thebibliography}{72}
% BibTex style file: bmc-mathphys.bst (version 2.1), 2014-07-24
\ifx \bisbn   \undefined \def \bisbn  #1{ISBN #1}\fi
\ifx \binits  \undefined \def \binits#1{#1}\fi
\ifx \bauthor  \undefined \def \bauthor#1{#1}\fi
\ifx \batitle  \undefined \def \batitle#1{#1}\fi
\ifx \bjtitle  \undefined \def \bjtitle#1{#1}\fi
\ifx \bvolume  \undefined \def \bvolume#1{\textbf{#1}}\fi
\ifx \byear  \undefined \def \byear#1{#1}\fi
\ifx \bissue  \undefined \def \bissue#1{#1}\fi
\ifx \bfpage  \undefined \def \bfpage#1{#1}\fi
\ifx \blpage  \undefined \def \blpage #1{#1}\fi
\ifx \burl  \undefined \def \burl#1{\textsf{#1}}\fi
\ifx \doiurl  \undefined \def \doiurl#1{\url{https://doi.org/#1}}\fi
\ifx \betal  \undefined \def \betal{\textit{et al.}}\fi
\ifx \binstitute  \undefined \def \binstitute#1{#1}\fi
\ifx \binstitutionaled  \undefined \def \binstitutionaled#1{#1}\fi
\ifx \bctitle  \undefined \def \bctitle#1{#1}\fi
\ifx \beditor  \undefined \def \beditor#1{#1}\fi
\ifx \bpublisher  \undefined \def \bpublisher#1{#1}\fi
\ifx \bbtitle  \undefined \def \bbtitle#1{#1}\fi
\ifx \bedition  \undefined \def \bedition#1{#1}\fi
\ifx \bseriesno  \undefined \def \bseriesno#1{#1}\fi
\ifx \blocation  \undefined \def \blocation#1{#1}\fi
\ifx \bsertitle  \undefined \def \bsertitle#1{#1}\fi
\ifx \bsnm \undefined \def \bsnm#1{#1}\fi
\ifx \bsuffix \undefined \def \bsuffix#1{#1}\fi
\ifx \bparticle \undefined \def \bparticle#1{#1}\fi
\ifx \barticle \undefined \def \barticle#1{#1}\fi
\bibcommenthead
\ifx \bconfdate \undefined \def \bconfdate #1{#1}\fi
\ifx \botherref \undefined \def \botherref #1{#1}\fi
\ifx \url \undefined \def \url#1{\textsf{#1}}\fi
\ifx \bchapter \undefined \def \bchapter#1{#1}\fi
\ifx \bbook \undefined \def \bbook#1{#1}\fi
\ifx \bcomment \undefined \def \bcomment#1{#1}\fi
\ifx \oauthor \undefined \def \oauthor#1{#1}\fi
\ifx \citeauthoryear \undefined \def \citeauthoryear#1{#1}\fi
\ifx \endbibitem  \undefined \def \endbibitem {}\fi
\ifx \bconflocation  \undefined \def \bconflocation#1{#1}\fi
\ifx \arxivurl  \undefined \def \arxivurl#1{\textsf{#1}}\fi
\csname PreBibitemsHook\endcsname

%%% 1
\bibitem[\protect\citeauthoryear{Long et~al.}{2015}]{long2015fully}
\begin{bchapter}
\bauthor{\bsnm{Long}, \binits{J.}},
\bauthor{\bsnm{Shelhamer}, \binits{E.}},
\bauthor{\bsnm{Darrell}, \binits{T.}}:
\bctitle{Fully convolutional networks for semantic segmentation}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2015})
\end{bchapter}
\endbibitem

%%% 2
\bibitem[\protect\citeauthoryear{Dosovitskiy et~al.}{2021}]{dosovitskiy2020image}
\begin{bchapter}
\bauthor{\bsnm{Dosovitskiy}, \binits{A.}},
\bauthor{\bsnm{Beyer}, \binits{L.}},
\bauthor{\bsnm{Kolesnikov}, \binits{A.}},
\bauthor{\bsnm{Weissenborn}, \binits{D.}},
\bauthor{\bsnm{Zhai}, \binits{X.}},
\bauthor{\bsnm{Unterthiner}, \binits{T.}},
\bauthor{\bsnm{Dehghani}, \binits{M.}},
\bauthor{\bsnm{Minderer}, \binits{M.}},
\bauthor{\bsnm{Heigold}, \binits{G.}},
\bauthor{\bsnm{Gelly}, \binits{S.}}, \betal:
\bctitle{An image is worth 16x16 words: Transformers for image recognition at scale}.
In: \bbtitle{International Conference on Learning Representations}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 3
\bibitem[\protect\citeauthoryear{Zheng et~al.}{2021}]{zheng2021rethinking}
\begin{bchapter}
\bauthor{\bsnm{Zheng}, \binits{S.}},
\bauthor{\bsnm{Lu}, \binits{J.}},
\bauthor{\bsnm{Zhao}, \binits{H.}},
\bauthor{\bsnm{Zhu}, \binits{X.}},
\bauthor{\bsnm{Luo}, \binits{Z.}},
\bauthor{\bsnm{Wang}, \binits{Y.}},
\bauthor{\bsnm{Fu}, \binits{Y.}},
\bauthor{\bsnm{Feng}, \binits{J.}},
\bauthor{\bsnm{Xiang}, \binits{T.}},
\bauthor{\bsnm{Torr}, \binits{P.H.}}, \betal:
\bctitle{Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 4
\bibitem[\protect\citeauthoryear{Xie et~al.}{2021}]{xie2021segformer}
\begin{bchapter}
\bauthor{\bsnm{Xie}, \binits{E.}},
\bauthor{\bsnm{Wang}, \binits{W.}},
\bauthor{\bsnm{Yu}, \binits{Z.}},
\bauthor{\bsnm{Anandkumar}, \binits{A.}},
\bauthor{\bsnm{Alvarez}, \binits{J.M.}},
\bauthor{\bsnm{Luo}, \binits{P.}}:
\bctitle{Segformer: Simple and efficient design for semantic segmentation with transformers}.
In: \bbtitle{Advances in Neural Information Processing Systems}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 5
\bibitem[\protect\citeauthoryear{Luong et~al.}{2015}]{luong2015effective}
\begin{botherref}
\oauthor{\bsnm{Luong}, \binits{M.-T.}},
\oauthor{\bsnm{Pham}, \binits{H.}},
\oauthor{\bsnm{Manning}, \binits{C.D.}}:
Effective approaches to attention-based neural machine translation.
arXiv preprint
(2015)
\end{botherref}
\endbibitem

%%% 6
\bibitem[\protect\citeauthoryear{Liu et~al.}{2021}]{liu2021swin}
\begin{bchapter}
\bauthor{\bsnm{Liu}, \binits{Z.}},
\bauthor{\bsnm{Lin}, \binits{Y.}},
\bauthor{\bsnm{Cao}, \binits{Y.}},
\bauthor{\bsnm{Hu}, \binits{H.}},
\bauthor{\bsnm{Wei}, \binits{Y.}},
\bauthor{\bsnm{Zhang}, \binits{Z.}},
\bauthor{\bsnm{Lin}, \binits{S.}},
\bauthor{\bsnm{Guo}, \binits{B.}}:
\bctitle{Swin transformer: Hierarchical vision transformer using shifted windows}.
In: \bbtitle{IEEE International Conference on Computer Vision}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 7
\bibitem[\protect\citeauthoryear{Huang et~al.}{2021}]{huang2021shuffle}
\begin{botherref}
\oauthor{\bsnm{Huang}, \binits{Z.}},
\oauthor{\bsnm{Ben}, \binits{Y.}},
\oauthor{\bsnm{Luo}, \binits{G.}},
\oauthor{\bsnm{Cheng}, \binits{P.}},
\oauthor{\bsnm{Yu}, \binits{G.}},
\oauthor{\bsnm{Fu}, \binits{B.}}:
Shuffle transformer: Rethinking spatial shuffle for vision transformer.
arXiv preprint
(2021)
\end{botherref}
\endbibitem

%%% 8
\bibitem[\protect\citeauthoryear{Yuan et~al.}{2021}]{yuan2021hrformer}
\begin{botherref}
\oauthor{\bsnm{Yuan}, \binits{Y.}},
\oauthor{\bsnm{Fu}, \binits{R.}},
\oauthor{\bsnm{Huang}, \binits{L.}},
\oauthor{\bsnm{Lin}, \binits{W.}},
\oauthor{\bsnm{Zhang}, \binits{C.}},
\oauthor{\bsnm{Chen}, \binits{X.}},
\oauthor{\bsnm{Wang}, \binits{J.}}:
Hrformer: High-resolution transformer for dense prediction.
arXiv preprint
(2021)
\end{botherref}
\endbibitem

%%% 9
\bibitem[\protect\citeauthoryear{Huang et~al.}{2019}]{huang2019ccnet}
\begin{bchapter}
\bauthor{\bsnm{Huang}, \binits{Z.}},
\bauthor{\bsnm{Wang}, \binits{X.}},
\bauthor{\bsnm{Huang}, \binits{L.}},
\bauthor{\bsnm{Huang}, \binits{C.}},
\bauthor{\bsnm{Wei}, \binits{Y.}},
\bauthor{\bsnm{Liu}, \binits{W.}}:
\bctitle{Ccnet: Criss-cross attention for semantic segmentation}.
In: \bbtitle{IEEE International Conference on Computer Vision}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 10
\bibitem[\protect\citeauthoryear{Ho et~al.}{2019}]{ho2019axial}
\begin{botherref}
\oauthor{\bsnm{Ho}, \binits{J.}},
\oauthor{\bsnm{Kalchbrenner}, \binits{N.}},
\oauthor{\bsnm{Weissenborn}, \binits{D.}},
\oauthor{\bsnm{Salimans}, \binits{T.}}:
Axial attention in multidimensional transformers.
arXiv preprint
(2019)
\end{botherref}
\endbibitem

%%% 11
\bibitem[\protect\citeauthoryear{Wang et~al.}{2020}]{wang2020axial}
\begin{bchapter}
\bauthor{\bsnm{Wang}, \binits{H.}},
\bauthor{\bsnm{Zhu}, \binits{Y.}},
\bauthor{\bsnm{Green}, \binits{B.}},
\bauthor{\bsnm{Adam}, \binits{H.}},
\bauthor{\bsnm{Yuille}, \binits{A.}},
\bauthor{\bsnm{Chen}, \binits{L.-C.}}:
\bctitle{Axial-deeplab: Stand-alone axial-attention for panoptic segmentation}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2020})
\end{bchapter}
\endbibitem

%%% 12
\bibitem[\protect\citeauthoryear{Zhang et~al.}{2020}]{zhang2020dynamic}
\begin{bchapter}
\bauthor{\bsnm{Zhang}, \binits{L.}},
\bauthor{\bsnm{Xu}, \binits{D.}},
\bauthor{\bsnm{Arnab}, \binits{A.}},
\bauthor{\bsnm{Torr}, \binits{P.H.}}:
\bctitle{Dynamic graph message passing networks}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2020})
\end{bchapter}
\endbibitem

%%% 13
\bibitem[\protect\citeauthoryear{Zhang et~al.}{2022}]{zhang2022dynamic}
\begin{botherref}
\oauthor{\bsnm{Zhang}, \binits{L.}},
\oauthor{\bsnm{Chen}, \binits{M.}},
\oauthor{\bsnm{Arnab}, \binits{A.}},
\oauthor{\bsnm{Xue}, \binits{X.}},
\oauthor{\bsnm{Torr}, \binits{P.H.}}:
Dynamic graph message passing networks for visual recognition.
IEEE Transactions on Pattern Analysis and Machine Intelligence
(2022)
\end{botherref}
\endbibitem

%%% 14
\bibitem[\protect\citeauthoryear{Hou et~al.}{2020}]{hou2020strip}
\begin{bchapter}
\bauthor{\bsnm{Hou}, \binits{Q.}},
\bauthor{\bsnm{Zhang}, \binits{L.}},
\bauthor{\bsnm{Cheng}, \binits{M.-M.}},
\bauthor{\bsnm{Feng}, \binits{J.}}:
\bctitle{Strip pooling: Rethinking spatial pooling for scene parsing}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2020})
\end{bchapter}
\endbibitem

%%% 15
\bibitem[\protect\citeauthoryear{Li et~al.}{2021a}]{li2021towards}
\begin{botherref}
\oauthor{\bsnm{Li}, \binits{X.}},
\oauthor{\bsnm{Li}, \binits{X.}},
\oauthor{\bsnm{You}, \binits{A.}},
\oauthor{\bsnm{Zhang}, \binits{L.}},
\oauthor{\bsnm{Cheng}, \binits{G.}},
\oauthor{\bsnm{Yang}, \binits{K.}},
\oauthor{\bsnm{Tong}, \binits{Y.}},
\oauthor{\bsnm{Lin}, \binits{Z.}}:
Towards efficient scene understanding via squeeze reasoning.
IEEE Transactions on Image Processing
(2021)
\end{botherref}
\endbibitem

%%% 16
\bibitem[\protect\citeauthoryear{Li et~al.}{2021b}]{li2021global}
\begin{botherref}
\oauthor{\bsnm{Li}, \binits{X.}},
\oauthor{\bsnm{Zhang}, \binits{L.}},
\oauthor{\bsnm{Cheng}, \binits{G.}},
\oauthor{\bsnm{Yang}, \binits{K.}},
\oauthor{\bsnm{Tong}, \binits{Y.}},
\oauthor{\bsnm{Zhu}, \binits{X.}},
\oauthor{\bsnm{Xiang}, \binits{T.}}:
Global aggregation then local distribution for scene parsing.
IEEE Transactions on Image Processing
(2021)
\end{botherref}
\endbibitem

%%% 17
\bibitem[\protect\citeauthoryear{Li et~al.}{2020}]{li2020improving}
\begin{bchapter}
\bauthor{\bsnm{Li}, \binits{X.}},
\bauthor{\bsnm{Li}, \binits{X.}},
\bauthor{\bsnm{Zhang}, \binits{L.}},
\bauthor{\bsnm{Cheng}, \binits{G.}},
\bauthor{\bsnm{Shi}, \binits{J.}},
\bauthor{\bsnm{Lin}, \binits{Z.}},
\bauthor{\bsnm{Tan}, \binits{S.}},
\bauthor{\bsnm{Tong}, \binits{Y.}}:
\bctitle{Improving semantic segmentation via decoupled body and edge supervision}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2020})
\end{bchapter}
\endbibitem

%%% 18
\bibitem[\protect\citeauthoryear{Liu et~al.}{2018}]{liu2018generating}
\begin{bchapter}
\bauthor{\bsnm{Liu}, \binits{P.J.}},
\bauthor{\bsnm{Saleh}, \binits{M.}},
\bauthor{\bsnm{Pot}, \binits{E.}},
\bauthor{\bsnm{Goodrich}, \binits{B.}},
\bauthor{\bsnm{Sepassi}, \binits{R.}},
\bauthor{\bsnm{Kaiser}, \binits{L.}},
\bauthor{\bsnm{Shazeer}, \binits{N.}}:
\bctitle{Generating wikipedia by summarizing long sequences}.
In: \bbtitle{International Conference on Learning Representations}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 19
\bibitem[\protect\citeauthoryear{Shen et~al.}{2021}]{shen2021efficient}
\begin{bchapter}
\bauthor{\bsnm{Shen}, \binits{Z.}},
\bauthor{\bsnm{Zhang}, \binits{M.}},
\bauthor{\bsnm{Zhao}, \binits{H.}},
\bauthor{\bsnm{Yi}, \binits{S.}},
\bauthor{\bsnm{Li}, \binits{H.}}:
\bctitle{Efficient attention: Attention with linear complexities}.
In: \bbtitle{IEEE Winter Conference on Applications of Computer Vision}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 20
\bibitem[\protect\citeauthoryear{Xu et~al.}{2021}]{xu2021co}
\begin{bchapter}
\bauthor{\bsnm{Xu}, \binits{W.}},
\bauthor{\bsnm{Xu}, \binits{Y.}},
\bauthor{\bsnm{Chang}, \binits{T.}},
\bauthor{\bsnm{Tu}, \binits{Z.}}:
\bctitle{Co-scale conv-attentional image transformers}.
In: \bbtitle{IEEE International Conference on Computer Vision}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 21
\bibitem[\protect\citeauthoryear{Cao et~al.}{2019}]{cao2019gcnet}
\begin{bchapter}
\bauthor{\bsnm{Cao}, \binits{Y.}},
\bauthor{\bsnm{Xu}, \binits{J.}},
\bauthor{\bsnm{Lin}, \binits{S.}},
\bauthor{\bsnm{Wei}, \binits{F.}},
\bauthor{\bsnm{Hu}, \binits{H.}}:
\bctitle{Gcnet: Non-local networks meet squeeze-excitation networks and beyond}.
In: \bbtitle{IEEE International Conference on Computer Vision Workshops}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 22
\bibitem[\protect\citeauthoryear{Woo et~al.}{2018}]{woo2018cbam}
\begin{bchapter}
\bauthor{\bsnm{Woo}, \binits{S.}},
\bauthor{\bsnm{Park}, \binits{J.}},
\bauthor{\bsnm{Lee}, \binits{J.-Y.}},
\bauthor{\bsnm{Kweon}, \binits{I.S.}}:
\bctitle{Cbam: Convolutional block attention module}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 23
\bibitem[\protect\citeauthoryear{Wang et~al.}{2020}]{wang2020linformer}
\begin{botherref}
\oauthor{\bsnm{Wang}, \binits{S.}},
\oauthor{\bsnm{Li}, \binits{B.Z.}},
\oauthor{\bsnm{Khabsa}, \binits{M.}},
\oauthor{\bsnm{Fang}, \binits{H.}},
\oauthor{\bsnm{Ma}, \binits{H.}}:
Linformer: Self-attention with linear complexity.
arXiv preprint
(2020)
\end{botherref}
\endbibitem

%%% 24
\bibitem[\protect\citeauthoryear{Choromanski et~al.}{2021}]{choromanski2020rethinking}
\begin{bchapter}
\bauthor{\bsnm{Choromanski}, \binits{K.}},
\bauthor{\bsnm{Likhosherstov}, \binits{V.}},
\bauthor{\bsnm{Dohan}, \binits{D.}},
\bauthor{\bsnm{Song}, \binits{X.}},
\bauthor{\bsnm{Gane}, \binits{A.}},
\bauthor{\bsnm{Sarlos}, \binits{T.}},
\bauthor{\bsnm{Hawkins}, \binits{P.}},
\bauthor{\bsnm{Davis}, \binits{J.}},
\bauthor{\bsnm{Mohiuddin}, \binits{A.}},
\bauthor{\bsnm{Kaiser}, \binits{L.}}, \betal:
\bctitle{Rethinking attention with performers}.
In: \bbtitle{International Conference on Learning Representations}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 25
\bibitem[\protect\citeauthoryear{Chen et~al.}{2017}]{chen2017rethinking}
\begin{botherref}
\oauthor{\bsnm{Chen}, \binits{L.-C.}},
\oauthor{\bsnm{Papandreou}, \binits{G.}},
\oauthor{\bsnm{Schroff}, \binits{F.}},
\oauthor{\bsnm{Adam}, \binits{H.}}:
Rethinking atrous convolution for semantic image segmentation.
arXiv preprint
(2017)
\end{botherref}
\endbibitem

%%% 26
\bibitem[\protect\citeauthoryear{Mehta and Rastegari}{2022}]{mehta2021mobilevit}
\begin{bchapter}
\bauthor{\bsnm{Mehta}, \binits{S.}},
\bauthor{\bsnm{Rastegari}, \binits{M.}}:
\bctitle{Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer}.
In: \bbtitle{International Conference on Learning Representations}
(\byear{2022})
\end{bchapter}
\endbibitem

%%% 27
\bibitem[\protect\citeauthoryear{Vaswani et~al.}{2017}]{vaswani2017attention}
\begin{bchapter}
\bauthor{\bsnm{Vaswani}, \binits{A.}},
\bauthor{\bsnm{Shazeer}, \binits{N.}},
\bauthor{\bsnm{Parmar}, \binits{N.}},
\bauthor{\bsnm{Uszkoreit}, \binits{J.}},
\bauthor{\bsnm{Jones}, \binits{L.}},
\bauthor{\bsnm{Gomez}, \binits{A.N.}},
\bauthor{\bsnm{Kaiser}, \binits{{\L}.}},
\bauthor{\bsnm{Polosukhin}, \binits{I.}}:
\bctitle{Attention is all you need}.
In: \bbtitle{Advances in Neural Information Processing Systems}
(\byear{2017})
\end{bchapter}
\endbibitem

%%% 28
\bibitem[\protect\citeauthoryear{Chen et~al.}{2022}]{chen2022mixformer}
\begin{bchapter}
\bauthor{\bsnm{Chen}, \binits{Q.}},
\bauthor{\bsnm{Wu}, \binits{Q.}},
\bauthor{\bsnm{Wang}, \binits{J.}},
\bauthor{\bsnm{Hu}, \binits{Q.}},
\bauthor{\bsnm{Hu}, \binits{T.}},
\bauthor{\bsnm{Ding}, \binits{E.}},
\bauthor{\bsnm{Cheng}, \binits{J.}},
\bauthor{\bsnm{Wang}, \binits{J.}}:
\bctitle{Mixformer: Mixing features across windows and dimensions}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2022})
\end{bchapter}
\endbibitem

%%% 29
\bibitem[\protect\citeauthoryear{Pan et~al.}{2022}]{pan2022integration}
\begin{bchapter}
\bauthor{\bsnm{Pan}, \binits{X.}},
\bauthor{\bsnm{Ge}, \binits{C.}},
\bauthor{\bsnm{Lu}, \binits{R.}},
\bauthor{\bsnm{Song}, \binits{S.}},
\bauthor{\bsnm{Chen}, \binits{G.}},
\bauthor{\bsnm{Huang}, \binits{Z.}},
\bauthor{\bsnm{Huang}, \binits{G.}}:
\bctitle{On the integration of self-attention and convolution}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2022})
\end{bchapter}
\endbibitem

%%% 30
\bibitem[\protect\citeauthoryear{Sandler et~al.}{2018}]{sandler2018mobilenetv2}
\begin{bchapter}
\bauthor{\bsnm{Sandler}, \binits{M.}},
\bauthor{\bsnm{Howard}, \binits{A.}},
\bauthor{\bsnm{Zhu}, \binits{M.}},
\bauthor{\bsnm{Zhmoginov}, \binits{A.}},
\bauthor{\bsnm{Chen}, \binits{L.-C.}}:
\bctitle{Mobilenetv2: Inverted residuals and linear bottlenecks}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 31
\bibitem[\protect\citeauthoryear{Howard et~al.}{2019}]{howard2019searching}
\begin{bchapter}
\bauthor{\bsnm{Howard}, \binits{A.}},
\bauthor{\bsnm{Sandler}, \binits{M.}},
\bauthor{\bsnm{Chu}, \binits{G.}},
\bauthor{\bsnm{Chen}, \binits{L.-C.}},
\bauthor{\bsnm{Chen}, \binits{B.}},
\bauthor{\bsnm{Tan}, \binits{M.}},
\bauthor{\bsnm{Wang}, \binits{W.}},
\bauthor{\bsnm{Zhu}, \binits{Y.}},
\bauthor{\bsnm{Pang}, \binits{R.}},
\bauthor{\bsnm{Vasudevan}, \binits{V.}}, \betal:
\bctitle{Searching for mobilenetv3}.
In: \bbtitle{IEEE International Conference on Computer Vision}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 32
\bibitem[\protect\citeauthoryear{Zhang et~al.}{2022}]{zhang2022topformer}
\begin{bchapter}
\bauthor{\bsnm{Zhang}, \binits{W.}},
\bauthor{\bsnm{Huang}, \binits{Z.}},
\bauthor{\bsnm{Luo}, \binits{G.}},
\bauthor{\bsnm{Chen}, \binits{T.}},
\bauthor{\bsnm{Wang}, \binits{X.}},
\bauthor{\bsnm{Liu}, \binits{W.}},
\bauthor{\bsnm{Yu}, \binits{G.}},
\bauthor{\bsnm{Shen}, \binits{C.}}:
\bctitle{Topformer: Token pyramid transformer for mobile semantic segmentation}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2022})
\end{bchapter}
\endbibitem

%%% 33
\bibitem[\protect\citeauthoryear{Wan et~al.}{2023}]{wan2023seaformer}
\begin{bchapter}
\bauthor{\bsnm{Wan}, \binits{Q.}},
\bauthor{\bsnm{Huang}, \binits{Z.}},
\bauthor{\bsnm{Lu}, \binits{J.}},
\bauthor{\bsnm{Yu}, \binits{G.}},
\bauthor{\bsnm{Zhang}, \binits{L.}}:
\bctitle{Seaformer: Squeeze-enhanced axial transformer for mobile semantic segmentation}.
In: \bbtitle{International Conference on Learning Representations}
(\byear{2023})
\end{bchapter}
\endbibitem

%%% 34
\bibitem[\protect\citeauthoryear{Yang et~al.}{2022}]{yang2022lite}
\begin{bchapter}
\bauthor{\bsnm{Yang}, \binits{C.}},
\bauthor{\bsnm{Wang}, \binits{Y.}},
\bauthor{\bsnm{Zhang}, \binits{J.}},
\bauthor{\bsnm{Zhang}, \binits{H.}},
\bauthor{\bsnm{Wei}, \binits{Z.}},
\bauthor{\bsnm{Lin}, \binits{Z.}},
\bauthor{\bsnm{Yuille}, \binits{A.}}:
\bctitle{Lite vision transformer with enhanced self-attention}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2022})
\end{bchapter}
\endbibitem

%%% 35
\bibitem[\protect\citeauthoryear{Chen et~al.}{2022}]{chen2022mobile}
\begin{bchapter}
\bauthor{\bsnm{Chen}, \binits{Y.}},
\bauthor{\bsnm{Dai}, \binits{X.}},
\bauthor{\bsnm{Chen}, \binits{D.}},
\bauthor{\bsnm{Liu}, \binits{M.}},
\bauthor{\bsnm{Dong}, \binits{X.}},
\bauthor{\bsnm{Yuan}, \binits{L.}},
\bauthor{\bsnm{Liu}, \binits{Z.}}:
\bctitle{Mobile-former: Bridging mobilenet and transformer}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2022})
\end{bchapter}
\endbibitem

%%% 36
\bibitem[\protect\citeauthoryear{Pan et~al.}{2022}]{pan2022edgevits}
\begin{bchapter}
\bauthor{\bsnm{Pan}, \binits{J.}},
\bauthor{\bsnm{Bulat}, \binits{A.}},
\bauthor{\bsnm{Tan}, \binits{F.}},
\bauthor{\bsnm{Zhu}, \binits{X.}},
\bauthor{\bsnm{Dudziak}, \binits{L.}},
\bauthor{\bsnm{Li}, \binits{H.}},
\bauthor{\bsnm{Tzimiropoulos}, \binits{G.}},
\bauthor{\bsnm{Martinez}, \binits{B.}}:
\bctitle{Edgevits: Competing light-weight cnns on mobile devices with vision transformers}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2022})
\end{bchapter}
\endbibitem

%%% 37
\bibitem[\protect\citeauthoryear{Mehta and Rastegari}{2022}]{mehta2022separable}
\begin{botherref}
\oauthor{\bsnm{Mehta}, \binits{S.}},
\oauthor{\bsnm{Rastegari}, \binits{M.}}:
Separable self-attention for mobile vision transformers.
arXiv preprint
(2022)
\end{botherref}
\endbibitem

%%% 38
\bibitem[\protect\citeauthoryear{Zhang et~al.}{2022}]{zhang2022edgeformer}
\begin{botherref}
\oauthor{\bsnm{Zhang}, \binits{H.}},
\oauthor{\bsnm{Hu}, \binits{W.}},
\oauthor{\bsnm{Wang}, \binits{X.}}:
Edgeformer: Improving light-weight convnets by learning from vision transformers.
arXiv preprint
(2022)
\end{botherref}
\endbibitem

%%% 39
\bibitem[\protect\citeauthoryear{Li et~al.}{2022}]{li2022efficientformer}
\begin{botherref}
\oauthor{\bsnm{Li}, \binits{Y.}},
\oauthor{\bsnm{Yuan}, \binits{G.}},
\oauthor{\bsnm{Wen}, \binits{Y.}},
\oauthor{\bsnm{Hu}, \binits{E.}},
\oauthor{\bsnm{Evangelidis}, \binits{G.}},
\oauthor{\bsnm{Tulyakov}, \binits{S.}},
\oauthor{\bsnm{Wang}, \binits{Y.}},
\oauthor{\bsnm{Ren}, \binits{J.}}:
Efficientformer: Vision transformers at mobilenet speed.
arXiv preprint
(2022)
\end{botherref}
\endbibitem

%%% 40
\bibitem[\protect\citeauthoryear{Hou et~al.}{2021}]{hou2021coordinate}
\begin{bchapter}
\bauthor{\bsnm{Hou}, \binits{Q.}},
\bauthor{\bsnm{Zhou}, \binits{D.}},
\bauthor{\bsnm{Feng}, \binits{J.}}:
\bctitle{Coordinate attention for efficient mobile network design}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 41
\bibitem[\protect\citeauthoryear{Gao et~al.}{2020}]{gao2020kronecker}
\begin{bchapter}
\bauthor{\bsnm{Gao}, \binits{H.}},
\bauthor{\bsnm{Wang}, \binits{Z.}},
\bauthor{\bsnm{Ji}, \binits{S.}}:
\bctitle{Kronecker attention networks}.
In: \bbtitle{ACM SIGKDD}
(\byear{2020})
\end{bchapter}
\endbibitem

%%% 42
\bibitem[\protect\citeauthoryear{Li et~al.}{2019}]{li2019dfanet}
\begin{bchapter}
\bauthor{\bsnm{Li}, \binits{H.}},
\bauthor{\bsnm{Xiong}, \binits{P.}},
\bauthor{\bsnm{Fan}, \binits{H.}},
\bauthor{\bsnm{Sun}, \binits{J.}}:
\bctitle{Dfanet: Deep feature aggregation for real-time semantic segmentation}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 43
\bibitem[\protect\citeauthoryear{Zhao et~al.}{2018}]{zhao2018icnet}
\begin{bchapter}
\bauthor{\bsnm{Zhao}, \binits{H.}},
\bauthor{\bsnm{Qi}, \binits{X.}},
\bauthor{\bsnm{Shen}, \binits{X.}},
\bauthor{\bsnm{Shi}, \binits{J.}},
\bauthor{\bsnm{Jia}, \binits{J.}}:
\bctitle{Icnet for real-time semantic segmentation on high-resolution images}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 44
\bibitem[\protect\citeauthoryear{Yu et~al.}{2018}]{yu2018bisenet}
\begin{bchapter}
\bauthor{\bsnm{Yu}, \binits{C.}},
\bauthor{\bsnm{Wang}, \binits{J.}},
\bauthor{\bsnm{Peng}, \binits{C.}},
\bauthor{\bsnm{Gao}, \binits{C.}},
\bauthor{\bsnm{Yu}, \binits{G.}},
\bauthor{\bsnm{Sang}, \binits{N.}}:
\bctitle{Bisenet: Bilateral segmentation network for real-time semantic segmentation}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 45
\bibitem[\protect\citeauthoryear{Yu et~al.}{2021}]{yu2021bisenet}
\begin{botherref}
\oauthor{\bsnm{Yu}, \binits{C.}},
\oauthor{\bsnm{Gao}, \binits{C.}},
\oauthor{\bsnm{Wang}, \binits{J.}},
\oauthor{\bsnm{Yu}, \binits{G.}},
\oauthor{\bsnm{Shen}, \binits{C.}},
\oauthor{\bsnm{Sang}, \binits{N.}}:
Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation.
International Journal of Computer Vision
(2021)
\end{botherref}
\endbibitem

%%% 46
\bibitem[\protect\citeauthoryear{Poudel et~al.}{2019}]{poudel2019fast}
\begin{bchapter}
\bauthor{\bsnm{Poudel}, \binits{R.P.}},
\bauthor{\bsnm{Liwicki}, \binits{S.}},
\bauthor{\bsnm{Cipolla}, \binits{R.}}:
\bctitle{Fast-scnn: Fast semantic segmentation network}.
In: \bbtitle{British Machine Vision Conference}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 47
\bibitem[\protect\citeauthoryear{Hong et~al.}{2021}]{hong2021deep}
\begin{botherref}
\oauthor{\bsnm{Hong}, \binits{Y.}},
\oauthor{\bsnm{Pan}, \binits{H.}},
\oauthor{\bsnm{Sun}, \binits{W.}},
\oauthor{\bsnm{Jia}, \binits{Y.}}:
Deep dual-resolution networks for real-time and accurate semantic segmentation of road scenes.
arXiv preprint
(2021)
\end{botherref}
\endbibitem

%%% 48
\bibitem[\protect\citeauthoryear{Huang et~al.}{2021}]{huang2021alignseg}
\begin{botherref}
\oauthor{\bsnm{Huang}, \binits{Z.}},
\oauthor{\bsnm{Wei}, \binits{Y.}},
\oauthor{\bsnm{Wang}, \binits{X.}},
\oauthor{\bsnm{Liu}, \binits{W.}},
\oauthor{\bsnm{Huang}, \binits{T.S.}},
\oauthor{\bsnm{Shi}, \binits{H.}}:
Alignseg: Feature-aligned segmentation networks.
IEEE Transactions on Pattern Analysis and Machine Intelligence
(2021)
\end{botherref}
\endbibitem

%%% 49
\bibitem[\protect\citeauthoryear{Qi et~al.}{2021}]{qi2021multi}
\begin{bchapter}
\bauthor{\bsnm{Qi}, \binits{L.}},
\bauthor{\bsnm{Kuen}, \binits{J.}},
\bauthor{\bsnm{Gu}, \binits{J.}},
\bauthor{\bsnm{Lin}, \binits{Z.}},
\bauthor{\bsnm{Wang}, \binits{Y.}},
\bauthor{\bsnm{Chen}, \binits{Y.}},
\bauthor{\bsnm{Li}, \binits{Y.}},
\bauthor{\bsnm{Jia}, \binits{J.}}:
\bctitle{Multi-scale aligned distillation for low-resolution detection}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 50
\bibitem[\protect\citeauthoryear{Hu et~al.}{2022}]{hu2022cross}
\begin{botherref}
\oauthor{\bsnm{Hu}, \binits{B.}},
\oauthor{\bsnm{Zhou}, \binits{S.}},
\oauthor{\bsnm{Xiong}, \binits{Z.}},
\oauthor{\bsnm{Wu}, \binits{F.}}:
Cross-resolution distillation for efficient 3d medical image registration.
IEEE Transactions on Circuits and Systems for Video Technology
(2022)
\end{botherref}
\endbibitem

%%% 51
\bibitem[\protect\citeauthoryear{Yuan et~al.}{2020}]{yuan2020object}
\begin{bchapter}
\bauthor{\bsnm{Yuan}, \binits{Y.}},
\bauthor{\bsnm{Chen}, \binits{X.}},
\bauthor{\bsnm{Wang}, \binits{J.}}:
\bctitle{Object-contextual representations for semantic segmentation}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2020})
\end{bchapter}
\endbibitem

%%% 52
\bibitem[\protect\citeauthoryear{Li et~al.}{2021}]{li2021convmlp}
\begin{botherref}
\oauthor{\bsnm{Li}, \binits{J.}},
\oauthor{\bsnm{Hassani}, \binits{A.}},
\oauthor{\bsnm{Walton}, \binits{S.}},
\oauthor{\bsnm{Shi}, \binits{H.}}:
Convmlp: Hierarchical convolutional mlps for vision.
arXiv preprint
(2021)
\end{botherref}
\endbibitem

%%% 53
\bibitem[\protect\citeauthoryear{Kirillov et~al.}{2019}]{kirillov2019panoptic}
\begin{bchapter}
\bauthor{\bsnm{Kirillov}, \binits{A.}},
\bauthor{\bsnm{Girshick}, \binits{R.}},
\bauthor{\bsnm{He}, \binits{K.}},
\bauthor{\bsnm{Doll{\'a}r}, \binits{P.}}:
\bctitle{Panoptic feature pyramid networks}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 54
\bibitem[\protect\citeauthoryear{Tan and Le}{2019}]{tan2019efficientnet}
\begin{bchapter}
\bauthor{\bsnm{Tan}, \binits{M.}},
\bauthor{\bsnm{Le}, \binits{Q.}}:
\bctitle{Efficientnet: Rethinking model scaling for convolutional neural networks}.
In: \bbtitle{International Conference on Machine Learning}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 55
\bibitem[\protect\citeauthoryear{Chen et~al.}{2018}]{chen2018encoder}
\begin{bchapter}
\bauthor{\bsnm{Chen}, \binits{L.-C.}},
\bauthor{\bsnm{Zhu}, \binits{Y.}},
\bauthor{\bsnm{Papandreou}, \binits{G.}},
\bauthor{\bsnm{Schroff}, \binits{F.}},
\bauthor{\bsnm{Adam}, \binits{H.}}:
\bctitle{Encoder-decoder with atrous separable convolution for semantic image segmentation}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 56
\bibitem[\protect\citeauthoryear{He et~al.}{2016}]{he2016deep}
\begin{bchapter}
\bauthor{\bsnm{He}, \binits{K.}},
\bauthor{\bsnm{Zhang}, \binits{X.}},
\bauthor{\bsnm{Ren}, \binits{S.}},
\bauthor{\bsnm{Sun}, \binits{J.}}:
\bctitle{Deep residual learning for image recognition}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2016})
\end{bchapter}
\endbibitem

%%% 57
\bibitem[\protect\citeauthoryear{Ma et~al.}{2018}]{ma2018shufflenet}
\begin{bchapter}
\bauthor{\bsnm{Ma}, \binits{N.}},
\bauthor{\bsnm{Zhang}, \binits{X.}},
\bauthor{\bsnm{Zheng}, \binits{H.-T.}},
\bauthor{\bsnm{Sun}, \binits{J.}}:
\bctitle{Shufflenet v2: Practical guidelines for efficient cnn architecture design}.
In: \bbtitle{European Conference on Computer Vision}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 58
\bibitem[\protect\citeauthoryear{Zhou et~al.}{2017}]{zhou2017scene}
\begin{bchapter}
\bauthor{\bsnm{Zhou}, \binits{B.}},
\bauthor{\bsnm{Zhao}, \binits{H.}},
\bauthor{\bsnm{Puig}, \binits{X.}},
\bauthor{\bsnm{Fidler}, \binits{S.}},
\bauthor{\bsnm{Barriuso}, \binits{A.}},
\bauthor{\bsnm{Torralba}, \binits{A.}}:
\bctitle{Scene parsing through ade20k dataset}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2017})
\end{bchapter}
\endbibitem

%%% 59
\bibitem[\protect\citeauthoryear{Cordts et~al.}{2016}]{cordts2016cityscapes}
\begin{bchapter}
\bauthor{\bsnm{Cordts}, \binits{M.}},
\bauthor{\bsnm{Omran}, \binits{M.}},
\bauthor{\bsnm{Ramos}, \binits{S.}},
\bauthor{\bsnm{Rehfeld}, \binits{T.}},
\bauthor{\bsnm{Enzweiler}, \binits{M.}},
\bauthor{\bsnm{Benenson}, \binits{R.}},
\bauthor{\bsnm{Franke}, \binits{U.}},
\bauthor{\bsnm{Roth}, \binits{S.}},
\bauthor{\bsnm{Schiele}, \binits{B.}}:
\bctitle{The cityscapes dataset for semantic urban scene understanding}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2016})
\end{bchapter}
\endbibitem

%%% 60
\bibitem[\protect\citeauthoryear{Mottaghi et~al.}{2014}]{mottaghi2014role}
\begin{bchapter}
\bauthor{\bsnm{Mottaghi}, \binits{R.}},
\bauthor{\bsnm{Chen}, \binits{X.}},
\bauthor{\bsnm{Liu}, \binits{X.}},
\bauthor{\bsnm{Cho}, \binits{N.-G.}},
\bauthor{\bsnm{Lee}, \binits{S.-W.}},
\bauthor{\bsnm{Fidler}, \binits{S.}},
\bauthor{\bsnm{Urtasun}, \binits{R.}},
\bauthor{\bsnm{Yuille}, \binits{A.}}:
\bctitle{The role of context for object detection and semantic segmentation in the wild}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2014})
\end{bchapter}
\endbibitem

%%% 61
\bibitem[\protect\citeauthoryear{Caesar et~al.}{2018}]{caesar2018coco}
\begin{bchapter}
\bauthor{\bsnm{Caesar}, \binits{H.}},
\bauthor{\bsnm{Uijlings}, \binits{J.}},
\bauthor{\bsnm{Ferrari}, \binits{V.}}:
\bctitle{Coco-stuff: Thing and stuff classes in context}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 62
\bibitem[\protect\citeauthoryear{Contributors}{2019}]{contributors2020tnn}
\begin{botherref}
\oauthor{\bsnm{Contributors}, \binits{T.}}:
TNN: A high-performance, lightweight neural network inference framework.
(2019)
\end{botherref}
\endbibitem

%%% 63
\bibitem[\protect\citeauthoryear{Deng et~al.}{2009}]{deng2009imagenet}
\begin{bchapter}
\bauthor{\bsnm{Deng}, \binits{J.}},
\bauthor{\bsnm{Dong}, \binits{W.}},
\bauthor{\bsnm{Socher}, \binits{R.}},
\bauthor{\bsnm{Li}, \binits{L.-J.}},
\bauthor{\bsnm{Li}, \binits{K.}},
\bauthor{\bsnm{Fei-Fei}, \binits{L.}}:
\bctitle{Imagenet: A large-scale hierarchical image database}.
In: \bbtitle{IEEE Conference on Computer Vision and Pattern Recognition}
(\byear{2009})
\end{bchapter}
\endbibitem

%%% 64
\bibitem[\protect\citeauthoryear{Ioffe and Szegedy}{2015}]{ioffe2015batch}
\begin{bchapter}
\bauthor{\bsnm{Ioffe}, \binits{S.}},
\bauthor{\bsnm{Szegedy}, \binits{C.}}:
\bctitle{Batch normalization: Accelerating deep network training by reducing internal covariate shift}.
In: \bbtitle{International Conference on Machine Learning}
(\byear{2015})
\end{bchapter}
\endbibitem

%%% 65
\bibitem[\protect\citeauthoryear{Contributors}{2020}]{contributors2020mmsegmentation}
\begin{botherref}
\oauthor{\bsnm{Contributors}, \binits{M.}}:
MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark
(2020)
\end{botherref}
\endbibitem

%%% 66
\bibitem[\protect\citeauthoryear{Huang et~al.}{2019}]{huang2019interlaced}
\begin{botherref}
\oauthor{\bsnm{Huang}, \binits{L.}},
\oauthor{\bsnm{Yuan}, \binits{Y.}},
\oauthor{\bsnm{Guo}, \binits{J.}},
\oauthor{\bsnm{Zhang}, \binits{C.}},
\oauthor{\bsnm{Chen}, \binits{X.}},
\oauthor{\bsnm{Wang}, \binits{J.}}:
Interlaced sparse self-attention for semantic segmentation.
arXiv preprint
(2019)
\end{botherref}
\endbibitem

%%% 67
\bibitem[\protect\citeauthoryear{Chen et~al.}{2018}]{chen20182}
\begin{bchapter}
\bauthor{\bsnm{Chen}, \binits{Y.}},
\bauthor{\bsnm{Kalantidis}, \binits{Y.}},
\bauthor{\bsnm{Li}, \binits{J.}},
\bauthor{\bsnm{Yan}, \binits{S.}},
\bauthor{\bsnm{Feng}, \binits{J.}}:
\bctitle{A\^{} 2-nets: Double attention networks}.
In: \bbtitle{Advances in Neural Information Processing Systems}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 68
\bibitem[\protect\citeauthoryear{Vasu et~al.}{2022}]{vasu2022improved}
\begin{botherref}
\oauthor{\bsnm{Vasu}, \binits{P.K.A.}},
\oauthor{\bsnm{Gabriel}, \binits{J.}},
\oauthor{\bsnm{Zhu}, \binits{J.}},
\oauthor{\bsnm{Tuzel}, \binits{O.}},
\oauthor{\bsnm{Ranjan}, \binits{A.}}:
An improved one millisecond mobile backbone.
arXiv preprint
(2022)
\end{botherref}
\endbibitem

%%% 69
\bibitem[\protect\citeauthoryear{Kingma and Ba}{2014}]{kingma2014adam}
\begin{botherref}
\oauthor{\bsnm{Kingma}, \binits{D.P.}},
\oauthor{\bsnm{Ba}, \binits{J.}}:
Adam: A method for stochastic optimization.
arXiv preprint
(2014)
\end{botherref}
\endbibitem

%%% 70
\bibitem[\protect\citeauthoryear{Lin et~al.}{2017}]{lin2017focal}
\begin{bchapter}
\bauthor{\bsnm{Lin}, \binits{T.-Y.}},
\bauthor{\bsnm{Goyal}, \binits{P.}},
\bauthor{\bsnm{Girshick}, \binits{R.}},
\bauthor{\bsnm{He}, \binits{K.}},
\bauthor{\bsnm{Doll{\'a}r}, \binits{P.}}:
\bctitle{Focal loss for dense object detection}.
In: \bbtitle{IEEE International Conference on Computer Vision}
(\byear{2017})
\end{bchapter}
\endbibitem

%%% 71
\bibitem[\protect\citeauthoryear{Wang et~al.}{2021}]{wang2021pyramid}
\begin{bchapter}
\bauthor{\bsnm{Wang}, \binits{W.}},
\bauthor{\bsnm{Xie}, \binits{E.}},
\bauthor{\bsnm{Li}, \binits{X.}},
\bauthor{\bsnm{Fan}, \binits{D.-P.}},
\bauthor{\bsnm{Song}, \binits{K.}},
\bauthor{\bsnm{Liang}, \binits{D.}},
\bauthor{\bsnm{Lu}, \binits{T.}},
\bauthor{\bsnm{Luo}, \binits{P.}},
\bauthor{\bsnm{Shao}, \binits{L.}}:
\bctitle{Pyramid vision transformer: A versatile backbone for dense prediction without convolutions}.
In: \bbtitle{IEEE International Conference on Computer Vision}
(\byear{2021})
\end{bchapter}
\endbibitem

%%% 72
\bibitem[\protect\citeauthoryear{Yan et~al.}{2021}]{yan2021contnet}
\begin{botherref}
\oauthor{\bsnm{Yan}, \binits{H.}},
\oauthor{\bsnm{Li}, \binits{Z.}},
\oauthor{\bsnm{Li}, \binits{W.}},
\oauthor{\bsnm{Wang}, \binits{C.}},
\oauthor{\bsnm{Wu}, \binits{M.}},
\oauthor{\bsnm{Zhang}, \binits{C.}}:
Contnet: Why not use convolution and transformer at the same time?
arXiv preprint
(2021)
\end{botherref}
\endbibitem

\end{thebibliography}
