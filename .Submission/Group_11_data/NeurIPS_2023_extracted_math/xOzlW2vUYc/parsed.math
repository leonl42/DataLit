('2.0', '\\mathbf{X} = [\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\ldots, \\mathbf{x}^{(L)}] \\in \\mathbb{R}^{L \\times N}')
('2.0', '\\mathbf{Y} = [\\mathbf{x}^{(L+1)}, \\mathbf{x}^{(L+2)}, \\ldots, \\mathbf{x}^{(L+T)}] \\in \\mathbb{R}^{T \\times N}')
('2.0', 'N')
('2.0', 'L')
('2.0', 'T')
('2.0', '\\mathbf{x}^{(i)} \\in \\mathbb{R}^{1 \\times N}')
('2.0', 'N')
('2.0', 'i')
('2.0', 'x^{(i)}_j \\in \\mathbb{R}^{1 \\times 1}')
('2.0', 'j')
('2.0', 'i')
('2.1', '\\mathbf{X} \\in \\mathbb{R}^{L \\times N}')
('2.1', 'N')
('2.1', '\\mathbf{X}_{\\text{crosscnn}} \\in \\mathbb{R}^{L \\times N}')
('2.1', '\\hat{\\mathbf{Y}} \\in \\mathbb{R}^{T \\times N}')
('2.1', '\\mathbf{Y}')
('2.1', '\\mathbf{X}')
('2.1', '\\begin{aligned}\n    &\\mathbf{X}_{\\text{crosscnn}} = \\text{CrossCNN}(\\mathbf{X}) , \\\\\n    &\\mathbf{X_{\\text{trans}}} = \\text{Transpose}(\\mathbf{X}_{\\text{crosscnn}}) ,  \\\\\n    &\\mathbf{X_{\\text{emb}}} = \\text{Embedding}(\\mathbf{X_{\\text{trans}}}), \\\\\n    &\\mathbf{X}_{\\text{FFN}} = \\text{FFN}(\\mathbf{X_{\\text{emb}}}), \\\\\n    &\\mathbf{\\hat{Y}} = \\text{Projection}(\\mathbf{X}_{\\text{FFN}}),\n\\end{aligned}')
('2.1', '\\mathbf{X}_{\\text{crosscnn}} \\in \\mathbb{R}^{L \\times N}')
('2.1', '\\mathbf{X_{\\text{emb}}}, \\mathbf{X}_{\\text{FFN}} \\in \\mathbb{R}^{N \\times D}')
('2.1', '\\mathbf{\\hat{Y}} \\in \\mathbb{R}^{T \\times N}')
('2.1', 'N')
('2.1', 'L')
('2.1', 'T')
('2.1', 'D')
('2.2', 'L \\times N')
('2.2', 'i')
('2.2', '\\mathbf{x}^{(i)} \\in \\mathbb{R}^{1 \\times N} = [x^{(i)}_1, x^{(i)}_2, \\ldots, x^{(i)}_N]')
('2.2', 'N-1')
('2.2', '\\hat{\\mathbf{x}}^{(i)} = [x^{(i)}_2, x^{(i)}_3, \\ldots, x^{(i)}_N, x^{(i)}_1, x^{(i)}_2, \\ldots, x^{(i)}_N]')
('2.2', 'i')
('2.2', 'N')
('2.2', '\\mathbf{w}^{(i)} = [w^{(i)}_1, w^{(i)}_2, \\ldots, w^{(i)}_N]')
('2.2', 'j')
('2.2', 'c^{(i)}_j')
('2.2', 'c^{(i)}_j = \\sum_{k=1}^{N} w^{(i)}_k \\cdot \\hat{x}^{(i)}_{(j+k) }, \\quad j = 1, 2, \\ldots, N, \\quad i = 1, 2, \\ldots, L.')
('2.2', 'i')
('2.2', '\\mathbf{c}^{(i)} = [c^{(i)}_1, c^{(i)}_2, \\ldots, c^{(i)}_N] \\in \\mathbb{R}^{1 \\times N}')
('2.2', '\\mathbf{X}_{\\text{crosscnn}}')
('2.2', '\\mathbf{X}_{\\text{emb}}')
('2.2', 'M')
('2.2', '\\begin{aligned}\n    \\mathbf{X_{h}} &= \\text{Dropout}(\\text{Gelu}(\\text{Dense}(\\text{LayerNorm}( \\mathbf{X_{m-1}})))),\\\\\n    \\mathbf{X_m} &= \\text{Dropout}(\\text{Dense}(\\mathbf{X_h}))) +\\mathbf{X_{m-1}}.\n\\end{aligned}')
('2.2', '\\mathbf{X_{m-1}}')
('2.2', '\\mathbf{X_m} \\in \\mathbb{R}^{N \\times D}')
('2.2', 'm')
('2.2', '\\mathbf{X_h} \\in \\mathbb{R}^{N \\times H}')
('2.2', 'H')
('2.2', '\\mathbf{X_{0}}=\\mathbf{X_{\\text{emb}}}')
('2.2', '\\mathbf{\\hat{Y}} = [\\mathbf{\\hat{x}}^{(L+1)}, \\mathbf{\\hat{x}}^{(L+2)}, \\ldots, \\mathbf{\\hat{x}}^{(L+T)}] \\in \\mathbb{R}^{T \\times N}')
('2.2', '\\hat{\\mathbf{Y}}')
('2.2', '\\mathbf{Y}')
('2.2', 'T')
('2.2', '\\mathcal{L} = \\frac{1}{T} \\sum_{i=1}^{T} \\left\\| \\hat{\\mathbf{x}}^{(L+i)} - \\mathbf{x}^{(L+i)} \\right\\|_{2}^{2}.')
('3.0.1', 'T')
('3.0.1', '\\{96, 192, 336, 720\\}')
('3.0.2', '\\mathbf{X}\\in\\mathbb{R}^{L\\times N}')
('3.0.2', 'L')
('3.0.2', 'T')
('3.0.2', 'N')
('3.0.2', 'D')
('3.0.2', 'M')
('3.0.2', '\\mathbf{Padding}=\\mathbf{X}[:, 1:]')
('3.0.2', '\\mathbf{Padding}= \\texttt{Concatenate}(\\mathbf{Padding}, \\mathbf{X})')
('3.0.2', '\\mathbf{X}=\\texttt{CrossCNN}(\\mathbf{Padding}) + \\mathbf{X}')
('3.0.2', '\\mathbf{X}=\\mathbf{X}.\\texttt{transpose}')
('3.0.2', '\\mathbf{H}^{0}=\\texttt{MLP}(\\mathbf{X})')
('3.0.2', '\\mathbf{H}^{1} = \\mathbf{H}^{0} + \\texttt{FFN}(\\mathbf{H}^{0})')
('3.0.2', '\\mathbf{H}^{2} = \\mathbf{H}^{1} + \\texttt{FFN}(\\mathbf{H}^{1})')
('3.0.2', '\\mathbf{H}^{M}=\\texttt{LayerNorm}(\\mathbf{H}^{M})')
('3.0.2', '\\mathbf{\\hat{Y}}=\\texttt{MLP}(\\mathbf{H}^{M})')
('3.0.2', '\\mathbf{\\hat{Y}}=\\mathbf{\\hat{Y}}.\\texttt{transpose}')
('3.0.2', '\\mathbf{\\hat{Y}}')
('3.4.1', 'Noise\\_strength')
