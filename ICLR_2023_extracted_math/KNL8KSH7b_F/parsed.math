('1', '{\\ell}_1')
('1', '\\textbf{S}')
('1', '\\textbf{B}')
('1', '\\textbf{C}')
('1', '\\textbf{SBC}')
('1', '\\textbf{SBCNet}')
('1', '1\\times1')
('1', '1\\times1')
('1', '\\%')
('1', '\\%')
('1', '\\%')
('1', '\\%')
('1', '\\%')
('2.0', '{\\ell}_1')
('2.0', '{\\ell}_2')
('2.0', '{\\ell}_1')
('2.0', '{\\ell}_1')
('2.0', 'k')
('2.1', '3\\times3')
('3.0', 'l')
('3.0', 'X^l\\in \\mathbb{R}^{c^{l-1}\\times h^{l-1}\\times w^{l-1}}')
('3.0', 'Y^l\\in \\mathbb{R}^{c^{l}\\times h^{l}\\times w^{l}}')
('3.0', 'W^l\\in \\mathbb{R}^{c^{l}\\times c^{l-1}\\times k^{l}\\times k^{l}}')
('3.0', 'c^{l-1}')
('3.0', 'c^{l}')
('3.0', 'k^{l}')
('3.0', 'l')
('3.0', '\\label{convolution operation}\nY^l = W^l \\otimes X^l,')
('3.0', '\\otimes')
('3.0', '\\overline{W}^l')
('3.0', '\\label{filter pruning}\n\\overline{W}^l [i,:,:,:] = W^l [K_f^l[i],:,:,:]')
('3.0', '\\overline{W}^l\\in \\mathbb{R}^{n^{l}\\times c^{l-1}\\times k^{l}\\times k^{l}}')
('3.0', 'K_f^l')
('3.0', 'W^l')
('3.0', 'n^{l}')
('3.0', '\\label{channel pruning}\n\\overline{W}^l [:,i,:,:] = W^l [:,K_c^l[i],:,:]')
('3.0', '\\overline{W}^l\\in \\mathbb{R}^{c^{l}\\times n^{l-1}\\times k^{l}\\times k^{l}}')
('3.0', 'K_c^l')
('3.0', 'W^l')
('3.0', 'n^{l-1}')
('3.0', 'W^l [i,:,:,:]')
('3.0', 'W^l [i]')
('3.1', '3\\times3')
('3.1', 'l')
('3.1', '\\label{convolution operation using new convolutional module}\nY^l = Y^l_S + Y^l_B = W^l_S \\otimes X^l + W^l_{B3}\\otimes(W^l_{B2}\\otimes (W^l_{B1} \\otimes X^l)),')
('3.1', 'W^l_S\\in \\mathbb{R}^{c^{l}\\times c^{l-1}\\times k^{l}\\times k^{l}}')
('3.1', 'W^l_{B1}\\in \\mathbb{R}^{{d}^l \\times c^{l-1} \\times 1 \\times 1}')
('3.1', 'W^l_{B2}\\in \\mathbb{R}^{{d}^l \\times 1 \\times k^{l} \\times k^{l}}')
('3.1', 'W^l_{B3} \\in \\mathbb{R}^{c^{l}\\times {d}^l \\times 1 \\times 1}')
('3.1', 'W^l_S')
('3.1', 'l')
('3.1', 'c^l')
('3.1', 'c^{l-1}')
('3.1', 'p^l')
('3.1', 'hw(2cd+dk^2)')
('3.1', 'hw(2cd+dk^2+(1-p)c^2k^2)')
('3.1', 'k^2 \\ll c')
('3.1', 'd \\le c')
('3.1', 'dk^2')
('3.1', '2 \\over {2+((1-p)ck^2)/d}')
('3.1', 'p')
('3.1', 'p')
('3.1', 'p')
('3.1', 'p')
('3.1', '{ck^2 \\over {2d}}\\times')
('3.1', '{d}^l')
('3.1', '{d}^l')
('3.1', '{d}^l')
('3.1', 'c^{l}')
('3.1', '{d}^l')
('3.1', '0.5c^{l}')
('3.2', 'l')
('3.2', '{\\ell}_1')
('3.2', '{I}^l \\in \\mathbb{R}^{c^l}')
('3.2', '\\label{filter importance score}\n{I}^l = [ \\Vert W^l_S [1]\\Vert_1,\\Vert W^l_S [2]\\Vert_1,\\cdots,\\Vert W^l_S [c^l]\\Vert_1]^{T},')
('3.2', 'l')
('3.2', '{\\delta}^l')
('3.2', '{M}^l \\in \\mathbb{R}^{c^l}')
('3.2', '{I}^l')
('3.2', '\\label{pruning masks}\n{M}^l [i] = \\begin{cases} 1,& {I}^l_{i} \\geq {\\delta}^l, \\\\ 0,& {I}^l_{i}<{\\delta}^l,  \\end{cases}')
('3.2', '{I}^l_{i}')
('3.2', 'i')
('3.2', '{I}^l')
('3.2', '{M}^l')
('3.2', '{n}^l')
('3.2', 'p^l = 1-n^l/c^l')
('3.2', '\\label{convolution operation when using pruning masks}\nY^l_S = {M}^l \\odot (W^l_S \\otimes X^l),')
('3.2', '\\odot')
('3.2', '{\\ell}_1')
('3.2', '{M}^l')
('3.2', '{\\delta}^l')
('3.2', '{M}^l')
('3.2', '{G}^l')
('3.2', '\\text{sigmoid}(\\cdot)')
('3.2', '\\label{soft pruning masks using sigmoid function}\n{G}^l = \\text{sigmoid}({I}^l-{\\delta}^l) = {1 \\over {1+e^{-({I}^l-{\\delta}^l)}}}.')
('3.2', '{G}^l')
('3.2', '{G}^l[i]')
('3.2', '{G}^l[i]')
('3.2', '\\label{hard pruning masks using indicator function}\n{M}^l[i] = \\mathds{1}_{\\geq 0.5}({G}^l[i]), \\,\\forall{i\\in[1,c^l]}.')
('3.2', '{G}^l[i]')
('3.2', '{I}^l_{i}')
('3.2', '{\\delta}^l')
('3.2', '{M}^l[i]')
('3.2', '\\mathds{1}_{ \\geq 0.5}(\\cdot)')
('3.2', '{M}^l')
('3.2', '{G}^l')
('3.2', '{\\delta}^l')
('3.2', '\\text{CNN with } N \\text{ convolutional layers to be pruned}; \\text{ t-}')
('3.2', '\\text{otal epochs } E; \\text{ training set }D; \\text{ total FLOPs }T_{total}\\text{ of the}')
('3.2', '\\text{CNN; target compression rate }C;')
('3.2', '\\text{Compact CNN satisfying the target compression }')
('3.2', '\\text{rate }C \\text{ and its optimal weight values } \\mathcal{\\overline{W}_S} \\text{ and } \\mathcal{W_B};')
('3.2', '\\text{Build the SBCNet with }\\mathcal{W_S} \\text{ and } \\mathcal{W_B} \\text{ based on Eq.(\\ref{convolution operation using new convolutional module});}')
('3.2', '\\text{Introduce learnable thresholds} \\text{ for each sparse path};')
('3.2', "\\text{Enforce epoch status}\\in\\text{\\{``prune'', ``train''\\}};")
('3.2', "\\text{epoch status is set as ``prune''};")
('3.2', '\\textbf{for}\\text{ epoch } t = 1, 2, . . . , E \\textbf{ do}')
('3.2', '\\textbf{for}\\text{ a mini-batch (}X,y\\text{) in }D\\textbf{ do}')
('3.2', "\\textbf{if} \\text{ epoch status is ``prune'' } \\textbf{then}")
('3.2', '\\textbf{for}\\text{ layer } l = 1, 2, . . . , N \\textbf{ do}')
('3.2', '\\text{Get }{I}^l \\text{ by Eq.(\\ref{filter importance score})};')
('3.2', '\\text{Get }{M}^l \\text{ by Eq.(\\ref{soft pruning masks using sigmoid function}) and Eq.(\\ref{hard pruning masks using indicator function})};')
('3.2', '\\text{Get } Y^l \\text{ by Eq.(\\ref{convolution operation when using pruning masks}) and Eq.(\\ref{convolution operation using new convolutional module})};')
('3.2', '\\textbf{end for}')
('3.2', '\\text{Calculate }T_{kept} \\text{ and }\\hat{C};')
('3.2', '\\textbf{if } \\hat{C} \\neq C \\textbf{ then}')
('3.2', '\\text{Update }\\mathcal{W_S}, \\mathcal{W_B} \\text{ and }\\Delta \\text{ with SGD};')
('3.2', '\\textbf{else}')
('3.2', '\\text{Remove the masks and prune, get } \\mathcal{\\overline{W}_S};')
('3.2', "\\text{Set epoch status as ``train''};")
('3.2', '\\textbf{end if}')
('3.2', '\\textbf{else}')
('3.2', '\\text{Get } Y^l\\text{ for each layer } l\\text{ by Eq.(\\ref{convolution output of the compressed network})};')
('3.2', '\\text{Update }\\mathcal{\\overline{W}_S} \\text{ and } \\mathcal{W_B} \\text{ with SGD};')
('3.2', '\\textbf{end if}')
('3.2', '\\textbf{end for}')
('3.2', '\\textbf{end for}')
('3.2', '\\text{Compact CNN with weights }\\mathcal{\\overline{W}_S} \\text{ and } \\mathcal{W_B};')
('3.2', '{\\ell}_1')
('3.2', '{\\ell}_1')
('3.2', '\\label{optimization problem with sparse regularization}\n\\mathop{\\min}_{\\mathcal{W_S},\\mathcal{W_B},\\Delta} {\\mathcal{L}(f(X;\\mathcal{W_S},\\mathcal{W_B},\\Delta),y)+\\lambda\\sum_{l=1}^N\\sum_{i=1}^{c^l}\\Vert W^l_S [i]\\Vert_1},')
('3.2', '\\mathcal{L}(\\cdot)')
('3.2', '\\mathcal{W_S}=\\{W^1_S,W^2_S,\\cdots,W^N_S\\}')
('3.2', '\\mathcal{W_B}=\\{W^1_B,W^2_B,\\cdots,W^N_B\\}')
('3.2', 'N')
('3.2', 'f(\\cdot;\\mathcal{W_S},\\mathcal{W_B},\\Delta)')
('3.2', 'X')
('3.2', 'y')
('3.2', '{\\Delta}')
('3.2', '\\lambda')
('3.2', '{\\ell}_1')
('3.2', '{\\ell}_1')
('3.2', '{\\Delta}')
('3.2', '{\\Delta}')
('3.2', '\\text{sigmoid}(\\cdot)')
('3.2', 'I^l')
('3.2', '{\\delta}^l')
('3.2', '{G}^l')
('3.2', '\\text{ReLU}(\\cdot)')
('3.2', '\\mathcal{M}=\\{M^1,M^2,\\cdots,M^N\\}')
('3.2', 'T_{kept}')
('3.2', '\\mathcal{M}')
('3.2', 'T_{total}')
('3.2', '\\hat{C} = T_{kept}/T_{total}')
('3.2', '\\hat{C}')
('3.2', 'CT_{total}')
('3.2', 'C')
('3.2', '\\label{FLOPs constraints}\n\\mathcal{R}(\\hat{C},C) = ({\\hat{C} \\over C} - 1)^2.')
('3.2', '\\label{optimization problem with sparse regularization and FLOPs constraints}\n\\begin{aligned}\n\\mathop{\\min}_{\\mathcal{W_S},\\mathcal{W_B},\\Delta} &{\\mathcal{L}(f(X;\\mathcal{W_S},\\mathcal{W_B},\\Delta),y)}\\\\\n&+{\\lambda}_1\\sum_{l=1}^N\\sum_{i=1}^{c^l}\\Vert W^l_S [i]\\Vert_1 +{\\lambda}_2\\mathcal{R}(\\hat{C},C),\n\\end{aligned}')
('3.2', '{\\lambda}_1')
('3.2', '{\\lambda}_2')
('3.2', '{\\ell}_1')
('3.2', '\\delta')
('3.2', 'C')
('3.2', '{\\Delta}')
('3.2', '\\mathcal{M}')
('3.2', '\\mathcal{L}(f(X;\\mathcal{W_S},\\mathcal{W_B},\\Delta),y)')
('3.2', '\\mathcal{R}(\\hat{C},C)')
('3.2', '\\mathcal{R}(\\hat{C},C)')
('3.2', '\\mathcal{L}(f(X;\\mathcal{W_S},\\mathcal{W_B},\\Delta),y)')
('3.2', '{M}^l')
('3.2', 'K_f^l')
('3.2', '\\overline{W}^l_S\\in \\mathbb{R}^{n^{l}\\times c^{l-1}\\times k^{l}\\times k^{l}}')
('3.2', 'l')
('3.2', 'Y^l_S')
('3.2', 'l')
('3.2', 'l')
('3.2', '\\label{convolution output of the compressed network}\nY^l [i] = \\begin{cases} Y^l_S [\\text{Pos}(i)]+Y^l_B [i],& i\\in K_f^l, \\\\ Y^l_B [i],& i\\notin K_f^l,  \\end{cases}')
('3.2', 'i\\in[1,c^l]')
('3.2', '\\text{Pos}(\\cdot)')
('3.2', 'i')
('3.2', 'K_f^l')
('3.2', '\\mathcal{\\overline{W}_S}=\\{\\overline{W}^1_S,\\overline{W}^2_S,\\cdots,\\overline{W}^N_S\\}')
('3.2', '\\mathcal{W_B}')
('3.2', '{\\ell}_1')
('4.0', '32 \\times 32')
('4.0', '32\\times32')
('4.0', '32 \\times 32')
('4.0', 'C')
('4.0', 'C')
('4.0', 'C')
('4.0', 'C')
('4.0', '\\%')
('4.0', '\\%')
('4.0', '{\\lambda}_2')
('4.0', '{\\lambda}_1')
('4.0', '{\\ell}_1')
('4.0', '{\\lambda}_1')
('4.0', '{\\lambda}_2')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', '{\\ell}_1')
('4.1', '{\\ell}_1')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', 'C')
('4.1', '\\times')
('4.2', 'C')
('4.2', 'C')
('4.2', 'C')
('4.2', 'C')
('4.2', 'C')
('4.3', '1\\times1')
('4.3', 'd^l')
('4.3', 'C')
