('2.1', 'N')
('2.1', 'N')
('2.1', 'N')
('2.1', 'p_{fake}(\\bm{x}) = G(\\mathcal{N})')
('2.1', 'G')
('2.1', '\\bm{x}')
('2.1', '\\mathcal{N}')
('2.1', 'p_{G}(\\bm{x})')
('2.1', '\\bm{\\theta}')
('2.1', '\\bm{\\theta}^* = \\mathop{\\mathrm{arg\\,min}}_{\\bm{\\theta}} D_\\text{KL}\\infdivx{p_{data}(\\bm{x})}{p_{G}(\\bm{x}; \\bm{\\theta})} \\text{.}')
('2.1', 'L_{D} = -\\mathbb{E}_{\\bm{x} \\sim p_{data}(\\bm{x})}[\\text{log}D(\\bm{x})] - \\mathbb{E}_{\\bm{x} \\sim p_{fake}(\\bm{x})}[\\text{log}(1-D(\\bm{x}))]')
('2.1', 'L_{fake} = -\\mathbb{E}_{\\bm{x} \\sim p_{fake}(\\bm{x})}[\\text{log}(D(\\bm{x}))] \\text{.}')
('2.2', 'K')
('2.2', 'K+1')
('2.2', 'K')
('2.2', 'K+1')
('2.2', 'K+1')
('2.2', 'L_{D} = L_{supervised} + L_{unsupervised}\n\\label{eq:classification_discriminator_loss}')
('2.2', '\\begin{split}\nL&_{supervised} = \\\\\n& -\\mathbb{E}_{\\bm{x},y \\sim p_{labeled}(\\bm{x},y)}\\text{log}[p_{model}(y \\mid \\bm{x}, y < K+1)]\n\\end{split}\n\\label{eq:classification_discriminator_supervised_loss}')
('2.2', '\\begin{split}\nL&_{unsupervised} = \\\\\n& -\\mathbb{E}_{\\bm{x} \\sim p_{unlabeled}(\\bm{x})}\\text{log}[1 - p_{model}(y = K+1 \\mid \\bm{x})] \\\\\n& -\\mathbb{E}_{\\bm{x} \\sim p_{fake}}\\text{log}[p_{model}(y = K+1 \\mid \\bm{x})]\n\\text{.}\n\\end{split}\n\\label{eq:classification_discriminator_unsupervised_loss}')
('2.2', 'L_{G} = -\\mathbb{E}_{\\bm{x} \\sim p_{fake}}\\text{log}[p_{model}(y < K+1 \\mid \\bm{x})] \\text{.}')
('2.2', 'f(\\bm{x})')
('2.2', 'L_{G} = \\@ifstar{\\norm}{\\norm*}{\n    \\mathbb{E}_{\\bm{x} \\sim p_{real}} f(\\bm{x}) -\n    \\mathbb{E}_{\\bm{x} \\sim p_{fake}} f(\\bm{x})\n}^2_2\n\\text{.}')
('3.0', '\\begin{split}\nL_{D} &= L_{supervised} + L_{unsupervised} \\\\\n&= L_{labeled} + L_{unlabeled} + L_{fake}\n\\end{split}\\text{.}\n\\label{eq:discriminator_discriminator_loss}')
('3.0', 'L_{labeled} =\n\\mathbb{E}_{\\bm{x},y \\sim p_{data}(\\bm{x},y)}\n[(D(\\bm{x}) - y)^2]\n\\text{.}\n\\label{eq:regression_discriminator_labeled_loss}')
('3.0', 'L_{unlabeled} = \\@ifstar{\\norm}{\\norm*}{\n    \\mathbb{E}_{\\bm{x} \\sim p_{labeled}} f(\\bm{x}) -\n    \\mathbb{E}_{\\bm{x} \\sim p_{unlabeled}} f(\\bm{x})\n}^2_2\n\\text{.}\n\\label{eq:regression_discriminator_unlabeled_loss}')
('3.0', 'L_{fake} = - \\@ifstar{\\norm}{\\norm*}{ \\log \\left(\n    \\@ifstar{\\abs}{\\abs*}*{ \\mathbb{E}_{\\bm{x} \\sim p_{fake}} f(\\bm{x}) -\n    \\mathbb{E}_{\\bm{x} \\sim p_{unlabeled}} f(\\bm{x}) } + 1 \\right) }_1\n\\text{.}\n\\label{eq:regression_discriminator_fake_loss}')
('3.0', 'L_{G} = \\@ifstar{\\norm}{\\norm*}{\n    \\mathbb{E}_{\\bm{x} \\sim p_{fake}} f(\\bm{x}) -\n    \\mathbb{E}_{\\bm{x} \\sim p_{unlabeled}} f(\\bm{x})\n}^2_2\n\\text{.}\n\\label{eq:regression_generator_loss}')
('3.0', 'L_{unlabeled}')
('3.0', 'L_G')
('3.0', 'L_G')
('3.0', 'L_{unlabeled}')
('3.0', 'L_{fake}')
('3.1', '\\begin{split}\nL &= L_{labeled} + L_{unlabeled} + L_{fake} \\\\\n&+ \\lambda \\, \\mathbb{E}_{\\bm{x} \\sim p_{interpolate}}\\left[ \\max \\left( \\left( \\@ifstar{\\norm}{\\norm*}{\\nabla_{\\hat{\\bm{x}}}(f(\\bm{x}))}_2^2 - 1 \\right), 0 \\right) \\right]\\text{.}\n\\end{split}\n\\label{eq:gradient penalty}')
('3.1', 'p_{interpolate}')
('3.1', '\\alpha p_{unlabeled} + (1-\\alpha)p_{fake}')
('3.1', '\\alpha \\sim \\mathcal{U}')
('3.1', 'f(\\bm{x})')
('3.1', 'L_{fake}')
('3.1', 'L_{fake}')
('3.1', 'L_{fake}')
('4.0.0', 'y = a_4 x^{4} + a_3 x^{3} + a_2 x^{2} + a_1 x\n\\text{.}\n\\label{eq:polynomial model}')
('4.0.0', 'a_1 = 1')
('4.0.0', '\\mathcal{U}(r_0, r_1)')
('4.0.0', 'r_0')
('4.0.0', 'r_1')
('4.0.0', 'a_3')
('4.0.0', '\\mathcal{U}(-1, 1)')
('4.0.0', 'a_2')
('4.0.0', 'a_4')
('4.0.0', 'b\\cdot\\mathcal{U}(-2, -1) + (1-b)\\cdot\\mathcal{U}(1, 2)')
('4.0.0', 'b')
('4.0.0', 'y')
('4.0.0', 'x')
('4.0.0', '-1')
('4.0.0', '1')
('4.0.0', 'a_3')
('4.0.0', 'a_3')
('4.0.0', 'a_2 = 2')
('4.0.0', 'a_3 = -1')
('4.0.0', 'a_4 = -1')
('4.0.0', 'a_3')
('4.0.0', 'a_3')
('4.0.0', 'a_3')
('4.0.2', '\\bm{d}_f = \\@ifstar{\\abs}{\\abs*}*{\\mathbb{E}_{\\bm{x} \\sim p_{1}} f(\\bm{x}) -\n    \\mathbb{E}_{\\bm{x} \\sim p_{2}} f(\\bm{x})}')
('4.0.2', 'p_1')
('4.0.2', 'p_2')
('4.0.2', 'd_f')
('4.0.2', 'L_{unlabeled}')
('4.0.2', 'L_{fake}')
('4.0.2', 'L_G')
('4.0.2', 'L_{fake} = - \\@ifstar{\\@ifstar{\\norm}{\\norm*}}{\\@ifstar{\\norm}{\\norm*}*}{ \\log \\left( \\bm{d}_f + 1 \\right) }_1\\quad L_{unlabeled}=L_{G}=\\@ifstar{\\@ifstar{\\norm}{\\norm*}}{\\@ifstar{\\norm}{\\norm*}*}{\\bm{d}_f}^2_2')
('4.0.2', 'L_{fake} = - \\@ifstar{\\@ifstar{\\norm}{\\norm*}}{\\@ifstar{\\norm}{\\norm*}*}{ \\sqrt{ \\bm{d}_f + 1} }_1\\quad L_{unlabeled}=L_{G}=\\@ifstar{\\@ifstar{\\norm}{\\norm*}}{\\@ifstar{\\norm}{\\norm*}*}{\\bm{d}_f}^2_2')
('4.0.2', 'L_{fake} = -\\@ifstar{\\@ifstar{\\norm}{\\norm*}}{\\@ifstar{\\norm}{\\norm*}*}{\\bm{d}_f}_1 \\quad L_{unlabeled}=L_{G}=\\@ifstar{\\@ifstar{\\norm}{\\norm*}}{\\@ifstar{\\norm}{\\norm*}*}{\\bm{d}_f}_2')
('4.1', 'NAE = \\dfrac{1}{N}\\sum^N_{i=1}\\dfrac{\\@ifstar{\\abs}{\\abs*}{y_i - \\hat{y}_i}}{y_{max} - y_{min}} \\times 100\\%\\text{.}')
('4.2.0', '\\scriptstyle\\sim')
('4.3', '\\text{MAE} = \\frac{1}{N}\\sum\\limits_{i=1}^{N}\\@ifstar{\\abs}{\\abs*}{\\hat{C}_i - C_i}')
('4.3', '\\text{NAE} = \\frac{1}{N}\\sum\\limits_{i=1}^{N}\\frac{\\@ifstar{\\abs}{\\abs*}{\\hat{C}_i - C_i}}{C_i}')
('4.3', '\\text{RMSE} = \\sqrt{\\frac{1}{N}\\sum\\limits_{i=1}^{N}(\\hat{C}_i - C_i)^2}')
