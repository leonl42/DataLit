('1', '\\varepsilon')
('2', '\\varepsilon')
('3.0', '\\varepsilon')
('4.0', '\\begin{gathered}\n\\label{eq:state-action-value}\nQ^{*}(a, b) = \\\\ \\max_{\\pi}\\mathop{\\mathrm{\\mathbb{E}}}[r_{t} + \\gamma r_{t+1} + \\gamma^{2} r_{t+2} + ... \\mid s_{t} = s, a_{t} = a, \\pi]\n\\end{gathered}')
('4.0', 'r_t')
('4.0', '\\gamma')
('4.0', 't')
('4.0', '\\pi')
('4.0', 's')
('4.0', 'a')
('4.0', 'i')
('4.0', "\\begin{gathered}\n\\label{eq:loss}\nL_{i}(\\theta_{i}) = \\\\ \\mathop{\\mathrm{\\mathbb{E}}}_{(s, a, r, s') \\sim U(D)} [(r + \\gamma \\max_{a'} Q(s', a'; \\theta^{-}_{i}) - Q(s, a; \\theta_{i}))^{2}]\n\\end{gathered}")
('4.0', '\\gamma')
('4.0', '\\theta_i')
('4.0', 'i')
('4.0', '\\theta_i^-')
('4.0', 'i')
('4.0', "\\begin{gathered}\n\\label{eq:gradient}\n\\nabla_{\\theta_{i}} L(\\theta_{i}) =  \\mathop{\\mathrm{\\mathbb{E}}}_{s, a, r, s'} [(r + \\gamma \\max_{a'} Q(s', a'; \\theta^{-}_{i}) - \\\\ - Q(s, a; \\theta_{i}) \\nabla_{\\theta_{i}} Q(s, a; \\theta_{i})].\n\\end{gathered}")
('4.0', '4,000,000')
('4.0', '1,000,000')
('4.0', '\\varepsilon')
('4.1', '\\varepsilon')
('4.1', '\\varepsilon')
('4.2', '\\varepsilon')
('4.2', "(s,a,r,s')")
('5.0', 'Q')
('5.1', "(s,a,r,s')")
('5.2', '\\varepsilon')
('5.2', '0.05')
