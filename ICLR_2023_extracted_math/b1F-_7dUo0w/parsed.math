('0', 'd \\gg n')
('0', 'j')
('0', 'h')
('0', 'j')
('0', '\\mathbf{\\Theta}^{[1]}_j \\in \\mathbb{R}^h')
('0', 'd')
('0', '\\mathbf{\\Theta}^{[1]} \\in \\mathbb{R}^{d \\times h}')
('0', 'j')
('0', 'k')
('0', '\\mathbf{\\Theta}^{[1]}_j')
('0', '\\mathbf{\\Theta}^{[1]}_k')
('0', 'j')
('0', '\\mathcal{Q}')
('0', '\\mathbf{Q}_j \\in \\mathbb{R}^{c}')
('0', 'j')
('0', '\\mathcal{B}')
('0', '\\mathbf{\\Theta}^{[1]}_j')
('0', 'j')
('0', '\\mathbf{Q}_j')
('1', 'd')
('1', 'n')
('1', 'd \\gg n')
('1', 'd \\gg n')
('1', 'n \\gg d')
('1', 'd \\gg n')
('1', 'd \\gg n')
('1', 'd \\gg n')
('1', 'd \\gg n')
('1', '\\textsc{Plato}')
('1', 'd \\gg n')
('1', 'd \\gg n')
('2', 'n \\gg d')
('2', 'n \\gg d')
('2', 'd \\gg n')
('3', 'd \\gg n')
('3', 'G')
('3', 'd \\gg n')
('3.0', '\\mathbf{X} \\in \\mathbb{R}^{n \\times d}')
('3.0', '\\mathbf{y} \\in \\mathbb{R}^{n}')
('3.0', 'd')
('3.0', 'n')
('3.0', 'd \\gg n')
('3.0', '\\mathcal{F}')
('3.0', '\\mathbf{\\hat{y}}')
('3.0', '\\mathbf{X}')
('3.0', 'G = (V, E)')
('3.0', '|V|')
('3.0', '|E|')
('3.0', 'j')
('3.0', 'G')
('3.0', '\\forall j \\in \\{1, \\ldots, d \\}\\text{, }\\exists v \\in V \\text{ s.t. } j \\mapsto v')
('3.0', 'G')
('3.0', 'G')
('3.1', 'j')
('3.1', 'h')
('3.1', 'j')
('3.1', '\\mathbf{\\Theta}^{[1]}_j \\in \\mathbb{R}^h')
('3.1', '\\mathbf{\\Theta}^{[1]} \\in \\mathbb{R}^{d \\times h}')
('3.1', 'j')
('3.1', 'k')
('3.1', '\\mathbf{\\Theta}^{[1]}_j')
('3.1', '\\mathbf{\\Theta}^{[1]}_k')
('3.3', 'j')
('3.3', 'G')
('3.3', 'j')
('3.3', '\\mathbf{M}_j \\in \\mathbb{R}^c')
('3.3', 'j')
('3.3', 'G')
('3.3', '\\mathbf{M}_j')
('3.3', 'G')
('3.3', 'G')
('3.3', '\\textsc{Plato}')
('3.3', 'G')
('3.3', '\\label{eq:pretrain} \\mathbf{M} = \\mathcal{H}(G).')
('3.3', '\\mathbf{M} \\in \\mathbb{R}^{d \\times c}')
('3.3', '\\mathcal{H}')
('3.3', 'G')
('3.3', '\\mathbf{X}')
('3.3', '\\mathbf{y}')
('3.3', '\\mathbf{M}')
('3.3', '\\mathcal{H}')
('3.3', 'G')
('3.3', 'G')
('3.3', 'G')
('3.4', '\\mathcal{Q}')
('3.4', '\\mathbf{M}_j \\in \\mathbb{R}^c')
('3.4', '\\mathbf{Q}_j \\in \\mathbb{R}^c')
('3.4', "\\label{eq:q-message-pass}\n\\begin{equation} \\label{eq_q}\\mathbf{Q} = \\mathcal{Q}(\\mathbf{M}, G, \\mathbf{X}_i; \\mathbf{\\Pi}).\\tag{\\ref{eq:q-message-pass}}\\end{equation}\nAs input, the message-passing function considers the pre-trained feature embeddings $\\mathbf{M}$, the knowledge graph $G$, and the sample value $\\mathbf{X}_i$.\n$\\mathcal{Q}$ uses an attention mechanism which considers the sample value $\\mathbf{X}_i$.\nThe only trainable weights in $\\mathcal{Q}$ are in the attention mechanism and are $\\mathbf{\\Pi}$.\n\n\\vspace{1.7mm}\\noindent{{\\bf The message passing network $\\mathcal{Q}$.}}\nLet $ \\mathbf{Q}_j^{[r]} $ be the embedding of input feature $ j $ after round $ r \\in \\{1, ..., R\\}$ of message passing. For each input feature $ j $, $ \\mathcal{Q}$ first initializes the updated feature embedding to the pretrained feature embedding. \n\\begin{equation} \\mathbf{Q}_j^{[0]} = \\mathbf{M}_j. \\end{equation} \n$ \\mathcal{Q} $ then conducts $ R $ rounds of message passing. In each round of message passing, the feature embedding $\\mathbf{Q}_j^{[r]}$ is updated from the feature embedding of each neighbor $k$ in the prior round $\\mathbf{Q}_k^{[r-1]}$ and its own feature embedding in the prior round $\\mathbf{Q}_j^{[r-1]}$. The ``message'' being passed is the embedding of each feature from the prior round.\n\\begin{equation} \\mathbf{Q}_j^{[r]} = \\sigma \\bigg[ \\overbrace{\\beta (\\sum_{k \\in N_j} \\alpha_{ijk} \\mathbf{Q}_k^{[r-1]} )}^{\\text{Weighted messages from neighbors}} + \\underbrace{{(1 - \\beta) \\mathbf{Q}_j^{[r-1]}}}_{\\text{Weighted message from self}} \\bigg].\\end{equation}\n\n$ \\mathbf{\\sigma}$ is an optional nonlinearity. $ N_j $ are the neighbors of feature node $ j $ in $ G $. \n\nDuring message-passing, $\\mathcal{Q}$ uses two scalar values $\\beta \\in \\mathbb{R}$ and $\\alpha_{ijk} \\in \\mathbb{R}$ to control the weights of messages. First, $\\mathcal{Q}$ uses hyperparameter $\\beta \\in \\mathbb{R}$ to control the weight of the messages aggregated from the feature node's neighbors vs. from the feature node itself. Second, $\\mathcal{Q}$ calculates an attention coefficient $\\alpha_{ijk} \\in \\mathbb{R}$ to allow distinct nodes in the same neighborhood to have distinct weights. The coefficient $\\alpha_{ijk}$ specifies the weight of the message between feature $j$ and neighbor $k$ for sample $i$.\n\nAfter $ R $ rounds of message-passing, the updated feature embeddings $ \\mathbf{Q}_j$ are set.\n\\begin{equation} \\mathbf{Q}_j = \\mathbf{Q}_j^{[R]}.\\end{equation}\n\n\\vspace{1.7mm}\\noindent{{\\bf The attention coefficient.}}\n\\textsc{Plato}'s attention coefficient $\\alpha_{ijk}$ is inspired by~\\cite{velivckovic2017graph} in which node attributes are used to calculate the weight of a message between neighboring nodes. For a sample $i$ in \\textsc{Plato}, the node attributes for features $j$ and $k$ are their sample values $\\mathbf{X}_{ij} \\in \\mathbb{R}$ and $\\mathbf{X}_{ik} \\in \\mathbb{R}$. \\textsc{Plato} thus uses the sample values $\\mathbf{X}_{ij}$ and $\\mathbf{X}_{ik}$ to calculate the attention coefficient. The attention coefficient $e_{ijk}$ indicates the importance of node $j$ to node $k$ for sample $i$.\n\\begin{equation} e_{ijk} = \\mathcal{A}(\\mathbf{X}_{ij}, \\mathbf{X}_{ik}; \\mathbf{\\Pi}).\\end{equation}\n $\\mathcal{A}$ is a shallow neural network parameterized by $\\mathbf{\\Pi}$ that is shared across samples and features. The number of trainable weights in $\\mathbf{\\Pi}$ is small since the input of $\\mathcal{A}$ is $\\mathbb{R}^2$ and the output of $\\mathcal{A}$ is a scalar $\\mathbb{R}$.\n \n To make the attention coefficients comparable across different nodes, \\textsc{Plato} normalizes the attention coefficients with a softmax function across the neighbors $N_j$ of node $j$.\n\\begin{equation} \\alpha_{ijk} = \\mathrm{softmax}_k(e_{ijk}) = \\frac{\\exp{(e_{ijk})}}{\\sum_{t \\in N_j}\\exp{(e_{ijt}})} .\\end{equation}")
('3.4', '\\mathcal{Q}')
('3.4', '\\mathbf{Q} = \\mathcal{Q}(\\mathbf{M}, G, \\mathbf{X}_i; \\mathbf{\\Pi})')
('3.4', '\\mathbf{Q}_j \\in \\mathbb{R}^c')
('3.4', '\\mathbf{Q} \\in \\mathbb{R}^{d \\times c}')
('3.4', 'j')
('3.4', '\\mathcal{B}')
('3.4', '\\mathbf{\\hat{\\Theta}}^{[1]}_j  = \\mathcal{B}(\\mathbf{Q}_j | \\mathbf{X}_i ; \\mathbf{\\Phi})')
('3.4', '\\mathbf{\\hat{\\Theta}}^{[1]}_j \\in \\mathbb{R}^{h}')
('3.4', '\\mathcal{B}')
('3.4', '\\mathbf{\\hat{\\Theta}}^{[1]} \\in \\mathbb{R}^{d \\times h}')
('3.4', '\\mathbf{\\hat{\\Theta}} = \\{\\mathbf{\\hat{\\Theta}}^{[1]} | \\mathbf{X}_i\\}  \\cup \\{ \\mathbf{\\Theta}^{[2]}, \\ldots, \\mathbf{\\Theta}^{[L]} \\}')
('3.4', '\\mathcal{F}')
('3.4', '\\mathbf{\\hat{\\Theta}}')
('3.4', '\\mathbf{\\hat{y}}_i = \\mathcal{F}(\\mathbf{X}_i; \\hat{\\mathbf{\\Theta}} | \\mathbf{X}_i)')
('3.4', '\\mathbf{\\hat{y}}_i \\in \\mathbb{R}')
('3.4', '\\mathbf{\\Pi}, \\mathbf{\\Phi}')
('3.4', '\\mathbf{\\Theta}^{[2]}, \\ldots, \\mathbf{\\Theta}^{[L]}')
('3.5', '\\mathcal{F}')
('3.5', 'h')
('3.5', 'j')
('3.5', '\\mathbf{\\Theta}^{[1]}_j \\in \\mathbb{R}^h')
('3.5', '\\mathbf{\\Theta}^{[1]} \\in \\mathbb{R}^{d \\times h}')
('3.5', 'd')
('3.5', 'j')
('3.5', '\\mathbf{\\hat{\\Theta}}_j^{[1]} \\in \\mathbb{R}^h')
('3.5', '\\mathbf{Q}_j \\in \\mathbb{R}^c')
('3.5', 'j')
('3.5', '\\mathcal{F}')
('3.5', '\\label{eq:p}\\mathbf{\\hat{\\Theta}}^{[1]}_j  = \\mathcal{B}(\\mathbf{Q}_j | \\mathbf{X}_i ; \\mathbf{\\Phi}).')
('3.5', '\\mathcal{B}')
('3.5', '\\mathbf{\\Phi}')
('3.5', '\\mathbf{Q}_j')
('3.5', 'j')
('3.5', '\\mathbf{X}_i')
('3.5', '\\mathbf{\\Phi}')
('3.5', '\\mathcal{B}')
('3.5', '\\mathcal{B}')
('3.5', '\\mathbf{\\Phi}')
('3.5', 'j \\in \\{1, \\ldots, d\\}')
('3.5', '\\mathcal{B}')
('3.5', '\\mathbf{\\Phi}')
('3.5', 'd \\gg n')
('3.5', '\\mathcal{T}')
('3.5', 'h')
('3.5', '\\mathbf{\\Theta}^{[1]} \\in \\mathbb{R}^{d \\times h}')
('3.5', '\\mathcal{T}')
('3.5', 'dh')
('3.5', '\\mathcal{B}')
('3.5', '\\mathbf{\\Phi}')
('3.5', '\\mathbf{\\hat{\\Theta}}_j')
('3.5', '\\mathbf{Q}_j')
('3.5', 'j \\in \\{1, \\ldots, d\\}')
('3.5', '\\Phi')
('3.5', 'dh')
('3.5', '\\mathcal{B}')
('3.5', '\\mathbf{Q}_j \\in \\mathbb{R}^{c}')
('3.5', '\\mathbf{\\hat{\\Theta}^{[1]}} \\in \\mathbb{R}^h')
('3.5', '|\\Phi| = ch')
('3.5', '\\mathcal{B}')
('3.5', 'c')
('3.5', 'd')
('3.5', '|\\Phi| = ch \\ll dh')
('4', 'd \\gg n')
('4', 'd \\sim n')
('4', 'd \\gg n')
('4', 'd \\sim n')
('4', '\\mathbf{y}')
('4', '\\mathbf{\\hat{y}}')
('4.0', 'd \\gg n')
('4.0', '\\mathbf{\\hat{\\Theta}^{[1]}}')
('4.0', '\\mathcal{F}')
('4.0', '\\mathbf{M} \\in \\mathbb{R}^{d \\times c}')
('4.0', '\\mathbf{Q} \\in \\mathbb{R}^{d \\times c}')
('4.0', '\\mathbf{Q}')
('4.0', '\\mathbf{\\hat{\\Theta}}^{[1]}')
('4.0', '\\mathbf{\\hat{\\Theta}^{[1]}}_j = \\mathcal{B}(\\mathbf{Q}_j | \\mathbf{X}_i)')
('4.0', '\\mathbf{M}')
('4.0', '\\mathbf{Q}')
('4.0', '\\mathbf{\\hat{\\Theta}}^{[1]}')
('4.0', '\\mathbf{\\hat{\\Theta}^{[1]}}_j = \\mathcal{B}(\\mathbf{M}_j)')
('4.0', '\\mathbf{M}')
('4.0', '\\mathbf{Q}')
('4.0', '\\mathbf{Q}')
('4.0', 'G')
('4.0', 'G')
('4.0', 'G')
('4.0', '\\textsc{Plato}')
('4.0', '0.412')
('4.0', '0.583')
('4.0', '2, \\ldots, L')
('4.0', '2, ..., L')
('4.0', '0.583')
('4.0', '0.550')
('4.0', '2, \\ldots, L')
('4.0', '\\textsc{Plato}')
('4.0', 'd \\sim n')
('4.0', 'd \\sim n')
('4.0', '\\frac{d}{n} = 1.1')
('4.0', '\\frac{d}{n} = 2.0')
('4.0', 'd \\sim n')
('4.0', 'd \\gg n')
('4.0', 'd \\sim n')
('4.0', 'd \\gg n')
('4.0', 'd \\sim n')
('4.0', 'd \\sim n')
('4.0', 'd \\gg n')
('5', 'd \\gg n')
('5', '10.19\\%')
('5', 'd \\sim n')
('5', 'd \\gg n')
('6', '\\mathcal{H}')
('6', 'c')
('6', '\\mathcal{Q}')
('6', 'R')
('6', '\\beta')
('6', '\\mathcal{A}')
('6', '\\mathcal{B}')
('6', '2, \\ldots, L')
('6', '\\mathcal{F}')
('6', 'L')
('6', 'X^T')
('6', '\\lambda')
('6', '\\lambda')
('6', '\\lambda')
('8', '0.582 \\pm 0.025')
('8', '0.575 \\pm 0.011')
('8', '0.583 \\pm 0.019')
('9', 'd \\gg n')
('9', 'd \\gg n')
('10', '\\lambda')
('10', 'j')
('10', 'k')
('10', 'E')
('10', '\\mathbf{\\Theta} \\in \\mathbb{R}^d')
('10', 'd')
('10', 'D_j')
('10', 'j')
('10', '\\lambda \\sum_{j, k \\in E} (\\mathbf{\\Theta}_j - \\mathbf{\\Theta}_k)^2')
('10', '\\lambda \\sum_{j, k \\in E} (\\frac{\\mathbf{\\Theta}_j}{\\sqrt{D_j}} - \\frac{\\mathbf{\\Theta}_k}{\\sqrt{D_k}})^2')
('10', '\\sum_{j, k \\in E} |\\mathbf{\\Theta}_j - \\mathbf{\\Theta}_k|')
('12', 'd \\gg n')
('12', 'd \\sim n')
