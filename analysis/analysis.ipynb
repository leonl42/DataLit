{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import copy \n",
    "\n",
    "df = pd.read_csv(\"../feature_extraction/iclr.csv\")\n",
    "\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traom error Linear Regression: 1.7319079524980154\n",
      "Test error Linear Regression: 1.421142220880844\n",
      "Test error Avg: 1.6133419337861847\n",
      "-------------------------------------------------------------------------\n",
      "                                 Coefficients\n",
      "num_equations                        0.000256\n",
      "mean_num_new_symbols_introduced     -1.313887\n",
      "num_overall_unique_symbols           0.006394\n",
      "mean_num_unique_symbols             -0.044681\n",
      "std_of_unique_symbols                0.108664\n",
      "max_representational_complexity     -0.024518\n"
     ]
    }
   ],
   "source": [
    "x = copy.deepcopy(df)[[\"num_equations\",\"mean_num_new_symbols_introduced\",\"num_overall_unique_symbols\",\"mean_num_unique_symbols\",\"std_of_unique_symbols\",\"max_representational_complexity\"]]\n",
    "y = copy.deepcopy(df).recommendation_avg\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1,\n",
    "                                                    random_state=0\n",
    "                                                    )\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "def norm(x,y):\n",
    "    return np.mean((np.asarray(x)-np.asarray(y))**2)\n",
    "\n",
    "print(\"Train error Linear Regression: {0}\".format(norm(linreg.predict(X_train),y_train)))\n",
    "print(\"Test error Linear Regression: {0}\".format(norm(linreg.predict(X_test),y_test)))\n",
    "print(\"Test error Avg: {0}\".format(norm(np.mean(y_train),y_test)))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "cdf = pd.DataFrame(linreg.coef_, X_train.columns, columns=['Coefficients'])\n",
    "print(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: \n",
      "  Accuracy  Logistic Regression  Random guess  Predict class Withdraw  Predict class Reject  Predict class Desk Reject  Predict class Top-25%  Predict class Top-5%  Predict class Poster  Random guess Reject or Poster\n",
      "0    Train             0.442623      0.281211                0.155107              0.379571                   0.002522               0.085750              0.017654              0.359395                       0.354351\n",
      "1     Test             0.395894      0.275660                0.143695              0.392962                   0.008798               0.064516              0.046921              0.343109                       0.325513\n",
      "-------------------------------------------------------------------------\n",
      "Prediction Distribution: \n",
      "                Set  Withdraw  Reject  Desk Reject  Top-25%  Top-5%  Poster\n",
      "0         Train set       123     301            2       68      14     285\n",
      "1  Train prediction        38     449            0        0       1     305\n",
      "2          Test set        49     134            3       22      16     117\n",
      "3   Test prediction        11     195            0        0       0     135\n",
      "-------------------------------------------------------------------------\n",
      "(6, 6)\n",
      "Coefficients: \n",
      "        status  equations  mean_num_nsi  num_unique  mean_num_unique  std_unique  complexity\n",
      "0     Withdraw  -0.002079      1.287663   -0.007956         0.208178   -0.381784    0.050449\n",
      "1       Reject  -0.000065      0.720448    0.012323        -0.159076    0.012957   -0.024120\n",
      "2  Desk Reject   0.001055     -0.115294   -0.021196         0.154382    0.119225    0.104342\n",
      "3      Top-25%   0.000075     -0.052911    0.016071        -0.236892    0.220119   -0.068860\n",
      "4       Top-5%   0.001082     -0.373616   -0.015488         0.044690   -0.161481    0.005113\n",
      "5       Poster  -0.000068     -1.466290    0.016246        -0.011282    0.190964   -0.066925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miri/miniconda3/envs/DataLit/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = copy.deepcopy(df)[[\"num_equations\",\"mean_num_new_symbols_introduced\",\"num_overall_unique_symbols\",\"mean_num_unique_symbols\",\"std_of_unique_symbols\",\"max_representational_complexity\"]]\n",
    "y = copy.deepcopy(df).status\n",
    "y = np.asarray(y)\n",
    "y[y == \"Withdraw\"] = 0\n",
    "y[y == \"Reject\"] = 1\n",
    "y[y == \"Desk Reject\"] = 2\n",
    "y[y == \"Top-25%\"] = 3\n",
    "y[y == \"Top-5%\"] = 4\n",
    "y[y == \"Poster\"] = 5\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,\n",
    "                                                    random_state=0\n",
    "                                                    )\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=50000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "def acc(x,y):\n",
    "    return np.mean((np.asarray(x) == np.asarray(y)).astype(np.int32))\n",
    "\n",
    "clf = pd.DataFrame({\"Accuracy\" : [\"Train\", \"Test\"],\n",
    "                    \"Logistic Regression\" : [acc(logreg.predict(X_train),y_train),acc(logreg.predict(X_test),y_test)],\n",
    "                    \"Random guess\" : [acc(np.random.choice(y_train,size=y_train.size),y_train),acc(np.random.choice(y_train,size=y_test.size),y_test)],\n",
    "                    \"Predict class Withdraw\" : [acc(0,y_train),acc(0,y_test)],\n",
    "                    \"Predict class Reject\" : [acc(1,y_train),acc(1,y_test)],\n",
    "                    \"Predict class Desk Reject\" : [acc(2,y_train),acc(2,y_test)],\n",
    "                    \"Predict class Top-25%\" : [acc(3,y_train),acc(3,y_test)],\n",
    "                    \"Predict class Top-5%\" : [acc(4,y_train),acc(4,y_test)],\n",
    "                    \"Predict class Poster\" : [acc(5,y_train),acc(5,y_test)],\n",
    "                    \"Random guess Reject or Poster\" : [acc(np.random.choice(np.delete(y_train,(y_train == 0) | (y_train == 2) | (y_train == 3) | (y_train == 4)),size=y_train.size),y_train),acc(np.random.choice(np.delete(y_train,(y_train == 0) | (y_train == 2) | (y_train == 3) | (y_train == 4)),size=y_test.size),y_test)],})\n",
    "print(\"Accuracies: \")\n",
    "print(clf)\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "clf = pd.DataFrame({\"Set\" : [\"Train set\", \"Train prediction\", \"Test set\", \"Test prediction\"],\n",
    "                    \"Withdraw\" : [np.sum(y_train == 0),np.sum(y_train_pred == 0),np.sum(y_test == 0),np.sum(y_test_pred == 0)],\n",
    "                    \"Reject\" : [np.sum(y_train == 1),np.sum(y_train_pred == 1),np.sum(y_test == 1),np.sum(y_test_pred == 1)],\n",
    "                    \"Desk Reject\" : [np.sum(y_train == 2),np.sum(y_train_pred == 2),np.sum(y_test == 2),np.sum(y_test_pred == 2)],\n",
    "                    \"Top-25%\" : [np.sum(y_train == 3),np.sum(y_train_pred == 3),np.sum(y_test == 3),np.sum(y_test_pred == 3)],\n",
    "                    \"Top-5%\" : [np.sum(y_train == 4),np.sum(y_train_pred == 4),np.sum(y_test == 4),np.sum(y_test_pred == 4)],\n",
    "                    \"Poster\" : [np.sum(y_train == 5),np.sum(y_train_pred == 5),np.sum(y_test == 5),np.sum(y_test_pred == 5)]})\n",
    "print(\"Prediction Distribution: \")\n",
    "print(clf)\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(logreg.coef_.shape)\n",
    "print(\"Coefficients: \")\n",
    "clf = pd.DataFrame(columns=[\"equations\",\"mean_num_nsi\",\"num_unique\",\"mean_num_unique\",\"std_unique\",\"complexity\"],data=logreg.coef_)\n",
    "clf[\"status\"] = [\"Withdraw\",\"Reject\",\"Desk Reject\",\"Top-25%\",\"Top-5%\",\"Poster\"]\n",
    "clf = clf[[\"status\",\"equations\",\"mean_num_nsi\",\"num_unique\",\"mean_num_unique\",\"std_unique\",\"complexity\"]]\n",
    "pd.set_option('display.width',1000)\n",
    "print(clf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataLit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
