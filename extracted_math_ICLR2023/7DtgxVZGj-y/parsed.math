\mathcal{O}
\mathcal{A}
\mathcal{T}
a_{t}\sim p(a_{t}|o_{\leq t},a_{<t})
o_{t},r_{t}\sim p(o_{t},r_{t}|o_{<t},a_{<t})
s_{t}\sim p(s_{t}|s_{t-1},a_{t-1},o_{t})
s_{t}\sim q(s_{t}|s_{t-1},a_{t-1})
r_{t}\sim q(r_{t}|s_{t})
E_{p}(\sum_{t=1}^{T}r_{t})
P(a|c=invariant\_encoder(o))
P(a|(c,s)=encoder(o))
o_{t}
\tilde{s_{t}}=invariant\_encoder(o_{t})
s_{t}\sim p(s_{t}|s_{t-1},a_{t-1},\tilde{s_{t}})
\tilde{s_{t}}
q
K=\{k_{0},k_{1},...k_{2B}\}
\{k_{+}\}
\{k_{-}\}
q
K
k_{+}
{k_{-}}
\ell^{q}_{t}=\log\frac{\exp(q^{T}Wk_{+})}{\exp(q^{T}Wk_{+})+\sum_{i=0}^{2(B-1)%
}\exp(q^{T}Wk_{i})}
2B
k_{+}
B
2B
\displaystyle\begin{aligned} &\text{Invariant causal model:}&&p_{\theta}(%
\tilde{s_{t}}|o_{t})\\
\end{aligned}
\displaystyle\begin{aligned} &\text{Representation model:}&&p_{\theta}(s_{t}|s%
_{t-1},a_{t-1},\tilde{s_{t}})\\
&\text{Depth prediction model:}&&q_{\theta}(o^{d}_{t}|s_{t})\\
&\text{Reward model:}&&q_{\theta}(r_{t}|s_{t})\\
&\text{Predictive memory model:}&&q_{\theta}(s_{t}|s_{t-1},a_{t-1}).\end{aligned}
\mathcal{L}_{WM}=E_{p}\left(\sum_{t}\left(\ell^{q}_{t}+\ln q(o^{d}_{t}|s_{t})+%
\ln q(r_{t}|s_{t})-\beta\ell^{KL}_{t}\right)\right)
\ell^{KL}_{t}=KL(p(s_{t}|s_{t-1},a_{t-1},\tilde{s_{t}})||q(s_{t}|s_{t-1},a_{t-%
1}))
H
\gamma
\displaystyle\begin{aligned} &\text{Action model:}&&q_{\phi}(a_{t}|s_{t})\\
&\text{Value model:}&&E_{q(\cdot|s_{\tau})}{\textstyle\sum_{\tau=t}^{t+H}%
\gamma^{\tau-t}r_{\tau}}.\end{aligned}
K
3e^{5}
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
\pm
3\cdot 10^{5}
o
\times
B
L
\beta
3\cdot 10^{-4}
H
1\cdot 10^{-4}
1\cdot 10^{-4}
100
\epsilon
10^{-5}
