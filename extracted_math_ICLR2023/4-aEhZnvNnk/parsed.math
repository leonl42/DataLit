{L_{0},L_{1},...,L_{m}}
W_{j}^{\prime}
W_{j}
L_{j}
E=\frac{E_{c}}{|E_{c}|}\;,\;\;\;E_{c}=\mathbin{\|}_{j=0}^{m}{(W_{j}^{\prime}-W%
_{j})/|W_{j}^{\prime}-W_{j}|}
\mathbin{\|}
\mathbin{\|}_{j=1}^{m}{a_{j}}
a_{0}
a_{1}
a_{m}
768
768*3=2304
L_{0}=cls.predictions.transform.LayerNorm.weight
L_{1}=cls.predictions.transform.LayerNorm.bias
L_{2}=cls.predictions.transform.dense.bias
P
(k,m)
P=k+m
k
m
k+m-1
[(k_{1},m_{1}),...,(k_{n},m_{n})]
[(2,1),(1,1),(1,2),(1,3)]
0.05,0.10,0.15,...,0.95
0.1,0.3,0.5,0.7,0.9
B
C
A
B
A
B
A
C
A
sim(A,B)>sim(A,C)\iff(E_{A}*E_{B})>(E_{A}*E_{C})
sim
sim(A,B)>sim(A,C)
(A,B,C)
A
B
C
(E_{A}*E_{B})>(E_{A}*E_{C})
A
B
C
wrong=44
10
ABC
ABC
total
wrong
error=wrong/total
I
Neural
AB
AC
ABC
ABC
total
wrong
error=wrong/total
I
Neural
AB
AC
I
ABC
ABC
I
[(2,1),(1,1),(1,2),(1,3)]
(A,B,C)
I
I=\frac{T_{emb}\bigcap{T_{neural}}}{min(|T_{emb}|,|T_{neural}|)}
I
T_{emb}
T_{neural}
1
(E_{A}*E_{B})
(E_{A}*E_{C})
I
50\%
sim(A,B)>sim(C,D)\iff(E_{A}*E_{B})>(E_{C}*E_{D})
total
wrong
error=wrong/total
total
wrong
error=wrong/total
I
M
\{W_{j}\}
\{L_{j}\}
M
T
T=T_{0}+T_{1}+...
T_{i}
M
\{L_{j}\}
\{W_{j}\}
inputs\_and\_labels
T_{i}
inputs\_and\_labels
M
inputs\_and\_labels
\{W^{\prime}_{j}\}
\{L_{j}\}
dW_{j}=W_{j}^{\prime}-W_{j}
E_{c}=\mathbin{\|}_{j=1}^{m}{dW_{j}^{\prime}/|dW_{j}|}
E={E_{c}}/{|E_{c}|}
E
T
\{L_{j}\}
\mathbin{\|}
\mathbin{\|}_{j=1}^{m}{a_{j}}
a_{0}
a_{1}
a_{m}
T
\{L_{j}\}
\mathbin{\|}
\mathbin{\|}_{j=1}^{m}{a_{j}}
a_{0}
a_{1}
a_{m}
[(2,1),(1,1),(1,2),(1,3)]
[(2,1),(1,1),(1,2),(1,3)]
L_{0}=cls.predictions.transform.LayerNorm.weight
L_{1}=cls.predictions.transform.LayerNorm.bias
L_{2}=cls.predictions.transform.dense.bias
L_{0}=bert.encoder.layer.11.output.LayerNorm.weight
L_{1}=bert.encoder.layer.11.output.LayerNorm.bias
L_{2}=bert.encoder.layer.11.output.dense.bias
[(2,1),(1,1),(1,2),(1,3)]
[(k_{1},m_{1}),...,(k_{n},m_{n})]
T=[t_{0},t_{1},...]
inputs\_and\_labels
(k_{i},m_{i})
P=k_{i}+m_{i}
S_{max}=\min(P,len(T))
s
S_{max}
I
T
L
len(L)=len(T)
j
len(T)
R=(j-s)\%P
R>=k_{i}
L[j]=I[j]
I[j]=mask
(I,L)
inputs\_and\_labels
inputs\_and\_labels
len(T)
len(T)
L_{0}=cls.predictions.transform.LayerNorm.weight
L_{1}=cls.predictions.transform.LayerNorm.bias
L_{2}=cls.predictions.transform.dense.bias
[(2,1),(1,1),(1,2),(1,3)]
0.1,0.3,0.5,0.7,0.9
5\times 5=25
25\times 3=75
75
0.05,0.10,0.15,...,0.95
0.05
0.05,0.10,0.15,...,0.95
L_{0}=bert.encoder.layer.11.output.LayerNorm.weight
L_{1}=bert.encoder.layer.11.output.LayerNorm.bias
L_{2}=bert.encoder.layer.11.output.dense.bias
I
I
