<
>
<
>
{\bm{x}}
y
g
g({\bm{x}})=\mathbb{E}_{\bm{\eta}}f({\bm{x}}+\bm{\eta})
\bm{\eta}\sim{\mathcal{N}}(0,\sigma^{2}{\bm{I}})
f
g
f
{\bm{x}}+\bm{\eta}
g
f
g
71.1\%
\ell_{2}
r=0.5
54.3\%
r=1.0
\ell_{2}
r
\sigma
\ell_{2}
\sigma
\ell_{2}
\ell_{2}
\ell_{2}
\ell_{p}
{\bm{x}}\in\mathbb{R}^{d}
y\in\mathcal{Y}=\{1,\dots,C\}
g:\mathbb{R}^{d}\rightarrow\mathcal{Y}
{\bm{x}}
y
{\bm{x}}
{\bm{x}}
g({\bm{x}})
g
g({\bm{x}})=\arg\max_{c\in\mathcal{Y}}~{}\mathrm{P}_{\bm{\eta}}[f({\bm{x}}+\bm%
{\eta})=c],~{}\text{where}~{}\bm{\eta}\sim\mathcal{N}(\bm{0},\sigma^{2}{\bm{I}%
}_{d}).
f
\bm{\eta}
\sigma
g({\bm{x}})
f
{\mathcal{N}}({\bm{x}},\sigma^{2}{\bm{I}}_{d})
{\bm{x}}
g
f
g
g
{\bm{x}}
\mathrm{P}_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y]\geq\max_{y^{\prime}\neq y}%
\mathrm{P}_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y^{\prime}]
{\bm{x}}^{\prime}
||{\bm{x}}^{\prime}-{\bm{x}}||_{2}\leq R
g({\bm{x}})=g({\bm{x}}^{\prime})
\displaystyle R=\frac{\sigma}{2}[\Phi^{-1}(P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})%
=y])-\Phi^{-1}(\max_{y^{\prime}\neq y}P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y^{%
\prime}])].
\displaystyle R
\displaystyle=\frac{\sigma}{2}[\Phi^{-1}(P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y%
])-\Phi^{-1}(\max_{y^{\prime}\neq y}P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y^{%
\prime}])].
\Phi
f
\theta_{\text{denoiser}}
\theta_{\text{encoder}}
\theta_{\text{output}}
{\bm{x}}
f
\displaystyle\hat{{\bm{x}}}=\text{Denoise}({\bm{x}}+\bm{\eta};\theta_{\text{%
denoiser}})
\displaystyle\hat{{\bm{x}}}
\displaystyle=
\displaystyle\text{Denoise}({\bm{x}}+\bm{\eta};\theta_{\text{denoiser}})
\displaystyle{\bm{h}}=\text{Encode}(\hat{{\bm{x}}};\theta_{\text{encoder}})
\displaystyle{\bm{h}}
\displaystyle=
\displaystyle\text{Encode}(\hat{{\bm{x}}};\theta_{\text{encoder}})
\displaystyle y=\text{Predict}({\bm{h}};\theta_{\text{output}})
\displaystyle y
\displaystyle=
\displaystyle\text{Predict}({\bm{h}};\theta_{\text{output}})
f
\theta_{\text{denoiser}}
{\bm{x}}+\bm{\eta}
\hat{{\bm{x}}}
\hat{{\bm{x}}}
{\bm{h}}
\theta_{\text{encoder}}
\theta_{\text{output}}
\theta_{\text{denoiser}}
\theta_{\text{encoder}}
\theta_{\text{denoiser}}
\theta_{\text{encoder}}
{\bm{h}}
\bm{\eta}
g
{\bm{h}}
{\bm{h}}
{\bm{x}}
\text{Mask}(x)
\text{Mask}({\bm{x}}+\bm{\eta})
\displaystyle{\bm{x}}\rightarrow{\bm{x}}+\bm{\eta}\rightarrow\text{Mask}({\bm{%
x}}+\bm{\eta})\xrightarrow{\text{Encoder}}{\bm{h}}\xrightarrow{\text{Decoder}}%
\hat{{\bm{x}}}.
\displaystyle{\bm{x}}\rightarrow{\bm{x}}+\bm{\eta}\rightarrow\text{Mask}({\bm{%
x}}+\bm{\eta})\xrightarrow{\text{Encoder}}{\bm{h}}\xrightarrow{\text{Decoder}}%
\hat{{\bm{x}}}.
{\bm{h}}
{\bm{h}}
\displaystyle{\bm{h}}=\text{Encode}({\bm{x}}+\bm{\eta};\theta_{\text{encoder}})
\displaystyle{\bm{h}}
\displaystyle=
\displaystyle\text{Encode}({\bm{x}}+\bm{\eta};\theta_{\text{encoder}})
\displaystyle y=\text{Predict}({\bm{h}};\theta_{\text{output}})
\displaystyle y
\displaystyle=
\displaystyle\text{Predict}({\bm{h}};\theta_{\text{output}})
f({\bm{x}};\theta_{\text{encoder}},\theta_{\text{output}})=\text{Predict}(%
\text{Encode}({\bm{x}};\theta_{\text{encoder}});\theta_{\text{output}})
F({\bm{x}};\theta_{\text{encoder}},\theta_{\text{output}})
f
g
\theta_{\text{encoder}}
\theta_{\text{output}}
\theta_{\text{encoder}}
\theta_{\text{encoder}}
\theta_{\text{output}}
\displaystyle L({\bm{x}},y;\theta_{\text{encoder}},\theta_{\text{output}})=%
\mathbb{E}_{\bm{\eta}}[\text{CrossEntropy}(F({\bm{x}}+\bm{\eta};\theta_{\text{%
encoder}},\theta_{\text{output}}),y)]+\lambda\cdot\mathbb{E}_{\bm{\eta}}[D_{%
\mathrm{KL}}(\hat{F}({\bm{x}};\theta_{\text{encoder}},\theta_{\text{output}})%
\|F({\bm{x}}+\bm{\eta};\theta_{\text{encoder}},\theta_{\text{output}}))]+\mu%
\cdot H(\hat{F}({\bm{x}};\theta_{\text{encoder}},\theta_{\text{output}}))
\displaystyle L({\bm{x}},y;\theta_{\text{encoder}},\theta_{\text{output}})
\displaystyle=
\displaystyle\mathbb{E}_{\bm{\eta}}[\text{CrossEntropy}(F({\bm{x}}+\bm{\eta};%
\theta_{\text{encoder}},\theta_{\text{output}}),y)]
\displaystyle+
\displaystyle\lambda\cdot\mathbb{E}_{\bm{\eta}}[D_{\mathrm{KL}}(\hat{F}({\bm{x%
}};\theta_{\text{encoder}},\theta_{\text{output}})\|F({\bm{x}}+\bm{\eta};%
\theta_{\text{encoder}},\theta_{\text{output}}))]
\displaystyle+
\displaystyle\mu\cdot H(\hat{F}({\bm{x}};\theta_{\text{encoder}},\theta_{\text%
{output}}))
\hat{F}({\bm{x}};\theta_{\text{encoder}},\theta_{\text{output}}):=\mathbb{E}_{%
\bm{\eta}\sim\mathcal{N}(\bm{0},\sigma^{2}{\bm{I}}_{d})}[F({\bm{x}}+\bm{\eta};%
\theta_{\text{encoder}},\theta_{\text{output}})]
\lambda,\mu>0
D_{\mathrm{KL}}(\cdot||\cdot)
H(\cdot)
F({\bm{x}}+\bm{\eta};\theta_{\text{encoder}},\theta_{\text{output}})
\bm{\eta}
224\times 224
16\times 16
\sigma
\beta_{1},\beta_{2}=0.9,0.95
1.5\times 10^{-4}
0.05
\sigma=0.25
\sigma=0.25
\beta_{1},\beta_{2}=0.9,0.999
5\times 10^{-4}
1\times 10^{-3}
\sigma\in\{0.25,0.5,1.0\}
\lambda=2.0
\mu=0.5
\sigma\in\{0.25,0.5\}
\lambda=2.0
\mu=0.1
\sigma=1.0
r
10^{5}
n=10,000,n_{0}=100
\alpha=0.001
r
r\geq 1.0
r
\sigma
r
r=1.5
53.7\%
15.3\%
12.0\%
r=2.0
\sigma
r
\ell_{2}
r
\sigma
r
r
224\times 224
5\times 10^{-5}
\ell_{2}
r
\sigma
\ell_{2}
\sigma
\ell_{2}
n=100,000
12.0\%
r=0.25
9.0\%
r=0.5
\ell_{2}
r
\sigma
(.)
(.)
\sigma=0.25
45.3\%
r=0.5
32.0
\sigma=0.25
\sigma=0.5,1.0
\ell_{2}
r
\sigma
(.)
(.)
\ell_{2}
r
\sigma
\ell_{2}
\geq
\beta_{1}
\beta_{2}
\sigma=0.25
\beta_{1}
\beta_{2}
\sigma\in\{0.25,0.5,1.0\}
\lambda=2,\eta=0.5~{}(\sigma\in\{0.25,0.5\})
\lambda=2,\eta=0.1~{}(\sigma=1.0)
R
{\bm{x}}
R=\frac{\sigma}{2}[\Phi^{-1}(P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y])-\Phi^{-1}%
(\max_{y^{\prime}\neq y}P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y^{\prime}])].
1-P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y]\geq\max_{y^{\prime}\neq y}P_{\bm{\eta%
}}[f({\bm{x}}+\bm{\eta})=y^{\prime}]
R\geq\frac{\sigma}{2}[\Phi^{-1}(P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y])-\Phi^{%
-1}(1-P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y])]\\
=\sigma\cdot\Phi^{-1}(P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y])=:\underline{R}.
{\bm{x}}
n_{0}=100
{\mathcal{N}}({\bm{x}},\sigma^{2}{\bm{I}}_{d})
n=10,000
P_{\bm{\eta}}[f({\bm{x}}+\bm{\eta})=y]
r
\ell_{2}
r
\sigma
(.)
(.)
n=10,000
1000
\sigma
\sigma\in[0,0.75]
r=1.0
\ell_{2}
r
\sigma
\sigma
\sigma
\sigma
